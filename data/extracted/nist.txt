NIST Special Publication 800-53 
Revision 5 
 
 
Security and Privacy Controls for Information 
Systems and Organizations 
 
 
 
 
JOINT TASK FORCE 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
This publication is available free of charge from: 
https://doi.org/10.6028/NIST.SP.800-53r5   
 
 
 
 
 
 
 
Note that NIST Special Publication (SP) 800-53, Revision 5 contains additional background, scoping, and 
implementation guidance in addition to the controls and control enhancements.  
This PDF is produced from OSCAL Source data and represents a derivative format of controls defined in NIST SP 
800-53, Revision 5, Security and Privacy Controls for Information Systems and Organization. This version 
contains only the controls and control enhancements.  
If there are any discrepancies noted in the content between this NIST SP 800-53, Revision 5 derivative data 
format and the latest published NIST SP 800-53, Revision 5 (normative), please contact sec-cert@nist.gov and 
refer to the official published documents.   
 NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
Table of Contents
Family: Access Control (AC)
AC-1 Policy and Procedures...........................................................................................................................1
AC-2 Account Management...........................................................................................................................1
(1) Automated System Account Management (2) Automated Temporary and Emergency Account Management (3)
Disable Accounts (4) Automated Audit Acons (5) Inacvity Logout (6) Dynamic Privilege Management (7) Privileged
User Accounts (8) Dynamic Account Management (9) Restricons on Use of Shared and Group Accounts (10) Shared
and Group Account Credenal Change (11) Usage Condions (12) Account Monitoring for Atypical Usage (13) Disable
Accounts for High-risk Individuals
AC-3 Access Enforcement.............................................................................................................................. 6
(1) Restricted Access to Privileged Funcons (2) Dual Authorizaon (3) Mandatory Access Control (4) Discreonary
Access Control (5) Security-relevant Informaon (6) Protecon of User and System Informaon (7) Role-based Access
Control (8) Revocaon of Access Authorizaons (9) Controlled Release (10) Audited Override of Access Control
Mechanisms (11) Restrict Access to Speciﬁc Informaon Types (12) Assert and Enforce Applicaon Access (13)
Aribute-based Access Control (14) Individual Access (15) Discreonary and Mandatory Access Control
AC-4 Informaon Flow Enforcement.......................................................................................................... 12
(1) Object Security and Privacy Aributes (2) Processing Domains (3) Dynamic Informaon Flow Control (4) Flow
Control of Encrypted Informaon (5) Embedded Data Types (6) Metadata (7) One-way Flow Mechanisms (8) Security
and Privacy Policy Filters (9) Human Reviews (10) Enable and Disable Security or Privacy Policy Filters (11) Conﬁguraon
of Security or Privacy Policy Filters (12) Data Type Idenﬁers (13) Decomposion into Policy-relevant Subcomponents
(14) Security or Privacy Policy Filter Constraints (15) Detecon of Unsanconed Informaon (16) Informaon Transfers
on Interconnected Systems (17) Domain Authencaon (18) Security Aribute Binding (19) Validaon of Metadata
(20) Approved Soluons (21) Physical or Logical Separaon of Informaon Flows (22) Access Only (23) Modify Non-
releasable Informaon (24) Internal Normalized Format (25) Data Sanizaon (26) Audit Filtering Acons (27)
Redundant/Independent Filtering Mechanisms (28) Linear Filter Pipelines (29) Filter Orchestraon Engines (30)
Filter Mechanisms Using Mulple Processes (31) Failed Content Transfer Prevenon (32) Process Requirements for
Informaon Transfer
AC-5 Separaon of Dues........................................................................................................................... 21
AC-6 Least Privilege..................................................................................................................................... 21
(1) Authorize Access to Security Funcons (2) Non-privileged Access for Nonsecurity Funcons (3) Network Access
to Privileged Commands (4) Separate Processing Domains (5) Privileged Accounts (6) Privileged Access by Non-
organizaonal Users (7) Review of User Privileges (8) Privilege Levels for Code Execuon (9) Log Use of Privileged
Funcons (10) Prohibit Non-privileged Users from Execung Privileged Funcons
AC-7 Unsuccessful Logon Aempts.............................................................................................................24
(1) Automac Account Lock (2) Purge or Wipe Mobile Device (3) Biometric Aempt Liming (4) Use of Alternate
Authencaon Factor
AC-8 System Use Noﬁcaon......................................................................................................................25
AC-9 Previous Logon Noﬁcaon................................................................................................................26
(1) Unsuccessful Logons (2) Successful and Unsuccessful Logons (3) Noﬁcaon of Account Changes (4) Addional
Logon Informaon
AC-10 Concurrent Session Control.............................................................................................................. 27
AC-11 Device Lock........................................................................................................................................27
(1) Paern-hiding Displays
AC-12 Session Terminaon.......................................................................................................................... 28
(1) User-iniated Logouts (2) Terminaon Message (3) Timeout Warning Message
AC-13 Supervision and Review — Access Control......................................................................................29
This document is produced from OSCAL source data
PAGE iNIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
AC-14 Permied Acons Without Idenﬁcaon or Authencaon.......................................................... 29
(1) Necessary Uses
AC-15 Automated Marking..........................................................................................................................30
AC-16 Security and Privacy Aributes........................................................................................................ 30
(1) Dynamic Aribute Associaon (2) Aribute Value Changes by Authorized Individuals (3) Maintenance of Aribute
Associaons by System (4) Associaon of Aributes by Authorized Individuals (5) Aribute Displays on Objects to Be
Output (6) Maintenance of Aribute Associaon (7) Consistent Aribute Interpretaon (8) Associaon Techniques
and Technologies (9) Aribute Reassignment — Regrading Mechanisms (10) Aribute Conﬁguraon by Authorized
Individuals
AC-17 Remote Access.................................................................................................................................. 33
(1) Monitoring and Control (2) Protecon of Conﬁdenality and Integrity Using Encrypon (3) Managed Access Control
Points (4) Privileged Commands and Access (5) Monitoring for Unauthorized Connecons (6) Protecon of Mechanism
Informaon (7) Addional Protecon for Security Funcon Access (8) Disable Nonsecure Network Protocols (9)
Disconnect or Disable Access (10) Authencate Remote Commands
AC-18 Wireless Access................................................................................................................................. 36
(1) Authencaon and Encrypon (2) Monitoring Unauthorized Connecons (3) Disable Wireless Networking (4)
Restrict Conﬁguraons by Users (5) Antennas and Transmission Power Levels
AC-19 Access Control for Mobile Devices...................................................................................................37
(1) Use of Writable and Portable Storage Devices (2) Use of Personally Owned Portable Storage Devices (3) Use of
Portable Storage Devices with No Idenﬁable Owner (4) Restricons for Classiﬁed Informaon (5) Full Device or
Container-based Encrypon
AC-20 Use of External Systems................................................................................................................... 39
(1) Limits on Authorized Use (2) Portable Storage Devices — Restricted Use (3) Non-organizaonally Owned Systems —
Restricted Use (4) Network Accessible Storage Devices — Prohibited Use (5) Portable Storage Devices — Prohibited Use
AC-21 Informaon Sharing.......................................................................................................................... 41
(1) Automated Decision Support (2) Informaon Search and Retrieval
AC-22 Publicly Accessible Content.............................................................................................................. 42
AC-23 Data Mining Protecon.................................................................................................................... 42
AC-24 Access Control Decisions.................................................................................................................. 43
(1) Transmit Access Authorizaon Informaon (2) No User or Process Identy
AC-25 Reference Monitor............................................................................................................................ 44
Family: Awareness and Training (AT)
AT-1 Policy and Procedures......................................................................................................................... 45
AT-2 Literacy Training and Awareness.........................................................................................................46
(1) Praccal Exercises (2) Insider Threat (3) Social Engineering and Mining (4) Suspicious Communicaons and
Anomalous System Behavior (5) Advanced Persistent Threat (6) Cyber Threat Environment
AT-3 Role-based Training............................................................................................................................. 48
(1) Environmental Controls (2) Physical Security Controls (3) Praccal Exercises (4) Suspicious Communicaons and
Anomalous System Behavior (5) Processing Personally Idenﬁable Informaon
AT-4 Training Records...................................................................................................................................50
AT-5 Contacts with Security Groups and Associaons............................................................................... 50
AT-6 Training Feedback................................................................................................................................ 50
This document is produced from OSCAL source data
PAGE iiNIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
Family: Audit and Accountability (AU)
AU-1 Policy and Procedures........................................................................................................................ 51
AU-2 Event Logging......................................................................................................................................51
(1) Compilaon of Audit Records from Mulple Sources (2) Selecon of Audit Events by Component (3) Reviews and
Updates (4) Privileged Funcons
AU-3 Content of Audit Records...................................................................................................................53
(1) Addional Audit Informaon (2) Centralized Management of Planned Audit Record Content (3) Limit Personally
Idenﬁable Informaon Elements
AU-4 Audit Log Storage Capacity................................................................................................................ 54
(1) Transfer to Alternate Storage
AU-5 Response to Audit Logging Process Failures......................................................................................54
(1) Storage Capacity Warning (2) Real-me Alerts (3) Conﬁgurable Traﬃc Volume Thresholds (4) Shutdown on Failure
(5) Alternate Audit Logging Capability
AU-6 Audit Record Review, Analysis, and Reporng..................................................................................56
(1) Automated Process Integraon (2) Automated Security Alerts (3) Correlate Audit Record Repositories (4) Central
Review and Analysis (5) Integrated Analysis of Audit Records (6) Correlaon with Physical Monitoring (7) Permied
Acons (8) Full Text Analysis of Privileged Commands (9) Correlaon with Informaon from Nontechnical Sources (10)
Audit Level Adjustment
AU-7 Audit Record Reducon and Report Generaon...............................................................................59
(1) Automac Processing (2) Automac Sort and Search
AU-8 Time Stamps....................................................................................................................................... 60
(1) Synchronizaon with Authoritave Time Source (2) Secondary Authoritave Time Source
AU-9 Protecon of Audit Informaon........................................................................................................ 60
(1) Hardware Write-once Media (2) Store on Separate Physical Systems or Components (3) Cryptographic Protecon (4)
Access by Subset of Privileged Users (5) Dual Authorizaon (6) Read-only Access (7) Store on Component with Diﬀerent
Operang System
AU-10 Non-repudiaon................................................................................................................................62
(1) Associaon of Idenes (2) Validate Binding of Informaon Producer Identy (3) Chain of Custody (4) Validate
Binding of Informaon Reviewer Identy (5) Digital Signatures
AU-11 Audit Record Retenon....................................................................................................................64
(1) Long-term Retrieval Capability
AU-12 Audit Record Generaon..................................................................................................................64
(1) System-wide and Time-correlated Audit Trail (2) Standardized Formats (3) Changes by Authorized Individuals (4)
Query Parameter Audits of Personally Idenﬁable Informaon
AU-13 Monitoring for Informaon Disclosure............................................................................................65
(1) Use of Automated Tools (2) Review of Monitored Sites (3) Unauthorized Replicaon of Informaon
AU-14 Session Audit.................................................................................................................................... 66
(1) System Start-up (2) Capture and Record Content (3) Remote Viewing and Listening
AU-15 Alternate Audit Logging Capability.................................................................................................. 67
AU-16 Cross-organizaonal Audit Logging..................................................................................................67
(1) Identy Preservaon (2) Sharing of Audit Informaon (3) Disassociability
Family: Assessment, Authorizaon, and Monitoring (CA)
CA-1 Policy and Procedures.........................................................................................................................69
This document is produced from OSCAL source data
PAGE iiiNIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
CA-2 Control Assessments...........................................................................................................................70
(1) Independent Assessors (2) Specialized Assessments (3) Leveraging Results from External Organizaons
CA-3 Informaon Exchange......................................................................................................................... 72
(1) Unclassiﬁed Naonal Security System Connecons (2) Classiﬁed Naonal Security System Connecons (3)
Unclassiﬁed Non-naonal Security System Connecons (4) Connecons to Public Networks (5) Restricons on External
System Connecons (6) Transfer Authorizaons (7) Transive Informaon Exchanges
CA-4 Security Cerﬁcaon...........................................................................................................................74
CA-5 Plan of Acon and Milestones........................................................................................................... 74
(1) Automaon Support for Accuracy and Currency
CA-6 Authorizaon.......................................................................................................................................75
(1) Joint Authorizaon — Intra-organizaon (2) Joint Authorizaon — Inter-organizaon
CA-7 Connuous Monitoring.......................................................................................................................76
(1) Independent Assessment (2) Types of Assessments (3) Trend Analyses (4) Risk Monitoring (5) Consistency Analysis
(6) Automaon Support for Monitoring
CA-8 Penetraon Tesng............................................................................................................................. 79
(1) Independent Penetraon Tesng Agent or Team (2) Red Team Exercises (3) Facility Penetraon Tesng
CA-9 Internal System Connecons.............................................................................................................. 80
(1) Compliance Checks
Family: Conﬁguraon Management (CM)
CM-1 Policy and Procedures....................................................................................................................... 82
CM-2 Baseline Conﬁguraon.......................................................................................................................82
(1) Reviews and Updates (2) Automaon Support for Accuracy and Currency (3) Retenon of Previous Conﬁguraons
(4) Unauthorized Soware (5) Authorized Soware (6) Development and Test Environments (7) Conﬁgure Systems and
Components for High-risk Areas
CM-3 Conﬁguraon Change Control........................................................................................................... 84
(1) Automated Documentaon, Noﬁcaon, and Prohibion of Changes (2) Tesng, Validaon, and Documentaon
of Changes (3) Automated Change Implementaon (4) Security and Privacy Representaves (5) Automated Security
Response (6) Cryptography Management (7) Review System Changes (8) Prevent or Restrict Conﬁguraon Changes
CM-4 Impact Analyses................................................................................................................................. 87
(1) Separate Test Environments (2) Veriﬁcaon of Controls
CM-5 Access Restricons for Change..........................................................................................................88
(1) Automated Access Enforcement and Audit Records (2) Review System Changes (3) Signed Components (4)
Dual Authorizaon (5) Privilege Limitaon for Producon and Operaon (6) Limit Library Privileges (7) Automac
Implementaon of Security Safeguards
CM-6 Conﬁguraon Sengs........................................................................................................................90
(1) Automated Management, Applicaon, and Veriﬁcaon (2) Respond to Unauthorized Changes (3) Unauthorized
Change Detecon (4) Conformance Demonstraon
CM-7 Least Funconality............................................................................................................................. 91
(1) Periodic Review (2) Prevent Program Execuon (3) Registraon Compliance (4) Unauthorized Soware — Deny-by-
excepon (5) Authorized Soware — Allow-by-excepon (6) Conﬁned Environments with Limited Privileges (7) Code
Execuon in Protected Environments (8) Binary or Machine Executable Code (9) Prohibing The Use of Unauthorized
Hardware
CM-8 System Component Inventory........................................................................................................... 95
(1) Updates During Installaon and Removal (2) Automated Maintenance (3) Automated Unauthorized Component
Detecon (4) Accountability Informaon (5) No Duplicate Accounng of Components (6) Assessed Conﬁguraons and
This document is produced from OSCAL source data
PAGE ivNIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
Approved Deviaons (7) Centralized Repository (8) Automated Locaon Tracking (9) Assignment of Components to
Systems
CM-9 Conﬁguraon Management Plan...................................................................................................... 98
(1) Assignment of Responsibility
CM-10 Soware Usage Restricons............................................................................................................99
(1) Open-source Soware
CM-11 User-installed Soware....................................................................................................................99
(1) Alerts for Unauthorized Installaons (2) Soware Installaon with Privileged Status (3) Automated Enforcement and
Monitoring
CM-12 Informaon Locaon..................................................................................................................... 100
(1) Automated Tools to Support Informaon Locaon
CM-13 Data Acon Mapping.....................................................................................................................101
CM-14 Signed Components....................................................................................................................... 101
Family: Conngency Planning (CP)
CP-1 Policy and Procedures.......................................................................................................................102
CP-2 Conngency Plan...............................................................................................................................103
(1) Coordinate with Related Plans (2) Capacity Planning (3) Resume Mission and Business Funcons (4) Resume All
Mission and Business Funcons (5) Connue Mission and Business Funcons (6) Alternate Processing and Storage Sites
(7) Coordinate with External Service Providers (8) Idenfy Crical Assets
CP-3 Conngency Training......................................................................................................................... 106
(1) Simulated Events (2) Mechanisms Used in Training Environments
CP-4 Conngency Plan Tesng.................................................................................................................. 107
(1) Coordinate with Related Plans (2) Alternate Processing Site (3) Automated Tesng (4) Full Recovery and
Reconstuon (5) Self-challenge
CP-5 Conngency Plan Update..................................................................................................................108
CP-6 Alternate Storage Site....................................................................................................................... 108
(1) Separaon from Primary Site (2) Recovery Time and Recovery Point Objecves (3) Accessibility
CP-7 Alternate Processing Site.................................................................................................................. 109
(1) Separaon from Primary Site (2) Accessibility (3) Priority of Service (4) Preparaon for Use (5) Equivalent
Informaon Security Safeguards (6) Inability to Return to Primary Site
CP-8 Telecommunicaons Services........................................................................................................... 111
(1) Priority of Service Provisions (2) Single Points of Failure (3) Separaon of Primary and Alternate Providers (4)
Provider Conngency Plan (5) Alternate Telecommunicaon Service Tesng
CP-9 System Backup...................................................................................................................................113
(1) Tesng for Reliability and Integrity (2) Test Restoraon Using Sampling (3) Separate Storage for Crical Informaon
(4) Protecon from Unauthorized Modiﬁcaon (5) Transfer to Alternate Storage Site (6) Redundant Secondary System
(7) Dual Authorizaon for Deleon or Destrucon (8) Cryptographic Protecon
CP-10 System Recovery and Reconstuon............................................................................................. 115
(1) Conngency Plan Tesng (2) Transacon Recovery (3) Compensang Security Controls (4) Restore Within Time
Period (5) Failover Capability (6) Component Protecon
CP-11 Alternate Communicaons Protocols.............................................................................................116
CP-12 Safe Mode........................................................................................................................................116
CP-13 Alternave Security Mechanisms................................................................................................... 117
This document is produced from OSCAL source data
PAGE vNIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
Family: Idenﬁcaon and Authencaon (IA)
IA-1 Policy and Procedures........................................................................................................................118
IA-2 Idenﬁcaon and Authencaon (Organizaonal Users)................................................................ 118
(1) Mul-factor Authencaon to Privileged Accounts (2) Mul-factor Authencaon to Non-privileged Accounts (3)
Local Access to Privileged Accounts (4) Local Access to Non-privileged Accounts (5) Individual Authencaon with
Group Authencaon (6) Access to Accounts —separate Device (7) Network Access to Non-privileged Accounts —
Separate Device (8) Access to Accounts — Replay Resistant (9) Network Access to Non-privileged Accounts — Replay
Resistant (10) Single Sign-on (11) Remote Access — Separate Device (12) Acceptance of PIV Credenals (13) Out-of-
band Authencaon
IA-3 Device Idenﬁcaon and Authencaon......................................................................................... 122
(1) Cryptographic Bidireconal Authencaon (2) Cryptographic Bidireconal Network Authencaon (3) Dynamic
Address Allocaon (4) Device Aestaon
IA-4 Idenﬁer Management...................................................................................................................... 123
(1) Prohibit Account Idenﬁers as Public Idenﬁers (2) Supervisor Authorizaon (3) Mulple Forms of Cerﬁcaon
(4) Idenfy User Status (5) Dynamic Management (6) Cross-organizaon Management (7) In-person Registraon (8)
Pairwise Pseudonymous Idenﬁers (9) Aribute Maintenance and Protecon
IA-5 Authencator Management.............................................................................................................. 125
(1) Password-based Authencaon (2) Public Key-based Authencaon (3) In-person or Trusted External Party
Registraon (4) Automated Support for Password Strength Determinaon (5) Change Authencators Prior to Delivery
(6) Protecon of Authencators (7) No Embedded Unencrypted Stac Authencators (8) Mulple System Accounts (9)
Federated Credenal Management (10) Dynamic Credenal Binding (11) Hardware Token-based Authencaon (12)
Biometric Authencaon Performance (13) Expiraon of Cached Authencators (14) Managing Content of PKI Trust
Stores (15) Gsa-approved Products and Services (16) In-person or Trusted External Party Authencator Issuance (17)
Presentaon Aack Detecon for Biometric Authencators (18) Password Managers
IA-6 Authencaon Feedback................................................................................................................... 131
IA-7 Cryptographic Module Authencaon..............................................................................................131
IA-8 Idenﬁcaon and Authencaon (Non-organizaonal Users).........................................................132
(1) Acceptance of PIV Credenals from Other Agencies (2) Acceptance of External Authencators (3) Use of Ficam-
approved Products (4) Use of Deﬁned Proﬁles (5) Acceptance of PIV-I Credenals (6) Disassociability
IA-9 Service Idenﬁcaon and Authencaon.........................................................................................134
(1) Informaon Exchange (2) Transmission of Decisions
IA-10 Adapve Authencaon..................................................................................................................134
IA-11 Re-authencaon.............................................................................................................................134
IA-12 Identy Prooﬁng.............................................................................................................................. 135
(1) Supervisor Authorizaon (2) Identy Evidence (3) Identy Evidence Validaon and Veriﬁcaon (4) In-person
Validaon and Veriﬁcaon (5) Address Conﬁrmaon (6) Accept Externally-proofed Idenes
Family: Incident Response (IR)
IR-1 Policy and Procedures........................................................................................................................137
IR-2 Incident Response Training................................................................................................................138
(1) Simulated Events (2) Automated Training Environments (3) Breach
IR-3 Incident Response Tesng..................................................................................................................139
(1) Automated Tesng (2) Coordinaon with Related Plans (3) Connuous Improvement
IR-4 Incident Handling............................................................................................................................... 140
(1) Automated Incident Handling Processes (2) Dynamic Reconﬁguraon (3) Connuity of Operaons (4) Informaon
Correlaon (5) Automac Disabling of System (6) Insider Threats (7) Insider Threats — Intra-organizaon Coordinaon
(8) Correlaon with External Organizaons (9) Dynamic Response Capability (10) Supply Chain Coordinaon (11)
This document is produced from OSCAL source data
PAGE viNIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
Integrated Incident Response Team (12) Malicious Code and Forensic Analysis (13) Behavior Analysis (14) Security
Operaons Center (15) Public Relaons and Reputaon Repair
IR-5 Incident Monitoring........................................................................................................................... 144
(1) Automated Tracking, Data Collecon, and Analysis
IR-6 Incident Reporng..............................................................................................................................145
(1) Automated Reporng (2) Vulnerabilies Related to Incidents (3) Supply Chain Coordinaon
IR-7 Incident Response Assistance............................................................................................................ 146
(1) Automaon Support for Availability of Informaon and Support (2) Coordinaon with External Providers
IR-8 Incident Response Plan......................................................................................................................147
(1) Breaches
IR-9 Informaon Spillage Response.......................................................................................................... 148
(1) Responsible Personnel (2) Training (3) Post-spill Operaons (4) Exposure to Unauthorized Personnel
IR-10 Integrated Informaon Security Analysis Team.............................................................................. 149
Family: Maintenance (MA)
MA-1 Policy and Procedures..................................................................................................................... 150
MA-2 Controlled Maintenance..................................................................................................................150
(1) Record Content (2) Automated Maintenance Acvies
MA-3 Maintenance Tools...........................................................................................................................151
(1) Inspect Tools (2) Inspect Media (3) Prevent Unauthorized Removal (4) Restricted Tool Use (5) Execuon with
Privilege (6) Soware Updates and Patches
MA-4 Nonlocal Maintenance.....................................................................................................................153
(1) Logging and Review (2) Document Nonlocal Maintenance (3) Comparable Security and Sanizaon (4)
Authencaon and Separaon of Maintenance Sessions (5) Approvals and Noﬁcaons (6) Cryptographic Protecon
(7) Disconnect Veriﬁcaon
MA-5 Maintenance Personnel...................................................................................................................155
(1) Individuals Without Appropriate Access (2) Security Clearances for Classiﬁed Systems (3) Cizenship Requirements
for Classiﬁed Systems (4) Foreign Naonals (5) Non-system Maintenance
MA-6 Timely Maintenance........................................................................................................................ 157
(1) Prevenve Maintenance (2) Predicve Maintenance (3) Automated Support for Predicve Maintenance
MA-7 Field Maintenance........................................................................................................................... 158
Family: Media Protecon (MP)
MP-1 Policy and Procedures......................................................................................................................159
MP-2 Media Access....................................................................................................................................159
(1) Automated Restricted Access (2) Cryptographic Protecon
MP-3 Media Marking.................................................................................................................................160
MP-4 Media Storage.................................................................................................................................. 160
(1) Cryptographic Protecon (2) Automated Restricted Access
MP-5 Media Transport...............................................................................................................................161
(1) Protecon Outside of Controlled Areas (2) Documentaon of Acvies (3) Custodians (4) Cryptographic Protecon
This document is produced from OSCAL source data
PAGE viiNIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
MP-6 Media Sanizaon........................................................................................................................... 162
(1) Review, Approve, Track, Document, and Verify (2) Equipment Tesng (3) Nondestrucve Techniques (4) Controlled
Unclassiﬁed Informaon (5) Classiﬁed Informaon (6) Media Destrucon (7) Dual Authorizaon (8) Remote Purging or
Wiping of Informaon
MP-7 Media Use........................................................................................................................................ 164
(1) Prohibit Use Without Owner (2) Prohibit Use of Sanizaon-resistant Media
MP-8 Media Downgrading.........................................................................................................................165
(1) Documentaon of Process (2) Equipment Tesng (3) Controlled Unclassiﬁed Informaon (4) Classiﬁed Informaon
Family: Physical and Environmental Protecon (PE)
PE-1 Policy and Procedures....................................................................................................................... 167
PE-2 Physical Access Authorizaons......................................................................................................... 168
(1) Access by Posion or Role (2) Two Forms of Idenﬁcaon (3) Restrict Unescorted Access
PE-3 Physical Access Control..................................................................................................................... 169
(1) System Access (2) Facility and Systems (3) Connuous Guards (4) Lockable Casings (5) Tamper Protecon (6) Facility
Penetraon Tesng (7) Physical Barriers (8) Access Control Vesbules
PE-4 Access Control for Transmission....................................................................................................... 171
PE-5 Access Control for Output Devices................................................................................................... 171
(1) Access to Output by Authorized Individuals (2) Link to Individual Identy (3) Marking Output Devices
PE-6 Monitoring Physical Access...............................................................................................................172
(1) Intrusion Alarms and Surveillance Equipment (2) Automated Intrusion Recognion and Responses (3) Video
Surveillance (4) Monitoring Physical Access to Systems
PE-7 Visitor Control....................................................................................................................................173
PE-8 Visitor Access Records.......................................................................................................................173
(1) Automated Records Maintenance and Review (2) Physical Access Records (3) Limit Personally Idenﬁable
Informaon Elements
PE-9 Power Equipment and Cabling..........................................................................................................174
(1) Redundant Cabling (2) Automac Voltage Controls
PE-10 Emergency Shutoﬀ...........................................................................................................................175
(1) Accidental and Unauthorized Acvaon
PE-11 Emergency Power............................................................................................................................ 175
(1) Alternate Power Supply — Minimal Operaonal Capability (2) Alternate Power Supply — Self-contained
PE-12 Emergency Lighng..........................................................................................................................176
(1) Essenal Mission and Business Funcons
PE-13 Fire Protecon................................................................................................................................. 176
(1) Detecon Systems — Automac Acvaon and Noﬁcaon (2) Suppression Systems — Automac Acvaon and
Noﬁcaon (3) Automac Fire Suppression (4) Inspecons
PE-14 Environmental Controls...................................................................................................................178
(1) Automac Controls (2) Monitoring with Alarms and Noﬁcaons
PE-15 Water Damage Protecon...............................................................................................................178
(1) Automaon Support
PE-16 Delivery and Removal..................................................................................................................... 179
This document is produced from OSCAL source data
PAGE viiiNIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
PE-17 Alternate Work Site.........................................................................................................................179
PE-18 Locaon of System Components.................................................................................................... 179
(1) Facility Site
PE-19 Informaon Leakage........................................................................................................................180
(1) Naonal Emissions Policies and Procedures
PE-20 Asset Monitoring and Tracking....................................................................................................... 180
PE-21 Electromagnec Pulse Protecon................................................................................................... 180
PE-22 Component Marking........................................................................................................................181
PE-23 Facility Locaon............................................................................................................................... 181
Family: Planning (PL)
PL-1 Policy and Procedures....................................................................................................................... 182
PL-2 System Security and Privacy Plans....................................................................................................183
(1) Concept of Operaons (2) Funconal Architecture (3) Plan and Coordinate with Other Organizaonal Enes
PL-3 System Security Plan Update............................................................................................................ 184
PL-4 Rules of Behavior...............................................................................................................................185
(1) Social Media and External Site/Applicaon Usage Restricons
PL-5 Privacy Impact Assessment............................................................................................................... 186
PL-6 Security-related Acvity Planning.....................................................................................................186
PL-7 Concept of Operaons...................................................................................................................... 186
PL-8 Security and Privacy Architectures................................................................................................... 186
(1) Defense in Depth (2) Supplier Diversity
PL-9 Central Management.........................................................................................................................188
PL-10 Baseline Selecon............................................................................................................................189
PL-11 Baseline Tailoring.............................................................................................................................189
Family: Program Management (PM)
PM-1 Informaon Security Program Plan.................................................................................................191
PM-2 Informaon Security Program Leadership Role..............................................................................192
PM-3 Informaon Security and Privacy Resources.................................................................................. 192
PM-4 Plan of Acon and Milestones Process...........................................................................................193
PM-5 System Inventory............................................................................................................................. 193
(1) Inventory of Personally Idenﬁable Informaon
PM-6 Measures of Performance............................................................................................................... 194
PM-7 Enterprise Architecture....................................................................................................................194
(1) Oﬄoading
PM-8 Crical Infrastructure Plan...............................................................................................................195
PM-9 Risk Management Strategy..............................................................................................................195
PM-10 Authorizaon Process.................................................................................................................... 196
This document is produced from OSCAL source data
PAGE ixNIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
PM-11 Mission and Business Process Deﬁnion......................................................................................196
PM-12 Insider Threat Program..................................................................................................................197
PM-13 Security and Privacy Workforce.................................................................................................... 197
PM-14 Tesng, Training, and Monitoring................................................................................................. 198
PM-15 Security and Privacy Groups and Associaons............................................................................. 198
PM-16 Threat Awareness Program........................................................................................................... 198
(1) Automated Means for Sharing Threat Intelligence
PM-17 Protecng Controlled Unclassiﬁed Informaon on External Systems..........................................199
PM-18 Privacy Program Plan.....................................................................................................................200
PM-19 Privacy Program Leadership Role..................................................................................................201
PM-20 Disseminaon of Privacy Program Informaon............................................................................201
(1) Privacy Policies on Websites, Applicaons, and Digital Services
PM-21 Accounng of Disclosures..............................................................................................................202
PM-22 Personally Idenﬁable Informaon Quality Management...........................................................202
PM-23 Data Governance Body.................................................................................................................. 203
PM-24 Data Integrity Board...................................................................................................................... 204
PM-25 Minimizaon of Personally Idenﬁable Informaon Used in Tesng, Training, and Research....204
PM-26 Complaint Management................................................................................................................ 204
PM-27 Privacy Reporng........................................................................................................................... 205
PM-28 Risk Framing................................................................................................................................... 205
PM-29 Risk Management Program Leadership Roles.............................................................................. 206
PM-30 Supply Chain Risk Management Strategy..................................................................................... 206
(1) Suppliers of Crical or Mission-essenal Items
PM-31 Connuous Monitoring Strategy................................................................................................... 207
PM-32 Purposing........................................................................................................................................208
Family: Personnel Security (PS)
PS-1 Policy and Procedures....................................................................................................................... 209
PS-2 Posion Risk Designaon..................................................................................................................209
PS-3 Personnel Screening.......................................................................................................................... 210
(1) Classiﬁed Informaon (2) Formal Indoctrinaon (3) Informaon Requiring Special Protecve Measures (4)
Cizenship Requirements
PS-4 Personnel Terminaon...................................................................................................................... 211
(1) Post-employment Requirements (2) Automated Acons
PS-5 Personnel Transfer.............................................................................................................................212
PS-6 Access Agreements............................................................................................................................213
(1) Informaon Requiring Special Protecon (2) Classiﬁed Informaon Requiring Special Protecon (3) Post-
employment Requirements
PS-7 External Personnel Security.............................................................................................................. 214
This document is produced from OSCAL source data
PAGE xNIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
PS-8 Personnel Sancons.......................................................................................................................... 214
PS-9 Posion Descripons.........................................................................................................................215
Family: Personally Idenﬁable Informaon Processing and Transparency (PT)
PT-1 Policy and Procedures....................................................................................................................... 216
PT-2 Authority to Process Personally Idenﬁable Informaon................................................................217
(1) Data Tagging (2) Automaon
PT-3 Personally Idenﬁable Informaon Processing Purposes................................................................ 218
(1) Data Tagging (2) Automaon
PT-4 Consent...............................................................................................................................................219
(1) Tailored Consent (2) Just-in-me Consent (3) Revocaon
PT-5 Privacy Noce.................................................................................................................................... 220
(1) Just-in-me Noce (2) Privacy Act Statements
PT-6 System of Records Noce..................................................................................................................222
(1) Roune Uses (2) Exempon Rules
PT-7 Speciﬁc Categories of Personally Idenﬁable Informaon.............................................................. 223
(1) Social Security Numbers (2) First Amendment Informaon
PT-8 Computer Matching Requirements...................................................................................................224
Family: Risk Assessment (RA)
RA-1 Policy and Procedures.......................................................................................................................225
RA-2 Security Categorizaon..................................................................................................................... 225
(1) Impact-level Priorizaon
RA-3 Risk Assessment................................................................................................................................227
(1) Supply Chain Risk Assessment (2) Use of All-source Intelligence (3) Dynamic Threat Awareness (4) Predicve Cyber
Analycs
RA-4 Risk Assessment Update...................................................................................................................229
RA-5 Vulnerability Monitoring and Scanning........................................................................................... 229
(1) Update Tool Capability (2) Update Vulnerabilies to Be Scanned (3) Breadth and Depth of Coverage (4) Discoverable
Informaon (5) Privileged Access (6) Automated Trend Analyses (7) Automated Detecon and Noﬁcaon of
Unauthorized Components (8) Review Historic Audit Logs (9) Penetraon Tesng and Analyses (10) Correlate Scanning
Informaon (11) Public Disclosure Program
RA-6 Technical Surveillance Countermeasures Survey............................................................................. 232
RA-7 Risk Response....................................................................................................................................232
RA-8 Privacy Impact Assessments.............................................................................................................233
RA-9 Cricality Analysis............................................................................................................................. 234
RA-10 Threat Hunng................................................................................................................................ 234
Family: System and Services Acquision (SA)
SA-1 Policy and Procedures.......................................................................................................................236
SA-2 Allocaon of Resources.....................................................................................................................236
SA-3 System Development Life Cycle........................................................................................................237
(1) Manage Preproducon Environment (2) Use of Live or Operaonal Data (3) Technology Refresh
This document is produced from OSCAL source data
PAGE xiNIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
SA-4 Acquision Process............................................................................................................................239
(1) Funconal Properes of Controls (2) Design and Implementaon Informaon for Controls (3) Development
Methods, Techniques, and Pracces (4) Assignment of Components to Systems (5) System, Component, and Service
Conﬁguraons (6) Use of Informaon Assurance Products (7) Niap-approved Protecon Proﬁles (8) Connuous
Monitoring Plan for Controls (9) Funcons, Ports, Protocols, and Services in Use (10) Use of Approved PIV Products (11)
System of Records (12) Data Ownership
SA-5 System Documentaon..................................................................................................................... 243
(1) Funconal Properes of Security Controls (2) Security-relevant External System Interfaces (3) High-level Design (4)
Low-level Design (5) Source Code
SA-6 Soware Usage Restricons............................................................................................................. 244
SA-7 User-installed Soware..................................................................................................................... 244
SA-8 Security and Privacy Engineering Principles.....................................................................................244
(1) Clear Abstracons (2) Least Common Mechanism (3) Modularity and Layering (4) Parally Ordered Dependencies
(5) Eﬃciently Mediated Access (6) Minimized Sharing (7) Reduced Complexity (8) Secure Evolvability (9) Trusted
Components (10) Hierarchical Trust (11) Inverse Modiﬁcaon Threshold (12) Hierarchical Protecon (13) Minimized
Security Elements (14) Least Privilege (15) Predicate Permission (16) Self-reliant Trustworthiness (17) Secure
Distributed Composion (18) Trusted Communicaons Channels (19) Connuous Protecon (20) Secure Metadata
Management (21) Self-analysis (22) Accountability and Traceability (23) Secure Defaults (24) Secure Failure and
Recovery (25) Economic Security (26) Performance Security (27) Human Factored Security (28) Acceptable Security
(29) Repeatable and Documented Procedures (30) Procedural Rigor (31) Secure System Modiﬁcaon (32) Suﬃcient
Documentaon (33) Minimizaon
SA-9 External System Services...................................................................................................................259
(1) Risk Assessments and Organizaonal Approvals (2) Idenﬁcaon of Funcons, Ports, Protocols, and Services (3)
Establish and Maintain Trust Relaonship with Providers (4) Consistent Interests of Consumers and Providers (5)
Processing, Storage, and Service Locaon (6) Organizaon-controlled Cryptographic Keys (7) Organizaon-controlled
Integrity Checking (8) Processing and Storage Locaon — U.s. Jurisdicon
SA-10 Developer Conﬁguraon Management.......................................................................................... 262
(1) Soware and Firmware Integrity Veriﬁcaon (2) Alternave Conﬁguraon Management Processes (3) Hardware
Integrity Veriﬁcaon (4) Trusted Generaon (5) Mapping Integrity for Version Control (6) Trusted Distribuon (7)
Security and Privacy Representaves
SA-11 Developer Tesng and Evaluaon.................................................................................................. 265
(1) Stac Code Analysis (2) Threat Modeling and Vulnerability Analyses (3) Independent Veriﬁcaon of Assessment
Plans and Evidence (4) Manual Code Reviews (5) Penetraon Tesng (6) Aack Surface Reviews (7) Verify Scope of
Tesng and Evaluaon (8) Dynamic Code Analysis (9) Interacve Applicaon Security Tesng
SA-12 Supply Chain Protecon..................................................................................................................268
(1) Acquision Strategies  Tools  Methods (2) Supplier Reviews (3) Trusted Shipping and Warehousing (4) Diversity of
Suppliers (5) Limitaon of Harm (6) Minimizing Procurement Time (7) Assessments Prior to Selecon  Acceptance 
Update (8) Use of All-source Intelligence (9) Operaons Security (10) Validate as Genuine and Not Altered (11)
Penetraon Tesng  Analysis of Elements, Processes, and Actors (12) Inter-organizaonal Agreements (13) Crical
Informaon System Components (14) Identy and Traceability (15) Processes to Address Weaknesses or Deﬁciencies
SA-13 Trustworthiness............................................................................................................................... 270
SA-14 Cricality Analysis........................................................................................................................... 270
(1) Crical Components with No Viable Alternave Sourcing
SA-15 Development Process, Standards, and Tools..................................................................................270
(1) Quality Metrics (2) Security and Privacy Tracking Tools (3) Cricality Analysis (4) Threat Modeling and Vulnerability
Analysis (5) Aack Surface Reducon (6) Connuous Improvement (7) Automated Vulnerability Analysis (8) Reuse
of Threat and Vulnerability Informaon (9) Use of Live Data (10) Incident Response Plan (11) Archive System or
Component (12) Minimize Personally Idenﬁable Informaon
SA-16 Developer-provided Training...........................................................................................................274
This document is produced from OSCAL source data
PAGE xiiNIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
SA-17 Developer Security and Privacy Architecture and Design..............................................................274
(1) Formal Policy Model (2) Security-relevant Components (3) Formal Correspondence (4) Informal Correspondence
(5) Conceptually Simple Design (6) Structure for Tesng (7) Structure for Least Privilege (8) Orchestraon (9) Design
Diversity
SA-18 Tamper Resistance and Detecon.................................................................................................. 278
(1) Mulple Phases of System Development Life Cycle (2) Inspecon of Systems or Components
SA-19 Component Authencity.................................................................................................................278
(1) An-counterfeit Training (2) Conﬁguraon Control for Component Service and Repair (3) Component Disposal (4)
An-counterfeit Scanning
SA-20 Customized Development of Crical Components........................................................................ 279
SA-21 Developer Screening....................................................................................................................... 279
(1) Validaon of Screening
SA-22 Unsupported System Components................................................................................................. 280
(1) Alternave Sources for Connued Support
SA-23 Specializaon................................................................................................................................... 281
Family: System and Communicaons Protecon (SC)
SC-1 Policy and Procedures....................................................................................................................... 282
SC-2 Separaon of System and User Funconality.................................................................................. 282
(1) Interfaces for Non-privileged Users (2) Disassociability
SC-3 Security Funcon Isolaon................................................................................................................283
(1) Hardware Separaon (2) Access and Flow Control Funcons (3) Minimize Nonsecurity Funconality (4) Module
Coupling and Cohesiveness (5) Layered Structures
SC-4 Informaon in Shared System Resources.........................................................................................285
(1) Security Levels (2) Mullevel or Periods Processing
SC-5 Denial-of-service Protecon..............................................................................................................285
(1) Restrict Ability to Aack Other Systems (2) Capacity, Bandwidth, and Redundancy (3) Detecon and Monitoring
SC-6 Resource Availability......................................................................................................................... 287
SC-7 Boundary Protecon......................................................................................................................... 287
(1) Physically Separated Subnetworks (2) Public Access (3) Access Points (4) External Telecommunicaons Services (5)
Deny by Default — Allow by Excepon (6) Response to Recognized Failures (7) Split Tunneling for Remote Devices (8)
Route Traﬃc to Authencated Proxy Servers (9) Restrict Threatening Outgoing Communicaons Traﬃc (10) Prevent
Exﬁltraon (11) Restrict Incoming Communicaons Traﬃc (12) Host-based Protecon (13) Isolaon of Security Tools,
Mechanisms, and Support Components (14) Protect Against Unauthorized Physical Connecons (15) Networked
Privileged Accesses (16) Prevent Discovery of System Components (17) Automated Enforcement of Protocol Formats
(18) Fail Secure (19) Block Communicaon from Non-organizaonally Conﬁgured Hosts (20) Dynamic Isolaon and
Segregaon (21) Isolaon of System Components (22) Separate Subnets for Connecng to Diﬀerent Security Domains
(23) Disable Sender Feedback on Protocol Validaon Failure (24) Personally Idenﬁable Informaon (25) Unclassiﬁed
Naonal Security System Connecons (26) Classiﬁed Naonal Security System Connecons (27) Unclassiﬁed Non-
naonal Security System Connecons (28) Connecons to Public Networks (29) Separate Subnets to Isolate Funcons
SC-8 Transmission Conﬁdenality and Integrity.......................................................................................295
(1) Cryptographic Protecon (2) Pre- and Post-transmission Handling (3) Cryptographic Protecon for Message
Externals (4) Conceal or Randomize Communicaons (5) Protected Distribuon System
SC-9 Transmission Conﬁdenality............................................................................................................. 297
SC-10 Network Disconnect........................................................................................................................ 297
This document is produced from OSCAL source data
PAGE xiiiNIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
SC-11 Trusted Path.....................................................................................................................................297
(1) Irrefutable Communicaons Path
SC-12 Cryptographic Key Establishment and Management..................................................................... 298
(1) Availability (2) Symmetric Keys (3) Asymmetric Keys (4) PKI Cerﬁcates (5) PKI Cerﬁcates  Hardware Tokens (6)
Physical Control of Keys
SC-13 Cryptographic Protecon................................................................................................................ 299
(1) Fips-validated Cryptography (2) Nsa-approved Cryptography (3) Individuals Without Formal Access Approvals (4)
Digital Signatures
SC-14 Public Access Protecons................................................................................................................300
SC-15 Collaborave Compung Devices and Applicaons.......................................................................300
(1) Physical or Logical Disconnect (2) Blocking Inbound and Outbound Communicaons Traﬃc (3) Disabling and
Removal in Secure Work Areas (4) Explicitly Indicate Current Parcipants
SC-16 Transmission of Security and Privacy Aributes............................................................................ 301
(1) Integrity Veriﬁcaon (2) An-spooﬁng Mechanisms (3) Cryptographic Binding
SC-17 Public Key Infrastructure Cerﬁcates............................................................................................. 302
SC-18 Mobile Code.................................................................................................................................... 302
(1) Idenfy Unacceptable Code and Take Correcve Acons (2) Acquision, Development, and Use (3) Prevent
Downloading and Execuon (4) Prevent Automac Execuon (5) Allow Execuon Only in Conﬁned Environments
SC-19 Voice Over Internet Protocol.......................................................................................................... 303
SC-20 Secure Name/Address Resoluon Service (Authoritave Source)................................................ 304
(1) Child Subspaces (2) Data Origin and Integrity
SC-21 Secure Name/Address Resoluon Service (Recursive or Caching Resolver)................................. 304
(1) Data Origin and Integrity
SC-22 Architecture and Provisioning for Name/Address Resoluon Service.......................................... 305
SC-23 Session Authencity........................................................................................................................ 305
(1) Invalidate Session Idenﬁers at Logout (2) User-iniated Logouts and Message Displays (3) Unique System-
generated Session Idenﬁers (4) Unique Session Idenﬁers with Randomizaon (5) Allowed Cerﬁcate Authories
SC-24 Fail in Known State......................................................................................................................... 306
SC-25 Thin Nodes.......................................................................................................................................306
SC-26 Decoys.............................................................................................................................................. 307
(1) Detecon of Malicious Code
SC-27 Plaorm-independent Applicaons................................................................................................307
SC-28 Protecon of Informaon at Rest...................................................................................................307
(1) Cryptographic Protecon (2) Oﬄine Storage (3) Cryptographic Keys
SC-29 Heterogeneity.................................................................................................................................. 308
(1) Virtualizaon Techniques
SC-30 Concealment and Misdirecon.......................................................................................................309
(1) Virtualizaon Techniques (2) Randomness (3) Change Processing and Storage Locaons (4) Misleading Informaon
(5) Concealment of System Components
SC-31 Covert Channel Analysis..................................................................................................................310
(1) Test Covert Channels for Exploitability (2) Maximum Bandwidth (3) Measure Bandwidth in Operaonal
Environments
This document is produced from OSCAL source data
PAGE xivNIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
SC-32 System Paroning......................................................................................................................... 311
(1) Separate Physical Domains for Privileged Funcons
SC-33 Transmission Preparaon Integrity.................................................................................................312
SC-34 Non-modiﬁable Executable Programs............................................................................................ 312
(1) No Writable Storage (2) Integrity Protecon on Read-only Media (3) Hardware-based Protecon
SC-35 External Malicious Code Idenﬁcaon...........................................................................................313
SC-36 Distributed Processing and Storage................................................................................................313
(1) Polling Techniques (2) Synchronizaon
SC-37 Out-of-band Channels..................................................................................................................... 314
(1) Ensure Delivery and Transmission
SC-38 Operaons Security......................................................................................................................... 314
SC-39 Process Isolaon..............................................................................................................................315
(1) Hardware Separaon (2) Separate Execuon Domain Per Thread
SC-40 Wireless Link Protecon................................................................................................................. 315
(1) Electromagnec Interference (2) Reduce Detecon Potenal (3) Imitave or Manipulave Communicaons
Decepon (4) Signal Parameter Idenﬁcaon
SC-41 Port and I/O Device Access.............................................................................................................317
SC-42 Sensor Capability and Data.............................................................................................................317
(1) Reporng to Authorized Individuals or Roles (2) Authorized Use (3) Prohibit Use of Devices (4) Noce of Collecon
(5) Collecon Minimizaon
SC-43 Usage Restricons........................................................................................................................... 319
SC-44 Detonaon Chambers..................................................................................................................... 319
SC-45 System Time Synchronizaon......................................................................................................... 319
(1) Synchronizaon with Authoritave Time Source (2) Secondary Authoritave Time Source
SC-46 Cross Domain Policy Enforcement.................................................................................................. 320
SC-47 Alternate Communicaons Paths................................................................................................... 320
SC-48 Sensor Relocaon............................................................................................................................ 321
(1) Dynamic Relocaon of Sensors or Monitoring Capabilies
SC-49 Hardware-enforced Separaon and Policy Enforcement............................................................... 321
SC-50 Soware-enforced Separaon and Policy Enforcement................................................................ 321
SC-51 Hardware-based Protecon............................................................................................................ 322
Family: System and Informaon Integrity (SI)
SI-1 Policy and Procedures........................................................................................................................ 323
SI-2 Flaw Remediaon...............................................................................................................................323
(1) Central Management (2) Automated Flaw Remediaon Status (3) Time to Remediate Flaws and Benchmarks for
Correcve Acons (4) Automated Patch Management Tools (5) Automac Soware and Firmware Updates (6) Removal
of Previous Versions of Soware and Firmware
SI-3 Malicious Code Protecon................................................................................................................. 325
(1) Central Management (2) Automac Updates (3) Non-privileged Users (4) Updates Only by Privileged Users (5)
Portable Storage Devices (6) Tesng and Veriﬁcaon (7) Nonsignature-based Detecon (8) Detect Unauthorized
Commands (9) Authencate Remote Commands (10) Malicious Code Analysis
This document is produced from OSCAL source data
PAGE xvNIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
SI-4 System Monitoring............................................................................................................................. 328
(1) System-wide Intrusion Detecon System (2) Automated Tools and Mechanisms for Real-me Analysis (3)
Automated Tool and Mechanism Integraon (4) Inbound and Outbound Communicaons Traﬃc (5) System-generated
Alerts (6) Restrict Non-privileged Users (7) Automated Response to Suspicious Events (8) Protecon of Monitoring
Informaon (9) Tesng of Monitoring Tools and Mechanisms (10) Visibility of Encrypted Communicaons (11) Analyze
Communicaons Traﬃc Anomalies (12) Automated Organizaon-generated Alerts (13) Analyze Traﬃc and Event
Paerns (14) Wireless Intrusion Detecon (15) Wireless to Wireline Communicaons (16) Correlate Monitoring
Informaon (17) Integrated Situaonal Awareness (18) Analyze Traﬃc and Covert Exﬁltraon (19) Risk for Individuals
(20) Privileged Users (21) Probaonary Periods (22) Unauthorized Network Services (23) Host-based Devices (24)
Indicators of Compromise (25) Opmize Network Traﬃc Analysis
SI-5 Security Alerts, Advisories, and Direcves........................................................................................335
(1) Automated Alerts and Advisories
SI-6 Security and Privacy Funcon Veriﬁcaon........................................................................................ 336
(1) Noﬁcaon of Failed Security Tests (2) Automaon Support for Distributed Tesng (3) Report Veriﬁcaon Results
SI-7 Soware, Firmware, and Informaon Integrity................................................................................ 337
(1) Integrity Checks (2) Automated Noﬁcaons of Integrity Violaons (3) Centrally Managed Integrity Tools (4)
Tamper-evident Packaging (5) Automated Response to Integrity Violaons (6) Cryptographic Protecon (7) Integraon
of Detecon and Response (8) Auding Capability for Signiﬁcant Events (9) Verify Boot Process (10) Protecon of
Boot Firmware (11) Conﬁned Environments with Limited Privileges (12) Integrity Veriﬁcaon (13) Code Execuon in
Protected Environments (14) Binary or Machine Executable Code (15) Code Authencaon (16) Time Limit on Process
Execuon Without Supervision (17) Runme Applicaon Self-protecon
SI-8 Spam Protecon................................................................................................................................. 341
(1) Central Management (2) Automac Updates (3) Connuous Learning Capability
SI-9 Informaon Input Restricons...........................................................................................................341
SI-10 Informaon Input Validaon........................................................................................................... 342
(1) Manual Override Capability (2) Review and Resolve Errors (3) Predictable Behavior (4) Timing Interacons (5)
Restrict Inputs to Trusted Sources and Approved Formats (6) Injecon Prevenon
SI-11 Error Handling...................................................................................................................................343
SI-12 Informaon Management and Retenon........................................................................................344
(1) Limit Personally Idenﬁable Informaon Elements (2) Minimize Personally Idenﬁable Informaon in Tesng,
Training, and Research (3) Informaon Disposal
SI-13 Predictable Failure Prevenon.........................................................................................................345
(1) Transferring Component Responsibilies (2) Time Limit on Process Execuon Without Supervision (3) Manual
Transfer Between Components (4) Standby Component Installaon and Noﬁcaon (5) Failover Capability
SI-14 Non-persistence................................................................................................................................ 347
(1) Refresh from Trusted Sources (2) Non-persistent Informaon (3) Non-persistent Connecvity
SI-15 Informaon Output Filtering............................................................................................................348
SI-16 Memory Protecon.......................................................................................................................... 348
SI-17 Fail-safe Procedures..........................................................................................................................348
SI-18 Personally Idenﬁable Informaon Quality Operaons................................................................. 349
(1) Automaon Support (2) Data Tags (3) Collecon (4) Individual Requests (5) Noce of Correcon or Deleon
SI-19 De-idenﬁcaon............................................................................................................................... 351
(1) Collecon (2) Archiving (3) Release (4) Removal, Masking, Encrypon, Hashing, or Replacement of Direct Idenﬁers
(5) Stascal Disclosure Control (6) Diﬀerenal Privacy (7) Validated Algorithms and Soware (8) Movated Intruder
SI-20 Tainng..............................................................................................................................................353
This document is produced from OSCAL source data
PAGE xviNIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
SI-21 Informaon Refresh..........................................................................................................................353
SI-22 Informaon Diversity........................................................................................................................354
SI-23 Informaon Fragmentaon..............................................................................................................354
Family: Supply Chain Risk Management (SR)
SR-1 Policy and Procedures....................................................................................................................... 355
SR-2 Supply Chain Risk Management Plan...............................................................................................356
(1) Establish Scrm Team
SR-3 Supply Chain Controls and Processes...............................................................................................357
(1) Diverse Supply Base (2) Limitaon of Harm (3) Sub-er Flow Down
SR-4 Provenance........................................................................................................................................ 358
(1) Identy (2) Track and Trace (3) Validate as Genuine and Not Altered (4) Supply Chain Integrity — Pedigree
SR-5 Acquision Strategies, Tools, and Methods..................................................................................... 360
(1) Adequate Supply (2) Assessments Prior to Selecon, Acceptance, Modiﬁcaon, or Update
SR-6 Supplier Assessments and Reviews.................................................................................................. 361
(1) Tesng and Analysis
SR-7 Supply Chain Operaons Security.................................................................................................... 362
SR-8 Noﬁcaon Agreements................................................................................................................... 363
SR-9 Tamper Resistance and Detecon.................................................................................................... 363
(1) Mulple Stages of System Development Life Cycle
SR-10 Inspecon of Systems or Components........................................................................................... 363
SR-11 Component Authencity.................................................................................................................364
(1) An-counterfeit Training (2) Conﬁguraon Control for Component Service and Repair (3) An-counterfeit Scanning
SR-12 Component Disposal....................................................................................................................... 365
References.................................................................................................................................................. 366
This document is produced from OSCAL source data
PAGE xviiNIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
FAMILY: ACCESS CONTROL
AC-1 POLICY AND PROCEDURES
Control:
a. Develop, document, and disseminate to [Assignment: organizaon-deﬁned personnel or roles]:
1. [Selecon (one or more): Organizaon-level; Mission/business process-level; System-level]
access control policy that:
(a) Addresses purpose, scope, roles, responsibilies, management commitment,
coordinaon among organizaonal enes, and compliance; and
(b) Is consistent with applicable laws, execuve orders, direcves, regulaons, policies,
standards, and guidelines; and
2. Procedures to facilitate the implementaon of the access control policy and the associated
access controls;
b. Designate an [Assignment: organizaon-deﬁned oﬃcial] to manage the development,
documentaon, and disseminaon of the access control policy and procedures; and
c. Review and update the current access control:
1. Policy [Assignment: organizaon-deﬁned frequency] and following [Assignment:
organizaon-deﬁned events]; and
2. Procedures [Assignment: organizaon-deﬁned frequency] and following [Assignment:
organizaon-deﬁned events].
Discussion: Access control policy and procedures address the controls in the AC family that are
implemented within systems and organizaons. The risk management strategy is an important
factor in establishing such policies and procedures. Policies and procedures contribute to security
and privacy assurance. Therefore, it is important that security and privacy programs collaborate on
the development of access control policy and procedures. Security and privacy program policies
and procedures at the organizaon level are preferable, in general, and may obviate the need for
mission- or system-speciﬁc policies and procedures. The policy can be included as part of the general
security and privacy policy or be represented by mulple policies reﬂecng the complex nature
of organizaons. Procedures can be established for security and privacy programs, for mission or
business processes, and for systems, if needed. Procedures describe how the policies or controls
are implemented and can be directed at the individual or role that is the object of the procedure.
Procedures can be documented in system security and privacy plans or in one or more separate
documents. Events that may precipitate an update to access control policy and procedures include
assessment or audit ﬁndings, security incidents or breaches, or changes in laws, execuve orders,
direcves, regulaons, policies, standards, and guidelines. Simply restang controls does not
constute an organizaonal policy or procedure.
Related controls: IA-1, PM-9, PM-24, PS-8, SI-12.
References: [IR 7874], [OMB A-130], [SP 800-100], [SP 800-12], [SP 800-30], [SP 800-39]
AC-2 ACCOUNT MANAGEMENT
Control:
a. Deﬁne and document the types of accounts allowed and speciﬁcally prohibited for use within the
system;
b. Assign account managers;
This document is produced from OSCAL source data
FAMILY: AC PAGE 1NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
c. Require [Assignment: organizaon-deﬁned prerequisites and criteria] for group and role
membership;
d. Specify:
1. Authorized users of the system;
2. Group and role membership; and
3. Access authorizaons (i.e., privileges) and [Assignment: organizaon-deﬁned aributes (as
required)] for each account;
e. Require approvals by [Assignment: organizaon-deﬁned personnel or roles] for requests to create
accounts;
f. Create, enable, modify, disable, and remove accounts in accordance with [Assignment:
organizaon-deﬁned policy, procedures, prerequisites, and criteria];
g. Monitor the use of accounts;
h. Nofy account managers and [Assignment: organizaon-deﬁned personnel or roles] within:
1. [Assignment: organizaon-deﬁned me period] when accounts are no longer required;
2. [Assignment: organizaon-deﬁned me period] when users are terminated or transferred;
and
3. [Assignment: organizaon-deﬁned me period] when system usage or need-to-know
changes for an individual;
i. Authorize access to the system based on:
1. A valid access authorizaon;
2. Intended system usage; and
3. [Assignment: organizaon-deﬁned aributes (as required)];
j. Review accounts for compliance with account management requirements [Assignment:
organizaon-deﬁned frequency];
k. Establish and implement a process for changing shared or group account authencators (if
deployed) when individuals are removed from the group; and
l. Align account management processes with personnel terminaon and transfer processes.
Discussion: Examples of system account types include individual, shared, group, system, guest,
anonymous, emergency, developer, temporary, and service. Idenﬁcaon of authorized system users
and the speciﬁcaon of access privileges reﬂect the requirements in other controls in the security
plan. Users requiring administrave privileges on system accounts receive addional scruny by
organizaonal personnel responsible for approving such accounts and privileged access, including
system owner, mission or business owner, senior agency informaon security oﬃcer, or senior agency
oﬃcial for privacy. Types of accounts that organizaons may wish to prohibit due to increased risk
include shared, group, emergency, anonymous, temporary, and guest accounts.
Where access involves personally idenﬁable informaon, security programs collaborate with the
senior agency oﬃcial for privacy to establish the speciﬁc condions for group and role membership;
specify authorized users, group and role membership, and access authorizaons for each account;
and create, adjust, or remove system accounts in accordance with organizaonal policies. Policies
can include such informaon as account expiraon dates or other factors that trigger the disabling of
accounts. Organizaons may choose to deﬁne access privileges or other aributes by account, type
of account, or a combinaon of the two. Examples of other aributes required for authorizing access
This document is produced from OSCAL source data
FAMILY: AC PAGE 2NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
include restricons on me of day, day of week, and point of origin. In deﬁning other system account
aributes, organizaons consider system-related requirements and mission/business requirements.
Failure to consider these factors could aﬀect system availability.
Temporary and emergency accounts are intended for short-term use. Organizaons establish
temporary accounts as part of normal account acvaon procedures when there is a need for short-
term accounts without the demand for immediacy in account acvaon. Organizaons establish
emergency accounts in response to crisis situaons and with the need for rapid account acvaon.
Therefore, emergency account acvaon may bypass normal account authorizaon processes.
Emergency and temporary accounts are not to be confused with infrequently used accounts, including
local logon accounts used for special tasks or when network resources are unavailable (may also be
known as accounts of last resort). Such accounts remain available and are not subject to automac
disabling or removal dates. Condions for disabling or deacvang accounts include when shared/
group, emergency, or temporary accounts are no longer required and when individuals are transferred
or terminated. Changing shared/group authencators when members leave the group is intended to
ensure that former group members do not retain access to the shared or group account. Some types
of system accounts may require specialized training.
Related controls: AC-3, AC-5, AC-6, AC-17, AC-18, AC-20, AC-24, AU-2, AU-12, CM-5, IA-2, IA-4, IA-5,
IA-8, MA-3, MA-5, PE-2, PL-4, PS-2, PS-4, PS-5, PS-7, PT-2, PT-3, SC-7, SC-12, SC-13, SC-37.
(1) ACCOUNT MANAGEMENT | AUTOMATED SYSTEM ACCOUNT MANAGEMENT
Support the management of system accounts using [Assignment: organizaon-deﬁned
automated mechanisms].
Discussion: Automated system account management includes using automated mechanisms
to create, enable, modify, disable, and remove accounts; nofy account managers when an
account is created, enabled, modiﬁed, disabled, or removed, or when users are terminated
or transferred; monitor system account usage; and report atypical system account usage.
Automated mechanisms can include internal system funcons and email, telephonic, and text
messaging noﬁcaons.
(2) ACCOUNT MANAGEMENT | AUTOMATED TEMPORARY AND EMERGENCY ACCOUNT
MANAGEMENT
Automacally [Selecon: remove; disable] temporary and emergency accounts aer
[Assignment: organizaon-deﬁned me period for each type of account].
Discussion: Management of temporary and emergency accounts includes the removal or disabling
of such accounts automacally aer a predeﬁned me period rather than at the convenience of
the system administrator. Automac removal or disabling of accounts provides a more consistent
implementaon.
This document is produced from OSCAL source data
FAMILY: AC PAGE 3NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(3) ACCOUNT MANAGEMENT | DISABLE ACCOUNTS
Disable accounts within [Assignment: organizaon-deﬁned me period] when the accounts:
(a) Have expired;
(b) Are no longer associated with a user or individual;
(c) Are in violaon of organizaonal policy; or
(d) Have been inacve for [Assignment: organizaon-deﬁned me period].
Discussion: Disabling expired, inacve, or otherwise anomalous accounts supports the concepts
of least privilege and least funconality which reduce the aack surface of the system.
(4) ACCOUNT MANAGEMENT | AUTOMATED AUDIT ACTIONS
Automacally audit account creaon, modiﬁcaon, enabling, disabling, and removal acons.
Discussion: Account management audit records are deﬁned in accordance with AU-2 and
reviewed, analyzed, and reported in accordance with AU-6.
Related controls: AU-2, AU-6.
(5) ACCOUNT MANAGEMENT | INACTIVITY LOGOUT
Require that users log out when [Assignment: organizaon-deﬁned me period of expected
inacvity or descripon of when to log out].
Discussion: Inacvity logout is behavior- or policy-based and requires users to take physical
acon to log out when they are expecng inacvity longer than the deﬁned period. Automac
enforcement of inacvity logout is addressed by AC-11.
Related control: AC-11.
(6) ACCOUNT MANAGEMENT | DYNAMIC PRIVILEGE MANAGEMENT
Implement [Assignment: organizaon-deﬁned dynamic privilege management capabilies].
Discussion: In contrast to access control approaches that employ stac accounts and predeﬁned
user privileges, dynamic access control approaches rely on runme access control decisions
facilitated by dynamic privilege management, such as aribute-based access control. While user
idenes remain relavely constant over me, user privileges typically change more frequently
based on ongoing mission or business requirements and the operaonal needs of organizaons.
An example of dynamic privilege management is the immediate revocaon of privileges from
users as opposed to requiring that users terminate and restart their sessions to reﬂect changes
in privileges. Dynamic privilege management can also include mechanisms that change user
privileges based on dynamic rules as opposed to eding speciﬁc user proﬁles. Examples include
automac adjustments of user privileges if they are operang out of their normal work mes,
if their job funcon or assignment changes, or if systems are under duress or in emergency
situaons. Dynamic privilege management includes the eﬀects of privilege changes, for example,
when there are changes to encrypon keys used for communicaons.
Related control: AC-16.
This document is produced from OSCAL source data
FAMILY: AC PAGE 4NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(7) ACCOUNT MANAGEMENT | PRIVILEGED USER ACCOUNTS
(a) Establish and administer privileged user accounts in accordance with [Selecon: a role-
based access scheme; an aribute-based access scheme];
(b) Monitor privileged role or aribute assignments;
(c) Monitor changes to roles or aributes; and
(d) Revoke access when privileged role or aribute assignments are no longer appropriate.
Discussion: Privileged roles are organizaon-deﬁned roles assigned to individuals that allow
those individuals to perform certain security-relevant funcons that ordinary users are not
authorized to perform. Privileged roles include key management, account management,
database administraon, system and network administraon, and web administraon. A role-
based access scheme organizes permied system access and privileges into roles. In contrast,
an aribute-based access scheme speciﬁes allowed system access and privileges based on
aributes.
(8) ACCOUNT MANAGEMENT | DYNAMIC ACCOUNT MANAGEMENT
Create, acvate, manage, and deacvate [Assignment: organizaon-deﬁned system accounts]
dynamically.
Discussion: Approaches for dynamically creang, acvang, managing, and deacvang system
accounts rely on automacally provisioning the accounts at runme for enes that were
previously unknown. Organizaons plan for the dynamic management, creaon, acvaon,
and deacvaon of system accounts by establishing trust relaonships, business rules, and
mechanisms with appropriate authories to validate related authorizaons and privileges.
Related control: AC-16.
(9) ACCOUNT MANAGEMENT | RESTRICTIONS ON USE OF SHARED AND GROUP ACCOUNTS
Only permit the use of shared and group accounts that meet [Assignment: organizaon-
deﬁned condions for establishing shared and group accounts].
Discussion: Before perming the use of shared or group accounts, organizaons consider the
increased risk due to the lack of accountability with such accounts.
(10) ACCOUNT MANAGEMENT | SHARED AND GROUP ACCOUNT CREDENTIAL CHANGE
[Withdrawn: Incorporated into AC-2.]
(11) ACCOUNT MANAGEMENT | USAGE CONDITIONS
Enforce [Assignment: organizaon-deﬁned circumstances and/or usage condions] for
[Assignment: organizaon-deﬁned system accounts].
Discussion: Specifying and enforcing usage condions helps to enforce the principle of least
privilege, increase user accountability, and enable eﬀecve account monitoring. Account
monitoring includes alerts generated if the account is used in violaon of organizaonal
parameters. Organizaons can describe speciﬁc condions or circumstances under which system
accounts can be used, such as by restricng usage to certain days of the week, me of day, or
speciﬁc duraons of me.
This document is produced from OSCAL source data
FAMILY: AC PAGE 5NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(12) ACCOUNT MANAGEMENT | ACCOUNT MONITORING FOR ATYPICAL USAGE
(a) Monitor system accounts for [Assignment: organizaon-deﬁned atypical usage]; and
(b) Report atypical usage of system accounts to [Assignment: organizaon-deﬁned personnel
or roles].
Discussion: Atypical usage includes accessing systems at certain mes of the day or from locaons
that are not consistent with the normal usage paerns of individuals. Monitoring for atypical
usage may reveal rogue behavior by individuals or an aack in progress. Account monitoring
may inadvertently create privacy risks since data collected to idenfy atypical usage may reveal
previously unknown informaon about the behavior of individuals. Organizaons assess and
document privacy risks from monitoring accounts for atypical usage in their privacy impact
assessment and make determinaons that are in alignment with their privacy program plan.
Related controls: AU-6, AU-7, CA-7, IR-8, SI-4.
(13) ACCOUNT MANAGEMENT | DISABLE ACCOUNTS FOR HIGH-RISK INDIVIDUALS
Disable accounts of individuals within [Assignment: organizaon-deﬁned me period] of
discovery of [Assignment: organizaon-deﬁned signiﬁcant risks].
Discussion: Users who pose a signiﬁcant security and/or privacy risk include individuals for whom
reliable evidence indicates either the intenon to use authorized access to systems to cause
harm or through whom adversaries will cause harm. Such harm includes adverse impacts to
organizaonal operaons, organizaonal assets, individuals, other organizaons, or the Naon.
Close coordinaon among system administrators, legal staﬀ, human resource managers, and
authorizing oﬃcials is essenal when disabling system accounts for high-risk individuals.
Related controls: AU-6, SI-4.
References: [SP 800-162], [SP 800-178], [SP 800-192]
AC-3 ACCESS ENFORCEMENT
Control: Enforce approved authorizaons for logical access to informaon and system resources in
accordance with applicable access control policies.
Discussion: Access control policies control access between acve enes or subjects (i.e., users
or processes acng on behalf of users) and passive enes or objects (i.e., devices, ﬁles, records,
domains) in organizaonal systems. In addion to enforcing authorized access at the system level and
recognizing that systems can host many applicaons and services in support of mission and business
funcons, access enforcement mechanisms can also be employed at the applicaon and service level
to provide increased informaon security and privacy. In contrast to logical access controls that are
implemented within the system, physical access controls are addressed by the controls in the Physical
and Environmental Protecon (PE) family.
Related controls: AC-2, AC-4, AC-5, AC-6, AC-16, AC-17, AC-18, AC-19, AC-20, AC-21, AC-22, AC-24,
AC-25, AT-2, AT-3, AU-9, CA-9, CM-5, CM-11, IA-2, IA-5, IA-6, IA-7, IA-11, MA-3, MA-4, MA-5, MP-4,
PM-2, PS-3, PT-2, PT-3, SA-17, SC-2, SC-3, SC-4, SC-12, SC-13, SC-28, SC-31, SC-34, SI-4, SI-8.
(1) ACCESS ENFORCEMENT | RESTRICTED ACCESS TO PRIVILEGED FUNCTIONS
[Withdrawn: Incorporated into AC-6.]
This document is produced from OSCAL source data
FAMILY: AC PAGE 6NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(2) ACCESS ENFORCEMENT | DUAL AUTHORIZATION
Enforce dual authorizaon for [Assignment: organizaon-deﬁned privileged commands and/or
other organizaon-deﬁned acons].
Discussion: Dual authorizaon, also known as two-person control, reduces risk related to insider
threats. Dual authorizaon mechanisms require the approval of two authorized individuals
to execute. To reduce the risk of collusion, organizaons consider rotang dual authorizaon
dues. Organizaons consider the risk associated with implemenng dual authorizaon
mechanisms when immediate responses are necessary to ensure public and environmental
safety.
Related controls: CP-9, MP-6.
(3) ACCESS ENFORCEMENT | MANDATORY ACCESS CONTROL
Enforce [Assignment: organizaon-deﬁned mandatory access control policy] over the set of
covered subjects and objects speciﬁed in the policy, and where the policy:
(a) Is uniformly enforced across the covered subjects and objects within the system;
(b) Speciﬁes that a subject that has been granted access to informaon is constrained from
doing any of the following;
(1) Passing the informaon to unauthorized subjects or objects;
(2) Granng its privileges to other subjects;
(3) Changing one or more security aributes (speciﬁed by the policy) on subjects,
objects, the system, or system components;
(4) Choosing the security aributes and aribute values (speciﬁed by the policy) to be
associated with newly created or modiﬁed objects; and
(5) Changing the rules governing access control; and
(c) Speciﬁes that [Assignment: organizaon-deﬁned subjects] may explicitly be granted
[Assignment: organizaon-deﬁned privileges] such that they are not limited by any
deﬁned subset (or all) of the above constraints.
Discussion: Mandatory access control is a type of nondiscreonary access control. Mandatory
access control policies constrain what acons subjects can take with informaon obtained
from objects for which they have already been granted access. This prevents the subjects
from passing the informaon to unauthorized subjects and objects. Mandatory access control
policies constrain acons that subjects can take with respect to the propagaon of access control
privileges; that is, a subject with a privilege cannot pass that privilege to other subjects. The
policy is uniformly enforced over all subjects and objects to which the system has control.
Otherwise, the access control policy can be circumvented. This enforcement is provided by an
implementaon that meets the reference monitor concept as described in AC-25. The policy is
bounded by the system (i.e., once the informaon is passed outside of the control of the system,
addional means may be required to ensure that the constraints on the informaon remain in
eﬀect).
The trusted subjects described above are granted privileges consistent with the concept of
least privilege (see AC-6). Trusted subjects are only given the minimum privileges necessary
for sasfying organizaonal mission/business needs relave to the above policy. The control
is most applicable when there is a mandate that establishes a policy regarding access to
controlled unclassiﬁed informaon or classiﬁed informaon and some users of the system are
This document is produced from OSCAL source data
FAMILY: AC PAGE 7NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
not authorized access to all such informaon resident in the system. Mandatory access control
can operate in conjuncon with discreonary access control as described in AC-3(4). A subject
constrained in its operaon by mandatory access control policies can sll operate under the
less rigorous constraints of AC-3(4), but mandatory access control policies take precedence
over the less rigorous constraints of AC-3(4). For example, while a mandatory access control
policy imposes a constraint that prevents a subject from passing informaon to another subject
operang at a diﬀerent impact or classiﬁcaon level, AC-3(4) permits the subject to pass the
informaon to any other subject with the same impact or classiﬁcaon level as the subject.
Examples of mandatory access control policies include the Bell-LaPadula policy to protect
conﬁdenality of informaon and the Biba policy to protect the integrity of informaon.
Related control: SC-7.
(4) ACCESS ENFORCEMENT | DISCRETIONARY ACCESS CONTROL
Enforce [Assignment: organizaon-deﬁned discreonary access control policy] over the set
of covered subjects and objects speciﬁed in the policy, and where the policy speciﬁes that a
subject that has been granted access to informaon can do one or more of the following:
(a) Pass the informaon to any other subjects or objects;
(b) Grant its privileges to other subjects;
(c) Change security aributes on subjects, objects, the system, or the system’s components;
(d) Choose the security aributes to be associated with newly created or revised objects; or
(e) Change the rules governing access control.
Discussion: When discreonary access control policies are implemented, subjects are not
constrained with regard to what acons they can take with informaon for which they have
already been granted access. Thus, subjects that have been granted access to informaon are
not prevented from passing the informaon to other subjects or objects (i.e., subjects have the
discreon to pass). Discreonary access control can operate in conjuncon with mandatory
access control as described in AC-3(3) and AC-3(15). A subject that is constrained in its operaon
by mandatory access control policies can sll operate under the less rigorous constraints of
discreonary access control. Therefore, while AC-3(3) imposes constraints that prevent a subject
from passing informaon to another subject operang at a diﬀerent impact or classiﬁcaon
level, AC-3(4) permits the subject to pass the informaon to any subject at the same impact or
classiﬁcaon level. The policy is bounded by the system. Once the informaon is passed outside
of system control, addional means may be required to ensure that the constraints remain in
eﬀect. While tradional deﬁnions of discreonary access control require identy-based access
control, that limitaon is not required for this parcular use of discreonary access control.
(5) ACCESS ENFORCEMENT | SECURITY-RELEVANT INFORMATION
Prevent access to [Assignment: organizaon-deﬁned security-relevant informaon] except
during secure, non-operable system states.
Discussion: Security-relevant informaon is informaon within systems that can potenally
impact the operaon of security funcons or the provision of security services in a manner
that could result in failure to enforce system security and privacy policies or maintain the
separaon of code and data. Security-relevant informaon includes access control lists, ﬁltering
rules for routers or ﬁrewalls, conﬁguraon parameters for security services, and cryptographic
key management informaon. Secure, non-operable system states include the mes in which
This document is produced from OSCAL source data
FAMILY: AC PAGE 8NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
systems are not performing mission or business-related processing, such as when the system is
oﬄine for maintenance, boot-up, troubleshoong, or shut down.
Related controls: CM-6, SC-39.
(6) ACCESS ENFORCEMENT | PROTECTION OF USER AND SYSTEM INFORMATION
[Withdrawn: Incorporated into MP-4, SC-28.]
(7) ACCESS ENFORCEMENT | ROLE-BASED ACCESS CONTROL
Enforce a role-based access control policy over deﬁned subjects and objects and control access
based upon [Assignment: organizaon-deﬁned roles and users authorized to assume such
roles].
Discussion: Role-based access control (RBAC) is an access control policy that enforces access
to objects and system funcons based on the deﬁned role (i.e., job funcon) of the subject.
Organizaons can create speciﬁc roles based on job funcons and the authorizaons (i.e.,
privileges) to perform needed operaons on the systems associated with the organizaon-
deﬁned roles. When users are assigned to speciﬁc roles, they inherit the authorizaons or
privileges deﬁned for those roles. RBAC simpliﬁes privilege administraon for organizaons
because privileges are not assigned directly to every user (which can be a large number of
individuals) but are instead acquired through role assignments. RBAC can also increase privacy
and security risk if individuals assigned to a role are given access to informaon beyond what
they need to support organizaonal missions or business funcons. RBAC can be implemented
as a mandatory or discreonary form of access control. For organizaons implemenng RBAC
with mandatory access controls, the requirements in AC-3(3) deﬁne the scope of the subjects
and objects covered by the policy.
(8) ACCESS ENFORCEMENT | REVOCATION OF ACCESS AUTHORIZATIONS
Enforce the revocaon of access authorizaons resulng from changes to the security
aributes of subjects and objects based on [Assignment: organizaon-deﬁned rules governing
the ming of revocaons of access authorizaons].
Discussion: Revocaon of access rules may diﬀer based on the types of access revoked. For
example, if a subject (i.e., user or process acng on behalf of a user) is removed from a group,
access may not be revoked unl the next me the object is opened or the next me the subject
aempts to access the object. Revocaon based on changes to security labels may take eﬀect
immediately. Organizaons provide alternave approaches on how to make revocaons
immediate if systems cannot provide such capability and immediate revocaon is necessary.
(9) ACCESS ENFORCEMENT | CONTROLLED RELEASE
Release informaon outside of the system only if:
(a) The receiving [Assignment: organizaon-deﬁned system or system component] provides
[Assignment: organizaon-deﬁned controls]; and
(b) [Assignment: organizaon-deﬁned controls] are used to validate the appropriateness of
the informaon designated for release.
Discussion: Organizaons can only directly protect informaon when it resides within the system.
Addional controls may be needed to ensure that organizaonal informaon is adequately
protected once it is transmied outside of the system. In situaons where the system is unable
This document is produced from OSCAL source data
FAMILY: AC PAGE 9NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
to determine the adequacy of the protecons provided by external enes, as a migaon
measure, organizaons procedurally determine whether the external systems are providing
adequate controls. The means used to determine the adequacy of controls provided by external
systems include conducng periodic assessments (inspecons/tests), establishing agreements
between the organizaon and its counterpart organizaons, or some other process. The
means used by external enes to protect the informaon received need not be the same as
those used by the organizaon, but the means employed are suﬃcient to provide consistent
adjudicaon of the security and privacy policy to protect the informaon and individuals’
privacy.
Controlled release of informaon requires systems to implement technical or procedural
means to validate the informaon prior to releasing it to external systems. For example, if
the system passes informaon to a system controlled by another organizaon, technical
means are employed to validate that the security and privacy aributes associated with the
exported informaon are appropriate for the receiving system. Alternavely, if the system passes
informaon to a printer in organizaon-controlled space, procedural means can be employed to
ensure that only authorized individuals gain access to the printer.
Related controls: CA-3, PT-7, PT-8, SA-9, SC-16.
(10) ACCESS ENFORCEMENT | AUDITED OVERRIDE OF ACCESS CONTROL MECHANISMS
Employ an audited override of automated access control mechanisms under [Assignment:
organizaon-deﬁned condions] by [Assignment: organizaon-deﬁned roles].
Discussion: In certain situaons, such as when there is a threat to human life or an event that
threatens the organizaon’s ability to carry out crical missions or business funcons, an
override capability for access control mechanisms may be needed. Override condions are
deﬁned by organizaons and used only in those limited circumstances. Audit events are deﬁned
in AU-2. Audit records are generated in AU-12.
Related controls: AU-2, AU-6, AU-10, AU-12, AU-14.
(11) ACCESS ENFORCEMENT | RESTRICT ACCESS TO SPECIFIC INFORMATION TYPES
Restrict access to data repositories containing [Assignment: organizaon-deﬁned informaon
types].
Discussion: Restricng access to speciﬁc informaon is intended to provide ﬂexibility regarding
access control of speciﬁc informaon types within a system. For example, role-based access
could be employed to allow access to only a speciﬁc type of personally idenﬁable informaon
within a database rather than allowing access to the database in its enrety. Other examples
include restricng access to cryptographic keys, authencaon informaon, and selected system
informaon.
Related controls: CM-8, CM-12, CM-13, PM-5.
This document is produced from OSCAL source data
FAMILY: AC PAGE 10NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(12) ACCESS ENFORCEMENT | ASSERT AND ENFORCE APPLICATION ACCESS
(a) Require applicaons to assert, as part of the installaon process, the access needed
to the following system applicaons and funcons: [Assignment: organizaon-deﬁned
system applicaons and funcons];
(b) Provide an enforcement mechanism to prevent unauthorized access; and
(c) Approve access changes aer inial installaon of the applicaon.
Discussion: Asserng and enforcing applicaon access is intended to address applicaons that
need to access exisng system applicaons and funcons, including user contacts, global
posioning systems, cameras, keyboards, microphones, networks, phones, or other ﬁles.
Related control: CM-7.
(13) ACCESS ENFORCEMENT | ATTRIBUTE-BASED ACCESS CONTROL
Enforce aribute-based access control policy over deﬁned subjects and objects and
control access based upon [Assignment: organizaon-deﬁned aributes to assume access
permissions].
Discussion: Aribute-based access control is an access control policy that restricts system access
to authorized users based on speciﬁed organizaonal aributes (e.g., job funcon, identy),
acon aributes (e.g., read, write, delete), environmental aributes (e.g., me of day, locaon),
and resource aributes (e.g., classiﬁcaon of a document). Organizaons can create rules based
on aributes and the authorizaons (i.e., privileges) to perform needed operaons on the
systems associated with organizaon-deﬁned aributes and rules. When users are assigned to
aributes deﬁned in aribute-based access control policies or rules, they can be provisioned to
a system with the appropriate privileges or dynamically granted access to a protected resource.
Aribute-based access control can be implemented as either a mandatory or discreonary form
of access control. When implemented with mandatory access controls, the requirements in
AC-3(3) deﬁne the scope of the subjects and objects covered by the policy.
(14) ACCESS ENFORCEMENT | INDIVIDUAL ACCESS
Provide [Assignment: organizaon-deﬁned mechanisms] to enable individuals to have
access to the following elements of their personally idenﬁable informaon: [Assignment:
organizaon-deﬁned elements].
Discussion: Individual access aﬀords individuals the ability to review personally idenﬁable
informaon about them held within organizaonal records, regardless of format. Access helps
individuals to develop an understanding about how their personally idenﬁable informaon
is being processed. It can also help individuals ensure that their data is accurate. Access
mechanisms can include request forms and applicaon interfaces. For federal agencies, PRIVACT
processes can be located in systems of record noces and on agency websites. Access to certain
types of records may not be appropriate (e.g., for federal agencies, law enforcement records
within a system of records may be exempt from disclosure under the PRIVACT) or may require
certain levels of authencaon assurance. Organizaonal personnel consult with the senior
agency oﬃcial for privacy and legal counsel to determine appropriate mechanisms and access
rights or limitaons.
Related controls: IA-8, PM-20, PM-21, PM-22, PT-6.
This document is produced from OSCAL source data
FAMILY: AC PAGE 11NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(15) ACCESS ENFORCEMENT | DISCRETIONARY AND MANDATORY ACCESS CONTROL
(a) Enforce [Assignment: organizaon-deﬁned mandatory access control policy] over the set
of covered subjects and objects speciﬁed in the policy; and
(b) Enforce [Assignment: organizaon-deﬁned discreonary access control policy] over the
set of covered subjects and objects speciﬁed in the policy.
Discussion: Simultaneously implemenng a mandatory access control policy and a discreonary
access control policy can provide addional protecon against the unauthorized execuon of
code by users or processes acng on behalf of users. This helps prevent a single compromised
user or process from compromising the enre system.
Related controls: AC-4, SC-2, SC-3.
References: [IR 7874], [OMB A-130], [PRIVACT], [SP 800-162], [SP 800-178], [SP 800-57-1], [SP
800-57-2], [SP 800-57-3]
AC-4 INFORMATION FLOW ENFORCEMENT
Control: Enforce approved authorizaons for controlling the ﬂow of informaon within the system and
between connected systems based on [Assignment: organizaon-deﬁned informaon ﬂow control
policies].
Discussion: Informaon ﬂow control regulates where informaon can travel within a system and
between systems (in contrast to who is allowed to access the informaon) and without regard to
subsequent accesses to that informaon. Flow control restricons include blocking external traﬃc
that claims to be from within the organizaon, keeping export-controlled informaon from being
transmied in the clear to the Internet, restricng web requests that are not from the internal web
proxy server, and liming informaon transfers between organizaons based on data structures and
content. Transferring informaon between organizaons may require an agreement specifying how
the informaon ﬂow is enforced (see CA-3). Transferring informaon between systems in diﬀerent
security or privacy domains with diﬀerent security or privacy policies introduces the risk that such
transfers violate one or more domain security or privacy policies. In such situaons, informaon
owners/stewards provide guidance at designated policy enforcement points between connected
systems. Organizaons consider mandang speciﬁc architectural soluons to enforce speciﬁc security
and privacy policies. Enforcement includes prohibing informaon transfers between connected
systems (i.e., allowing access only), verifying write permissions before accepng informaon from
another security or privacy domain or connected system, employing hardware mechanisms to enforce
one-way informaon ﬂows, and implemenng trustworthy regrading mechanisms to reassign security
or privacy aributes and labels.
Organizaons commonly employ informaon ﬂow control policies and enforcement mechanisms
to control the ﬂow of informaon between designated sources and desnaons within systems
and between connected systems. Flow control is based on the characteriscs of the informaon
and/or the informaon path. Enforcement occurs, for example, in boundary protecon devices that
employ rule sets or establish conﬁguraon sengs that restrict system services, provide a packet-
ﬁltering capability based on header informaon, or provide a message-ﬁltering capability based
on message content. Organizaons also consider the trustworthiness of ﬁltering and/or inspecon
mechanisms (i.e., hardware, ﬁrmware, and soware components) that are crical to informaon ﬂow
enforcement. Control enhancements 3 through 32 primarily address cross-domain soluon needs
that focus on more advanced ﬁltering techniques, in-depth analysis, and stronger ﬂow enforcement
mechanisms implemented in cross-domain products, such as high-assurance guards. Such capabilies
This document is produced from OSCAL source data
FAMILY: AC PAGE 12NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
are generally not available in commercial oﬀ-the-shelf products. Informaon ﬂow enforcement also
applies to control plane traﬃc (e.g., roung and DNS).
Related controls: AC-3, AC-6, AC-16, AC-17, AC-19, AC-21, AU-10, CA-3, CA-9, CM-7, PL-9, PM-24, SA-17,
SC-4, SC-7, SC-16, SC-31.
(1) INFORMATION FLOW ENFORCEMENT | OBJECT SECURITY AND PRIVACY ATTRIBUTES
Use [Assignment: organizaon-deﬁned security and privacy aributes] associated with
[Assignment: organizaon-deﬁned informaon, source, and desnaon objects] to enforce
[Assignment: organizaon-deﬁned informaon ﬂow control policies] as a basis for ﬂow control
decisions.
Discussion: Informaon ﬂow enforcement mechanisms compare security and privacy aributes
associated with informaon (i.e., data content and structure) and source and desnaon objects
and respond appropriately when the enforcement mechanisms encounter informaon ﬂows
not explicitly allowed by informaon ﬂow policies. For example, an informaon object labeled
Secret would be allowed to ﬂow to a desnaon object labeled Secret, but an informaon
object labeled Top Secret would not be allowed to ﬂow to a desnaon object labeled Secret. A
dataset of personally idenﬁable informaon may be tagged with restricons against combining
with other types of datasets and, thus, would not be allowed to ﬂow to the restricted dataset.
Security and privacy aributes can also include source and desnaon addresses employed in
traﬃc ﬁlter ﬁrewalls. Flow enforcement using explicit security or privacy aributes can be used,
for example, to control the release of certain types of informaon.
(2) INFORMATION FLOW ENFORCEMENT | PROCESSING DOMAINS
Use protected processing domains to enforce [Assignment: organizaon-deﬁned informaon
ﬂow control policies] as a basis for ﬂow control decisions.
Discussion: Protected processing domains within systems are processing spaces that have
controlled interacons with other processing spaces, enabling control of informaon ﬂows
between these spaces and to/from informaon objects. A protected processing domain can be
provided, for example, by implemenng domain and type enforcement. In domain and type
enforcement, system processes are assigned to domains, informaon is idenﬁed by types, and
informaon ﬂows are controlled based on allowed informaon accesses (i.e., determined by
domain and type), allowed signaling among domains, and allowed process transions to other
domains.
Related control: SC-39.
(3) INFORMATION FLOW ENFORCEMENT | DYNAMIC INFORMATION FLOW CONTROL
Enforce [Assignment: organizaon-deﬁned informaon ﬂow control policies].
Discussion: Organizaonal policies regarding dynamic informaon ﬂow control include allowing
or disallowing informaon ﬂows based on changing condions or mission or operaonal
consideraons. Changing condions include changes in risk tolerance due to changes in the
immediacy of mission or business needs, changes in the threat environment, and detecon of
potenally harmful or adverse events.
Related control: SI-4.
This document is produced from OSCAL source data
FAMILY: AC PAGE 13NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(4) INFORMATION FLOW ENFORCEMENT | FLOW CONTROL OF ENCRYPTED INFORMATION
Prevent encrypted informaon from bypassing [Assignment: organizaon-deﬁned informaon
ﬂow control mechanisms] by [Selecon (one or more): decrypng the informaon; blocking
the ﬂow of the encrypted informaon; terminang communicaons sessions aempng to
pass encrypted informaon; [Assignment: organizaon-deﬁned procedure or method]].
Discussion: Flow control mechanisms include content checking, security policy ﬁlters, and data
type idenﬁers. The term encrypon is extended to cover encoded data not recognized by
ﬁltering mechanisms.
Related control: SI-4.
(5) INFORMATION FLOW ENFORCEMENT | EMBEDDED DATA TYPES
Enforce [Assignment: organizaon-deﬁned limitaons] on embedding data types within other
data types.
Discussion: Embedding data types within other data types may result in reduced ﬂow control
eﬀecveness. Data type embedding includes inserng ﬁles as objects within other ﬁles and using
compressed or archived data types that may include mulple embedded data types. Limitaons
on data type embedding consider the levels of embedding and prohibit levels of data type
embedding that are beyond the capability of the inspecon tools.
(6) INFORMATION FLOW ENFORCEMENT | METADATA
Enforce informaon ﬂow control based on [Assignment: organizaon-deﬁned metadata].
Discussion: Metadata is informaon that describes the characteriscs of data. Metadata can
include structural metadata describing data structures or descripve metadata describing data
content. Enforcement of allowed informaon ﬂows based on metadata enables simpler and
more eﬀecve ﬂow control. Organizaons consider the trustworthiness of metadata regarding
data accuracy (i.e., knowledge that the metadata values are correct with respect to the data),
data integrity (i.e., protecng against unauthorized changes to metadata tags), and the binding
of metadata to the data payload (i.e., employing suﬃciently strong binding techniques with
appropriate assurance).
Related controls: AC-16, SI-7.
(7) INFORMATION FLOW ENFORCEMENT | ONE-WAY FLOW MECHANISMS
Enforce one-way informaon ﬂows through hardware-based ﬂow control mechanisms.
Discussion: One-way ﬂow mechanisms may also be referred to as a unidireconal network,
unidireconal security gateway, or data diode. One-way ﬂow mechanisms can be used to
prevent data from being exported from a higher impact or classiﬁed domain or system while
perming data from a lower impact or unclassiﬁed domain or system to be imported.
This document is produced from OSCAL source data
FAMILY: AC PAGE 14NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(8) INFORMATION FLOW ENFORCEMENT | SECURITY AND PRIVACY POLICY FILTERS
(a) Enforce informaon ﬂow control using [Assignment: organizaon-deﬁned security or
privacy policy ﬁlters] as a basis for ﬂow control decisions for [Assignment: organizaon-
deﬁned informaon ﬂows]; and
(b) [Selecon (one or more): Block; Strip; Modify; Quaranne] data aer a ﬁlter processing
failure in accordance with [Assignment: organizaon-deﬁned security or privacy policy].
Discussion: Organizaon-deﬁned security or privacy policy ﬁlters can address data structures and
content. For example, security or privacy policy ﬁlters for data structures can check for maximum
ﬁle lengths, maximum ﬁeld sizes, and data/ﬁle types (for structured and unstructured data).
Security or privacy policy ﬁlters for data content can check for speciﬁc words, enumerated values
or data value ranges, and hidden content. Structured data permits the interpretaon of data
content by applicaons. Unstructured data refers to digital informaon without a data structure
or with a data structure that does not facilitate the development of rule sets to address the
impact or classiﬁcaon level of the informaon conveyed by the data or the ﬂow enforcement
decisions. Unstructured data consists of bitmap objects that are inherently non-language-
based (i.e., image, video, or audio ﬁles) and textual objects that are based on wrien or printed
languages. Organizaons can implement more than one security or privacy policy ﬁlter to meet
informaon ﬂow control objecves.
(9) INFORMATION FLOW ENFORCEMENT | HUMAN REVIEWS
Enforce the use of human reviews for [Assignment: organizaon-deﬁned informaon ﬂows]
under the following condions: [Assignment: organizaon-deﬁned condions].
Discussion: Organizaons deﬁne security or privacy policy ﬁlters for all situaons where
automated ﬂow control decisions are possible. When a fully automated ﬂow control decision is
not possible, then a human review may be employed in lieu of or as a complement to automated
security or privacy policy ﬁltering. Human reviews may also be employed as deemed necessary
by organizaons.
(10) INFORMATION FLOW ENFORCEMENT | ENABLE AND DISABLE SECURITY OR PRIVACY
POLICY FILTERS
Provide the capability for privileged administrators to enable and disable [Assignment:
organizaon-deﬁned security or privacy policy ﬁlters] under the following condions:
[Assignment: organizaon-deﬁned condions].
Discussion: For example, as allowed by the system authorizaon, administrators can enable
security or privacy policy ﬁlters to accommodate approved data types. Administrators also have
the capability to select the ﬁlters that are executed on a speciﬁc data ﬂow based on the type of
data that is being transferred, the source and desnaon security domains, and other security or
privacy relevant features, as needed.
This document is produced from OSCAL source data
FAMILY: AC PAGE 15NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(11) INFORMATION FLOW ENFORCEMENT | CONFIGURATION OF SECURITY OR PRIVACY
POLICY FILTERS
Provide the capability for privileged administrators to conﬁgure [Assignment: organizaon-
deﬁned security or privacy policy ﬁlters] to support diﬀerent security or privacy policies.
Discussion: Documentaon contains detailed informaon for conﬁguring security or privacy policy
ﬁlters. For example, administrators can conﬁgure security or privacy policy ﬁlters to include the
list of inappropriate words that security or privacy policy mechanisms check in accordance with
the deﬁnions provided by organizaons.
(12) INFORMATION FLOW ENFORCEMENT | DATA TYPE IDENTIFIERS
When transferring informaon between diﬀerent security domains, use [Assignment:
organizaon-deﬁned data type idenﬁers] to validate data essenal for informaon ﬂow
decisions.
Discussion: Data type idenﬁers include ﬁlenames, ﬁle types, ﬁle signatures or tokens, and
mulple internal ﬁle signatures or tokens. Systems only allow transfer of data that is compliant
with data type format speciﬁcaons. Idenﬁcaon and validaon of data types is based
on deﬁned speciﬁcaons associated with each allowed data format. The ﬁlename and
number alone are not used for data type idenﬁcaon. Content is validated syntaccally and
semancally against its speciﬁcaon to ensure that it is the proper data type.
(13) INFORMATION FLOW ENFORCEMENT | DECOMPOSITION INTO POLICY-RELEVANT
SUBCOMPONENTS
When transferring informaon between diﬀerent security domains, decompose informaon
into [Assignment: organizaon-deﬁned policy-relevant subcomponents] for submission to
policy enforcement mechanisms.
Discussion: Decomposing informaon into policy-relevant subcomponents prior to informaon
transfer facilitates policy decisions on source, desnaon, cerﬁcates, classiﬁcaon,
aachments, and other security- or privacy-related component diﬀerenators. Policy
enforcement mechanisms apply ﬁltering, inspecon, and/or sanizaon rules to the policy-
relevant subcomponents of informaon to facilitate ﬂow enforcement prior to transferring such
informaon to diﬀerent security domains.
(14) INFORMATION FLOW ENFORCEMENT | SECURITY OR PRIVACY POLICY FILTER
CONSTRAINTS
When transferring informaon between diﬀerent security domains, implement [Assignment:
organizaon-deﬁned security or privacy policy ﬁlters] requiring fully enumerated formats that
restrict data structure and content.
Discussion: Data structure and content restricons reduce the range of potenal malicious or
unsanconed content in cross-domain transacons. Security or privacy policy ﬁlters that restrict
data structures include restricng ﬁle sizes and ﬁeld lengths. Data content policy ﬁlters include
encoding formats for character sets, restricng character data ﬁelds to only contain alpha-
numeric characters, prohibing special characters, and validang schema structures.
This document is produced from OSCAL source data
FAMILY: AC PAGE 16NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(15) INFORMATION FLOW ENFORCEMENT | DETECTION OF UNSANCTIONED INFORMATION
When transferring informaon between diﬀerent security domains, examine the informaon
for the presence of [Assignment: organizaon-deﬁned unsanconed informaon] and prohibit
the transfer of such informaon in accordance with the [Assignment: organizaon-deﬁned
security or privacy policy].
Discussion: Unsanconed informaon includes malicious code, informaon that is inappropriate
for release from the source network, or executable code that could disrupt or harm the services
or systems on the desnaon network.
Related control: SI-3.
(16) INFORMATION FLOW ENFORCEMENT | INFORMATION TRANSFERS ON
INTERCONNECTED SYSTEMS
[Withdrawn: Incorporated into AC-4.]
(17) INFORMATION FLOW ENFORCEMENT | DOMAIN AUTHENTICATION
Uniquely idenfy and authencate source and desnaon points by [Selecon (one or more):
organizaon; system; applicaon; service; individual] for informaon transfer.
Discussion: Aribuon is a crical component of a security and privacy concept of operaons. The
ability to idenfy source and desnaon points for informaon ﬂowing within systems allows
the forensic reconstrucon of events and encourages policy compliance by aribung policy
violaons to speciﬁc organizaons or individuals. Successful domain authencaon requires that
system labels disnguish among systems, organizaons, and individuals involved in preparing,
sending, receiving, or disseminang informaon. Aribuon also allows organizaons to beer
maintain the lineage of personally idenﬁable informaon processing as it ﬂows through
systems and can facilitate consent tracking, as well as correcon, deleon, or access requests
from individuals.
Related controls: IA-2, IA-3, IA-9.
(18) INFORMATION FLOW ENFORCEMENT | SECURITY ATTRIBUTE BINDING
[Withdrawn: Incorporated into AC-16.]
(19) INFORMATION FLOW ENFORCEMENT | VALIDATION OF METADATA
When transferring informaon between diﬀerent security domains, implement [Assignment:
organizaon-deﬁned security or privacy policy ﬁlters] on metadata.
Discussion: All informaon (including metadata and the data to which the metadata applies) is
subject to ﬁltering and inspecon. Some organizaons disnguish between metadata and data
payloads (i.e., only the data to which the metadata is bound). Other organizaons do not make
such disncons and consider metadata and the data to which the metadata applies to be part
of the payload.
This document is produced from OSCAL source data
FAMILY: AC PAGE 17NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(20) INFORMATION FLOW ENFORCEMENT | APPROVED SOLUTIONS
Employ [Assignment: organizaon-deﬁned soluons in approved conﬁguraons] to control the
ﬂow of [Assignment: organizaon-deﬁned informaon] across security domains.
Discussion: Organizaons deﬁne approved soluons and conﬁguraons in cross-domain policies
and guidance in accordance with the types of informaon ﬂows across classiﬁcaon boundaries.
The Naonal Security Agency (NSA) Naonal Cross Domain Strategy and Management Oﬃce
provides a lisng of approved cross-domain soluons. Contact ncdsmo@nsa.gov for more
informaon.
(21) INFORMATION FLOW ENFORCEMENT | PHYSICAL OR LOGICAL SEPARATION OF
INFORMATION FLOWS
Separate informaon ﬂows logically or physically using [Assignment: organizaon-deﬁned
mechanisms and/or techniques] to accomplish [Assignment: organizaon-deﬁned required
separaons by types of informaon].
Discussion: Enforcing the separaon of informaon ﬂows associated with deﬁned types of data
can enhance protecon by ensuring that informaon is not commingled while in transit and
by enabling ﬂow control by transmission paths that are not otherwise achievable. Types of
separable informaon include inbound and outbound communicaons traﬃc, service requests
and responses, and informaon of diﬀering security impact or classiﬁcaon levels.
Related control: SC-32.
(22) INFORMATION FLOW ENFORCEMENT | ACCESS ONLY
Provide access from a single device to compung plaorms, applicaons, or data residing in
mulple diﬀerent security domains, while prevenng informaon ﬂow between the diﬀerent
security domains.
Discussion: The system provides a capability for users to access each connected security domain
without providing any mechanisms to allow users to transfer data or informaon between the
diﬀerent security domains. An example of an access-only soluon is a terminal that provides
a user access to informaon with diﬀerent security classiﬁcaons while assuredly keeping the
informaon separate.
(23) INFORMATION FLOW ENFORCEMENT | MODIFY NON-RELEASABLE INFORMATION
When transferring informaon between diﬀerent security domains, modify non-releasable
informaon by implemenng [Assignment: organizaon-deﬁned modiﬁcaon acon].
Discussion: Modifying non-releasable informaon can help prevent a data spill or aack when
informaon is transferred across security domains. Modiﬁcaon acons include masking,
permutaon, alteraon, removal, or redacon.
(24) INFORMATION FLOW ENFORCEMENT | INTERNAL NORMALIZED FORMAT
When transferring informaon between diﬀerent security domains, parse incoming data into
an internal normalized format and regenerate the data to be consistent with its intended
speciﬁcaon.
Discussion: Converng data into normalized forms is one of most of eﬀecve mechanisms to stop
malicious aacks and large classes of data exﬁltraon.
This document is produced from OSCAL source data
FAMILY: AC PAGE 18NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(25) INFORMATION FLOW ENFORCEMENT | DATA SANITIZATION
When transferring informaon between diﬀerent security domains, sanize data to minimize
[Selecon (one or more): delivery of malicious content, command and control of malicious
code, malicious code augmentaon, and steganography encoded data; spillage of sensive
informaon] in accordance with [Assignment: organizaon-deﬁned policy].
Discussion: Data sanizaon is the process of irreversibly removing or destroying data stored on
a memory device (e.g., hard drives, ﬂash memory/solid state drives, mobile devices, CDs, and
DVDs) or in hard copy form.
Related control: MP-6.
(26) INFORMATION FLOW ENFORCEMENT | AUDIT FILTERING ACTIONS
When transferring informaon between diﬀerent security domains, record and audit content
ﬁltering acons and results for the informaon being ﬁltered.
Discussion: Content ﬁltering is the process of inspecng informaon as it traverses a cross-
domain soluon and determines if the informaon meets a predeﬁned policy. Content ﬁltering
acons and the results of ﬁltering acons are recorded for individual messages to ensure that
the correct ﬁlter acons were applied. Content ﬁlter reports are used to assist in troubleshoong
acons by, for example, determining why message content was modiﬁed and/or why it failed the
ﬁltering process. Audit events are deﬁned in AU-2. Audit records are generated in AU-12.
Related controls: AU-2, AU-3, AU-12.
(27) INFORMATION FLOW ENFORCEMENT | REDUNDANT/INDEPENDENT FILTERING
MECHANISMS
When transferring informaon between diﬀerent security domains, implement content
ﬁltering soluons that provide redundant and independent ﬁltering mechanisms for each data
type.
Discussion: Content ﬁltering is the process of inspecng informaon as it traverses a cross-
domain soluon and determines if the informaon meets a predeﬁned policy. Redundant and
independent content ﬁltering eliminates a single point of failure ﬁltering system. Independence
is deﬁned as the implementaon of a content ﬁlter that uses a diﬀerent code base and
supporng libraries (e.g., two JPEG ﬁlters using diﬀerent vendors’ JPEG libraries) and mulple,
independent system processes.
(28) INFORMATION FLOW ENFORCEMENT | LINEAR FILTER PIPELINES
When transferring informaon between diﬀerent security domains, implement a linear
content ﬁlter pipeline that is enforced with discreonary and mandatory access controls.
Discussion: Content ﬁltering is the process of inspecng informaon as it traverses a cross-
domain soluon and determines if the informaon meets a predeﬁned policy. The use of linear
content ﬁlter pipelines ensures that ﬁlter processes are non-bypassable and always invoked.
In general, the use of parallel ﬁltering architectures for content ﬁltering of a single data type
introduces bypass and non-invocaon issues.
This document is produced from OSCAL source data
FAMILY: AC PAGE 19NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(29) INFORMATION FLOW ENFORCEMENT | FILTER ORCHESTRATION ENGINES
When transferring informaon between diﬀerent security domains, employ content ﬁlter
orchestraon engines to ensure that:
(a) Content ﬁltering mechanisms successfully complete execuon without errors; and
(b) Content ﬁltering acons occur in the correct order and comply with [Assignment:
organizaon-deﬁned policy].
Discussion: Content ﬁltering is the process of inspecng informaon as it traverses a cross-
domain soluon and determines if the informaon meets a predeﬁned security policy. An
orchestraon engine coordinates the sequencing of acvies (manual and automated) in
a content ﬁltering process. Errors are deﬁned as either anomalous acons or unexpected
terminaon of the content ﬁlter process. This is not the same as a ﬁlter failing content due to
non-compliance with policy. Content ﬁlter reports are a commonly used mechanism to ensure
that expected ﬁltering acons are completed successfully.
(30) INFORMATION FLOW ENFORCEMENT | FILTER MECHANISMS USING MULTIPLE
PROCESSES
When transferring informaon between diﬀerent security domains, implement content
ﬁltering mechanisms using mulple processes.
Discussion: The use of mulple processes to implement content ﬁltering mechanisms reduces the
likelihood of a single point of failure.
(31) INFORMATION FLOW ENFORCEMENT | FAILED CONTENT TRANSFER PREVENTION
When transferring informaon between diﬀerent security domains, prevent the transfer of
failed content to the receiving domain.
Discussion: Content that failed ﬁltering checks can corrupt the system if transferred to the
receiving domain.
(32) INFORMATION FLOW ENFORCEMENT | PROCESS REQUIREMENTS FOR INFORMATION
TRANSFER
When transferring informaon between diﬀerent security domains, the process that transfers
informaon between ﬁlter pipelines:
(a) Does not ﬁlter message content;
(b) Validates ﬁltering metadata;
(c) Ensures the content associated with the ﬁltering metadata has successfully completed
ﬁltering; and
(d) Transfers the content to the desnaon ﬁlter pipeline.
Discussion: The processes transferring informaon between ﬁlter pipelines have minimum
complexity and funconality to provide assurance that the processes operate correctly.
References: [IR 8112], [SP 800-160-1], [SP 800-162], [SP 800-178]
This document is produced from OSCAL source data
FAMILY: AC PAGE 20NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
AC-5 SEPARATION OF DUTIES
Control:
a. Idenfy and document [Assignment: organizaon-deﬁned dues of individuals requiring
separaon]; and
b. Deﬁne system access authorizaons to support separaon of dues.
Discussion: Separaon of dues addresses the potenal for abuse of authorized privileges and helps to
reduce the risk of malevolent acvity without collusion. Separaon of dues includes dividing mission
or business funcons and support funcons among diﬀerent individuals or roles, conducng system
support funcons with diﬀerent individuals, and ensuring that security personnel who administer
access control funcons do not also administer audit funcons. Because separaon of duty violaons
can span systems and applicaon domains, organizaons consider the enrety of systems and
system components when developing policy on separaon of dues. Separaon of dues is enforced
through the account management acvies in AC-2, access control mechanisms in AC-3, and identy
management acvies in IA-2, IA-4, and IA-12.
Related controls: AC-2, AC-3, AC-6, AU-9, CM-5, CM-11, CP-9, IA-2, IA-4, IA-5, IA-12, MA-3, MA-5, PS-2,
SA-8, SA-17.
References: None
AC-6 LEAST PRIVILEGE
Control: Employ the principle of least privilege, allowing only authorized accesses for users (or
processes acng on behalf of users) that are necessary to accomplish assigned organizaonal tasks.
Discussion: Organizaons employ least privilege for speciﬁc dues and systems. The principle of least
privilege is also applied to system processes, ensuring that the processes have access to systems
and operate at privilege levels no higher than necessary to accomplish organizaonal missions or
business funcons. Organizaons consider the creaon of addional processes, roles, and accounts
as necessary to achieve least privilege. Organizaons apply least privilege to the development,
implementaon, and operaon of organizaonal systems.
Related controls: AC-2, AC-3, AC-5, AC-16, CM-5, CM-11, PL-2, PM-12, SA-8, SA-15, SA-17, SC-38.
(1) LEAST PRIVILEGE | AUTHORIZE ACCESS TO SECURITY FUNCTIONS
Authorize access for [Assignment: organizaon-deﬁned individuals or roles] to:
(a) [Assignment: organizaon-deﬁned security funcons (deployed in hardware, soware,
and ﬁrmware)]; and
(b) [Assignment: organizaon-deﬁned security-relevant informaon].
Discussion: Security funcons include establishing system accounts, conﬁguring access
authorizaons (i.e., permissions, privileges), conﬁguring sengs for events to be audited, and
establishing intrusion detecon parameters. Security-relevant informaon includes ﬁltering
rules for routers or ﬁrewalls, conﬁguraon parameters for security services, cryptographic
key management informaon, and access control lists. Authorized personnel include security
administrators, system administrators, system security oﬃcers, system programmers, and other
privileged users.
Related controls: AC-17, AC-18, AC-19, AU-9, PE-2.
This document is produced from OSCAL source data
FAMILY: AC PAGE 21NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(2) LEAST PRIVILEGE | NON-PRIVILEGED ACCESS FOR NONSECURITY FUNCTIONS
Require that users of system accounts (or roles) with access to [Assignment: organizaon-
deﬁned security funcons or security-relevant informaon] use non-privileged accounts or
roles, when accessing nonsecurity funcons.
Discussion: Requiring the use of non-privileged accounts when accessing nonsecurity funcons
limits exposure when operang from within privileged accounts or roles. The inclusion of roles
addresses situaons where organizaons implement access control policies, such as role-based
access control, and where a change of role provides the same degree of assurance in the change
of access authorizaons for the user and the processes acng on behalf of the user as would be
provided by a change between a privileged and non-privileged account.
Related controls: AC-17, AC-18, AC-19, PL-4.
(3) LEAST PRIVILEGE | NETWORK ACCESS TO PRIVILEGED COMMANDS
Authorize network access to [Assignment: organizaon-deﬁned privileged commands] only for
[Assignment: organizaon-deﬁned compelling operaonal needs] and document the raonale
for such access in the security plan for the system.
Discussion: Network access is any access across a network connecon in lieu of local access (i.e.,
user being physically present at the device).
Related controls: AC-17, AC-18, AC-19.
(4) LEAST PRIVILEGE | SEPARATE PROCESSING DOMAINS
Provide separate processing domains to enable ﬁner-grained allocaon of user privileges.
Discussion: Providing separate processing domains for ﬁner-grained allocaon of user privileges
includes using virtualizaon techniques to permit addional user privileges within a virtual
machine while restricng privileges to other virtual machines or to the underlying physical
machine, implemenng separate physical domains, and employing hardware or soware domain
separaon mechanisms.
Related controls: AC-4, SC-2, SC-3, SC-30, SC-32, SC-39.
(5) LEAST PRIVILEGE | PRIVILEGED ACCOUNTS
Restrict privileged accounts on the system to [Assignment: organizaon-deﬁned personnel or
roles].
Discussion: Privileged accounts, including super user accounts, are typically described as system
administrator for various types of commercial oﬀ-the-shelf operang systems. Restricng
privileged accounts to speciﬁc personnel or roles prevents day-to-day users from accessing
privileged informaon or privileged funcons. Organizaons may diﬀerenate in the applicaon
of restricng privileged accounts between allowed privileges for local accounts and for
domain accounts provided that they retain the ability to control system conﬁguraons for key
parameters and as otherwise necessary to suﬃciently migate risk.
Related controls: IA-2, MA-3, MA-4.
This document is produced from OSCAL source data
FAMILY: AC PAGE 22NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(6) LEAST PRIVILEGE | PRIVILEGED ACCESS BY NON-ORGANIZATIONAL USERS
Prohibit privileged access to the system by non-organizaonal users.
Discussion: An organizaonal user is an employee or an individual considered by the organizaon
to have the equivalent status of an employee. Organizaonal users include contractors, guest
researchers, or individuals detailed from other organizaons. A non-organizaonal user is a
user who is not an organizaonal user. Policies and procedures for granng equivalent status
of employees to individuals include a need-to-know, cizenship, and the relaonship to the
organizaon.
Related controls: AC-18, AC-19, IA-2, IA-8.
(7) LEAST PRIVILEGE | REVIEW OF USER PRIVILEGES
(a) Review [Assignment: organizaon-deﬁned frequency] the privileges assigned to
[Assignment: organizaon-deﬁned roles or classes of users] to validate the need for such
privileges; and
(b) Reassign or remove privileges, if necessary, to correctly reﬂect organizaonal mission and
business needs.
Discussion: The need for certain assigned user privileges may change over me to reﬂect changes
in organizaonal mission and business funcons, environments of operaon, technologies, or
threats. A periodic review of assigned user privileges is necessary to determine if the raonale
for assigning such privileges remains valid. If the need cannot be revalidated, organizaons take
appropriate correcve acons.
Related control: CA-7.
(8) LEAST PRIVILEGE | PRIVILEGE LEVELS FOR CODE EXECUTION
Prevent the following soware from execung at higher privilege levels than users execung
the soware: [Assignment: organizaon-deﬁned soware].
Discussion: In certain situaons, soware applicaons or programs need to execute with elevated
privileges to perform required funcons. However, depending on the soware funconality and
conﬁguraon, if the privileges required for execuon are at a higher level than the privileges
assigned to organizaonal users invoking such applicaons or programs, those users may
indirectly be provided with greater privileges than assigned.
(9) LEAST PRIVILEGE | LOG USE OF PRIVILEGED FUNCTIONS
Log the execuon of privileged funcons.
Discussion: The misuse of privileged funcons, either intenonally or unintenonally by
authorized users or by unauthorized external enes that have compromised system accounts,
is a serious and ongoing concern and can have signiﬁcant adverse impacts on organizaons.
Logging and analyzing the use of privileged funcons is one way to detect such misuse and, in
doing so, help migate the risk from insider threats and the advanced persistent threat.
Related controls: AU-2, AU-3, AU-12.
This document is produced from OSCAL source data
FAMILY: AC PAGE 23NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(10) LEAST PRIVILEGE | PROHIBIT NON-PRIVILEGED USERS FROM EXECUTING PRIVILEGED
FUNCTIONS
Prevent non-privileged users from execung privileged funcons.
Discussion: Privileged funcons include disabling, circumvenng, or altering implemented
security or privacy controls, establishing system accounts, performing system integrity checks,
and administering cryptographic key management acvies. Non-privileged users are individuals
who do not possess appropriate authorizaons. Privileged funcons that require protecon
from non-privileged users include circumvenng intrusion detecon and prevenon mechanisms
or malicious code protecon mechanisms. Prevenng non-privileged users from execung
privileged funcons is enforced by AC-3.
References: None
AC-7 UNSUCCESSFUL LOGON ATTEMPTS
Control:
a. Enforce a limit of [Assignment: organizaon-deﬁned number] consecuve invalid logon aempts
by a user during a [Assignment: organizaon-deﬁned me period]; and
b. Automacally [Selecon (one or more): lock the account or node for an [Assignment:
organizaon-deﬁned me period]; lock the account or node unl released by an administrator;
delay next logon prompt per [Assignment: organizaon-deﬁned delay algorithm]; nofy system
administrator; take other [Assignment: organizaon-deﬁned acon]] when the maximum
number of unsuccessful aempts is exceeded.
Discussion: The need to limit unsuccessful logon aempts and take subsequent acon when the
maximum number of aempts is exceeded applies regardless of whether the logon occurs via a
local or network connecon. Due to the potenal for denial of service, automac lockouts iniated
by systems are usually temporary and automacally release aer a predetermined, organizaon-
deﬁned me period. If a delay algorithm is selected, organizaons may employ diﬀerent algorithms
for diﬀerent components of the system based on the capabilies of those components. Responses
to unsuccessful logon aempts may be implemented at the operang system and the applicaon
levels. Organizaon-deﬁned acons that may be taken when the number of allowed consecuve
invalid logon aempts is exceeded include prompng the user to answer a secret queson in addion
to the username and password, invoking a lockdown mode with limited user capabilies (instead of
full lockout), allowing users to only logon from speciﬁed Internet Protocol (IP) addresses, requiring
a CAPTCHA to prevent automated aacks, or applying user proﬁles such as locaon, me of day, IP
address, device, or Media Access Control (MAC) address. If automac system lockout or execuon
of a delay algorithm is not implemented in support of the availability objecve, organizaons
consider a combinaon of other acons to help prevent brute force aacks. In addion to the above,
organizaons can prompt users to respond to a secret queson before the number of allowed
unsuccessful logon aempts is exceeded. Automacally unlocking an account aer a speciﬁed period
of me is generally not permied. However, excepons may be required based on operaonal
mission or need.
Related controls: AC-2, AC-9, AU-2, AU-6, IA-5.
(1) UNSUCCESSFUL LOGON ATTEMPTS | AUTOMATIC ACCOUNT LOCK
[Withdrawn: Incorporated into AC-7.]
This document is produced from OSCAL source data
FAMILY: AC PAGE 24NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(2) UNSUCCESSFUL LOGON ATTEMPTS | PURGE OR WIPE MOBILE DEVICE
Purge or wipe informaon from [Assignment: organizaon-deﬁned mobile devices] based
on [Assignment: organizaon-deﬁned purging or wiping requirements and techniques] aer
[Assignment: organizaon-deﬁned number] consecuve, unsuccessful device logon aempts.
Discussion: A mobile device is a compung device that has a small form factor such that it
can be carried by a single individual; is designed to operate without a physical connecon;
possesses local, non-removable or removable data storage; and includes a self-contained power
source. Purging or wiping the device applies only to mobile devices for which the organizaon-
deﬁned number of unsuccessful logons occurs. The logon is to the mobile device, not to any one
account on the device. Successful logons to accounts on mobile devices reset the unsuccessful
logon count to zero. Purging or wiping may be unnecessary if the informaon on the device is
protected with suﬃciently strong encrypon mechanisms.
Related controls: AC-19, MP-5, MP-6.
(3) UNSUCCESSFUL LOGON ATTEMPTS | BIOMETRIC ATTEMPT LIMITING
Limit the number of unsuccessful biometric logon aempts to [Assignment: organizaon-
deﬁned number].
Discussion: Biometrics are probabilisc in nature. The ability to successfully authencate can be
impacted by many factors, including matching performance and presentaon aack detecon
mechanisms. Organizaons select the appropriate number of aempts for users based on
organizaonally-deﬁned factors.
Related control: IA-3.
(4) UNSUCCESSFUL LOGON ATTEMPTS | USE OF ALTERNATE AUTHENTICATION FACTOR
(a) Allow the use of [Assignment: organizaon-deﬁned authencaon factors] that are
diﬀerent from the primary authencaon factors aer the number of organizaon-
deﬁned consecuve invalid logon aempts have been exceeded; and
(b) Enforce a limit of [Assignment: organizaon-deﬁned number] consecuve invalid
logon aempts through use of the alternave factors by a user during a [Assignment:
organizaon-deﬁned me period].
Discussion: The use of alternate authencaon factors supports the objecve of availability and
allows a user who has inadvertently been locked out to use addional authencaon factors to
bypass the lockout.
Related control: IA-3.
References: [SP 800-124], [SP 800-63-3]
AC-8 SYSTEM USE NOTIFICATION
Control:
a. Display [Assignment: organizaon-deﬁned system use noﬁcaon message or banner] to users
before granng access to the system that provides privacy and security noces consistent with
This document is produced from OSCAL source data
FAMILY: AC PAGE 25NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
applicable laws, execuve orders, direcves, regulaons, policies, standards, and guidelines and
state that:
1. Users are accessing a U.S. Government system;
2. System usage may be monitored, recorded, and subject to audit;
3. Unauthorized use of the system is prohibited and subject to criminal and civil penales; and
4. Use of the system indicates consent to monitoring and recording;
b. Retain the noﬁcaon message or banner on the screen unl users acknowledge the usage
condions and take explicit acons to log on to or further access the system; and
c. For publicly accessible systems:
1. Display system use informaon [Assignment: organizaon-deﬁned condions], before
granng further access to the publicly accessible system;
2. Display references, if any, to monitoring, recording, or auding that are consistent with
privacy accommodaons for such systems that generally prohibit those acvies; and
3. Include a descripon of the authorized uses of the system.
Discussion: System use noﬁcaons can be implemented using messages or warning banners displayed
before individuals log in to systems. System use noﬁcaons are used only for access via logon
interfaces with human users. Noﬁcaons are not required when human interfaces do not exist.
Based on an assessment of risk, organizaons consider whether or not a secondary system use
noﬁcaon is needed to access applicaons or other system resources aer the inial network logon.
Organizaons consider system use noﬁcaon messages or banners displayed in mulple languages
based on organizaonal needs and the demographics of system users. Organizaons consult with
the privacy oﬃce for input regarding privacy messaging and the Oﬃce of the General Counsel or
organizaonal equivalent for legal review and approval of warning banner content.
Related controls: AC-14, PL-4, SI-4.
References: None
AC-9 PREVIOUS LOGON NOTIFICATION
Control: Nofy the user, upon successful logon to the system, of the date and me of the last logon.
Discussion: Previous logon noﬁcaon is applicable to system access via human user interfaces and
access to systems that occurs in other types of architectures. Informaon about the last successful
logon allows the user to recognize if the date and me provided is not consistent with the user’s last
access.
Related controls: AC-7, PL-4.
(1) PREVIOUS LOGON NOTIFICATION | UNSUCCESSFUL LOGONS
Nofy the user, upon successful logon, of the number of unsuccessful logon aempts since the
last successful logon.
Discussion: Informaon about the number of unsuccessful logon aempts since the last
successful logon allows the user to recognize if the number of unsuccessful logon aempts is
consistent with the user’s actual logon aempts.
This document is produced from OSCAL source data
FAMILY: AC PAGE 26NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(2) PREVIOUS LOGON NOTIFICATION | SUCCESSFUL AND UNSUCCESSFUL LOGONS
Nofy the user, upon successful logon, of the number of [Selecon: successful logons;
unsuccessful logon aempts; both] during [Assignment: organizaon-deﬁned me period].
Discussion: Informaon about the number of successful and unsuccessful logon aempts within a
speciﬁed me period allows the user to recognize if the number and type of logon aempts are
consistent with the user’s actual logon aempts.
(3) PREVIOUS LOGON NOTIFICATION | NOTIFICATION OF ACCOUNT CHANGES
Nofy the user, upon successful logon, of changes to [Assignment: organizaon-deﬁned
security-related characteriscs or parameters of the user’s account] during [Assignment:
organizaon-deﬁned me period].
Discussion: Informaon about changes to security-related account characteriscs within a
speciﬁed me period allows users to recognize if changes were made without their knowledge.
(4) PREVIOUS LOGON NOTIFICATION | ADDITIONAL LOGON INFORMATION
Nofy the user, upon successful logon, of the following addional informaon: [Assignment:
organizaon-deﬁned addional informaon].
Discussion: Organizaons can specify addional informaon to be provided to users upon logon,
including the locaon of the last logon. User locaon is deﬁned as informaon that can be
determined by systems, such as Internet Protocol (IP) addresses from which network logons
occurred, noﬁcaons of local logons, or device idenﬁers.
References: None
AC-10 CONCURRENT SESSION CONTROL
Control: Limit the number of concurrent sessions for each [Assignment: organizaon-deﬁned account
and/or account type] to [Assignment: organizaon-deﬁned number].
Discussion: Organizaons may deﬁne the maximum number of concurrent sessions for system
accounts globally, by account type, by account, or any combinaon thereof. For example,
organizaons may limit the number of concurrent sessions for system administrators or other
individuals working in parcularly sensive domains or mission-crical applicaons. Concurrent
session control addresses concurrent sessions for system accounts. It does not, however, address
concurrent sessions by single users via mulple system accounts.
Related control: SC-23.
References: None
AC-11 DEVICE LOCK
Control:
a. Prevent further access to the system by [Selecon (one or more): iniang a device lock aer
[Assignment: organizaon-deﬁned me period] of inacvity; requiring the user to iniate a device
lock before leaving the system unaended]; and
b. Retain the device lock unl the user reestablishes access using established idenﬁcaon and
authencaon procedures.
This document is produced from OSCAL source data
FAMILY: AC PAGE 27NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
Discussion: Device locks are temporary acons taken to prevent logical access to organizaonal
systems when users stop work and move away from the immediate vicinity of those systems but
do not want to log out because of the temporary nature of their absences. Device locks can be
implemented at the operang system level or at the applicaon level. A proximity lock may be used to
iniate the device lock (e.g., via a Bluetooth-enabled device or dongle). User-iniated device locking is
behavior or policy-based and, as such, requires users to take physical acon to iniate the device lock.
Device locks are not an acceptable substute for logging out of systems, such as when organizaons
require users to log out at the end of workdays.
Related controls: AC-2, AC-7, IA-11, PL-4.
(1) DEVICE LOCK | PATTERN-HIDING DISPLAYS
Conceal, via the device lock, informaon previously visible on the display with a publicly
viewable image.
Discussion: The paern-hiding display can include stac or dynamic images, such as paerns used
with screen savers, photographic images, solid colors, clock, baery life indicator, or a blank
screen with the caveat that controlled unclassiﬁed informaon is not displayed.
References: None
AC-12 SESSION TERMINATION
Control: Automacally terminate a user session aer [Assignment: organizaon-deﬁned condions or
trigger events requiring session disconnect].
Discussion: Session terminaon addresses the terminaon of user-iniated logical sessions (in contrast
to SC-10, which addresses the terminaon of network connecons associated with communicaons
sessions (i.e., network disconnect)). A logical session (for local, network, and remote access) is
iniated whenever a user (or process acng on behalf of a user) accesses an organizaonal system.
Such user sessions can be terminated without terminang network sessions. Session terminaon ends
all processes associated with a user’s logical session except for those processes that are speciﬁcally
created by the user (i.e., session owner) to connue aer the session is terminated. Condions or
trigger events that require automac terminaon of the session include organizaon-deﬁned periods
of user inacvity, targeted responses to certain types of incidents, or me-of-day restricons on
system use.
Related controls: MA-4, SC-10, SC-23.
(1) SESSION TERMINATION | USER-INITIATED LOGOUTS
Provide a logout capability for user-iniated communicaons sessions whenever
authencaon is used to gain access to [Assignment: organizaon-deﬁned informaon
resources].
Discussion: Informaon resources to which users gain access via authencaon include local
workstaons, databases, and password-protected websites or web-based services.
This document is produced from OSCAL source data
FAMILY: AC PAGE 28NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(2) SESSION TERMINATION | TERMINATION MESSAGE
Display an explicit logout message to users indicang the terminaon of authencated
communicaons sessions.
Discussion: Logout messages for web access can be displayed aer authencated sessions have
been terminated. However, for certain types of sessions, including ﬁle transfer protocol (FTP)
sessions, systems typically send logout messages as ﬁnal messages prior to terminang sessions.
(3) SESSION TERMINATION | TIMEOUT WARNING MESSAGE
Display an explicit message to users indicang that the session will end in [Assignment:
organizaon-deﬁned me unl end of session].
Discussion: To increase usability, nofy users of pending session terminaon and prompt users to
connue the session. The pending session terminaon me period is based on the parameters
deﬁned in the AC-12 base control.
References: None
AC-13 Supervision and Review — Access Control
[Withdrawn: Incorporated into AC-2, AU-6.]
AC-14 PERMITTED ACTIONS WITHOUT IDENTIFICATION OR AUTHENTICATION
Control:
a. Idenfy [Assignment: organizaon-deﬁned user acons] that can be performed on the system
without idenﬁcaon or authencaon consistent with organizaonal mission and business
funcons; and
b. Document and provide supporng raonale in the security plan for the system, user acons not
requiring idenﬁcaon or authencaon.
Discussion: Speciﬁc user acons may be permied without idenﬁcaon or authencaon if
organizaons determine that idenﬁcaon and authencaon are not required for the speciﬁed
user acons. Organizaons may allow a limited number of user acons without idenﬁcaon or
authencaon, including when individuals access public websites or other publicly accessible federal
systems, when individuals use mobile phones to receive calls, or when facsimiles are received.
Organizaons idenfy acons that normally require idenﬁcaon or authencaon but may,
under certain circumstances, allow idenﬁcaon or authencaon mechanisms to be bypassed.
Such bypasses may occur, for example, via a soware-readable physical switch that commands
bypass of the logon funconality and is protected from accidental or unmonitored use. Perming
acons without idenﬁcaon or authencaon does not apply to situaons where idenﬁcaon
and authencaon have already occurred and are not repeated but rather to situaons where
idenﬁcaon and authencaon have not yet occurred. Organizaons may decide that there
are no user acons that can be performed on organizaonal systems without idenﬁcaon and
authencaon, and therefore, the value for the assignment operaon can be none.
Related controls: AC-8, IA-2, PL-2.
(1) PERMITTED ACTIONS WITHOUT IDENTIFICATION OR AUTHENTICATION | NECESSARY
USES
[Withdrawn: Incorporated into AC-14.]
This document is produced from OSCAL source data
FAMILY: AC PAGE 29NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
References: None
AC-15 Automated Marking
[Withdrawn: Incorporated into MP-3.]
AC-16 SECURITY AND PRIVACY ATTRIBUTES
Control:
a. Provide the means to associate [Assignment: organizaon-deﬁned types of security and privacy
aributes] with [Assignment: organizaon-deﬁned security and privacy aribute values] for
informaon in storage, in process, and/or in transmission;
b. Ensure that the aribute associaons are made and retained with the informaon;
c. Establish the following permied security and privacy aributes from the aributes deﬁned
in AC-16a for [Assignment: organizaon-deﬁned systems]: [Assignment: organizaon-deﬁned
security and privacy aributes];
d. Determine the following permied aribute values or ranges for each of the established
aributes: [Assignment: organizaon-deﬁned aribute values or ranges for established
aributes];
e. Audit changes to aributes; and
f. Review [Assignment: organizaon-deﬁned security and privacy aributes] for applicability
[Assignment: organizaon-deﬁned frequency].
Discussion: Informaon is represented internally within systems using abstracons known as data
structures. Internal data structures can represent diﬀerent types of enes, both acve and passive.
Acve enes, also known as subjects, are typically associated with individuals, devices, or processes
acng on behalf of individuals. Passive enes, also known as objects, are typically associated with
data structures, such as records, buﬀers, tables, ﬁles, inter-process pipes, and communicaons
ports. Security aributes, a form of metadata, are abstracons that represent the basic properes
or characteriscs of acve and passive enes with respect to safeguarding informaon. Privacy
aributes, which may be used independently or in conjuncon with security aributes, represent
the basic properes or characteriscs of acve or passive enes with respect to the management of
personally idenﬁable informaon. Aributes can be either explicitly or implicitly associated with the
informaon contained in organizaonal systems or system components.
Aributes may be associated with acve enes (i.e., subjects) that have the potenal to send
or receive informaon, cause informaon to ﬂow among objects, or change the system state.
These aributes may also be associated with passive enes (i.e., objects) that contain or receive
informaon. The associaon of aributes to subjects and objects by a system is referred to as binding
and is inclusive of seng the aribute value and the aribute type. Aributes, when bound to
data or informaon, permit the enforcement of security and privacy policies for access control and
informaon ﬂow control, including data retenon limits, permied uses of personally idenﬁable
informaon, and idenﬁcaon of personal informaon within data objects. Such enforcement
occurs through organizaonal processes or system funcons or mechanisms. The binding techniques
implemented by systems aﬀect the strength of aribute binding to informaon. Binding strength and
the assurance associated with binding techniques play important parts in the trust that organizaons
have in the informaon ﬂow enforcement process. The binding techniques aﬀect the number and
degree of addional reviews required by organizaons. The content or assigned values of aributes
can directly aﬀect the ability of individuals to access organizaonal informaon.
This document is produced from OSCAL source data
FAMILY: AC PAGE 30NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
Organizaons can deﬁne the types of aributes needed for systems to support missions or business
funcons. There are many values that can be assigned to a security aribute. By specifying the
permied aribute ranges and values, organizaons ensure that aribute values are meaningful and
relevant. Labeling refers to the associaon of aributes with the subjects and objects represented by
the internal data structures within systems. This facilitates system-based enforcement of informaon
security and privacy policies. Labels include classiﬁcaon of informaon in accordance with legal and
compliance requirements (e.g., top secret, secret, conﬁdenal, controlled unclassiﬁed), informaon
impact level; high value asset informaon, access authorizaons, naonality; data life cycle protecon
(i.e., encrypon and data expiraon), personally idenﬁable informaon processing permissions,
including individual consent to personally idenﬁable informaon processing, and contractor
aﬃliaon. A related term to labeling is marking. Marking refers to the associaon of aributes
with objects in a human-readable form and displayed on system media. Marking enables manual,
procedural, or process-based enforcement of informaon security and privacy policies. Security and
privacy labels may have the same value as media markings (e.g., top secret, secret, conﬁdenal). See
MP-3 (Media Marking).
Related controls: AC-3, AC-4, AC-6, AC-21, AC-25, AU-2, AU-10, MP-3, PE-22, PT-2, PT-3, PT-4, SC-11,
SC-16, SI-12, SI-18.
(1) SECURITY AND PRIVACY ATTRIBUTES | DYNAMIC ATTRIBUTE ASSOCIATION
Dynamically associate security and privacy aributes with [Assignment: organizaon-
deﬁned subjects and objects] in accordance with the following security and privacy policies as
informaon is created and combined: [Assignment: organizaon-deﬁned security and privacy
policies].
Discussion: Dynamic associaon of aributes is appropriate whenever the security or privacy
characteriscs of informaon change over me. Aributes may change due to informaon
aggregaon issues (i.e., characteriscs of individual data elements are diﬀerent from the
combined elements), changes in individual access authorizaons (i.e., privileges), changes in the
security category of informaon, or changes in security or privacy policies. Aributes may also
change situaonally.
(2) SECURITY AND PRIVACY ATTRIBUTES | ATTRIBUTE VALUE CHANGES BY AUTHORIZED
INDIVIDUALS
Provide authorized individuals (or processes acng on behalf of individuals) the capability to
deﬁne or change the value of associated security and privacy aributes.
Discussion: The content or assigned values of aributes can directly aﬀect the ability of
individuals to access organizaonal informaon. Therefore, it is important for systems to be able
to limit the ability to create or modify aributes to authorized individuals.
(3) SECURITY AND PRIVACY ATTRIBUTES | MAINTENANCE OF ATTRIBUTE ASSOCIATIONS BY
SYSTEM
Maintain the associaon and integrity of [Assignment: organizaon-deﬁned security and
privacy aributes] to [Assignment: organizaon-deﬁned subjects and objects].
Discussion: Maintaining the associaon and integrity of security and privacy aributes to subjects
and objects with suﬃcient assurance helps to ensure that the aribute associaons can be
used as the basis of automated policy acons. The integrity of speciﬁc items, such as security
conﬁguraon ﬁles, may be maintained through the use of an integrity monitoring mechanism
This document is produced from OSCAL source data
FAMILY: AC PAGE 31NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
that detects anomalies and changes that deviate from known good baselines. Automated policy
acons include retenon date expiraons, access control decisions, informaon ﬂow control
decisions, and informaon disclosure decisions.
(4) SECURITY AND PRIVACY ATTRIBUTES | ASSOCIATION OF ATTRIBUTES BY AUTHORIZED
INDIVIDUALS
Provide the capability to associate [Assignment: organizaon-deﬁned security and privacy
aributes] with [Assignment: organizaon-deﬁned subjects and objects] by authorized
individuals (or processes acng on behalf of individuals).
Discussion: Systems, in general, provide the capability for privileged users to assign security
and privacy aributes to system-deﬁned subjects (e.g., users) and objects (e.g., directories,
ﬁles, and ports). Some systems provide addional capability for general users to assign security
and privacy aributes to addional objects (e.g., ﬁles, emails). The associaon of aributes
by authorized individuals is described in the design documentaon. The support provided by
systems can include prompng users to select security and privacy aributes to be associated
with informaon objects, employing automated mechanisms to categorize informaon with
aributes based on deﬁned policies, or ensuring that the combinaon of the security or privacy
aributes selected is valid. Organizaons consider the creaon, deleon, or modiﬁcaon of
aributes when deﬁning auditable events.
(5) SECURITY AND PRIVACY ATTRIBUTES | ATTRIBUTE DISPLAYS ON OBJECTS TO BE OUTPUT
Display security and privacy aributes in human-readable form on each object that the
system transmits to output devices to idenfy [Assignment: organizaon-deﬁned special
disseminaon, handling, or distribuon instrucons] using [Assignment: organizaon-deﬁned
human-readable, standard naming convenons].
Discussion: System outputs include printed pages, screens, or equivalent items. System output
devices include printers, notebook computers, video displays, smart phones, and tablets. To
migate the risk of unauthorized exposure of informaon (e.g., shoulder surﬁng), the outputs
display full aribute values when unmasked by the subscriber.
(6) SECURITY AND PRIVACY ATTRIBUTES | MAINTENANCE OF ATTRIBUTE ASSOCIATION
Require personnel to associate and maintain the associaon of [Assignment: organizaon-
deﬁned security and privacy aributes] with [Assignment: organizaon-deﬁned subjects and
objects] in accordance with [Assignment: organizaon-deﬁned security and privacy policies].
Discussion: Maintaining aribute associaon requires individual users (as opposed to the system)
to maintain associaons of deﬁned security and privacy aributes with subjects and objects.
(7) SECURITY AND PRIVACY ATTRIBUTES | CONSISTENT ATTRIBUTE INTERPRETATION
Provide a consistent interpretaon of security and privacy aributes transmied between
distributed system components.
Discussion: To enforce security and privacy policies across mulple system components in
distributed systems, organizaons provide a consistent interpretaon of security and privacy
aributes employed in access enforcement and ﬂow enforcement decisions. Organizaons
can establish agreements and processes to help ensure that distributed system components
implement aributes with consistent interpretaons in automated access enforcement and ﬂow
enforcement acons.
This document is produced from OSCAL source data
FAMILY: AC PAGE 32NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(8) SECURITY AND PRIVACY ATTRIBUTES | ASSOCIATION TECHNIQUES AND TECHNOLOGIES
Implement [Assignment: organizaon-deﬁned techniques and technologies] in associang
security and privacy aributes to informaon.
Discussion: The associaon of security and privacy aributes to informaon within systems
is important for conducng automated access enforcement and ﬂow enforcement acons.
The associaon of such aributes to informaon (i.e., binding) can be accomplished with
technologies and techniques that provide diﬀerent levels of assurance. For example, systems
can cryptographically bind aributes to informaon using digital signatures that support
cryptographic keys protected by hardware devices (somemes known as hardware roots of
trust).
Related controls: SC-12, SC-13.
(9) SECURITY AND PRIVACY ATTRIBUTES | ATTRIBUTE REASSIGNMENT — REGRADING
MECHANISMS
Change security and privacy aributes associated with informaon only via regrading
mechanisms validated using [Assignment: organizaon-deﬁned techniques or procedures].
Discussion: A regrading mechanism is a trusted process authorized to re-classify and re-label
data in accordance with a deﬁned policy excepon. Validated regrading mechanisms are
used by organizaons to provide the requisite levels of assurance for aribute reassignment
acvies. The validaon is facilitated by ensuring that regrading mechanisms are single purpose
and of limited funcon. Since security and privacy aribute changes can directly aﬀect policy
enforcement acons, implemenng trustworthy regrading mechanisms is necessary to help
ensure that such mechanisms perform in a consistent and correct mode of operaon.
(10) SECURITY AND PRIVACY ATTRIBUTES | ATTRIBUTE CONFIGURATION BY AUTHORIZED
INDIVIDUALS
Provide authorized individuals the capability to deﬁne or change the type and value of security
and privacy aributes available for associaon with subjects and objects.
Discussion: The content or assigned values of security and privacy aributes can directly aﬀect
the ability of individuals to access organizaonal informaon. Thus, it is important for systems
to be able to limit the ability to create or modify the type and value of aributes available for
associaon with subjects and objects to authorized individuals only.
References: [FIPS 140-3], [FIPS 186-4], [OMB A-130], [SP 800-162], [SP 800-178]
AC-17 REMOTE ACCESS
Control:
a. Establish and document usage restricons, conﬁguraon/connecon requirements, and
implementaon guidance for each type of remote access allowed; and
b. Authorize each type of remote access to the system prior to allowing such connecons.
Discussion: Remote access is access to organizaonal systems (or processes acng on behalf of users)
that communicate through external networks such as the Internet. Types of remote access include
dial-up, broadband, and wireless. Organizaons use encrypted virtual private networks (VPNs) to
enhance conﬁdenality and integrity for remote connecons. The use of encrypted VPNs provides
This document is produced from OSCAL source data
FAMILY: AC PAGE 33NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
suﬃcient assurance to the organizaon that it can eﬀecvely treat such connecons as internal
networks if the cryptographic mechanisms used are implemented in accordance with applicable laws,
execuve orders, direcves, regulaons, policies, standards, and guidelines. Sll, VPN connecons
traverse external networks, and the encrypted VPN does not enhance the availability of remote
connecons. VPNs with encrypted tunnels can also aﬀect the ability to adequately monitor network
communicaons traﬃc for malicious code. Remote access controls apply to systems other than
public web servers or systems designed for public access. Authorizaon of each remote access type
addresses authorizaon prior to allowing remote access without specifying the speciﬁc formats
for such authorizaon. While organizaons may use informaon exchange and system connecon
security agreements to manage remote access connecons to other systems, such agreements are
addressed as part of CA-3. Enforcing access restricons for remote access is addressed via AC-3.
Related controls: AC-2, AC-3, AC-4, AC-18, AC-19, AC-20, CA-3, CM-10, IA-2, IA-3, IA-8, MA-4, PE-17,
PL-2, PL-4, SC-10, SC-12, SC-13, SI-4.
(1) REMOTE ACCESS | MONITORING AND CONTROL
Employ automated mechanisms to monitor and control remote access methods.
Discussion: Monitoring and control of remote access methods allows organizaons to detect
aacks and help ensure compliance with remote access policies by auding the connecon
acvies of remote users on a variety of system components, including servers, notebook
computers, workstaons, smart phones, and tablets. Audit logging for remote access is enforced
by AU-2. Audit events are deﬁned in AU-2a.
Related controls: AU-2, AU-6, AU-12, AU-14.
(2) REMOTE ACCESS | PROTECTION OF CONFIDENTIALITY AND INTEGRITY USING
ENCRYPTION
Implement cryptographic mechanisms to protect the conﬁdenality and integrity of remote
access sessions.
Discussion: Virtual private networks can be used to protect the conﬁdenality and integrity of
remote access sessions. Transport Layer Security (TLS) is an example of a cryptographic protocol
that provides end-to-end communicaons security over networks and is used for Internet
communicaons and online transacons.
Related controls: SC-8, SC-12, SC-13.
(3) REMOTE ACCESS | MANAGED ACCESS CONTROL POINTS
Route remote accesses through authorized and managed network access control points.
Discussion: Organizaons consider the Trusted Internet Connecons (TIC) iniave DHS TIC
requirements for external network connecons since liming the number of access control
points for remote access reduces aack surfaces.
Related control: SC-7.
This document is produced from OSCAL source data
FAMILY: AC PAGE 34NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(4) REMOTE ACCESS | PRIVILEGED COMMANDS AND ACCESS
(a) Authorize the execuon of privileged commands and access to security-relevant
informaon via remote access only in a format that provides assessable evidence and for
the following needs: [Assignment: organizaon-deﬁned needs]; and
(b) Document the raonale for remote access in the security plan for the system.
Discussion: Remote access to systems represents a signiﬁcant potenal vulnerability that can be
exploited by adversaries. As such, restricng the execuon of privileged commands and access
to security-relevant informaon via remote access reduces the exposure of the organizaon and
the suscepbility to threats by adversaries to the remote access capability.
Related controls: AC-6, SC-12, SC-13.
(5) REMOTE ACCESS | MONITORING FOR UNAUTHORIZED CONNECTIONS
[Withdrawn: Incorporated into SI-4.]
(6) REMOTE ACCESS | PROTECTION OF MECHANISM INFORMATION
Protect informaon about remote access mechanisms from unauthorized use and disclosure.
Discussion: Remote access to organizaonal informaon by non-organizaonal enes can
increase the risk of unauthorized use and disclosure about remote access mechanisms. The
organizaon considers including remote access requirements in the informaon exchange
agreements with other organizaons, as applicable. Remote access requirements can also be
included in rules of behavior (see PL-4) and access agreements (see PS-6).
Related controls: AT-2, AT-3, PS-6.
(7) REMOTE ACCESS | ADDITIONAL PROTECTION FOR SECURITY FUNCTION ACCESS
[Withdrawn: Incorporated into AC-3(10).]
(8) REMOTE ACCESS | DISABLE NONSECURE NETWORK PROTOCOLS
[Withdrawn: Incorporated into CM-7.]
(9) REMOTE ACCESS | DISCONNECT OR DISABLE ACCESS
Provide the capability to disconnect or disable remote access to the system within
[Assignment: organizaon-deﬁned me period].
Discussion: The speed of system disconnect or disablement varies based on the cricality of
missions or business funcons and the need to eliminate immediate or future remote access to
systems.
(10) REMOTE ACCESS | AUTHENTICATE REMOTE COMMANDS
Implement [Assignment: organizaon-deﬁned mechanisms] to authencate [Assignment:
organizaon-deﬁned remote commands].
Discussion: Authencang remote commands protects against unauthorized commands and the
replay of authorized commands. The ability to authencate remote commands is important for
remote systems for which loss, malfuncon, misdirecon, or exploitaon would have immediate
This document is produced from OSCAL source data
FAMILY: AC PAGE 35NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
or serious consequences, such as injury, death, property damage, loss of high value assets,
failure of mission or business funcons, or compromise of classiﬁed or controlled unclassiﬁed
informaon. Authencaon mechanisms for remote commands ensure that systems accept
and execute commands in the order intended, execute only authorized commands, and reject
unauthorized commands. Cryptographic mechanisms can be used, for example, to authencate
remote commands.
Related controls: SC-12, SC-13, SC-23.
References: [IR 7966], [SP 800-113], [SP 800-114], [SP 800-121], [SP 800-46], [SP 800-77]
AC-18 WIRELESS ACCESS
Control:
a. Establish conﬁguraon requirements, connecon requirements, and implementaon guidance
for each type of wireless access; and
b. Authorize each type of wireless access to the system prior to allowing such connecons.
Discussion: Wireless technologies include microwave, packet radio (ultra-high frequency or very high
frequency), 802.11x, and Bluetooth. Wireless networks use authencaon protocols that provide
authencator protecon and mutual authencaon.
Related controls: AC-2, AC-3, AC-17, AC-19, CA-9, CM-7, IA-2, IA-3, IA-8, PL-4, SC-40, SC-43, SI-4.
(1) WIRELESS ACCESS | AUTHENTICATION AND ENCRYPTION
Protect wireless access to the system using authencaon of [Selecon (one or more): users;
devices] and encrypon.
Discussion: Wireless networking capabilies represent a signiﬁcant potenal vulnerability
that can be exploited by adversaries. To protect systems with wireless access points, strong
authencaon of users and devices along with strong encrypon can reduce suscepbility to
threats by adversaries involving wireless technologies.
Related controls: SC-8, SC-12, SC-13.
(2) WIRELESS ACCESS | MONITORING UNAUTHORIZED CONNECTIONS
[Withdrawn: Incorporated into SI-4.]
(3) WIRELESS ACCESS | DISABLE WIRELESS NETWORKING
Disable, when not intended for use, wireless networking capabilies embedded within system
components prior to issuance and deployment.
Discussion: Wireless networking capabilies that are embedded within system components
represent a signiﬁcant potenal vulnerability that can be exploited by adversaries. Disabling
wireless capabilies when not needed for essenal organizaonal missions or funcons can
reduce suscepbility to threats by adversaries involving wireless technologies.
This document is produced from OSCAL source data
FAMILY: AC PAGE 36NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(4) WIRELESS ACCESS | RESTRICT CONFIGURATIONS BY USERS
Idenfy and explicitly authorize users allowed to independently conﬁgure wireless networking
capabilies.
Discussion: Organizaonal authorizaons to allow selected users to conﬁgure wireless networking
capabilies are enforced, in part, by the access enforcement mechanisms employed within
organizaonal systems.
Related controls: SC-7, SC-15.
(5) WIRELESS ACCESS | ANTENNAS AND TRANSMISSION POWER LEVELS
Select radio antennas and calibrate transmission power levels to reduce the probability
that signals from wireless access points can be received outside of organizaon-controlled
boundaries.
Discussion: Acons that may be taken to limit unauthorized use of wireless communicaons
outside of organizaon-controlled boundaries include reducing the power of wireless
transmissions so that the transmissions are less likely to emit a signal that can be captured
outside of the physical perimeters of the organizaon, employing measures such as emissions
security to control wireless emanaons, and using direconal or beamforming antennas that
reduce the likelihood that unintended receivers will be able to intercept signals. Prior to taking
such migang acons, organizaons can conduct periodic wireless surveys to understand the
radio frequency proﬁle of organizaonal systems as well as other systems that may be operang
in the area.
Related control: PE-19.
References: [SP 800-94], [SP 800-97]
AC-19 ACCESS CONTROL FOR MOBILE DEVICES
Control:
a. Establish conﬁguraon requirements, connecon requirements, and implementaon guidance
for organizaon-controlled mobile devices, to include when such devices are outside of
controlled areas; and
b. Authorize the connecon of mobile devices to organizaonal systems.
Discussion: A mobile device is a compung device that has a small form factor such that it can easily
be carried by a single individual; is designed to operate without a physical connecon; possesses
local, non-removable or removable data storage; and includes a self-contained power source. Mobile
device funconality may also include voice communicaon capabilies, on-board sensors that allow
the device to capture informaon, and/or built-in features for synchronizing local data with remote
locaons. Examples include smart phones and tablets. Mobile devices are typically associated with
a single individual. The processing, storage, and transmission capability of the mobile device may
be comparable to or merely a subset of notebook/desktop systems, depending on the nature and
intended purpose of the device. Protecon and control of mobile devices is behavior or policy-
based and requires users to take physical acon to protect and control such devices when outside of
controlled areas. Controlled areas are spaces for which organizaons provide physical or procedural
controls to meet the requirements established for protecng informaon and systems.
Due to the large variety of mobile devices with diﬀerent characteriscs and capabilies, organizaonal
restricons may vary for the diﬀerent classes or types of such devices. Usage restricons and
speciﬁc implementaon guidance for mobile devices include conﬁguraon management, device
This document is produced from OSCAL source data
FAMILY: AC PAGE 37NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
idenﬁcaon and authencaon, implementaon of mandatory protecve soware, scanning devices
for malicious code, updang virus protecon soware, scanning for crical soware updates and
patches, conducng primary operang system (and possibly other resident soware) integrity checks,
and disabling unnecessary hardware.
Usage restricons and authorizaon to connect may vary among organizaonal systems. For example,
the organizaon may authorize the connecon of mobile devices to its network and impose a set of
usage restricons, while a system owner may withhold authorizaon for mobile device connecon
to speciﬁc applicaons or impose addional usage restricons before allowing mobile device
connecons to a system. Adequate security for mobile devices goes beyond the requirements
speciﬁed in AC-19. Many safeguards for mobile devices are reﬂected in other controls. AC-20
addresses mobile devices that are not organizaon-controlled.
Related controls: AC-3, AC-4, AC-7, AC-11, AC-17, AC-18, AC-20, CA-9, CM-2, CM-6, IA-2, IA-3, MP-2,
MP-4, MP-5, MP-7, PL-4, SC-7, SC-34, SC-43, SI-3, SI-4.
(1) ACCESS CONTROL FOR MOBILE DEVICES | USE OF WRITABLE AND PORTABLE STORAGE
DEVICES
[Withdrawn: Incorporated into MP-7.]
(2) ACCESS CONTROL FOR MOBILE DEVICES | USE OF PERSONALLY OWNED PORTABLE
STORAGE DEVICES
[Withdrawn: Incorporated into MP-7.]
(3) ACCESS CONTROL FOR MOBILE DEVICES | USE OF PORTABLE STORAGE DEVICES WITH
NO IDENTIFIABLE OWNER
[Withdrawn: Incorporated into MP-7.]
(4) ACCESS CONTROL FOR MOBILE DEVICES | RESTRICTIONS FOR CLASSIFIED INFORMATION
(a) Prohibit the use of unclassiﬁed mobile devices in facilies containing systems processing,
storing, or transming classiﬁed informaon unless speciﬁcally permied by the
authorizing oﬃcial; and
(b) Enforce the following restricons on individuals permied by the authorizing oﬃcial to
use unclassiﬁed mobile devices in facilies containing systems processing, storing, or
transming classiﬁed informaon:
(1) Connecon of unclassiﬁed mobile devices to classiﬁed systems is prohibited;
(2) Connecon of unclassiﬁed mobile devices to unclassiﬁed systems requires approval
from the authorizing oﬃcial;
(3) Use of internal or external modems or wireless interfaces within the unclassiﬁed
mobile devices is prohibited; and
(4) Unclassiﬁed mobile devices and the informaon stored on those devices are subject
to random reviews and inspecons by [Assignment: organizaon-deﬁned security
oﬃcials], and if classiﬁed inform
(c) Restrict the connecon of classiﬁed mobile devices to classiﬁed systems in accordance
with [Assignment: organizaon-deﬁned security policies].
Discussion: None.
This document is produced from OSCAL source data
FAMILY: AC PAGE 38NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
Related controls: CM-8, IR-4.
(5) ACCESS CONTROL FOR MOBILE DEVICES | FULL DEVICE OR CONTAINER-BASED
ENCRYPTION
Employ [Selecon: full-device encrypon; container-based encrypon] to protect the
conﬁdenality and integrity of informaon on [Assignment: organizaon-deﬁned mobile
devices].
Discussion: Container-based encrypon provides a more ﬁne-grained approach to data and
informaon encrypon on mobile devices, including encrypng selected data structures such as
ﬁles, records, or ﬁelds.
Related controls: SC-12, SC-13, SC-28.
References: [SP 800-114], [SP 800-124]
AC-20 USE OF EXTERNAL SYSTEMS
Control:
a. [Selecon (one or more): Establish [Assignment: organizaon-deﬁned terms and condions];
Idenfy [Assignment: organizaon-deﬁned controls asserted to be implemented on external
systems]], consistent with the trust relaonships established with other organizaons owning,
operang, and/or maintaining external systems, allowing authorized individuals to:
1. Access the system from external systems; and
2. Process, store, or transmit organizaon-controlled informaon using external systems; or
b. Prohibit the use of [Assignment: organizaonally-deﬁned types of external systems].
Discussion: External systems are systems that are used by but not part of organizaonal systems,
and for which the organizaon has no direct control over the implementaon of required controls
or the assessment of control eﬀecveness. External systems include personally owned systems,
components, or devices; privately owned compung and communicaons devices in commercial
or public facilies; systems owned or controlled by nonfederal organizaons; systems managed by
contractors; and federal informaon systems that are not owned by, operated by, or under the direct
supervision or authority of the organizaon. External systems also include systems owned or operated
by other components within the same organizaon and systems within the organizaon with diﬀerent
authorizaon boundaries. Organizaons have the opon to prohibit the use of any type of external
system or prohibit the use of speciﬁed types of external systems, (e.g., prohibit the use of any external
system that is not organizaonally owned or prohibit the use of personally-owned systems).
For some external systems (i.e., systems operated by other organizaons), the trust relaonships that
have been established between those organizaons and the originang organizaon may be such
that no explicit terms and condions are required. Systems within these organizaons may not be
considered external. These situaons occur when, for example, there are pre-exisng informaon
exchange agreements (either implicit or explicit) established between organizaons or components
or when such agreements are speciﬁed by applicable laws, execuve orders, direcves, regulaons,
policies, or standards. Authorized individuals include organizaonal personnel, contractors, or other
individuals with authorized access to organizaonal systems and over which organizaons have the
authority to impose speciﬁc rules of behavior regarding system access. Restricons that organizaons
impose on authorized individuals need not be uniform, as the restricons may vary depending on
trust relaonships between organizaons. Therefore, organizaons may choose to impose diﬀerent
security restricons on contractors than on state, local, or tribal governments.
This document is produced from OSCAL source data
FAMILY: AC PAGE 39NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
External systems used to access public interfaces to organizaonal systems are outside the scope
of AC-20. Organizaons establish speciﬁc terms and condions for the use of external systems in
accordance with organizaonal security policies and procedures. At a minimum, terms and condions
address the speciﬁc types of applicaons that can be accessed on organizaonal systems from
external systems and the highest security category of informaon that can be processed, stored, or
transmied on external systems. If the terms and condions with the owners of the external systems
cannot be established, organizaons may impose restricons on organizaonal personnel using those
external systems.
Related controls: AC-2, AC-3, AC-17, AC-19, CA-3, PL-2, PL-4, SA-9, SC-7.
(1) USE OF EXTERNAL SYSTEMS | LIMITS ON AUTHORIZED USE
Permit authorized individuals to use an external system to access the system or to process,
store, or transmit organizaon-controlled informaon only aer:
(a) Veriﬁcaon of the implementaon of controls on the external system as speciﬁed in the
organizaon’s security and privacy policies and security and privacy plans; or
(b) Retenon of approved system connecon or processing agreements with the
organizaonal enty hosng the external system.
Discussion: Liming authorized use recognizes circumstances where individuals using external
systems may need to access organizaonal systems. Organizaons need assurance that the
external systems contain the necessary controls so as not to compromise, damage, or otherwise
harm organizaonal systems. Veriﬁcaon that the required controls have been implemented can
be achieved by external, independent assessments, aestaons, or other means, depending on
the conﬁdence level required by organizaons.
Related control: CA-2.
(2) USE OF EXTERNAL SYSTEMS | PORTABLE STORAGE DEVICES — RESTRICTED USE
Restrict the use of organizaon-controlled portable storage devices by authorized individuals
on external systems using [Assignment: organizaon-deﬁned restricons].
Discussion: Limits on the use of organizaon-controlled portable storage devices in external
systems include restricons on how the devices may be used and under what condions the
devices may be used.
Related controls: MP-7, SC-41.
(3) USE OF EXTERNAL SYSTEMS | NON-ORGANIZATIONALLY OWNED SYSTEMS —
RESTRICTED USE
Restrict the use of non-organizaonally owned systems or system components to process,
store, or transmit organizaonal informaon using [Assignment: organizaon-deﬁned
restricons].
Discussion: Non-organizaonally owned systems or system components include systems or
system components owned by other organizaons as well as personally owned devices. There
are potenal risks to using non-organizaonally owned systems or components. In some cases,
the risk is suﬃciently high as to prohibit such use (see AC-20 b.). In other cases, the use of
such systems or system components may be allowed but restricted in some way. Restricons
include requiring the implementaon of approved controls prior to authorizing the connecon
of non-organizaonally owned systems and components; liming access to types of informaon,
services, or applicaons; using virtualizaon techniques to limit processing and storage acvies
This document is produced from OSCAL source data
FAMILY: AC PAGE 40NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
to servers or system components provisioned by the organizaon; and agreeing to the terms
and condions for usage. Organizaons consult with the Oﬃce of the General Counsel regarding
legal issues associated with using personally owned devices, including requirements for
conducng forensic analyses during invesgaons aer an incident.
(4) USE OF EXTERNAL SYSTEMS | NETWORK ACCESSIBLE STORAGE DEVICES — PROHIBITED
USE
Prohibit the use of [Assignment: organizaon-deﬁned network accessible storage devices] in
external systems.
Discussion: Network-accessible storage devices in external systems include online storage devices
in public, hybrid, or community cloud-based systems.
(5) USE OF EXTERNAL SYSTEMS | PORTABLE STORAGE DEVICES — PROHIBITED USE
Prohibit the use of organizaon-controlled portable storage devices by authorized individuals
on external systems.
Discussion: Limits on the use of organizaon-controlled portable storage devices in external
systems include a complete prohibion of the use of such devices. Prohibing such use is
enforced using technical methods and/or nontechnical (i.e., process-based) methods.
Related controls: MP-7, PL-4, PS-6, SC-41.
References: [FIPS 199], [SP 800-171], [SP 800-172]
AC-21 INFORMATION SHARING
Control:
a. Enable authorized users to determine whether access authorizaons assigned to a sharing
partner match the informaon’s access and use restricons for [Assignment: organizaon-
deﬁned informaon sharing circumstances where user discreon is required]; and
b. Employ [Assignment: organizaon-deﬁned automated mechanisms or manual processes] to
assist users in making informaon sharing and collaboraon decisions.
Discussion: Informaon sharing applies to informaon that may be restricted in some manner based
on some formal or administrave determinaon. Examples of such informaon include, contract-
sensive informaon, classiﬁed informaon related to special access programs or compartments,
privileged informaon, proprietary informaon, and personally idenﬁable informaon. Security
and privacy risk assessments as well as applicable laws, regulaons, and policies can provide useful
inputs to these determinaons. Depending on the circumstances, sharing partners may be deﬁned at
the individual, group, or organizaonal level. Informaon may be deﬁned by content, type, security
category, or special access program or compartment. Access restricons may include non-disclosure
agreements (NDA). Informaon ﬂow techniques and security aributes may be used to provide
automated assistance to users making sharing and collaboraon decisions.
Related controls: AC-3, AC-4, AC-16, PT-2, PT-7, RA-3, SC-15.
This document is produced from OSCAL source data
FAMILY: AC PAGE 41NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(1) INFORMATION SHARING | AUTOMATED DECISION SUPPORT
Employ [Assignment: organizaon-deﬁned automated mechanisms] to enforce informaon-
sharing decisions by authorized users based on access authorizaons of sharing partners and
access restricons on informaon to be shared.
Discussion: Automated mechanisms are used to enforce informaon sharing decisions.
(2) INFORMATION SHARING | INFORMATION SEARCH AND RETRIEVAL
Implement informaon search and retrieval services that enforce [Assignment: organizaon-
deﬁned informaon sharing restricons].
Discussion: Informaon search and retrieval services idenfy informaon system resources
relevant to an informaon need.
References: [IR 8062], [OMB A-130], [SP 800-150]
AC-22 PUBLICLY ACCESSIBLE CONTENT
Control:
a. Designate individuals authorized to make informaon publicly accessible;
b. Train authorized individuals to ensure that publicly accessible informaon does not contain
nonpublic informaon;
c. Review the proposed content of informaon prior to posng onto the publicly accessible system
to ensure that nonpublic informaon is not included; and
d. Review the content on the publicly accessible system for nonpublic informaon [Assignment:
organizaon-deﬁned frequency] and remove such informaon, if discovered.
Discussion: In accordance with applicable laws, execuve orders, direcves, policies, regulaons,
standards, and guidelines, the public is not authorized to have access to nonpublic informaon,
including informaon protected under the PRIVACT and proprietary informaon. Publicly accessible
content addresses systems that are controlled by the organizaon and accessible to the public,
typically without idenﬁcaon or authencaon. Posng informaon on non-organizaonal
systems (e.g., non-organizaonal public websites, forums, and social media) is covered by
organizaonal policy. While organizaons may have individuals who are responsible for developing
and implemenng policies about the informaon that can be made publicly accessible, publicly
accessible content addresses the management of the individuals who make such informaon publicly
accessible.
Related controls: AC-3, AT-2, AT-3, AU-13.
Reference: [PRIVACT]
AC-23 DATA MINING PROTECTION
Control: Employ [Assignment: organizaon-deﬁned data mining prevenon and detecon techniques]
for [Assignment: organizaon-deﬁned data storage objects] to detect and protect against
unauthorized data mining.
Discussion: Data mining is an analycal process that aempts to ﬁnd correlaons or paerns in
large data sets for the purpose of data or knowledge discovery. Data storage objects include
database records and database ﬁelds. Sensive informaon can be extracted from data mining
operaons. When informaon is personally idenﬁable informaon, it may lead to unancipated
This document is produced from OSCAL source data
FAMILY: AC PAGE 42NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
revelaons about individuals and give rise to privacy risks. Prior to performing data mining acvies,
organizaons determine whether such acvies are authorized. Organizaons may be subject
to applicable laws, execuve orders, direcves, regulaons, or policies that address data mining
requirements. Organizaonal personnel consult with the senior agency oﬃcial for privacy and legal
counsel regarding such requirements.
Data mining prevenon and detecon techniques include liming the number and frequency of
database queries to increase the work factor needed to determine the contents of databases,
liming types of responses provided to database queries, applying diﬀerenal privacy techniques or
homomorphic encrypon, and nofying personnel when atypical database queries or accesses occur.
Data mining protecon focuses on protecng informaon from data mining while such informaon
resides in organizaonal data stores. In contrast, AU-13 focuses on monitoring for organizaonal
informaon that may have been mined or otherwise obtained from data stores and is available
as open-source informaon residing on external sites, such as social networking or social media
websites.
EO 13587 requires the establishment of an insider threat program for deterring, detecng, and
migang insider threats, including the safeguarding of sensive informaon from exploitaon,
compromise, or other unauthorized disclosure. Data mining protecon requires organizaons to
idenfy appropriate techniques to prevent and detect unnecessary or unauthorized data mining. Data
mining can be used by an insider to collect organizaonal informaon for the purpose of exﬁltraon.
Related controls: PM-12, PT-2.
Reference: [EO 13587]
AC-24 ACCESS CONTROL DECISIONS
Control: [Selecon: Establish procedures; Implement mechanisms] to ensure [Assignment:
organizaon-deﬁned access control decisions] are applied to each access request prior to access
enforcement.
Discussion: Access control decisions (also known as authorizaon decisions) occur when authorizaon
informaon is applied to speciﬁc accesses. In contrast, access enforcement occurs when systems
enforce access control decisions. While it is common to have access control decisions and access
enforcement implemented by the same enty, it is not required, and it is not always an opmal
implementaon choice. For some architectures and distributed systems, diﬀerent enes may make
access control decisions and enforce access.
Related controls: AC-2, AC-3.
(1) ACCESS CONTROL DECISIONS | TRANSMIT ACCESS AUTHORIZATION INFORMATION
Transmit [Assignment: organizaon-deﬁned access authorizaon informaon] using
[Assignment: organizaon-deﬁned controls] to [Assignment: organizaon-deﬁned systems]
that enforce access control decisions.
Discussion: Authorizaon processes and access control decisions may occur in separate parts
of systems or in separate systems. In such instances, authorizaon informaon is transmied
securely (e.g., using cryptographic mechanisms) so that mely access control decisions can
be enforced at the appropriate locaons. To support the access control decisions, it may be
necessary to transmit as part of the access authorizaon informaon supporng security and
privacy aributes. This is because in distributed systems, there are various access control
decisions that need to be made, and diﬀerent enes make these decisions in a serial fashion,
each requiring those aributes to make the decisions. Protecng access authorizaon
This document is produced from OSCAL source data
FAMILY: AC PAGE 43NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
informaon ensures that such informaon cannot be altered, spoofed, or compromised during
transmission.
Related control: AU-10.
(2) ACCESS CONTROL DECISIONS | NO USER OR PROCESS IDENTITY
Enforce access control decisions based on [Assignment: organizaon-deﬁned security or
privacy aributes] that do not include the identy of the user or process acng on behalf of
the user.
Discussion: In certain situaons, it is important that access control decisions can be made
without informaon regarding the identy of the users issuing the requests. These are generally
instances where preserving individual privacy is of paramount importance. In other situaons,
user idenﬁcaon informaon is simply not needed for access control decisions, and especially
in the case of distributed systems, transming such informaon with the needed degree of
assurance may be very expensive or diﬃcult to accomplish. MAC, RBAC, ABAC, and label-based
control policies, for example, might not include user identy as an aribute.
References: [SP 800-162], [SP 800-178]
AC-25 REFERENCE MONITOR
Control: Implement a reference monitor for [Assignment: organizaon-deﬁned access control policies]
that is tamperproof, always invoked, and small enough to be subject to analysis and tesng, the
completeness of which can be assured.
Discussion: A reference monitor is a set of design requirements on a reference validaon mechanism
that, as a key component of an operang system, enforces an access control policy over all subjects
and objects. A reference validaon mechanism is always invoked, tamper-proof, and small enough
to be subject to analysis and tests, the completeness of which can be assured (i.e., veriﬁable).
Informaon is represented internally within systems using abstracons known as data structures.
Internal data structures can represent diﬀerent types of enes, both acve and passive. Acve
enes, also known as subjects, are associated with individuals, devices, or processes acng on behalf
of individuals. Passive enes, also known as objects, are associated with data structures, such as
records, buﬀers, communicaons ports, tables, ﬁles, and inter-process pipes. Reference monitors
enforce access control policies that restrict access to objects based on the identy of subjects or
groups to which the subjects belong. The system enforces the access control policy based on the
rule set established by the policy. The tamper-proof property of the reference monitor prevents
determined adversaries from compromising the funconing of the reference validaon mechanism.
The always invoked property prevents adversaries from bypassing the mechanism and violang the
security policy. The smallness property helps to ensure completeness in the analysis and tesng of
the mechanism to detect any weaknesses or deﬁciencies (i.e., latent ﬂaws) that would prevent the
enforcement of the security policy.
Related controls: AC-3, AC-16, SA-8, SA-17, SC-3, SC-11, SC-39, SI-13.
References: None
This document is produced from OSCAL source data
FAMILY: AC PAGE 44NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
FAMILY: AWARENESS AND TRAINING
AT-1 POLICY AND PROCEDURES
Control:
a. Develop, document, and disseminate to [Assignment: organizaon-deﬁned personnel or roles]:
1. [Selecon (one or more): Organizaon-level; Mission/business process-level; System-level]
awareness and training policy that:
(a) Addresses purpose, scope, roles, responsibilies, management commitment,
coordinaon among organizaonal enes, and compliance; and
(b) Is consistent with applicable laws, execuve orders, direcves, regulaons, policies,
standards, and guidelines; and
2. Procedures to facilitate the implementaon of the awareness and training policy and the
associated awareness and training controls;
b. Designate an [Assignment: organizaon-deﬁned oﬃcial] to manage the development,
documentaon, and disseminaon of the awareness and training policy and procedures; and
c. Review and update the current awareness and training:
1. Policy [Assignment: organizaon-deﬁned frequency] and following [Assignment:
organizaon-deﬁned events]; and
2. Procedures [Assignment: organizaon-deﬁned frequency] and following [Assignment:
organizaon-deﬁned events].
Discussion: Awareness and training policy and procedures address the controls in the AT family that
are implemented within systems and organizaons. The risk management strategy is an important
factor in establishing such policies and procedures. Policies and procedures contribute to security
and privacy assurance. Therefore, it is important that security and privacy programs collaborate on
the development of awareness and training policy and procedures. Security and privacy program
policies and procedures at the organizaon level are preferable, in general, and may obviate the need
for mission- or system-speciﬁc policies and procedures. The policy can be included as part of the
general security and privacy policy or be represented by mulple policies that reﬂect the complex
nature of organizaons. Procedures can be established for security and privacy programs, for mission
or business processes, and for systems, if needed. Procedures describe how the policies or controls
are implemented and can be directed at the individual or role that is the object of the procedure.
Procedures can be documented in system security and privacy plans or in one or more separate
documents. Events that may precipitate an update to awareness and training policy and procedures
include assessment or audit ﬁndings, security incidents or breaches, or changes in applicable laws,
execuve orders, direcves, regulaons, policies, standards, and guidelines. Simply restang controls
does not constute an organizaonal policy or procedure.
Related controls: PM-9, PS-8, SI-12.
References: [OMB A-130], [SP 800-100], [SP 800-12], [SP 800-30], [SP 800-39], [SP 800-50]
This document is produced from OSCAL source data
FAMILY: AT PAGE 45NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
AT-2 LITERACY TRAINING AND AWARENESS
Control:
a. Provide security and privacy literacy training to system users (including managers, senior
execuves, and contractors):
1. As part of inial training for new users and [Assignment: organizaon-deﬁned frequency]
thereaer; and
2. When required by system changes or following [Assignment: organizaon-deﬁned events];
b. Employ the following techniques to increase the security and privacy awareness of system users
[Assignment: organizaon-deﬁned awareness techniques];
c. Update literacy training and awareness content [Assignment: organizaon-deﬁned frequency]
and following [Assignment: organizaon-deﬁned events]; and
d. Incorporate lessons learned from internal or external security incidents or breaches into literacy
training and awareness techniques.
Discussion: Organizaons provide basic and advanced levels of literacy training to system users,
including measures to test the knowledge level of users. Organizaons determine the content of
literacy training and awareness based on speciﬁc organizaonal requirements, the systems to which
personnel have authorized access, and work environments (e.g., telework). The content includes an
understanding of the need for security and privacy as well as acons by users to maintain security
and personal privacy and to respond to suspected incidents. The content addresses the need for
operaons security and the handling of personally idenﬁable informaon.
Awareness techniques include displaying posters, oﬀering supplies inscribed with security and
privacy reminders, displaying logon screen messages, generang email advisories or noces from
organizaonal oﬃcials, and conducng awareness events. Literacy training aer the inial training
described in AT-2a.1 is conducted at a minimum frequency consistent with applicable laws, direcves,
regulaons, and policies. Subsequent literacy training may be sasﬁed by one or more short ad hoc
sessions and include topical informaon on recent aack schemes, changes to organizaonal security
and privacy policies, revised security and privacy expectaons, or a subset of topics from the inial
training. Updang literacy training and awareness content on a regular basis helps to ensure that the
content remains relevant. Events that may precipitate an update to literacy training and awareness
content include, but are not limited to, assessment or audit ﬁndings, security incidents or breaches,
or changes in applicable laws, execuve orders, direcves, regulaons, policies, standards, and
guidelines.
Related controls: AC-3, AC-17, AC-22, AT-3, AT-4, CP-3, IA-4, IR-2, IR-7, IR-9, PL-4, PM-13, PM-21, PS-7,
PT-2, SA-8, SA-16.
(1) LITERACY TRAINING AND AWARENESS | PRACTICAL EXERCISES
Provide praccal exercises in literacy training that simulate events and incidents.
Discussion: Praccal exercises include no-noce social engineering aempts to collect
informaon, gain unauthorized access, or simulate the adverse impact of opening malicious
email aachments or invoking, via spear phishing aacks, malicious web links.
Related controls: CA-2, CA-7, CP-4, IR-3.
This document is produced from OSCAL source data
FAMILY: AT PAGE 46NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(2) LITERACY TRAINING AND AWARENESS | INSIDER THREAT
Provide literacy training on recognizing and reporng potenal indicators of insider threat.
Discussion: Potenal indicators and possible precursors of insider threat can include behaviors
such as inordinate, long-term job dissasfacon; aempts to gain access to informaon not
required for job performance; unexplained access to ﬁnancial resources; bullying or harassment
of fellow employees; workplace violence; and other serious violaons of policies, procedures,
direcves, regulaons, rules, or pracces. Literacy training includes how to communicate the
concerns of employees and management regarding potenal indicators of insider threat through
channels established by the organizaon and in accordance with established policies and
procedures. Organizaons may consider tailoring insider threat awareness topics to the role. For
example, training for managers may be focused on changes in the behavior of team members,
while training for employees may be focused on more general observaons.
Related control: PM-12.
(3) LITERACY TRAINING AND AWARENESS | SOCIAL ENGINEERING AND MINING
Provide literacy training on recognizing and reporng potenal and actual instances of social
engineering and social mining.
Discussion: Social engineering is an aempt to trick an individual into revealing informaon
or taking an acon that can be used to breach, compromise, or otherwise adversely impact
a system. Social engineering includes phishing, pretexng, impersonaon, baing, quid pro
quo, thread-jacking, social media exploitaon, and tailgang. Social mining is an aempt
to gather informaon about the organizaon that may be used to support future aacks.
Literacy training includes informaon on how to communicate the concerns of employees and
management regarding potenal and actual instances of social engineering and data mining
through organizaonal channels based on established policies and procedures.
(4) LITERACY TRAINING AND AWARENESS | SUSPICIOUS COMMUNICATIONS AND
ANOMALOUS SYSTEM BEHAVIOR
Provide literacy training on recognizing suspicious communicaons and anomalous behavior in
organizaonal systems using [Assignment: organizaon-deﬁned indicators of malicious code].
Discussion: A well-trained workforce provides another organizaonal control that can be
employed as part of a defense-in-depth strategy to protect against malicious code coming into
organizaons via email or the web applicaons. Personnel are trained to look for indicaons of
potenally suspicious email (e.g., receiving an unexpected email, receiving an email containing
strange or poor grammar, or receiving an email from an unfamiliar sender that appears to
be from a known sponsor or contractor). Personnel are also trained on how to respond to
suspicious email or web communicaons. For this process to work eﬀecvely, personnel are
trained and made aware of what constutes suspicious communicaons. Training personnel on
how to recognize anomalous behaviors in systems can provide organizaons with early warning
for the presence of malicious code. Recognion of anomalous behavior by organizaonal
personnel can supplement malicious code detecon and protecon tools and systems employed
by organizaons.
This document is produced from OSCAL source data
FAMILY: AT PAGE 47NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(5) LITERACY TRAINING AND AWARENESS | ADVANCED PERSISTENT THREAT
Provide literacy training on the advanced persistent threat.
Discussion: An eﬀecve way to detect advanced persistent threats (APT) and to preclude
successful aacks is to provide speciﬁc literacy training for individuals. Threat literacy training
includes educang individuals on the various ways that APTs can inﬁltrate the organizaon (e.g.,
through websites, emails, adversement pop-ups, arcles, and social engineering). Eﬀecve
training includes techniques for recognizing suspicious emails, use of removable systems in non-
secure sengs, and the potenal targeng of individuals at home.
(6) LITERACY TRAINING AND AWARENESS | CYBER THREAT ENVIRONMENT
(a) Provide literacy training on the cyber threat environment; and
(b) Reﬂect current cyber threat informaon in system operaons.
Discussion: Since threats connue to change over me, threat literacy training by the organizaon
is dynamic. Moreover, threat literacy training is not performed in isolaon from the system
operaons that support organizaonal mission and business funcons.
Related control: RA-3.
References: [ODNI CTF], [OMB A-130], [SP 800-160-2], [SP 800-181], [SP 800-50]
AT-3 ROLE-BASED TRAINING
Control:
a. Provide role-based security and privacy training to personnel with the following roles and
responsibilies: [Assignment: organizaon-deﬁned roles and responsibilies]:
1. Before authorizing access to the system, informaon, or performing assigned dues, and
[Assignment: organizaon-deﬁned frequency] thereaer; and
2. When required by system changes;
b. Update role-based training content [Assignment: organizaon-deﬁned frequency] and following
[Assignment: organizaon-deﬁned events]; and
c. Incorporate lessons learned from internal or external security incidents or breaches into role-
based training.
Discussion: Organizaons determine the content of training based on the assigned roles and
responsibilies of individuals as well as the security and privacy requirements of organizaons and the
systems to which personnel have authorized access, including technical training speciﬁcally tailored
for assigned dues. Roles that may require role-based training include senior leaders or management
oﬃcials (e.g., head of agency/chief execuve oﬃcer, chief informaon oﬃcer, senior accountable
oﬃcial for risk management, senior agency informaon security oﬃcer, senior agency oﬃcial for
privacy), system owners; authorizing oﬃcials; system security oﬃcers; privacy oﬃcers; acquision
and procurement oﬃcials; enterprise architects; systems engineers; soware developers; systems
security engineers; privacy engineers; system, network, and database administrators; auditors;
personnel conducng conﬁguraon management acvies; personnel performing veriﬁcaon and
validaon acvies; personnel with access to system-level soware; control assessors; personnel
with conngency planning and incident response dues; personnel with privacy management
responsibilies; and personnel with access to personally idenﬁable informaon.
This document is produced from OSCAL source data
FAMILY: AT PAGE 48NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
Comprehensive role-based training addresses management, operaonal, and technical roles
and responsibilies covering physical, personnel, and technical controls. Role-based training also
includes policies, procedures, tools, methods, and arfacts for the security and privacy roles deﬁned.
Organizaons provide the training necessary for individuals to fulﬁll their responsibilies related
to operaons and supply chain risk management within the context of organizaonal security and
privacy programs. Role-based training also applies to contractors who provide services to federal
agencies. Types of training include web-based and computer-based training, classroom-style training,
and hands-on training (including micro-training). Updang role-based training on a regular basis helps
to ensure that the content remains relevant and eﬀecve. Events that may precipitate an update
to role-based training content include, but are not limited to, assessment or audit ﬁndings, security
incidents or breaches, or changes in applicable laws, execuve orders, direcves, regulaons, policies,
standards, and guidelines.
Related controls: AC-3, AC-17, AC-22, AT-2, AT-4, CP-3, IR-2, IR-4, IR-7, IR-9, PL-4, PM-13, PM-23, PS-7,
PS-9, SA-3, SA-8, SA-11, SA-16, SR-5, SR-6, SR-11.
(1) ROLE-BASED TRAINING | ENVIRONMENTAL CONTROLS
Provide [Assignment: organizaon-deﬁned personnel or roles] with inial and [Assignment:
organizaon-deﬁned frequency] training in the employment and operaon of environmental
controls.
Discussion: Environmental controls include ﬁre suppression and detecon devices or systems,
sprinkler systems, handheld ﬁre exnguishers, ﬁxed ﬁre hoses, smoke detectors, temperature or
humidity, heang, venlaon, air condioning, and power within the facility.
Related controls: PE-1, PE-11, PE-13, PE-14, PE-15.
(2) ROLE-BASED TRAINING | PHYSICAL SECURITY CONTROLS
Provide [Assignment: organizaon-deﬁned personnel or roles] with inial and [Assignment:
organizaon-deﬁned frequency] training in the employment and operaon of physical security
controls.
Discussion: Physical security controls include physical access control devices, physical intrusion
and detecon alarms, operang procedures for facility security guards, and monitoring or
surveillance equipment.
Related controls: PE-2, PE-3, PE-4.
(3) ROLE-BASED TRAINING | PRACTICAL EXERCISES
Provide praccal exercises in security and privacy training that reinforce training objecves.
Discussion: Praccal exercises for security include training for soware developers that addresses
simulated aacks that exploit common soware vulnerabilies or spear or whale phishing
aacks targeted at senior leaders or execuves. Praccal exercises for privacy include modules
with quizzes on idenfying and processing personally idenﬁable informaon in various
scenarios or scenarios on conducng privacy impact assessments.
(4) ROLE-BASED TRAINING | SUSPICIOUS COMMUNICATIONS AND ANOMALOUS SYSTEM
BEHAVIOR
[Withdrawn: Incorporated into AT-2(4).]
This document is produced from OSCAL source data
FAMILY: AT PAGE 49NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(5) ROLE-BASED TRAINING | PROCESSING PERSONALLY IDENTIFIABLE INFORMATION
Provide [Assignment: organizaon-deﬁned personnel or roles] with inial and [Assignment:
organizaon-deﬁned frequency] training in the employment and operaon of personally
idenﬁable informaon processing and transparency controls.
Discussion: Personally idenﬁable informaon processing and transparency controls include the
organizaon’s authority to process personally idenﬁable informaon and personally idenﬁable
informaon processing purposes. Role-based training for federal agencies addresses the types of
informaon that may constute personally idenﬁable informaon and the risks, consideraons,
and obligaons associated with its processing. Such training also considers the authority to
process personally idenﬁable informaon documented in privacy policies and noces, system
of records noces, computer matching agreements and noces, privacy impact assessments,
PRIVACT statements, contracts, informaon sharing agreements, memoranda of understanding,
and/or other documentaon.
Related controls: PT-2, PT-3, PT-5, PT-6.
References: [OMB A-130], [SP 800-181], [SP 800-50]
AT-4 TRAINING RECORDS
Control:
a. Document and monitor informaon security and privacy training acvies, including security and
privacy awareness training and speciﬁc role-based security and privacy training; and
b. Retain individual training records for [Assignment: organizaon-deﬁned me period].
Discussion: Documentaon for specialized training may be maintained by individual supervisors at the
discreon of the organizaon. The Naonal Archives and Records Administraon provides guidance
on records retenon for federal agencies.
Related controls: AT-2, AT-3, CP-3, IR-2, PM-14, SI-12.
Reference: [OMB A-130]
AT-5 Contacts with Security Groups and Associaons
[Withdrawn: Incorporated into PM-15.]
AT-6 TRAINING FEEDBACK
Control: Provide feedback on organizaonal training results to the following personnel [Assignment:
organizaon-deﬁned frequency]: [Assignment: organizaon-deﬁned personnel].
Discussion: Training feedback includes awareness training results and role-based training results.
Training results, especially failures of personnel in crical roles, can be indicave of a potenally
serious problem. Therefore, it is important that senior managers are made aware of such situaons
so that they can take appropriate response acons. Training feedback supports the evaluaon and
update of organizaonal training described in AT-2b and AT-3b.
References: None
This document is produced from OSCAL source data
FAMILY: AT PAGE 50NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
FAMILY: AUDIT AND ACCOUNTABILITY
AU-1 POLICY AND PROCEDURES
Control:
a. Develop, document, and disseminate to [Assignment: organizaon-deﬁned personnel or roles]:
1. [Selecon (one or more): Organizaon-level; Mission/business process-level; System-level]
audit and accountability policy that:
(a) Addresses purpose, scope, roles, responsibilies, management commitment,
coordinaon among organizaonal enes, and compliance; and
(b) Is consistent with applicable laws, execuve orders, direcves, regulaons, policies,
standards, and guidelines; and
2. Procedures to facilitate the implementaon of the audit and accountability policy and the
associated audit and accountability controls;
b. Designate an [Assignment: organizaon-deﬁned oﬃcial] to manage the development,
documentaon, and disseminaon of the audit and accountability policy and procedures; and
c. Review and update the current audit and accountability:
1. Policy [Assignment: organizaon-deﬁned frequency] and following [Assignment:
organizaon-deﬁned events]; and
2. Procedures [Assignment: organizaon-deﬁned frequency] and following [Assignment:
organizaon-deﬁned events].
Discussion: Audit and accountability policy and procedures address the controls in the AU family that
are implemented within systems and organizaons. The risk management strategy is an important
factor in establishing such policies and procedures. Policies and procedures contribute to security
and privacy assurance. Therefore, it is important that security and privacy programs collaborate on
the development of audit and accountability policy and procedures. Security and privacy program
policies and procedures at the organizaon level are preferable, in general, and may obviate the need
for mission- or system-speciﬁc policies and procedures. The policy can be included as part of the
general security and privacy policy or be represented by mulple policies that reﬂect the complex
nature of organizaons. Procedures can be established for security and privacy programs, for mission
or business processes, and for systems, if needed. Procedures describe how the policies or controls
are implemented and can be directed at the individual or role that is the object of the procedure.
Procedures can be documented in system security and privacy plans or in one or more separate
documents. Events that may precipitate an update to audit and accountability policy and procedures
include assessment or audit ﬁndings, security incidents or breaches, or changes in applicable laws,
execuve orders, direcves, regulaons, policies, standards, and guidelines. Simply restang controls
does not constute an organizaonal policy or procedure.
Related controls: PM-9, PS-8, SI-12.
References: [SP 800-100], [SP 800-12], [SP 800-30], [SP 800-39]
AU-2 EVENT LOGGING
Control:
a. Idenfy the types of events that the system is capable of logging in support of the audit funcon:
[Assignment: organizaon-deﬁned event types that the system is capable of logging];
This document is produced from OSCAL source data
FAMILY: AU PAGE 51NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
b. Coordinate the event logging funcon with other organizaonal enes requiring audit-related
informaon to guide and inform the selecon criteria for events to be logged;
c. Specify the following event types for logging within the system: [Assignment: organizaon-
deﬁned event types (subset of the event types deﬁned in AU-2a.) along with the frequency of (or
situaon requiring) logging for each idenﬁed event type];
d. Provide a raonale for why the event types selected for logging are deemed to be adequate to
support aer-the-fact invesgaons of incidents; and
e. Review and update the event types selected for logging [Assignment: organizaon-deﬁned
frequency].
Discussion: An event is an observable occurrence in a system. The types of events that require logging
are those events that are signiﬁcant and relevant to the security of systems and the privacy of
individuals. Event logging also supports speciﬁc monitoring and auding needs. Event types include
password changes, failed logons or failed accesses related to systems, security or privacy aribute
changes, administrave privilege usage, PIV credenal usage, data acon changes, query parameters,
or external credenal usage. In determining the set of event types that require logging, organizaons
consider the monitoring and auding appropriate for each of the controls to be implemented. For
completeness, event logging includes all protocols that are operaonal and supported by the system.
To balance monitoring and auding requirements with other system needs, event logging requires
idenfying the subset of event types that are logged at a given point in me. For example,
organizaons may determine that systems need the capability to log every ﬁle access successful and
unsuccessful, but not acvate that capability except for speciﬁc circumstances due to the potenal
burden on system performance. The types of events that organizaons desire to be logged may
change. Reviewing and updang the set of logged events is necessary to help ensure that the events
remain relevant and connue to support the needs of the organizaon. Organizaons consider how
the types of logging events can reveal informaon about individuals that may give rise to privacy
risk and how best to migate such risks. For example, there is the potenal to reveal personally
idenﬁable informaon in the audit trail, especially if the logging event is based on paerns or me of
usage.
Event logging requirements, including the need to log speciﬁc event types, may be referenced in
other controls and control enhancements. These include AC-2(4), AC-3(10), AC-6(9), AC-17(1), CM-3f,
CM-5(1), IA-3(3)(b), MA-4(1), MP-4(2), PE-3, PM-21, PT-7, RA-8, SC-7(9), SC-7(15), SI-3(8), SI-4(22),
SI-7(8), and SI-10(1). Organizaons include event types that are required by applicable laws, execuve
orders, direcves, policies, regulaons, standards, and guidelines. Audit records can be generated
at various levels, including at the packet level as informaon traverses the network. Selecng the
appropriate level of event logging is an important part of a monitoring and auding capability and can
idenfy the root causes of problems. When deﬁning event types, organizaons consider the logging
necessary to cover related event types, such as the steps in distributed, transacon-based processes
and the acons that occur in service-oriented architectures.
Related controls: AC-2, AC-3, AC-6, AC-7, AC-8, AC-16, AC-17, AU-3, AU-4, AU-5, AU-6, AU-7, AU-11,
AU-12, CM-3, CM-5, CM-6, CM-13, IA-3, MA-4, MP-4, PE-3, PM-21, PT-2, PT-7, RA-8, SA-8, SC-7, SC-18,
SI-3, SI-4, SI-7, SI-10, SI-11.
(1) EVENT LOGGING | COMPILATION OF AUDIT RECORDS FROM MULTIPLE SOURCES
[Withdrawn: Incorporated into AU-12.]
This document is produced from OSCAL source data
FAMILY: AU PAGE 52NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(2) EVENT LOGGING | SELECTION OF AUDIT EVENTS BY COMPONENT
[Withdrawn: Incorporated into AU-12.]
(3) EVENT LOGGING | REVIEWS AND UPDATES
[Withdrawn: Incorporated into AU-2.]
(4) EVENT LOGGING | PRIVILEGED FUNCTIONS
[Withdrawn: Incorporated into AC-6(9).]
References: [OMB A-130], [SP 800-92]
AU-3 CONTENT OF AUDIT RECORDS
Control: Ensure that audit records contain informaon that establishes the following:
a. What type of event occurred;
b. When the event occurred;
c. Where the event occurred;
d. Source of the event;
e. Outcome of the event; and
f. Identy of any individuals, subjects, or objects/enes associated with the event.
Discussion: Audit record content that may be necessary to support the auding funcon includes event
descripons (item a), me stamps (item b), source and desnaon addresses (item c), user or process
idenﬁers (items d and f), success or fail indicaons (item e), and ﬁlenames involved (items a, c, e,
and f) . Event outcomes include indicators of event success or failure and event-speciﬁc results, such
as the system security and privacy posture aer the event occurred. Organizaons consider how audit
records can reveal informaon about individuals that may give rise to privacy risks and how best to
migate such risks. For example, there is the potenal to reveal personally idenﬁable informaon in
the audit trail, especially if the trail records inputs or is based on paerns or me of usage.
Related controls: AU-2, AU-8, AU-12, AU-14, MA-4, PL-9, SA-8, SI-7, SI-11.
(1) CONTENT OF AUDIT RECORDS | ADDITIONAL AUDIT INFORMATION
Generate audit records containing the following addional informaon: [Assignment:
organizaon-deﬁned addional informaon].
Discussion: The ability to add informaon generated in audit records is dependent on system
funconality to conﬁgure the audit record content. Organizaons may consider addional
informaon in audit records including, but not limited to, access control or ﬂow control rules
invoked and individual idenes of group account users. Organizaons may also consider
liming addional audit record informaon to only informaon that is explicitly needed for audit
requirements. This facilitates the use of audit trails and audit logs by not including informaon in
audit records that could potenally be misleading, make it more diﬃcult to locate informaon of
interest, or increase the risk to individuals' privacy.
This document is produced from OSCAL source data
FAMILY: AU PAGE 53NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(2) CONTENT OF AUDIT RECORDS | CENTRALIZED MANAGEMENT OF PLANNED AUDIT
RECORD CONTENT
[Withdrawn: Incorporated into PL-9.]
(3) CONTENT OF AUDIT RECORDS | LIMIT PERSONALLY IDENTIFIABLE INFORMATION
ELEMENTS
Limit personally idenﬁable informaon contained in audit records to the following elements
idenﬁed in the privacy risk assessment: [Assignment: organizaon-deﬁned elements].
Discussion: Liming personally idenﬁable informaon in audit records when such informaon is
not needed for operaonal purposes helps reduce the level of privacy risk created by a system.
Related control: RA-3.
References: [IR 8062], [OMB A-130]
AU-4 AUDIT LOG STORAGE CAPACITY
Control: Allocate audit log storage capacity to accommodate [Assignment: organizaon-deﬁned audit
log retenon requirements].
Discussion: Organizaons consider the types of audit logging to be performed and the audit log
processing requirements when allocang audit log storage capacity. Allocang suﬃcient audit log
storage capacity reduces the likelihood of such capacity being exceeded and resulng in the potenal
loss or reducon of audit logging capability.
Related controls: AU-2, AU-5, AU-6, AU-7, AU-9, AU-11, AU-12, AU-14, SI-4.
(1) AUDIT LOG STORAGE CAPACITY | TRANSFER TO ALTERNATE STORAGE
Transfer audit logs [Assignment: organizaon-deﬁned frequency] to a diﬀerent system, system
component, or media other than the system or system component conducng the logging.
Discussion: Audit log transfer, also known as oﬀ-loading, is a common process in systems with
limited audit log storage capacity and thus supports availability of the audit logs. The inial
audit log storage is only used in a transitory fashion unl the system can communicate with
the secondary or alternate system allocated to audit log storage, at which point the audit
logs are transferred. Transferring audit logs to alternate storage is similar to AU-9(2) in that
audit logs are transferred to a diﬀerent enty. However, the purpose of selecng AU-9(2) is to
protect the conﬁdenality and integrity of audit records. Organizaons can select either control
enhancement to obtain the beneﬁt of increased audit log storage capacity and preserving the
conﬁdenality, integrity, and availability of audit records and logs.
References: None
AU-5 RESPONSE TO AUDIT LOGGING PROCESS FAILURES
Control:
a. Alert [Assignment: organizaon-deﬁned personnel or roles] within [Assignment: organizaon-
deﬁned me period] in the event of an audit logging process failure; and
b. Take the following addional acons: [Assignment: organizaon-deﬁned addional acons].
Discussion: Audit logging process failures include soware and hardware errors, failures in audit
log capturing mechanisms, and reaching or exceeding audit log storage capacity. Organizaon-
This document is produced from OSCAL source data
FAMILY: AU PAGE 54NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
deﬁned acons include overwring oldest audit records, shung down the system, and stopping the
generaon of audit records. Organizaons may choose to deﬁne addional acons for audit logging
process failures based on the type of failure, the locaon of the failure, the severity of the failure, or a
combinaon of such factors. When the audit logging process failure is related to storage, the response
is carried out for the audit log storage repository (i.e., the disnct system component where the audit
logs are stored), the system on which the audit logs reside, the total audit log storage capacity of the
organizaon (i.e., all audit log storage repositories combined), or all three. Organizaons may decide
to take no addional acons aer alerng designated roles or personnel.
Related controls: AU-2, AU-4, AU-7, AU-9, AU-11, AU-12, AU-14, SI-4, SI-12.
(1) RESPONSE TO AUDIT LOGGING PROCESS FAILURES | STORAGE CAPACITY WARNING
Provide a warning to [Assignment: organizaon-deﬁned personnel, roles, and/or locaons]
within [Assignment: organizaon-deﬁned me period] when allocated audit log storage
volume reaches [Assignment: organizaon-deﬁned percentage] of repository maximum audit
log storage capacity.
Discussion: Organizaons may have mulple audit log storage repositories distributed across
mulple system components with each repository having diﬀerent storage volume capacies.
(2) RESPONSE TO AUDIT LOGGING PROCESS FAILURES | REAL-TIME ALERTS
Provide an alert within [Assignment: organizaon-deﬁned real-me period] to [Assignment:
organizaon-deﬁned personnel, roles, and/or locaons] when the following audit failure
events occur: [Assignment: organizaon-deﬁned audit logging failure events requiring real-
me alerts].
Discussion: Alerts provide organizaons with urgent messages. Real-me alerts provide these
messages at informaon technology speed (i.e., the me from event detecon to alert occurs in
seconds or less).
(3) RESPONSE TO AUDIT LOGGING PROCESS FAILURES | CONFIGURABLE TRAFFIC VOLUME
THRESHOLDS
Enforce conﬁgurable network communicaons traﬃc volume thresholds reﬂecng limits on
audit log storage capacity and [Selecon: reject; delay] network traﬃc above those thresholds.
Discussion: Organizaons have the capability to reject or delay the processing of network
communicaons traﬃc if audit logging informaon about such traﬃc is determined to exceed
the storage capacity of the system audit logging funcon. The rejecon or delay response is
triggered by the established organizaonal traﬃc volume thresholds that can be adjusted based
on changes to audit log storage capacity.
(4) RESPONSE TO AUDIT LOGGING PROCESS FAILURES | SHUTDOWN ON FAILURE
Invoke a [Selecon: full system shutdown; paral system shutdown; degraded operaonal
mode with limited mission or business funconality available] in the event of [Assignment:
organizaon-deﬁned audit logging failures], unless an alternate audit logging capability exists.
Discussion: Organizaons determine the types of audit logging failures that can trigger automac
system shutdowns or degraded operaons. Because of the importance of ensuring mission
and business connuity, organizaons may determine that the nature of the audit logging
failure is not so severe that it warrants a complete shutdown of the system supporng the core
This document is produced from OSCAL source data
FAMILY: AU PAGE 55NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
organizaonal mission and business funcons. In those instances, paral system shutdowns or
operang in a degraded mode with reduced capability may be viable alternaves.
Related control: AU-15.
(5) RESPONSE TO AUDIT LOGGING PROCESS FAILURES | ALTERNATE AUDIT LOGGING
CAPABILITY
Provide an alternate audit logging capability in the event of a failure in primary audit logging
capability that implements [Assignment: organizaon-deﬁned alternate audit logging
funconality].
Discussion: Since an alternate audit logging capability may be a short-term protecon soluon
employed unl the failure in the primary audit logging capability is corrected, organizaons may
determine that the alternate audit logging capability need only provide a subset of the primary
audit logging funconality that is impacted by the failure.
Related control: AU-9.
References: None
AU-6 AUDIT RECORD REVIEW, ANALYSIS, AND REPORTING
Control:
a. Review and analyze system audit records [Assignment: organizaon-deﬁned frequency] for
indicaons of [Assignment: organizaon-deﬁned inappropriate or unusual acvity] and the
potenal impact of the inappropriate or unusual acvity;
b. Report ﬁndings to [Assignment: organizaon-deﬁned personnel or roles]; and
c. Adjust the level of audit record review, analysis, and reporng within the system when there is a
change in risk based on law enforcement informaon, intelligence informaon, or other credible
sources of informaon.
Discussion: Audit record review, analysis, and reporng covers informaon security- and privacy-
related logging performed by organizaons, including logging that results from the monitoring
of account usage, remote access, wireless connecvity, mobile device connecon, conﬁguraon
sengs, system component inventory, use of maintenance tools and non-local maintenance, physical
access, temperature and humidity, equipment delivery and removal, communicaons at system
interfaces, and use of mobile code or Voice over Internet Protocol (VoIP). Findings can be reported
to organizaonal enes that include the incident response team, help desk, and security or privacy
oﬃces. If organizaons are prohibited from reviewing and analyzing audit records or unable to
conduct such acvies, the review or analysis may be carried out by other organizaons granted such
authority. The frequency, scope, and/or depth of the audit record review, analysis, and reporng may
be adjusted to meet organizaonal needs based on new informaon received.
Related controls: AC-2, AC-3, AC-5, AC-6, AC-7, AC-17, AU-7, AU-16, CA-2, CA-7, CM-2, CM-5, CM-6,
CM-10, CM-11, IA-2, IA-3, IA-5, IA-8, IR-5, MA-4, MP-4, PE-3, PE-6, RA-5, SA-8, SC-7, SI-3, SI-4, SI-7.
This document is produced from OSCAL source data
FAMILY: AU PAGE 56NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(1) AUDIT RECORD REVIEW, ANALYSIS, AND REPORTING | AUTOMATED PROCESS
INTEGRATION
Integrate audit record review, analysis, and reporng processes using [Assignment:
organizaon-deﬁned automated mechanisms].
Discussion: Organizaonal processes that beneﬁt from integrated audit record review, analysis,
and reporng include incident response, connuous monitoring, conngency planning,
invesgaon and response to suspicious acvies, and Inspector General audits.
Related control: PM-7.
(2) AUDIT RECORD REVIEW, ANALYSIS, AND REPORTING | AUTOMATED SECURITY ALERTS
[Withdrawn: Incorporated into SI-4.]
(3) AUDIT RECORD REVIEW, ANALYSIS, AND REPORTING | CORRELATE AUDIT RECORD
REPOSITORIES
Analyze and correlate audit records across diﬀerent repositories to gain organizaon-wide
situaonal awareness.
Discussion: Organizaon-wide situaonal awareness includes awareness across all three levels
of risk management (i.e., organizaonal level, mission/business process level, and informaon
system level) and supports cross-organizaon awareness.
Related controls: AU-12, IR-4.
(4) AUDIT RECORD REVIEW, ANALYSIS, AND REPORTING | CENTRAL REVIEW AND ANALYSIS
Provide and implement the capability to centrally review and analyze audit records from
mulple components within the system.
Discussion: Automated mechanisms for centralized reviews and analyses include Security
Informaon and Event Management products.
Related controls: AU-2, AU-12.
(5) AUDIT RECORD REVIEW, ANALYSIS, AND REPORTING | INTEGRATED ANALYSIS OF AUDIT
RECORDS
Integrate analysis of audit records with analysis of [Selecon (one or more): vulnerability
scanning informaon; performance data; system monitoring informaon; [Assignment:
organizaon-deﬁned data/informaon collected from other sources]] to further enhance the
ability to idenfy inappropriate or unusual acvity.
Discussion: Integrated analysis of audit records does not require vulnerability scanning, the
generaon of performance data, or system monitoring. Rather, integrated analysis requires
that the analysis of informaon generated by scanning, monitoring, or other data collecon
acvies is integrated with the analysis of audit record informaon. Security Informaon and
Event Management tools can facilitate audit record aggregaon or consolidaon from mulple
system components as well as audit record correlaon and analysis. The use of standardized
audit record analysis scripts developed by organizaons (with localized script adjustments,
as necessary) provides more cost-eﬀecve approaches for analyzing audit record informaon
collected. The correlaon of audit record informaon with vulnerability scanning informaon
is important in determining the veracity of vulnerability scans of the system and in correlang
This document is produced from OSCAL source data
FAMILY: AU PAGE 57NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
aack detecon events with scanning results. Correlaon with performance data can uncover
denial-of-service aacks or other types of aacks that result in the unauthorized use of
resources. Correlaon with system monitoring informaon can assist in uncovering aacks and
in beer relang audit informaon to operaonal situaons.
Related controls: AU-12, IR-4.
(6) AUDIT RECORD REVIEW, ANALYSIS, AND REPORTING | CORRELATION WITH PHYSICAL
MONITORING
Correlate informaon from audit records with informaon obtained from monitoring physical
access to further enhance the ability to idenfy suspicious, inappropriate, unusual, or
malevolent acvity.
Discussion: The correlaon of physical audit record informaon and the audit records from
systems may assist organizaons in idenfying suspicious behavior or supporng evidence of
such behavior. For example, the correlaon of an individual’s identy for logical access to certain
systems with the addional physical security informaon that the individual was present at the
facility when the logical access occurred may be useful in invesgaons.
(7) AUDIT RECORD REVIEW, ANALYSIS, AND REPORTING | PERMITTED ACTIONS
Specify the permied acons for each [Selecon (one or more): system process; role; user]
associated with the review, analysis, and reporng of audit record informaon.
Discussion: Organizaons specify permied acons for system processes, roles, and users
associated with the review, analysis, and reporng of audit records through system account
management acvies. Specifying permied acons on audit record informaon is a way to
enforce the principle of least privilege. Permied acons are enforced by the system and include
read, write, execute, append, and delete.
(8) AUDIT RECORD REVIEW, ANALYSIS, AND REPORTING | FULL TEXT ANALYSIS OF
PRIVILEGED COMMANDS
Perform a full text analysis of logged privileged commands in a physically disnct component
or subsystem of the system, or other system that is dedicated to that analysis.
Discussion: Full text analysis of privileged commands requires a disnct environment for the
analysis of audit record informaon related to privileged users without compromising such
informaon on the system where the users have elevated privileges, including the capability to
execute privileged commands. Full text analysis refers to analysis that considers the full text of
privileged commands (i.e., commands and parameters) as opposed to analysis that considers
only the name of the command. Full text analysis includes the use of paern matching and
heuriscs.
Related controls: AU-3, AU-9, AU-11, AU-12.
(9) AUDIT RECORD REVIEW, ANALYSIS, AND REPORTING | CORRELATION WITH
INFORMATION FROM NONTECHNICAL SOURCES
Correlate informaon from nontechnical sources with audit record informaon to enhance
organizaon-wide situaonal awareness.
Discussion: Nontechnical sources include records that document organizaonal policy violaons
related to harassment incidents and the improper use of informaon assets. Such informaon
This document is produced from OSCAL source data
FAMILY: AU PAGE 58NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
can lead to a directed analycal eﬀort to detect potenal malicious insider acvity. Organizaons
limit access to informaon that is available from nontechnical sources due to its sensive nature.
Limited access minimizes the potenal for inadvertent release of privacy-related informaon to
individuals who do not have a need to know. The correlaon of informaon from nontechnical
sources with audit record informaon generally occurs only when individuals are suspected of
being involved in an incident. Organizaons obtain legal advice prior to iniang such acons.
Related control: PM-12.
(10) AUDIT RECORD REVIEW, ANALYSIS, AND REPORTING | AUDIT LEVEL ADJUSTMENT
[Withdrawn: Incorporated into AU-6.]
References: [SP 800-101], [SP 800-86]
AU-7 AUDIT RECORD REDUCTION AND REPORT GENERATION
Control: Provide and implement an audit record reducon and report generaon capability that:
a. Supports on-demand audit record review, analysis, and reporng requirements and aer-the-fact
invesgaons of incidents; and
b. Does not alter the original content or me ordering of audit records.
Discussion: Audit record reducon is a process that manipulates collected audit log informaon and
organizes it into a summary format that is more meaningful to analysts. Audit record reducon
and report generaon capabilies do not always emanate from the same system or from the same
organizaonal enes that conduct audit logging acvies. The audit record reducon capability
includes modern data mining techniques with advanced data ﬁlters to idenfy anomalous behavior
in audit records. The report generaon capability provided by the system can generate customizable
reports. Time ordering of audit records can be an issue if the granularity of the mestamp in the
record is insuﬃcient.
Related controls: AC-2, AU-2, AU-3, AU-4, AU-5, AU-6, AU-12, AU-16, CM-5, IA-5, IR-4, PM-12, SI-4.
(1) AUDIT RECORD REDUCTION AND REPORT GENERATION | AUTOMATIC PROCESSING
Provide and implement the capability to process, sort, and search audit records for events of
interest based on the following content: [Assignment: organizaon-deﬁned ﬁelds within audit
records].
Discussion: Events of interest can be idenﬁed by the content of audit records, including system
resources involved, informaon objects accessed, idenes of individuals, event types, event
locaons, event dates and mes, Internet Protocol addresses involved, or event success or
failure. Organizaons may deﬁne event criteria to any degree of granularity required, such as
locaons selectable by a general networking locaon or by speciﬁc system component.
(2) AUDIT RECORD REDUCTION AND REPORT GENERATION | AUTOMATIC SORT AND
SEARCH
[Withdrawn: Incorporated into AU-7(1).]
References: None
This document is produced from OSCAL source data
FAMILY: AU PAGE 59NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
AU-8 TIME STAMPS
Control:
a. Use internal system clocks to generate me stamps for audit records; and
b. Record me stamps for audit records that meet [Assignment: organizaon-deﬁned granularity of
me measurement] and that use Coordinated Universal Time, have a ﬁxed local me oﬀset from
Coordinated Universal Time, or that include the local me oﬀset as part of the me stamp.
Discussion: Time stamps generated by the system include date and me. Time is commonly
expressed in Coordinated Universal Time (UTC), a modern connuaon of Greenwich Mean Time
(GMT), or local me with an oﬀset from UTC. Granularity of me measurements refers to the
degree of synchronizaon between system clocks and reference clocks (e.g., clocks synchronizing
within hundreds of milliseconds or tens of milliseconds). Organizaons may deﬁne diﬀerent
me granularies for diﬀerent system components. Time service can be crical to other security
capabilies such as access control and idenﬁcaon and authencaon, depending on the nature of
the mechanisms used to support those capabilies.
Related controls: AU-3, AU-12, AU-14, SC-45.
(1) TIME STAMPS | SYNCHRONIZATION WITH AUTHORITATIVE TIME SOURCE
[Withdrawn: Incorporated into SC-45(1).]
(2) TIME STAMPS | SECONDARY AUTHORITATIVE TIME SOURCE
[Withdrawn: Incorporated into SC-45(2).]
References: None
AU-9 PROTECTION OF AUDIT INFORMATION
Control:
a. Protect audit informaon and audit logging tools from unauthorized access, modiﬁcaon, and
deleon; and
b. Alert [Assignment: organizaon-deﬁned personnel or roles] upon detecon of unauthorized
access, modiﬁcaon, or deleon of audit informaon.
Discussion: Audit informaon includes all informaon needed to successfully audit system acvity,
such as audit records, audit log sengs, audit reports, and personally idenﬁable informaon. Audit
logging tools are those programs and devices used to conduct system audit and logging acvies.
Protecon of audit informaon focuses on technical protecon and limits the ability to access and
execute audit logging tools to authorized individuals. Physical protecon of audit informaon is
addressed by both media protecon controls and physical and environmental protecon controls.
Related controls: AC-3, AC-6, AU-6, AU-11, AU-14, AU-15, MP-2, MP-4, PE-2, PE-3, PE-6, SA-8, SC-8, SI-4.
(1) PROTECTION OF AUDIT INFORMATION | HARDWARE WRITE-ONCE MEDIA
Write audit trails to hardware-enforced, write-once media.
Discussion: Wring audit trails to hardware-enforced, write-once media applies to the inial
generaon of audit trails (i.e., the collecon of audit records that represents the informaon
to be used for detecon, analysis, and reporng purposes) and to the backup of those audit
trails. Wring audit trails to hardware-enforced, write-once media does not apply to the inial
generaon of audit records prior to being wrien to an audit trail. Write-once, read-many
This document is produced from OSCAL source data
FAMILY: AU PAGE 60NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(WORM) media includes Compact Disc-Recordable (CD-R), Blu-Ray Disc Recordable (BD-R), and
Digital Versale Disc-Recordable (DVD-R). In contrast, the use of switchable write-protecon
media, such as tape cartridges, Universal Serial Bus (USB) drives, Compact Disc Re-Writeable
(CD-RW), and Digital Versale Disc-Read Write (DVD-RW) results in write-protected but not
write-once media.
Related controls: AU-4, AU-5.
(2) PROTECTION OF AUDIT INFORMATION | STORE ON SEPARATE PHYSICAL SYSTEMS OR
COMPONENTS
Store audit records [Assignment: organizaon-deﬁned frequency] in a repository that is part
of a physically diﬀerent system or system component than the system or component being
audited.
Discussion: Storing audit records in a repository separate from the audited system or system
component helps to ensure that a compromise of the system being audited does not also result
in a compromise of the audit records. Storing audit records on separate physical systems or
components also preserves the conﬁdenality and integrity of audit records and facilitates the
management of audit records as an organizaon-wide acvity. Storing audit records on separate
systems or components applies to inial generaon as well as backup or long-term storage of
audit records.
Related controls: AU-4, AU-5.
(3) PROTECTION OF AUDIT INFORMATION | CRYPTOGRAPHIC PROTECTION
Implement cryptographic mechanisms to protect the integrity of audit informaon and audit
tools.
Discussion: Cryptographic mechanisms used for protecng the integrity of audit informaon
include signed hash funcons using asymmetric cryptography. This enables the distribuon of
the public key to verify the hash informaon while maintaining the conﬁdenality of the secret
key used to generate the hash.
Related controls: AU-10, SC-12, SC-13.
(4) PROTECTION OF AUDIT INFORMATION | ACCESS BY SUBSET OF PRIVILEGED USERS
Authorize access to management of audit logging funconality to only [Assignment:
organizaon-deﬁned subset of privileged users or roles].
Discussion: Individuals or roles with privileged access to a system and who are also the subject
of an audit by that system may aﬀect the reliability of the audit informaon by inhibing audit
acvies or modifying audit records. Requiring privileged access to be further deﬁned between
audit-related privileges and other privileges limits the number of users or roles with audit-
related privileges.
Related control: AC-5.
(5) PROTECTION OF AUDIT INFORMATION | DUAL AUTHORIZATION
Enforce dual authorizaon for [Selecon (one or more): movement; deleon] of [Assignment:
organizaon-deﬁned audit informaon].
Discussion: Organizaons may choose diﬀerent selecon opons for diﬀerent types of audit
informaon. Dual authorizaon mechanisms (also known as two-person control) require the
approval of two authorized individuals to execute audit funcons. To reduce the risk of collusion,
This document is produced from OSCAL source data
FAMILY: AU PAGE 61NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
organizaons consider rotang dual authorizaon dues to other individuals. Organizaons do
not require dual authorizaon mechanisms when immediate responses are necessary to ensure
public and environmental safety.
Related control: AC-3.
(6) PROTECTION OF AUDIT INFORMATION | READ-ONLY ACCESS
Authorize read-only access to audit informaon to [Assignment: organizaon-deﬁned subset
of privileged users or roles].
Discussion: Restricng privileged user or role authorizaons to read-only helps to limit the
potenal damage to organizaons that could be iniated by such users or roles, such as deleng
audit records to cover up malicious acvity.
(7) PROTECTION OF AUDIT INFORMATION | STORE ON COMPONENT WITH DIFFERENT
OPERATING SYSTEM
Store audit informaon on a component running a diﬀerent operang system than the system
or component being audited.
Discussion: Storing auding informaon on a system component running a diﬀerent operang
system reduces the risk of a vulnerability speciﬁc to the system, resulng in a compromise of the
audit records.
Related controls: AU-4, AU-5, AU-11, SC-29.
References: [FIPS 140-3], [FIPS 180-4], [FIPS 202]
AU-10 NON-REPUDIATION
Control: Provide irrefutable evidence that an individual (or process acng on behalf of an individual)
has performed [Assignment: organizaon-deﬁned acons to be covered by non-repudiaon].
Discussion: Types of individual acons covered by non-repudiaon include creang informaon,
sending and receiving messages, and approving informaon. Non-repudiaon protects against claims
by authors of not having authored certain documents, senders of not having transmied messages,
receivers of not having received messages, and signatories of not having signed documents. Non-
repudiaon services can be used to determine if informaon originated from an individual or if an
individual took speciﬁc acons (e.g., sending an email, signing a contract, approving a procurement
request, or receiving speciﬁc informaon). Organizaons obtain non-repudiaon services by
employing various techniques or mechanisms, including digital signatures and digital message
receipts.
Related controls: AU-9, PM-12, SA-8, SC-8, SC-12, SC-13, SC-16, SC-17, SC-23.
(1) NON-REPUDIATION | ASSOCIATION OF IDENTITIES
(a) Bind the identy of the informaon producer with the informaon to [Assignment:
organizaon-deﬁned strength of binding]; and
(b) Provide the means for authorized individuals to determine the identy of the producer of
the informaon.
Discussion: Binding idenes to the informaon supports audit requirements that provide
organizaonal personnel with the means to idenfy who produced speciﬁc informaon in the
event of an informaon transfer. Organizaons determine and approve the strength of aribute
This document is produced from OSCAL source data
FAMILY: AU PAGE 62NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
binding between the informaon producer and the informaon based on the security category
of the informaon and other relevant risk factors.
Related controls: AC-4, AC-16.
(2) NON-REPUDIATION | VALIDATE BINDING OF INFORMATION PRODUCER IDENTITY
(a) Validate the binding of the informaon producer identy to the informaon at
[Assignment: organizaon-deﬁned frequency]; and
(b) Perform [Assignment: organizaon-deﬁned acons] in the event of a validaon error.
Discussion: Validang the binding of the informaon producer identy to the informaon
prevents the modiﬁcaon of informaon between producon and review. The validaon
of bindings can be achieved by, for example, using cryptographic checksums. Organizaons
determine if validaons are in response to user requests or generated automacally.
Related controls: AC-3, AC-4, AC-16.
(3) NON-REPUDIATION | CHAIN OF CUSTODY
Maintain reviewer or releaser credenals within the established chain of custody for
informaon reviewed or released.
Discussion: Chain of custody is a process that tracks the movement of evidence through its
collecon, safeguarding, and analysis life cycle by documenng each individual who handled
the evidence, the date and me the evidence was collected or transferred, and the purpose
for the transfer. If the reviewer is a human or if the review funcon is automated but separate
from the release or transfer funcon, the system associates the identy of the reviewer of the
informaon to be released with the informaon and the informaon label. In the case of human
reviews, maintaining the credenals of reviewers or releasers provides the organizaon with the
means to idenfy who reviewed and released the informaon. In the case of automated reviews,
it ensures that only approved review funcons are used.
Related controls: AC-4, AC-16.
(4) NON-REPUDIATION | VALIDATE BINDING OF INFORMATION REVIEWER IDENTITY
(a) Validate the binding of the informaon reviewer identy to the informaon at the
transfer or release points prior to release or transfer between [Assignment: organizaon-
deﬁned security domains]; and
(b) Perform [Assignment: organizaon-deﬁned acons] in the event of a validaon error.
Discussion: Validang the binding of the informaon reviewer identy to the informaon at
transfer or release points prevents the unauthorized modiﬁcaon of informaon between
review and the transfer or release. The validaon of bindings can be achieved by using
cryptographic checksums. Organizaons determine if validaons are in response to user
requests or generated automacally.
Related controls: AC-4, AC-16.
(5) NON-REPUDIATION | DIGITAL SIGNATURES
[Withdrawn: Incorporated into SI-7.]
References: [FIPS 140-3], [FIPS 180-4], [FIPS 186-4], [FIPS 202], [SP 800-177]
This document is produced from OSCAL source data
FAMILY: AU PAGE 63NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
AU-11 AUDIT RECORD RETENTION
Control: Retain audit records for [Assignment: organizaon-deﬁned me period consistent with
records retenon policy] to provide support for aer-the-fact invesgaons of incidents and to meet
regulatory and organizaonal informaon retenon requirements.
Discussion: Organizaons retain audit records unl it is determined that the records are no longer
needed for administrave, legal, audit, or other operaonal purposes. This includes the retenon
and availability of audit records relave to Freedom of Informaon Act (FOIA) requests, subpoenas,
and law enforcement acons. Organizaons develop standard categories of audit records relave to
such types of acons and standard response processes for each type of acon. The Naonal Archives
and Records Administraon (NARA) General Records Schedules provide federal policy on records
retenon.
Related controls: AU-2, AU-4, AU-5, AU-6, AU-9, AU-14, MP-6, RA-5, SI-12.
(1) AUDIT RECORD RETENTION | LONG-TERM RETRIEVAL CAPABILITY
Employ [Assignment: organizaon-deﬁned measures] to ensure that long-term audit records
generated by the system can be retrieved.
Discussion: Organizaons need to access and read audit records requiring long-term storage (on
the order of years). Measures employed to help facilitate the retrieval of audit records include
converng records to newer formats, retaining equipment capable of reading the records, and
retaining the necessary documentaon to help personnel understand how to interpret the
records.
Reference: [OMB A-130]
AU-12 AUDIT RECORD GENERATION
Control:
a. Provide audit record generaon capability for the event types the system is capable of auding
as deﬁned in AU-2a on [Assignment: organizaon-deﬁned system components];
b. Allow [Assignment: organizaon-deﬁned personnel or roles] to select the event types that are to
be logged by speciﬁc components of the system; and
c. Generate audit records for the event types deﬁned in AU-2c that include the audit record content
deﬁned in AU-3.
Discussion: Audit records can be generated from many diﬀerent system components. The event types
speciﬁed in AU-2d are the event types for which audit logs are to be generated and are a subset of all
event types for which the system can generate audit records.
Related controls: AC-6, AC-17, AU-2, AU-3, AU-4, AU-5, AU-6, AU-7, AU-14, CM-5, MA-4, MP-4, PM-12,
SA-8, SC-18, SI-3, SI-4, SI-7, SI-10.
(1) AUDIT RECORD GENERATION | SYSTEM-WIDE AND TIME-CORRELATED AUDIT TRAIL
Compile audit records from [Assignment: organizaon-deﬁned system components] into a
system-wide (logical or physical) audit trail that is me-correlated to within [Assignment:
This document is produced from OSCAL source data
FAMILY: AU PAGE 64NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
organizaon-deﬁned level of tolerance for the relaonship between me stamps of individual
records in the audit trail].
Discussion: Audit trails are me-correlated if the me stamps in the individual audit records can
be reliably related to the me stamps in other audit records to achieve a me ordering of the
records within organizaonal tolerances.
Related controls: AU-8, SC-45.
(2) AUDIT RECORD GENERATION | STANDARDIZED FORMATS
Produce a system-wide (logical or physical) audit trail composed of audit records in a
standardized format.
Discussion: Audit records that follow common standards promote interoperability and
informaon exchange between devices and systems. Promong interoperability and informaon
exchange facilitates the producon of event informaon that can be readily analyzed and
correlated. If logging mechanisms do not conform to standardized formats, systems may convert
individual audit records into standardized formats when compiling system-wide audit trails.
(3) AUDIT RECORD GENERATION | CHANGES BY AUTHORIZED INDIVIDUALS
Provide and implement the capability for [Assignment: organizaon-deﬁned individuals or
roles] to change the logging to be performed on [Assignment: organizaon-deﬁned system
components] based on [Assignment: organizaon-deﬁned selectable event criteria] within
[Assignment: organizaon-deﬁned me thresholds].
Discussion: Perming authorized individuals to make changes to system logging enables
organizaons to extend or limit logging as necessary to meet organizaonal requirements.
Logging that is limited to conserve system resources may be extended (either temporarily
or permanently) to address certain threat situaons. In addion, logging may be limited to a
speciﬁc set of event types to facilitate audit reducon, analysis, and reporng. Organizaons
can establish me thresholds in which logging acons are changed (e.g., near real-me, within
minutes, or within hours).
Related control: AC-3.
(4) AUDIT RECORD GENERATION | QUERY PARAMETER AUDITS OF PERSONALLY
IDENTIFIABLE INFORMATION
Provide and implement the capability for auding the parameters of user query events for
data sets containing personally idenﬁable informaon.
Discussion: Query parameters are explicit criteria that an individual or automated system submits
to a system to retrieve data. Auding of query parameters for datasets that contain personally
idenﬁable informaon augments the capability of an organizaon to track and understand the
access, usage, or sharing of personally idenﬁable informaon by authorized personnel.
References: None
AU-13 MONITORING FOR INFORMATION DISCLOSURE
Control:
a. Monitor [Assignment: organizaon-deﬁned open-source informaon and/or informaon sites]
[Assignment: organizaon-deﬁned frequency] for evidence of unauthorized disclosure of
organizaonal informaon; and
This document is produced from OSCAL source data
FAMILY: AU PAGE 65NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
b. If an informaon disclosure is discovered:
1. Nofy [Assignment: organizaon-deﬁned personnel or roles]; and
2. Take the following addional acons: [Assignment: organizaon-deﬁned addional acons].
Discussion: Unauthorized disclosure of informaon is a form of data leakage. Open-source informaon
includes social networking sites and code-sharing plaorms and repositories. Examples of
organizaonal informaon include personally idenﬁable informaon retained by the organizaon or
proprietary informaon generated by the organizaon.
Related controls: AC-22, PE-3, PM-12, RA-5, SC-7, SI-20.
(1) MONITORING FOR INFORMATION DISCLOSURE | USE OF AUTOMATED TOOLS
Monitor open-source informaon and informaon sites using [Assignment: organizaon-
deﬁned automated mechanisms].
Discussion: Automated mechanisms include commercial services that provide noﬁcaons and
alerts to organizaons and automated scripts to monitor new posts on websites.
(2) MONITORING FOR INFORMATION DISCLOSURE | REVIEW OF MONITORED SITES
Review the list of open-source informaon sites being monitored [Assignment: organizaon-
deﬁned frequency].
Discussion: Reviewing the current list of open-source informaon sites being monitored on a
regular basis helps to ensure that the selected sites remain relevant. The review also provides
the opportunity to add new open-source informaon sites with the potenal to provide
evidence of unauthorized disclosure of organizaonal informaon. The list of sites monitored
can be guided and informed by threat intelligence of other credible sources of informaon.
(3) MONITORING FOR INFORMATION DISCLOSURE | UNAUTHORIZED REPLICATION OF
INFORMATION
Employ discovery techniques, processes, and tools to determine if external enes are
replicang organizaonal informaon in an unauthorized manner.
Discussion: The unauthorized use or replicaon of organizaonal informaon by external
enes can cause adverse impacts on organizaonal operaons and assets, including damage
to reputaon. Such acvity can include the replicaon of an organizaonal website by an
adversary or hosle threat actor who aempts to impersonate the web-hosng organizaon.
Discovery tools, techniques, and processes used to determine if external enes are replicang
organizaonal informaon in an unauthorized manner include scanning external websites,
monitoring social media, and training staﬀ to recognize the unauthorized use of organizaonal
informaon.
References: None
AU-14 SESSION AUDIT
Control:
a. Provide and implement the capability for [Assignment: organizaon-deﬁned users or roles]
to [Selecon (one or more): record; view; hear; log] the content of a user session under
[Assignment: organizaon-deﬁned circumstances]; and
This document is produced from OSCAL source data
FAMILY: AU PAGE 66NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
b. Develop, integrate, and use session auding acvies in consultaon with legal counsel and in
accordance with applicable laws, execuve orders, direcves, regulaons, policies, standards,
and guidelines.
Discussion: Session audits can include monitoring keystrokes, tracking websites visited, and recording
informaon and/or ﬁle transfers. Session audit capability is implemented in addion to event logging
and may involve implementaon of specialized session capture technology. Organizaons consider
how session auding can reveal informaon about individuals that may give rise to privacy risk as well
as how to migate those risks. Because session auding can impact system and network performance,
organizaons acvate the capability under well-deﬁned situaons (e.g., the organizaon is suspicious
of a speciﬁc individual). Organizaons consult with legal counsel, civil liberes oﬃcials, and privacy
oﬃcials to ensure that any legal, privacy, civil rights, or civil liberes issues, including the use of
personally idenﬁable informaon, are appropriately addressed.
Related controls: AC-3, AC-8, AU-2, AU-3, AU-4, AU-5, AU-8, AU-9, AU-11, AU-12.
(1) SESSION AUDIT | SYSTEM START-UP
Iniate session audits automacally at system start-up.
Discussion: The automac iniaon of session audits at startup helps to ensure that the
informaon being captured on selected individuals is complete and not subject to compromise
through tampering by malicious threat actors.
(2) SESSION AUDIT | CAPTURE AND RECORD CONTENT
[Withdrawn: Incorporated into AU-14.]
(3) SESSION AUDIT | REMOTE VIEWING AND LISTENING
Provide and implement the capability for authorized users to remotely view and hear content
related to an established user session in real me.
Discussion: None.
Related control: AC-17.
References: None
AU-15 Alternate Audit Logging Capability
[Withdrawn: Moved to AU-5(5).]
AU-16 CROSS-ORGANIZATIONAL AUDIT LOGGING
Control: Employ [Assignment: organizaon-deﬁned methods] for coordinang [Assignment:
organizaon-deﬁned audit informaon] among external organizaons when audit informaon is
transmied across organizaonal boundaries.
Discussion: When organizaons use systems or services of external organizaons, the audit logging
capability necessitates a coordinated, cross-organizaon approach. For example, maintaining the
identy of individuals who request speciﬁc services across organizaonal boundaries may oen be
diﬃcult, and doing so may prove to have signiﬁcant performance and privacy ramiﬁcaons. Therefore,
it is oen the case that cross-organizaonal audit logging simply captures the identy of individuals
who issue requests at the inial system, and subsequent systems record that the requests originated
This document is produced from OSCAL source data
FAMILY: AU PAGE 67NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
from authorized individuals. Organizaons consider including processes for coordinang audit
informaon requirements and protecon of audit informaon in informaon exchange agreements.
Related controls: AU-3, AU-6, AU-7, CA-3, PT-7.
(1) CROSS-ORGANIZATIONAL AUDIT LOGGING | IDENTITY PRESERVATION
Preserve the identy of individuals in cross-organizaonal audit trails.
Discussion: Identy preservaon is applied when there is a need to be able to trace acons that
are performed across organizaonal boundaries to a speciﬁc individual.
Related controls: IA-2, IA-4, IA-5, IA-8.
(2) CROSS-ORGANIZATIONAL AUDIT LOGGING | SHARING OF AUDIT INFORMATION
Provide cross-organizaonal audit informaon to [Assignment: organizaon-deﬁned
organizaons] based on [Assignment: organizaon-deﬁned cross-organizaonal sharing
agreements].
Discussion: Due to the distributed nature of the audit informaon, cross-organizaon sharing
of audit informaon may be essenal for eﬀecve analysis of the auding being performed.
For example, the audit records of one organizaon may not provide suﬃcient informaon to
determine the appropriate or inappropriate use of organizaonal informaon resources by
individuals in other organizaons. In some instances, only individuals’ home organizaons have
the appropriate knowledge to make such determinaons, thus requiring the sharing of audit
informaon among organizaons.
Related controls: IR-4, SI-4.
(3) CROSS-ORGANIZATIONAL AUDIT LOGGING | DISASSOCIABILITY
Implement [Assignment: organizaon-deﬁned measures] to disassociate individuals from
audit informaon transmied across organizaonal boundaries.
Discussion: Preserving idenes in audit trails could have privacy ramiﬁcaons, such as enabling
the tracking and proﬁling of individuals, but may not be operaonally necessary. These risks
could be further ampliﬁed when transming informaon across organizaonal boundaries.
Implemenng privacy-enhancing cryptographic techniques can disassociate individuals from
audit informaon and reduce privacy risk while maintaining accountability.
References: None
This document is produced from OSCAL source data
FAMILY: AU PAGE 68NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
FAMILY: ASSESSMENT, AUTHORIZATION, AND MONITORING
CA-1 POLICY AND PROCEDURES
Control:
a. Develop, document, and disseminate to [Assignment: organizaon-deﬁned personnel or roles]:
1. [Selecon (one or more): Organizaon-level; Mission/business process-level; System-level]
assessment, authorizaon, and monitoring policy that:
(a) Addresses purpose, scope, roles, responsibilies, management commitment,
coordinaon among organizaonal enes, and compliance; and
(b) Is consistent with applicable laws, execuve orders, direcves, regulaons, policies,
standards, and guidelines; and
2. Procedures to facilitate the implementaon of the assessment, authorizaon, and
monitoring policy and the associated assessment, authorizaon, and monitoring controls;
b. Designate an [Assignment: organizaon-deﬁned oﬃcial] to manage the development,
documentaon, and disseminaon of the assessment, authorizaon, and monitoring policy and
procedures; and
c. Review and update the current assessment, authorizaon, and monitoring:
1. Policy [Assignment: organizaon-deﬁned frequency] and following [Assignment:
organizaon-deﬁned events]; and
2. Procedures [Assignment: organizaon-deﬁned frequency] and following [Assignment:
organizaon-deﬁned events].
Discussion: Assessment, authorizaon, and monitoring policy and procedures address the controls in
the CA family that are implemented within systems and organizaons. The risk management strategy
is an important factor in establishing such policies and procedures. Policies and procedures contribute
to security and privacy assurance. Therefore, it is important that security and privacy programs
collaborate on the development of assessment, authorizaon, and monitoring policy and procedures.
Security and privacy program policies and procedures at the organizaon level are preferable, in
general, and may obviate the need for mission- or system-speciﬁc policies and procedures. The policy
can be included as part of the general security and privacy policy or be represented by mulple
policies that reﬂect the complex nature of organizaons. Procedures can be established for security
and privacy programs, for mission or business processes, and for systems, if needed. Procedures
describe how the policies or controls are implemented and can be directed at the individual or role
that is the object of the procedure. Procedures can be documented in system security and privacy
plans or in one or more separate documents. Events that may precipitate an update to assessment,
authorizaon, and monitoring policy and procedures include assessment or audit ﬁndings, security
incidents or breaches, or changes in applicable laws, execuve orders, direcves, regulaons, policies,
standards, and guidelines. Simply restang controls does not constute an organizaonal policy or
procedure.
Related controls: PM-9, PS-8, SI-12.
References: [IR 8062], [OMB A-130], [SP 800-100], [SP 800-12], [SP 800-137], [SP 800-137A], [SP
800-30], [SP 800-37], [SP 800-39], [SP 800-53A]
This document is produced from OSCAL source data
FAMILY: CA PAGE 69NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
CA-2 CONTROL ASSESSMENTS
Control:
a. Select the appropriate assessor or assessment team for the type of assessment to be conducted;
b. Develop a control assessment plan that describes the scope of the assessment including:
1. Controls and control enhancements under assessment;
2. Assessment procedures to be used to determine control eﬀecveness; and
3. Assessment environment, assessment team, and assessment roles and responsibilies;
c. Ensure the control assessment plan is reviewed and approved by the authorizing oﬃcial or
designated representave prior to conducng the assessment;
d. Assess the controls in the system and its environment of operaon [Assignment: organizaon-
deﬁned frequency] to determine the extent to which the controls are implemented correctly,
operang as intended, and producing the desired outcome with respect to meeng established
security and privacy requirements;
e. Produce a control assessment report that document the results of the assessment; and
f. Provide the results of the control assessment to [Assignment: organizaon-deﬁned individuals or
roles].
Discussion: Organizaons ensure that control assessors possess the required skills and technical
experse to develop eﬀecve assessment plans and to conduct assessments of system-speciﬁc,
hybrid, common, and program management controls, as appropriate. The required skills include
general knowledge of risk management concepts and approaches as well as comprehensive
knowledge of and experience with the hardware, soware, and ﬁrmware system components
implemented.
Organizaons assess controls in systems and the environments in which those systems operate
as part of inial and ongoing authorizaons, connuous monitoring, FISMA annual assessments,
system design and development, systems security engineering, privacy engineering, and the system
development life cycle. Assessments help to ensure that organizaons meet informaon security and
privacy requirements, idenfy weaknesses and deﬁciencies in the system design and development
process, provide essenal informaon needed to make risk-based decisions as part of authorizaon
processes, and comply with vulnerability migaon procedures. Organizaons conduct assessments
on the implemented controls as documented in security and privacy plans. Assessments can
also be conducted throughout the system development life cycle as part of systems engineering
and systems security engineering processes. The design for controls can be assessed as RFPs are
developed, responses assessed, and design reviews conducted. If a design to implement controls and
subsequent implementaon in accordance with the design are assessed during development, the ﬁnal
control tesng can be a simple conﬁrmaon ulizing previously completed control assessment and
aggregang the outcomes.
Organizaons may develop a single, consolidated security and privacy assessment plan for the
system or maintain separate plans. A consolidated assessment plan clearly delineates the roles and
responsibilies for control assessment. If mulple organizaons parcipate in assessing a system, a
coordinated approach can reduce redundancies and associated costs.
Organizaons can use other types of assessment acvies, such as vulnerability scanning and system
monitoring, to maintain the security and privacy posture of systems during the system life cycle.
Assessment reports document assessment results in suﬃcient detail, as deemed necessary by
organizaons, to determine the accuracy and completeness of the reports and whether the controls
are implemented correctly, operang as intended, and producing the desired outcome with respect
This document is produced from OSCAL source data
FAMILY: CA PAGE 70NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
to meeng requirements. Assessment results are provided to the individuals or roles appropriate
for the types of assessments being conducted. For example, assessments conducted in support of
authorizaon decisions are provided to authorizing oﬃcials, senior agency oﬃcials for privacy, senior
agency informaon security oﬃcers, and authorizing oﬃcial designated representaves.
To sasfy annual assessment requirements, organizaons can use assessment results from the
following sources: inial or ongoing system authorizaons, connuous monitoring, systems
engineering processes, or system development life cycle acvies. Organizaons ensure that
assessment results are current, relevant to the determinaon of control eﬀecveness, and obtained
with the appropriate level of assessor independence. Exisng control assessment results can be
reused to the extent that the results are sll valid and can also be supplemented with addional
assessments as needed. Aer the inial authorizaons, organizaons assess controls during
connuous monitoring. Organizaons also establish the frequency for ongoing assessments in
accordance with organizaonal connuous monitoring strategies. External audits, including audits by
external enes such as regulatory agencies, are outside of the scope of CA-2.
Related controls: AC-20, CA-5, CA-6, CA-7, PM-9, RA-5, RA-10, SA-11, SC-38, SI-3, SI-12, SR-2, SR-3.
(1) CONTROL ASSESSMENTS | INDEPENDENT ASSESSORS
Employ independent assessors or assessment teams to conduct control assessments.
Discussion: Independent assessors or assessment teams are individuals or groups who conduct
imparal assessments of systems. Imparality means that assessors are free from any
perceived or actual conﬂicts of interest regarding the development, operaon, sustainment, or
management of the systems under assessment or the determinaon of control eﬀecveness.
To achieve imparality, assessors do not create a mutual or conﬂicng interest with the
organizaons where the assessments are being conducted, assess their own work, act as
management or employees of the organizaons they are serving, or place themselves in
posions of advocacy for the organizaons acquiring their services.
Independent assessments can be obtained from elements within organizaons or be contracted
to public or private sector enes outside of organizaons. Authorizing oﬃcials determine the
required level of independence based on the security categories of systems and/or the risk
to organizaonal operaons, organizaonal assets, or individuals. Authorizing oﬃcials also
determine if the level of assessor independence provides suﬃcient assurance that the results
are sound and can be used to make credible, risk-based decisions. Assessor independence
determinaon includes whether contracted assessment services have suﬃcient independence,
such as when system owners are not directly involved in contracng processes or cannot
inﬂuence the imparality of the assessors conducng the assessments. During the system design
and development phase, having independent assessors is analogous to having independent
SMEs involved in design reviews.
When organizaons that own the systems are small or the structures of the organizaons
require that assessments be conducted by individuals that are in the developmental,
operaonal, or management chain of the system owners, independence in assessment
processes can be achieved by ensuring that assessment results are carefully reviewed and
analyzed by independent teams of experts to validate the completeness, accuracy, integrity,
and reliability of the results. Assessments performed for purposes other than to support
authorizaon decisions are more likely to be useable for such decisions when performed by
assessors with suﬃcient independence, thereby reducing the need to repeat assessments.
This document is produced from OSCAL source data
FAMILY: CA PAGE 71NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(2) CONTROL ASSESSMENTS | SPECIALIZED ASSESSMENTS
Include as part of control assessments, [Assignment: organizaon-deﬁned frequency],
[Selecon: announced; unannounced], [Selecon (one or more): in-depth monitoring; security
instrumentaon; automated security test cases; vulnerability scanning; malicious user
tesng; insider threat assessment; performance and load tesng; data leakage or data loss
assessment; [Assignment: organizaon-deﬁned other forms of assessment]].
Discussion: Organizaons can conduct specialized assessments, including veriﬁcaon and
validaon, system monitoring, insider threat assessments, malicious user tesng, and other
forms of tesng. These assessments can improve readiness by exercising organizaonal
capabilies and indicang current levels of performance as a means of focusing acons to
improve security and privacy. Organizaons conduct specialized assessments in accordance with
applicable laws, execuve orders, direcves, regulaons, policies, standards, and guidelines.
Authorizing oﬃcials approve the assessment methods in coordinaon with the organizaonal
risk execuve funcon. Organizaons can include vulnerabilies uncovered during assessments
into vulnerability remediaon processes. Specialized assessments can also be conducted early in
the system development life cycle (e.g., during inial design, development, and unit tesng).
Related controls: PE-3, SI-2.
(3) CONTROL ASSESSMENTS | LEVERAGING RESULTS FROM EXTERNAL ORGANIZATIONS
Leverage the results of control assessments performed by [Assignment: organizaon-deﬁned
external organizaon] on [Assignment: organizaon-deﬁned system] when the assessment
meets [Assignment: organizaon-deﬁned requirements].
Discussion: Organizaons may rely on control assessments of organizaonal systems by other
(external) organizaons. Using such assessments and reusing exisng assessment evidence
can decrease the me and resources required for assessments by liming the independent
assessment acvies that organizaons need to perform. The factors that organizaons consider
in determining whether to accept assessment results from external organizaons can vary. Such
factors include the organizaon’s past experience with the organizaon that conducted the
assessment, the reputaon of the assessment organizaon, the level of detail of supporng
assessment evidence provided, and mandates imposed by applicable laws, execuve orders,
direcves, regulaons, policies, standards, and guidelines. Accredited tesng laboratories that
support the Common Criteria Program ISO 15408-1, the NIST Cryptographic Module Validaon
Program (CMVP), or the NIST Cryptographic Algorithm Validaon Program (CAVP) can provide
independent assessment results that organizaons can leverage.
Related control: SA-4.
References: [FIPS 199], [IR 8011-1], [IR 8062], [OMB A-130], [SP 800-115], [SP 800-137], [SP 800-18],
[SP 800-37], [SP 800-39], [SP 800-53A]
CA-3 INFORMATION EXCHANGE
Control:
a. Approve and manage the exchange of informaon between the system and other systems
using [Selecon (one or more): interconnecon security agreements; informaon exchange
security agreements; memoranda of understanding or agreement; service level agreements; user
agreements; nondisclosure agreements; [Assignment: organizaon-deﬁned type of agreement]];
This document is produced from OSCAL source data
FAMILY: CA PAGE 72NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
b. Document, as part of each exchange agreement, the interface characteriscs, security and
privacy requirements, controls, and responsibilies for each system, and the impact level of the
informaon communicated; and
c. Review and update the agreements [Assignment: organizaon-deﬁned frequency].
Discussion: System informaon exchange requirements apply to informaon exchanges between two
or more systems. System informaon exchanges include connecons via leased lines or virtual private
networks, connecons to internet service providers, database sharing or exchanges of database
transacon informaon, connecons and exchanges with cloud services, exchanges via web-based
services, or exchanges of ﬁles via ﬁle transfer protocols, network protocols (e.g., IPv4, IPv6), email, or
other organizaon-to-organizaon communicaons. Organizaons consider the risk related to new
or increased threats that may be introduced when systems exchange informaon with other systems
that may have diﬀerent security and privacy requirements and controls. This includes systems within
the same organizaon and systems that are external to the organizaon. A joint authorizaon of the
systems exchanging informaon, as described in CA-6(1) or CA-6(2), may help to communicate and
reduce risk.
Authorizing oﬃcials determine the risk associated with system informaon exchange and the controls
needed for appropriate risk migaon. The types of agreements selected are based on factors such
as the impact level of the informaon being exchanged, the relaonship between the organizaons
exchanging informaon (e.g., government to government, government to business, business to
business, government or business to service provider, government or business to individual), or the
level of access to the organizaonal system by users of the other system. If systems that exchange
informaon have the same authorizing oﬃcial, organizaons need not develop agreements. Instead,
the interface characteriscs between the systems (e.g., how the informaon is being exchanged.
how the informaon is protected) are described in the respecve security and privacy plans. If the
systems that exchange informaon have diﬀerent authorizing oﬃcials within the same organizaon,
the organizaons can develop agreements or provide the same informaon that would be provided
in the appropriate agreement type from CA-3a in the respecve security and privacy plans for the
systems. Organizaons may incorporate agreement informaon into formal contracts, especially for
informaon exchanges established between federal agencies and nonfederal organizaons (including
service providers, contractors, system developers, and system integrators). Risk consideraons include
systems that share the same networks.
Related controls: AC-4, AC-20, AU-16, CA-6, IA-3, IR-4, PL-2, PT-7, RA-3, SA-9, SC-7, SI-12.
(1) INFORMATION EXCHANGE | UNCLASSIFIED NATIONAL SECURITY SYSTEM CONNECTIONS
[Withdrawn: Incorporated into SC-7(25).]
(2) INFORMATION EXCHANGE | CLASSIFIED NATIONAL SECURITY SYSTEM CONNECTIONS
[Withdrawn: Incorporated into SC-7(26).]
(3) INFORMATION EXCHANGE | UNCLASSIFIED NON-NATIONAL SECURITY SYSTEM
CONNECTIONS
[Withdrawn: Incorporated into SC-7(27).]
(4) INFORMATION EXCHANGE | CONNECTIONS TO PUBLIC NETWORKS
[Withdrawn: Incorporated into SC-7(28).]
This document is produced from OSCAL source data
FAMILY: CA PAGE 73NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(5) INFORMATION EXCHANGE | RESTRICTIONS ON EXTERNAL SYSTEM CONNECTIONS
[Withdrawn: Incorporated into SC-7(5).]
(6) INFORMATION EXCHANGE | TRANSFER AUTHORIZATIONS
Verify that individuals or systems transferring data between interconnecng systems have the
requisite authorizaons (i.e., write permissions or privileges) prior to accepng such data.
Discussion: To prevent unauthorized individuals and systems from making informaon transfers
to protected systems, the protected system veriﬁes—via independent means— whether the
individual or system aempng to transfer informaon is authorized to do so. Veriﬁcaon of the
authorizaon to transfer informaon also applies to control plane traﬃc (e.g., roung and DNS)
and services (e.g., authencated SMTP relays).
Related controls: AC-2, AC-3, AC-4.
(7) INFORMATION EXCHANGE | TRANSITIVE INFORMATION EXCHANGES
(a) Idenfy transive (downstream) informaon exchanges with other systems through the
systems idenﬁed in CA-3a; and
(b) Take measures to ensure that transive (downstream) informaon exchanges cease
when the controls on idenﬁed transive (downstream) systems cannot be veriﬁed or
validated.
Discussion: Transive or downstream informaon exchanges are informaon exchanges between
the system or systems with which the organizaonal system exchanges informaon and other
systems. For mission-essenal systems, services, and applicaons, including high value assets,
it is necessary to idenfy such informaon exchanges. The transparency of the controls or
protecon measures in place in such downstream systems connected directly or indirectly to
organizaonal systems is essenal to understanding the security and privacy risks resulng from
those informaon exchanges. Organizaonal systems can inherit risk from downstream systems
through transive connecons and informaon exchanges, which can make the organizaonal
systems more suscepble to threats, hazards, and adverse impacts.
Related control: SC-7.
References: [FIPS 199], [OMB A-130], [SP 800-47]
CA-4 Security Cerﬁcaon
[Withdrawn: Incorporated into CA-2.]
CA-5 PLAN OF ACTION AND MILESTONES
Control:
a. Develop a plan of acon and milestones for the system to document the planned remediaon
acons of the organizaon to correct weaknesses or deﬁciencies noted during the assessment of
the controls and to reduce or eliminate known vulnerabilies in the system; and
b. Update exisng plan of acon and milestones [Assignment: organizaon-deﬁned frequency]
based on the ﬁndings from control assessments, independent audits or reviews, and connuous
monitoring acvies.
This document is produced from OSCAL source data
FAMILY: CA PAGE 74NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
Discussion: Plans of acon and milestones are useful for any type of organizaon to track planned
remedial acons. Plans of acon and milestones are required in authorizaon packages and subject to
federal reporng requirements established by OMB.
Related controls: CA-2, CA-7, PM-4, PM-9, RA-7, SI-2, SI-12.
(1) PLAN OF ACTION AND MILESTONES | AUTOMATION SUPPORT FOR ACCURACY AND
CURRENCY
Ensure the accuracy, currency, and availability of the plan of acon and milestones for the
system using [Assignment: organizaon-deﬁned automated mechanisms].
Discussion: Using automated tools helps maintain the accuracy, currency, and availability of
the plan of acon and milestones and facilitates the coordinaon and sharing of security and
privacy informaon throughout the organizaon. Such coordinaon and informaon sharing
help to idenfy systemic weaknesses or deﬁciencies in organizaonal systems and ensure that
appropriate resources are directed at the most crical system vulnerabilies in a mely manner.
References: [OMB A-130], [SP 800-37]
CA-6 AUTHORIZATION
Control:
a. Assign a senior oﬃcial as the authorizing oﬃcial for the system;
b. Assign a senior oﬃcial as the authorizing oﬃcial for common controls available for inheritance by
organizaonal systems;
c. Ensure that the authorizing oﬃcial for the system, before commencing operaons:
1. Accepts the use of common controls inherited by the system; and
2. Authorizes the system to operate;
d. Ensure that the authorizing oﬃcial for common controls authorizes the use of those controls for
inheritance by organizaonal systems;
e. Update the authorizaons [Assignment: organizaon-deﬁned frequency].
Discussion: Authorizaons are oﬃcial management decisions by senior oﬃcials to authorize operaon
of systems, authorize the use of common controls for inheritance by organizaonal systems, and
explicitly accept the risk to organizaonal operaons and assets, individuals, other organizaons,
and the Naon based on the implementaon of agreed-upon controls. Authorizing oﬃcials provide
budgetary oversight for organizaonal systems and common controls or assume responsibility for the
mission and business funcons supported by those systems or common controls. The authorizaon
process is a federal responsibility, and therefore, authorizing oﬃcials must be federal employees.
Authorizing oﬃcials are both responsible and accountable for security and privacy risks associated
with the operaon and use of organizaonal systems. Nonfederal organizaons may have similar
processes to authorize systems and senior oﬃcials that assume the authorizaon role and associated
responsibilies.
Authorizing oﬃcials issue ongoing authorizaons of systems based on evidence produced from
implemented connuous monitoring programs. Robust connuous monitoring programs reduce the
need for separate reauthorizaon processes. Through the employment of comprehensive connuous
monitoring processes, the informaon contained in authorizaon packages (i.e., security and privacy
plans, assessment reports, and plans of acon and milestones) is updated on an ongoing basis. This
provides authorizing oﬃcials, common control providers, and system owners with an up-to-date
This document is produced from OSCAL source data
FAMILY: CA PAGE 75NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
status of the security and privacy posture of their systems, controls, and operang environments.
To reduce the cost of reauthorizaon, authorizing oﬃcials can leverage the results of connuous
monitoring processes to the maximum extent possible as the basis for rendering reauthorizaon
decisions.
Related controls: CA-2, CA-3, CA-7, PM-9, PM-10, RA-3, SA-10, SI-12.
(1) AUTHORIZATION | JOINT AUTHORIZATION — INTRA-ORGANIZATION
Employ a joint authorizaon process for the system that includes mulple authorizing oﬃcials
from the same organizaon conducng the authorizaon.
Discussion: Assigning mulple authorizing oﬃcials from the same organizaon to serve as
co-authorizing oﬃcials for the system increases the level of independence in the risk-based
decision-making process. It also implements the concepts of separaon of dues and dual
authorizaon as applied to the system authorizaon process. The intra-organizaon joint
authorizaon process is most relevant for connected systems, shared systems, and systems with
mulple informaon owners.
Related control: AC-6.
(2) AUTHORIZATION | JOINT AUTHORIZATION — INTER-ORGANIZATION
Employ a joint authorizaon process for the system that includes mulple authorizing
oﬃcials with at least one authorizing oﬃcial from an organizaon external to the organizaon
conducng the authorizaon.
Discussion: Assigning mulple authorizing oﬃcials, at least one of whom comes from an
external organizaon, to serve as co-authorizing oﬃcials for the system increases the level
of independence in the risk-based decision-making process. It implements the concepts of
separaon of dues and dual authorizaon as applied to the system authorizaon process.
Employing authorizing oﬃcials from external organizaons to supplement the authorizing
oﬃcial from the organizaon that owns or hosts the system may be necessary when the
external organizaons have a vested interest or equies in the outcome of the authorizaon
decision. The inter-organizaon joint authorizaon process is relevant and appropriate for
connected systems, shared systems or services, and systems with mulple informaon owners.
The authorizing oﬃcials from the external organizaons are key stakeholders of the system
undergoing authorizaon.
Related control: AC-6.
References: [OMB A-130], [SP 800-137], [SP 800-37]
CA-7 CONTINUOUS MONITORING
Control: Develop a system-level connuous monitoring strategy and implement connuous monitoring
in accordance with the organizaon-level connuous monitoring strategy that includes:
a. Establishing the following system-level metrics to be monitored: [Assignment: organizaon-
deﬁned system-level metrics];
b. Establishing [Assignment: organizaon-deﬁned frequencies] for monitoring and [Assignment:
organizaon-deﬁned frequencies] for assessment of control eﬀecveness;
c. Ongoing control assessments in accordance with the connuous monitoring strategy;
d. Ongoing monitoring of system and organizaon-deﬁned metrics in accordance with the
connuous monitoring strategy;
This document is produced from OSCAL source data
FAMILY: CA PAGE 76NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
e. Correlaon and analysis of informaon generated by control assessments and monitoring;
f. Response acons to address results of the analysis of control assessment and monitoring
informaon; and
g. Reporng the security and privacy status of the system to [Assignment: organizaon-deﬁned
personnel or roles] [Assignment: organizaon-deﬁned frequency].
Discussion: Connuous monitoring at the system level facilitates ongoing awareness of the system
security and privacy posture to support organizaonal risk management decisions. The terms
connuous and ongoing imply that organizaons assess and monitor their controls and risks at a
frequency suﬃcient to support risk-based decisions. Diﬀerent types of controls may require diﬀerent
monitoring frequencies. The results of connuous monitoring generate risk response acons by
organizaons. When monitoring the eﬀecveness of mulple controls that have been grouped into
capabilies, a root-cause analysis may be needed to determine the speciﬁc control that has failed.
Connuous monitoring programs allow organizaons to maintain the authorizaons of systems and
common controls in highly dynamic environments of operaon with changing mission and business
needs, threats, vulnerabilies, and technologies. Having access to security and privacy informaon on
a connuing basis through reports and dashboards gives organizaonal oﬃcials the ability to make
eﬀecve and mely risk management decisions, including ongoing authorizaon decisions.
Automaon supports more frequent updates to hardware, soware, and ﬁrmware inventories,
authorizaon packages, and other system informaon. Eﬀecveness is further enhanced when
connuous monitoring outputs are formaed to provide informaon that is speciﬁc, measurable,
aconable, relevant, and mely. Connuous monitoring acvies are scaled in accordance with the
security categories of systems. Monitoring requirements, including the need for speciﬁc monitoring,
may be referenced in other controls and control enhancements, such as AC-2g, AC-2(7), AC-2(12)
(a), AC-2(7)(b), AC-2(7)(c), AC-17(1), AT-4a, AU-13, AU-13(1), AU-13(2), CM-3f, CM-6d, CM-11c, IR-5,
MA-2b, MA-3a, MA-4a, PE-3d, PE-6, PE-14b, PE-16, PE-20, PM-6, PM-23, PM-31, PS-7e, SA-9c, SR-4,
SC-5(3)(b), SC-7a, SC-7(24)(b), SC-18b, SC-43b, and SI-4.
Related controls: AC-2, AC-6, AC-17, AT-4, AU-6, AU-13, CA-2, CA-5, CA-6, CM-3, CM-4, CM-6, CM-11,
IA-5, IR-5, MA-2, MA-3, MA-4, PE-3, PE-6, PE-14, PE-16, PE-20, PL-2, PM-4, PM-6, PM-9, PM-10,
PM-12, PM-14, PM-23, PM-28, PM-31, PS-7, PT-7, RA-3, RA-5, RA-7, RA-10, SA-8, SA-9, SA-11, SC-5,
SC-7, SC-18, SC-38, SC-43, SI-3, SI-4, SI-12, SR-6.
(1) CONTINUOUS MONITORING | INDEPENDENT ASSESSMENT
Employ independent assessors or assessment teams to monitor the controls in the system on
an ongoing basis.
Discussion: Organizaons maximize the value of control assessments by requiring that
assessments be conducted by assessors with appropriate levels of independence. The level of
required independence is based on organizaonal connuous monitoring strategies. Assessor
independence provides a degree of imparality to the monitoring process. To achieve such
imparality, assessors do not create a mutual or conﬂicng interest with the organizaons
where the assessments are being conducted, assess their own work, act as management or
employees of the organizaons they are serving, or place themselves in advocacy posions for
the organizaons acquiring their services.
(2) CONTINUOUS MONITORING | TYPES OF ASSESSMENTS
[Withdrawn: Incorporated into CA-2.]
This document is produced from OSCAL source data
FAMILY: CA PAGE 77NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(3) CONTINUOUS MONITORING | TREND ANALYSES
Employ trend analyses to determine if control implementaons, the frequency of connuous
monitoring acvies, and the types of acvies used in the connuous monitoring process
need to be modiﬁed based on empirical data.
Discussion: Trend analyses include examining recent threat informaon that addresses the
types of threat events that have occurred in the organizaon or the Federal Government,
success rates of certain types of aacks, emerging vulnerabilies in technologies, evolving social
engineering techniques, the eﬀecveness of conﬁguraon sengs, results from mulple control
assessments, and ﬁndings from Inspectors General or auditors.
(4) CONTINUOUS MONITORING | RISK MONITORING
Ensure risk monitoring is an integral part of the connuous monitoring strategy that includes
the following:
(a) Eﬀecveness monitoring;
(b) Compliance monitoring; and
(c) Change monitoring.
Discussion: Risk monitoring is informed by the established organizaonal risk tolerance.
Eﬀecveness monitoring determines the ongoing eﬀecveness of the implemented risk
response measures. Compliance monitoring veriﬁes that required risk response measures
are implemented. It also veriﬁes that security and privacy requirements are sasﬁed. Change
monitoring idenﬁes changes to organizaonal systems and environments of operaon that may
aﬀect security and privacy risk.
(5) CONTINUOUS MONITORING | CONSISTENCY ANALYSIS
Employ the following acons to validate that policies are established and implemented
controls are operang in a consistent manner: [Assignment: organizaon-deﬁned acons].
Discussion: Security and privacy controls are oen added incrementally to a system. As a result,
policies for selecng and implemenng controls may be inconsistent, and the controls could fail
to work together in a consistent or coordinated manner. At a minimum, the lack of consistency
and coordinaon could mean that there are unacceptable security and privacy gaps in the
system. At worst, it could mean that some of the controls implemented in one locaon or by one
component are actually impeding the funconality of other controls (e.g., encrypng internal
network traﬃc can impede monitoring). In other situaons, failing to consistently monitor all
implemented network protocols (e.g., a dual stack of IPv4 and IPv6) may create unintended
vulnerabilies in the system that could be exploited by adversaries. It is important to validate
—through tesng, monitoring, and analysis—that the implemented controls are operang in a
consistent, coordinated, non-interfering manner.
(6) CONTINUOUS MONITORING | AUTOMATION SUPPORT FOR MONITORING
Ensure the accuracy, currency, and availability of monitoring results for the system using
[Assignment: organizaon-deﬁned automated mechanisms].
Discussion: Using automated tools for monitoring helps to maintain the accuracy, currency,
and availability of monitoring informaon which in turns helps to increase the level of
This document is produced from OSCAL source data
FAMILY: CA PAGE 78NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
ongoing awareness of the system security and privacy posture in support of organizaonal risk
management decisions.
References: [IR 8011-1], [IR 8062], [OMB A-130], [SP 800-115], [SP 800-137], [SP 800-37], [SP 800-39],
[SP 800-53A]
CA-8 PENETRATION TESTING
Control: Conduct penetraon tesng [Assignment: organizaon-deﬁned frequency] on [Assignment:
organizaon-deﬁned systems or system components].
Discussion: Penetraon tesng is a specialized type of assessment conducted on systems or individual
system components to idenfy vulnerabilies that could be exploited by adversaries. Penetraon
tesng goes beyond automated vulnerability scanning and is conducted by agents and teams with
demonstrable skills and experience that include technical experse in network, operang system,
and/or applicaon level security. Penetraon tesng can be used to validate vulnerabilies or
determine the degree of penetraon resistance of systems to adversaries within speciﬁed constraints.
Such constraints include me, resources, and skills. Penetraon tesng aempts to duplicate
the acons of adversaries and provides a more in-depth analysis of security- and privacy-related
weaknesses or deﬁciencies. Penetraon tesng is especially important when organizaons are
transioning from older technologies to newer technologies (e.g., transioning from IPv4 to IPv6
network protocols).
Organizaons can use the results of vulnerability analyses to support penetraon tesng acvies.
Penetraon tesng can be conducted internally or externally on the hardware, soware, or ﬁrmware
components of a system and can exercise both physical and technical controls. A standard method
for penetraon tesng includes a pretest analysis based on full knowledge of the system, pretest
idenﬁcaon of potenal vulnerabilies based on the pretest analysis, and tesng designed to
determine the exploitability of vulnerabilies. All pares agree to the rules of engagement before
commencing penetraon tesng scenarios. Organizaons correlate the rules of engagement for the
penetraon tests with the tools, techniques, and procedures that are ancipated to be employed
by adversaries. Penetraon tesng may result in the exposure of informaon that is protected
by laws or regulaons, to individuals conducng the tesng. Rules of engagement, contracts, or
other appropriate mechanisms can be used to communicate expectaons for how to protect this
informaon. Risk assessments guide the decisions on the level of independence required for the
personnel conducng penetraon tesng.
Related controls: RA-5, RA-10, SA-11, SR-5, SR-6.
(1) PENETRATION TESTING | INDEPENDENT PENETRATION TESTING AGENT OR TEAM
Employ an independent penetraon tesng agent or team to perform penetraon tesng on
the system or system components.
Discussion: Independent penetraon tesng agents or teams are individuals or groups who
conduct imparal penetraon tesng of organizaonal systems. Imparality implies that
penetraon tesng agents or teams are free from perceived or actual conﬂicts of interest with
respect to the development, operaon, or management of the systems that are the targets of
the penetraon tesng. CA-2(1) provides addional informaon on independent assessments
that can be applied to penetraon tesng.
Related control: CA-2.
This document is produced from OSCAL source data
FAMILY: CA PAGE 79NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(2) PENETRATION TESTING | RED TEAM EXERCISES
Employ the following red-team exercises to simulate aempts by adversaries to compromise
organizaonal systems in accordance with applicable rules of engagement: [Assignment:
organizaon-deﬁned red team exercises].
Discussion: Red team exercises extend the objecves of penetraon tesng by examining
the security and privacy posture of organizaons and the capability to implement eﬀecve
cyber defenses. Red team exercises simulate aempts by adversaries to compromise mission
and business funcons and provide a comprehensive assessment of the security and privacy
posture of systems and organizaons. Such aempts may include technology-based aacks
and social engineering-based aacks. Technology-based aacks include interacons with
hardware, soware, or ﬁrmware components and/or mission and business processes. Social
engineering-based aacks include interacons via email, telephone, shoulder surﬁng, or
personal conversaons. Red team exercises are most eﬀecve when conducted by penetraon
tesng agents and teams with knowledge of and experience with current adversarial taccs,
techniques, procedures, and tools. While penetraon tesng may be primarily laboratory-
based tesng, organizaons can use red team exercises to provide more comprehensive
assessments that reﬂect real-world condions. The results from red team exercises can be used
by organizaons to improve security and privacy awareness and training and to assess control
eﬀecveness.
(3) PENETRATION TESTING | FACILITY PENETRATION TESTING
Employ a penetraon tesng process that includes [Assignment: organizaon-deﬁned
frequency] [Selecon: announced; unannounced] aempts to bypass or circumvent controls
associated with physical access points to the facility.
Discussion: Penetraon tesng of physical access points can provide informaon on crical
vulnerabilies in the operang environments of organizaonal systems. Such informaon can
be used to correct weaknesses or deﬁciencies in physical controls that are necessary to protect
organizaonal systems.
Related controls: CA-2, PE-3.
References: None
CA-9 INTERNAL SYSTEM CONNECTIONS
Control:
a. Authorize internal connecons of [Assignment: organizaon-deﬁned system components or
classes of components] to the system;
b. Document, for each internal connecon, the interface characteriscs, security and privacy
requirements, and the nature of the informaon communicated;
c. Terminate internal system connecons aer [Assignment: organizaon-deﬁned condions]; and
d. Review [Assignment: organizaon-deﬁned frequency] the connued need for each internal
connecon.
Discussion: Internal system connecons are connecons between organizaonal systems and separate
constuent system components (i.e., connecons between components that are part of the same
system) including components used for system development. Intra-system connecons include
connecons with mobile devices, notebook and desktop computers, tablets, printers, copiers,
This document is produced from OSCAL source data
FAMILY: CA PAGE 80NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
facsimile machines, scanners, sensors, and servers. Instead of authorizing each internal system
connecon individually, organizaons can authorize internal connecons for a class of system
components with common characteriscs and/or conﬁguraons, including printers, scanners, and
copiers with a speciﬁed processing, transmission, and storage capability or smart phones and tablets
with a speciﬁc baseline conﬁguraon. The connued need for an internal system connecon is
reviewed from the perspecve of whether it provides support for organizaonal missions or business
funcons.
Related controls: AC-3, AC-4, AC-18, AC-19, CM-2, IA-3, SC-7, SI-12.
(1) INTERNAL SYSTEM CONNECTIONS | COMPLIANCE CHECKS
Perform security and privacy compliance checks on constuent system components prior to
the establishment of the internal connecon.
Discussion: Compliance checks include veriﬁcaon of the relevant baseline conﬁguraon.
Related control: CM-6.
References: [IR 8023], [SP 800-124]
This document is produced from OSCAL source data
FAMILY: CA PAGE 81NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
FAMILY: CONFIGURATION MANAGEMENT
CM-1 POLICY AND PROCEDURES
Control:
a. Develop, document, and disseminate to [Assignment: organizaon-deﬁned personnel or roles]:
1. [Selecon (one or more): Organizaon-level; Mission/business process-level; System-level]
conﬁguraon management policy that:
(a) Addresses purpose, scope, roles, responsibilies, management commitment,
coordinaon among organizaonal enes, and compliance; and
(b) Is consistent with applicable laws, execuve orders, direcves, regulaons, policies,
standards, and guidelines; and
2. Procedures to facilitate the implementaon of the conﬁguraon management policy and
the associated conﬁguraon management controls;
b. Designate an [Assignment: organizaon-deﬁned oﬃcial] to manage the development,
documentaon, and disseminaon of the conﬁguraon management policy and procedures; and
c. Review and update the current conﬁguraon management:
1. Policy [Assignment: organizaon-deﬁned frequency] and following [Assignment:
organizaon-deﬁned events]; and
2. Procedures [Assignment: organizaon-deﬁned frequency] and following [Assignment:
organizaon-deﬁned events].
Discussion: Conﬁguraon management policy and procedures address the controls in the CM family
that are implemented within systems and organizaons. The risk management strategy is an
important factor in establishing such policies and procedures. Policies and procedures contribute
to security and privacy assurance. Therefore, it is important that security and privacy programs
collaborate on the development of conﬁguraon management policy and procedures. Security and
privacy program policies and procedures at the organizaon level are preferable, in general, and may
obviate the need for mission- or system-speciﬁc policies and procedures. The policy can be included
as part of the general security and privacy policy or be represented by mulple policies that reﬂect
the complex nature of organizaons. Procedures can be established for security and privacy programs,
for mission/business processes, and for systems, if needed. Procedures describe how the policies
or controls are implemented and can be directed at the individual or role that is the object of the
procedure. Procedures can be documented in system security and privacy plans or in one or more
separate documents. Events that may precipitate an update to conﬁguraon management policy
and procedures include, but are not limited to, assessment or audit ﬁndings, security incidents or
breaches, or changes in applicable laws, execuve orders, direcves, regulaons, policies, standards,
and guidelines. Simply restang controls does not constute an organizaonal policy or procedure.
Related controls: PM-9, PS-8, SA-8, SI-12.
References: [OMB A-130], [SP 800-100], [SP 800-12], [SP 800-30], [SP 800-39]
CM-2 BASELINE CONFIGURATION
Control:
a. Develop, document, and maintain under conﬁguraon control, a current baseline conﬁguraon
of the system; and
This document is produced from OSCAL source data
FAMILY: CM PAGE 82NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
b. Review and update the baseline conﬁguraon of the system:
1. [Assignment: organizaon-deﬁned frequency];
2. When required due to [Assignment: organizaon-deﬁned circumstances]; and
3. When system components are installed or upgraded.
Discussion: Baseline conﬁguraons for systems and system components include connecvity,
operaonal, and communicaons aspects of systems. Baseline conﬁguraons are documented,
formally reviewed, and agreed-upon speciﬁcaons for systems or conﬁguraon items within those
systems. Baseline conﬁguraons serve as a basis for future builds, releases, or changes to systems
and include security and privacy control implementaons, operaonal procedures, informaon
about system components, network topology, and logical placement of components in the system
architecture. Maintaining baseline conﬁguraons requires creang new baselines as organizaonal
systems change over me. Baseline conﬁguraons of systems reﬂect the current enterprise
architecture.
Related controls: AC-19, AU-6, CA-9, CM-1, CM-3, CM-5, CM-6, CM-8, CM-9, CP-9, CP-10, CP-12, MA-2,
PL-8, PM-5, SA-8, SA-10, SA-15, SC-18.
(1) BASELINE CONFIGURATION | REVIEWS AND UPDATES
[Withdrawn: Incorporated into CM-2.]
(2) BASELINE CONFIGURATION | AUTOMATION SUPPORT FOR ACCURACY AND CURRENCY
Maintain the currency, completeness, accuracy, and availability of the baseline conﬁguraon
of the system using [Assignment: organizaon-deﬁned automated mechanisms].
Discussion: Automated mechanisms that help organizaons maintain consistent baseline
conﬁguraons for systems include conﬁguraon management tools, hardware, soware,
ﬁrmware inventory tools, and network management tools. Automated tools can be used at
the organizaon level, mission and business process level, or system level on workstaons,
servers, notebook computers, network components, or mobile devices. Tools can be used to
track version numbers on operang systems, applicaons, types of soware installed, and
current patch levels. Automaon support for accuracy and currency can be sasﬁed by the
implementaon of CM-8(2) for organizaons that combine system component inventory and
baseline conﬁguraon acvies.
Related controls: CM-7, IA-3, RA-5.
(3) BASELINE CONFIGURATION | RETENTION OF PREVIOUS CONFIGURATIONS
Retain [Assignment: organizaon-deﬁned number] of previous versions of baseline
conﬁguraons of the system to support rollback.
Discussion: Retaining previous versions of baseline conﬁguraons to support rollback include
hardware, soware, ﬁrmware, conﬁguraon ﬁles, conﬁguraon records, and associated
documentaon.
(4) BASELINE CONFIGURATION | UNAUTHORIZED SOFTWARE
[Withdrawn: Incorporated into CM-7(4).]
This document is produced from OSCAL source data
FAMILY: CM PAGE 83NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(5) BASELINE CONFIGURATION | AUTHORIZED SOFTWARE
[Withdrawn: Incorporated into CM-7(5).]
(6) BASELINE CONFIGURATION | DEVELOPMENT AND TEST ENVIRONMENTS
Maintain a baseline conﬁguraon for system development and test environments that is
managed separately from the operaonal baseline conﬁguraon.
Discussion: Establishing separate baseline conﬁguraons for development, tesng, and
operaonal environments protects systems from unplanned or unexpected events related to
development and tesng acvies. Separate baseline conﬁguraons allow organizaons to
apply the conﬁguraon management that is most appropriate for each type of conﬁguraon.
For example, the management of operaonal conﬁguraons typically emphasizes the need
for stability, while the management of development or test conﬁguraons requires greater
ﬂexibility. Conﬁguraons in the test environment mirror conﬁguraons in the operaonal
environment to the extent praccable so that the results of the tesng are representave of
the proposed changes to the operaonal systems. Separate baseline conﬁguraons do not
necessarily require separate physical environments.
Related controls: CM-4, SC-3, SC-7.
(7) BASELINE CONFIGURATION | CONFIGURE SYSTEMS AND COMPONENTS FOR HIGH-RISK
AREAS
(a) Issue [Assignment: organizaon-deﬁned systems or system components] with
[Assignment: organizaon-deﬁned conﬁguraons] to individuals traveling to locaons
that the organizaon deems to be of signiﬁcant risk; and
(b) Apply the following controls to the systems or components when the individuals return
from travel: [Assignment: organizaon-deﬁned controls].
Discussion: When it is known that systems or system components will be in high-risk areas
external to the organizaon, addional controls may be implemented to counter the increased
threat in such areas. For example, organizaons can take acons for notebook computers used
by individuals deparng on and returning from travel. Acons include determining the locaons
that are of concern, deﬁning the required conﬁguraons for the components, ensuring that
components are conﬁgured as intended before travel is iniated, and applying controls to
the components aer travel is completed. Specially conﬁgured notebook computers include
computers with sanized hard drives, limited applicaons, and more stringent conﬁguraon
sengs. Controls applied to mobile devices upon return from travel include examining the
mobile device for signs of physical tampering and purging and reimaging disk drives. Protecng
informaon that resides on mobile devices is addressed in the MP (Media Protecon) family.
Related controls: MP-4, MP-5.
References: [SP 800-124], [SP 800-128]
CM-3 CONFIGURATION CHANGE CONTROL
Control:
a. Determine and document the types of changes to the system that are conﬁguraon-controlled;
b. Review proposed conﬁguraon-controlled changes to the system and approve or disapprove
such changes with explicit consideraon for security and privacy impact analyses;
This document is produced from OSCAL source data
FAMILY: CM PAGE 84NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
c. Document conﬁguraon change decisions associated with the system;
d. Implement approved conﬁguraon-controlled changes to the system;
e. Retain records of conﬁguraon-controlled changes to the system for [Assignment: organizaon-
deﬁned me period];
f. Monitor and review acvies associated with conﬁguraon-controlled changes to the system;
and
g. Coordinate and provide oversight for conﬁguraon change control acvies through
[Assignment: organizaon-deﬁned conﬁguraon change control element] that convenes
[Selecon (one or more): [Assignment: organizaon-deﬁned frequency]; when [Assignment:
organizaon-deﬁned conﬁguraon change condions]].
Discussion: Conﬁguraon change control for organizaonal systems involves the systemac proposal,
jusﬁcaon, implementaon, tesng, review, and disposion of system changes, including
system upgrades and modiﬁcaons. Conﬁguraon change control includes changes to baseline
conﬁguraons, conﬁguraon items of systems, operaonal procedures, conﬁguraon sengs for
system components, remediate vulnerabilies, and unscheduled or unauthorized changes. Processes
for managing conﬁguraon changes to systems include Conﬁguraon Control Boards or Change
Advisory Boards that review and approve proposed changes. For changes that impact privacy risk,
the senior agency oﬃcial for privacy updates privacy impact assessments and system of records
noces. For new systems or major upgrades, organizaons consider including representaves from
the development organizaons on the Conﬁguraon Control Boards or Change Advisory Boards.
Auding of changes includes acvies before and aer changes are made to systems and the auding
acvies required to implement such changes. See also SA-10.
Related controls: CA-7, CM-2, CM-4, CM-5, CM-6, CM-9, CM-11, IA-3, MA-2, PE-16, PT-6, RA-8, SA-8,
SA-10, SC-28, SC-34, SC-37, SI-2, SI-3, SI-4, SI-7, SI-10, SR-11.
(1) CONFIGURATION CHANGE CONTROL | AUTOMATED DOCUMENTATION, NOTIFICATION,
AND PROHIBITION OF CHANGES
Use [Assignment: organizaon-deﬁned automated mechanisms] to:
(a) Document proposed changes to the system;
(b) Nofy [Assignment: organizaon-deﬁned approval authories] of proposed changes to
the system and request change approval;
(c) Highlight proposed changes to the system that have not been approved or disapproved
within [Assignment: organizaon-deﬁned me period];
(d) Prohibit changes to the system unl designated approvals are received;
(e) Document all changes to the system; and
(f) Nofy [Assignment: organizaon-deﬁned personnel] when approved changes to the
system are completed.
Discussion: None.
This document is produced from OSCAL source data
FAMILY: CM PAGE 85NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(2) CONFIGURATION CHANGE CONTROL | TESTING, VALIDATION, AND DOCUMENTATION
OF CHANGES
Test, validate, and document changes to the system before ﬁnalizing the implementaon of
the changes.
Discussion: Changes to systems include modiﬁcaons to hardware, soware, or ﬁrmware
components and conﬁguraon sengs deﬁned in CM-6. Organizaons ensure that tesng does
not interfere with system operaons that support organizaonal mission and business funcons.
Individuals or groups conducng tests understand security and privacy policies and procedures,
system security and privacy policies and procedures, and the health, safety, and environmental
risks associated with speciﬁc facilies or processes. Operaonal systems may need to be taken
oﬄine, or replicated to the extent feasible, before tesng can be conducted. If systems must
be taken oﬄine for tesng, the tests are scheduled to occur during planned system outages
whenever possible. If the tesng cannot be conducted on operaonal systems, organizaons
employ compensang controls.
(3) CONFIGURATION CHANGE CONTROL | AUTOMATED CHANGE IMPLEMENTATION
Implement changes to the current system baseline and deploy the updated baseline across the
installed base using [Assignment: organizaon-deﬁned automated mechanisms].
Discussion: Automated tools can improve the accuracy, consistency, and availability of
conﬁguraon baseline informaon. Automaon can also provide data aggregaon and data
correlaon capabilies, alerng mechanisms, and dashboards to support risk-based decision-
making within the organizaon.
(4) CONFIGURATION CHANGE CONTROL | SECURITY AND PRIVACY REPRESENTATIVES
Require [Assignment: organizaon-deﬁned security and privacy representaves] to be
members of the [Assignment: organizaon-deﬁned conﬁguraon change control element].
Discussion: Informaon security and privacy representaves include system security oﬃcers,
senior agency informaon security oﬃcers, senior agency oﬃcials for privacy, or system
privacy oﬃcers. Representaon by personnel with informaon security and privacy experse
is important because changes to system conﬁguraons can have unintended side eﬀects, some
of which may be security- or privacy-relevant. Detecng such changes early in the process can
help avoid unintended, negave consequences that could ulmately aﬀect the security and
privacy posture of systems. The conﬁguraon change control element referred to in the second
organizaon-deﬁned parameter reﬂects the change control elements deﬁned by organizaons in
CM-3g.
(5) CONFIGURATION CHANGE CONTROL | AUTOMATED SECURITY RESPONSE
Implement the following security responses automacally if baseline conﬁguraons are
changed in an unauthorized manner: [Assignment: organizaon-deﬁned security responses].
Discussion: Automated security responses include halng selected system funcons, halng
system processing, and issuing alerts or noﬁcaons to organizaonal personnel when there is
an unauthorized modiﬁcaon of a conﬁguraon item.
This document is produced from OSCAL source data
FAMILY: CM PAGE 86NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(6) CONFIGURATION CHANGE CONTROL | CRYPTOGRAPHY MANAGEMENT
Ensure that cryptographic mechanisms used to provide the following controls are under
conﬁguraon management: [Assignment: organizaon-deﬁned controls].
Discussion: The controls referenced in the control enhancement refer to security and privacy
controls from the control catalog. Regardless of the cryptographic mechanisms employed,
processes and procedures are in place to manage those mechanisms. For example, if system
components use cerﬁcates for idenﬁcaon and authencaon, a process is implemented to
address the expiraon of those cerﬁcates.
Related control: SC-12.
(7) CONFIGURATION CHANGE CONTROL | REVIEW SYSTEM CHANGES
Review changes to the system [Assignment: organizaon-deﬁned frequency] or when
[Assignment: organizaon-deﬁned circumstances] to determine whether unauthorized
changes have occurred.
Discussion: Indicaons that warrant a review of changes to the system and the speciﬁc
circumstances jusfying such reviews may be obtained from acvies carried out by
organizaons during the conﬁguraon change process or connuous monitoring process.
Related controls: AU-6, AU-7, CM-3.
(8) CONFIGURATION CHANGE CONTROL | PREVENT OR RESTRICT CONFIGURATION
CHANGES
Prevent or restrict changes to the conﬁguraon of the system under the following
circumstances: [Assignment: organizaon-deﬁned circumstances].
Discussion: System conﬁguraon changes can adversely aﬀect crical system security and privacy
funconality. Change restricons can be enforced through automated mechanisms.
References: [IR 8062], [SP 800-124], [SP 800-128]
CM-4 IMPACT ANALYSES
Control: Analyze changes to the system to determine potenal security and privacy impacts prior to
change implementaon.
Discussion: Organizaonal personnel with security or privacy responsibilies conduct impact analyses.
Individuals conducng impact analyses possess the necessary skills and technical experse to analyze
the changes to systems as well as the security or privacy ramiﬁcaons. Impact analyses include
reviewing security and privacy plans, policies, and procedures to understand control requirements;
reviewing system design documentaon and operaonal procedures to understand control
implementaon and how speciﬁc system changes might aﬀect the controls; reviewing the impact of
changes on organizaonal supply chain partners with stakeholders; and determining how potenal
changes to a system create new risks to the privacy of individuals and the ability of implemented
controls to migate those risks. Impact analyses also include risk assessments to understand the
impact of the changes and determine if addional controls are required.
Related controls: CA-7, CM-3, CM-8, CM-9, MA-2, RA-3, RA-5, RA-8, SA-5, SA-8, SA-10, SI-2.
This document is produced from OSCAL source data
FAMILY: CM PAGE 87NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(1) IMPACT ANALYSES | SEPARATE TEST ENVIRONMENTS
Analyze changes to the system in a separate test environment before implementaon in an
operaonal environment, looking for security and privacy impacts due to ﬂaws, weaknesses,
incompability, or intenonal malice.
Discussion: A separate test environment requires an environment that is physically or logically
separate and disnct from the operaonal environment. The separaon is suﬃcient to ensure
that acvies in the test environment do not impact acvies in the operaonal environment
and that informaon in the operaonal environment is not inadvertently transmied to the test
environment. Separate environments can be achieved by physical or logical means. If physically
separate test environments are not implemented, organizaons determine the strength of
mechanism required when implemenng logical separaon.
Related controls: SA-11, SC-7.
(2) IMPACT ANALYSES | VERIFICATION OF CONTROLS
Aer system changes, verify that the impacted controls are implemented correctly, operang
as intended, and producing the desired outcome with regard to meeng the security and
privacy requirements for the system.
Discussion: Implementaon in this context refers to installing changed code in the operaonal
system that may have an impact on security or privacy controls.
Related controls: SA-11, SC-3, SI-6.
Reference: [SP 800-128]
CM-5 ACCESS RESTRICTIONS FOR CHANGE
Control: Deﬁne, document, approve, and enforce physical and logical access restricons associated
with changes to the system.
Discussion: Changes to the hardware, soware, or ﬁrmware components of systems or the operaonal
procedures related to the system can potenally have signiﬁcant eﬀects on the security of the systems
or individuals’ privacy. Therefore, organizaons permit only qualiﬁed and authorized individuals to
access systems for purposes of iniang changes. Access restricons include physical and logical
access controls (see AC-3 and PE-3), soware libraries, workﬂow automaon, media libraries, abstract
layers (i.e., changes implemented into external interfaces rather than directly into systems), and
change windows (i.e., changes occur only during speciﬁed mes).
Related controls: AC-3, AC-5, AC-6, CM-9, PE-3, SC-28, SC-34, SC-37, SI-2, SI-10.
(1) ACCESS RESTRICTIONS FOR CHANGE | AUTOMATED ACCESS ENFORCEMENT AND AUDIT
RECORDS
(a) Enforce access restricons using [Assignment: organizaon-deﬁned automated
mechanisms]; and
(b) Automacally generate audit records of the enforcement acons.
Discussion: Organizaons log system accesses associated with applying conﬁguraon changes to
ensure that conﬁguraon change control is implemented and to support aer-the-fact acons
should organizaons discover any unauthorized changes.
Related controls: AU-2, AU-6, AU-7, AU-12, CM-6, CM-11, SI-12.
This document is produced from OSCAL source data
FAMILY: CM PAGE 88NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(2) ACCESS RESTRICTIONS FOR CHANGE | REVIEW SYSTEM CHANGES
[Withdrawn: Incorporated into CM-3(7).]
(3) ACCESS RESTRICTIONS FOR CHANGE | SIGNED COMPONENTS
[Withdrawn: Incorporated into CM-14.]
(4) ACCESS RESTRICTIONS FOR CHANGE | DUAL AUTHORIZATION
Enforce dual authorizaon for implemenng changes to [Assignment: organizaon-deﬁned
system components and system-level informaon].
Discussion: Organizaons employ dual authorizaon to help ensure that any changes to selected
system components and informaon cannot occur unless two qualiﬁed individuals approve and
implement such changes. The two individuals possess the skills and experse to determine if the
proposed changes are correct implementaons of approved changes. The individuals are also
accountable for the changes. Dual authorizaon may also be known as two-person control. To
reduce the risk of collusion, organizaons consider rotang dual authorizaon dues to other
individuals. System-level informaon includes operaonal procedures.
Related controls: AC-2, AC-5, CM-3.
(5) ACCESS RESTRICTIONS FOR CHANGE | PRIVILEGE LIMITATION FOR PRODUCTION AND
OPERATION
(a) Limit privileges to change system components and system-related informaon within a
producon or operaonal environment; and
(b) Review and reevaluate privileges [Assignment: organizaon-deﬁned frequency].
Discussion: In many organizaons, systems support mulple mission and business funcons.
Liming privileges to change system components with respect to operaonal systems is
necessary because changes to a system component may have far-reaching eﬀects on mission
and business processes supported by the system. The relaonships between systems and
mission/business processes are, in some cases, unknown to developers. System-related
informaon includes operaonal procedures.
Related control: AC-2.
(6) ACCESS RESTRICTIONS FOR CHANGE | LIMIT LIBRARY PRIVILEGES
Limit privileges to change soware resident within soware libraries.
Discussion: Soware libraries include privileged programs.
Related control: AC-2.
(7) ACCESS RESTRICTIONS FOR CHANGE | AUTOMATIC IMPLEMENTATION OF SECURITY
SAFEGUARDS
[Withdrawn: Incorporated into SI-7.]
References: [FIPS 140-3], [FIPS 186-4]
This document is produced from OSCAL source data
FAMILY: CM PAGE 89NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
CM-6 CONFIGURATION SETTINGS
Control:
a. Establish and document conﬁguraon sengs for components employed within the system that
reﬂect the most restricve mode consistent with operaonal requirements using [Assignment:
organizaon-deﬁned common secure conﬁguraons];
b. Implement the conﬁguraon sengs;
c. Idenfy, document, and approve any deviaons from established conﬁguraon sengs for
[Assignment: organizaon-deﬁned system components] based on [Assignment: organizaon-
deﬁned operaonal requirements]; and
d. Monitor and control changes to the conﬁguraon sengs in accordance with organizaonal
policies and procedures.
Discussion: Conﬁguraon sengs are the parameters that can be changed in the hardware, soware,
or ﬁrmware components of the system that aﬀect the security and privacy posture or funconality
of the system. Informaon technology products for which conﬁguraon sengs can be deﬁned
include mainframe computers, servers, workstaons, operang systems, mobile devices, input/
output devices, protocols, and applicaons. Parameters that impact the security posture of systems
include registry sengs; account, ﬁle, or directory permission sengs; and sengs for funcons,
protocols, ports, services, and remote connecons. Privacy parameters are parameters impacng
the privacy posture of systems, including the parameters required to sasfy other privacy controls.
Privacy parameters include sengs for access controls, data processing preferences, and processing
and retenon permissions. Organizaons establish organizaon-wide conﬁguraon sengs and
subsequently derive speciﬁc conﬁguraon sengs for systems. The established sengs become part
of the conﬁguraon baseline for the system.
Common secure conﬁguraons (also known as security conﬁguraon checklists, lockdown and
hardening guides, and security reference guides) provide recognized, standardized, and established
benchmarks that spulate secure conﬁguraon sengs for informaon technology products and
plaorms as well as instrucons for conﬁguring those products or plaorms to meet operaonal
requirements. Common secure conﬁguraons can be developed by a variety of organizaons,
including informaon technology product developers, manufacturers, vendors, federal agencies,
consora, academia, industry, and other organizaons in the public and private sectors.
Implementaon of a common secure conﬁguraon may be mandated at the organizaon level,
mission and business process level, system level, or at a higher level, including by a regulatory agency.
Common secure conﬁguraons include the United States Government Conﬁguraon Baseline USGCB
and security technical implementaon guides (STIGs), which aﬀect the implementaon of CM-6 and
other controls such as AC-19 and CM-7. The Security Content Automaon Protocol (SCAP) and the
deﬁned standards within the protocol provide an eﬀecve method to uniquely idenfy, track, and
control conﬁguraon sengs.
Related controls: AC-3, AC-19, AU-2, AU-6, CA-9, CM-2, CM-3, CM-5, CM-7, CM-11, CP-7, CP-9, CP-10,
IA-3, IA-5, PL-8, PL-9, RA-5, SA-4, SA-5, SA-8, SA-9, SC-18, SC-28, SC-43, SI-2, SI-4, SI-6.
(1) CONFIGURATION SETTINGS | AUTOMATED MANAGEMENT, APPLICATION, AND
VERIFICATION
Manage, apply, and verify conﬁguraon sengs for [Assignment: organizaon-deﬁned system
components] using [Assignment: organizaon-deﬁned automated mechanisms].
Discussion: Automated tools (e.g., hardening tools, baseline conﬁguraon tools) can improve the
accuracy, consistency, and availability of conﬁguraon sengs informaon. Automaon can also
This document is produced from OSCAL source data
FAMILY: CM PAGE 90NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
provide data aggregaon and data correlaon capabilies, alerng mechanisms, and dashboards
to support risk-based decision-making within the organizaon.
Related control: CA-7.
(2) CONFIGURATION SETTINGS | RESPOND TO UNAUTHORIZED CHANGES
Take the following acons in response to unauthorized changes to [Assignment: organizaon-
deﬁned conﬁguraon sengs]: [Assignment: organizaon-deﬁned acons].
Discussion: Responses to unauthorized changes to conﬁguraon sengs include alerng
designated organizaonal personnel, restoring established conﬁguraon sengs, or—in extreme
cases—halng aﬀected system processing.
Related controls: IR-4, IR-6, SI-7.
(3) CONFIGURATION SETTINGS | UNAUTHORIZED CHANGE DETECTION
[Withdrawn: Incorporated into SI-7.]
(4) CONFIGURATION SETTINGS | CONFORMANCE DEMONSTRATION
[Withdrawn: Incorporated into CM-4.]
References: [DOD STIG], [NCPR], [SP 800-126], [SP 800-128], [SP 800-70], [USGCB]
CM-7 LEAST FUNCTIONALITY
Control:
a. Conﬁgure the system to provide only [Assignment: organizaon-deﬁned mission essenal
capabilies]; and
b. Prohibit or restrict the use of the following funcons, ports, protocols, soware, and/or services:
[Assignment: organizaon-deﬁned prohibited or restricted funcons, system ports, protocols,
soware, and/or services].
Discussion: Systems provide a wide variety of funcons and services. Some of the funcons and
services rounely provided by default may not be necessary to support essenal organizaonal
missions, funcons, or operaons. Addionally, it is somemes convenient to provide mulple
services from a single system component, but doing so increases risk over liming the services
provided by that single component. Where feasible, organizaons limit component funconality to
a single funcon per component. Organizaons consider removing unused or unnecessary soware
and disabling unused or unnecessary physical and logical ports and protocols to prevent unauthorized
connecon of components, transfer of informaon, and tunneling. Organizaons employ network
scanning tools, intrusion detecon and prevenon systems, and end-point protecon technologies,
such as ﬁrewalls and host-based intrusion detecon systems, to idenfy and prevent the use of
prohibited funcons, protocols, ports, and services. Least funconality can also be achieved as part of
the fundamental design and development of the system (see SA-8, SC-2, and SC-3).
Related controls: AC-3, AC-4, CM-2, CM-5, CM-6, CM-11, RA-5, SA-4, SA-5, SA-8, SA-9, SA-15, SC-2, SC-3,
SC-7, SC-37, SI-4.
This document is produced from OSCAL source data
FAMILY: CM PAGE 91NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(1) LEAST FUNCTIONALITY | PERIODIC REVIEW
(a) Review the system [Assignment: organizaon-deﬁned frequency] to idenfy unnecessary
and/or nonsecure funcons, ports, protocols, soware, and services; and
(b) Disable or remove [Assignment: organizaon-deﬁned funcons, ports, protocols,
soware, and services within the system deemed to be unnecessary and/or nonsecure].
Discussion: Organizaons review funcons, ports, protocols, and services provided by systems or
system components to determine the funcons and services that are candidates for eliminaon.
Such reviews are especially important during transion periods from older technologies to
newer technologies (e.g., transion from IPv4 to IPv6). These technology transions may require
implemenng the older and newer technologies simultaneously during the transion period
and returning to minimum essenal funcons, ports, protocols, and services at the earliest
opportunity. Organizaons can either decide the relave security of the funcon, port, protocol,
and/or service or base the security decision on the assessment of other enes. Unsecure
protocols include Bluetooth, FTP, and peer-to-peer networking.
Related control: AC-18.
(2) LEAST FUNCTIONALITY | PREVENT PROGRAM EXECUTION
Prevent program execuon in accordance with [Selecon (one or more): [Assignment:
organizaon-deﬁned policies, rules of behavior, and/or access agreements regarding soware
program usage and restricons]; rules authorizing the terms and condions of soware
program usage].
Discussion: Prevenon of program execuon addresses organizaonal policies, rules of behavior,
and/or access agreements that restrict soware usage and the terms and condions imposed by
the developer or manufacturer, including soware licensing and copyrights. Restricons include
prohibing auto-execute features, restricng roles allowed to approve program execuon,
perming or prohibing speciﬁc soware programs, or restricng the number of program
instances executed at the same me.
Related controls: CM-8, PL-4, PL-9, PM-5, PS-6.
(3) LEAST FUNCTIONALITY | REGISTRATION COMPLIANCE
Ensure compliance with [Assignment: organizaon-deﬁned registraon requirements for
funcons, ports, protocols, and services].
Discussion: Organizaons use the registraon process to manage, track, and provide oversight for
systems and implemented funcons, ports, protocols, and services.
This document is produced from OSCAL source data
FAMILY: CM PAGE 92NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(4) LEAST FUNCTIONALITY | UNAUTHORIZED SOFTWARE — DENY-BY-EXCEPTION
(a) Idenfy [Assignment: organizaon-deﬁned soware programs not authorized to execute
on the system];
(b) Employ an allow-all, deny-by-excepon policy to prohibit the execuon of unauthorized
soware programs on the system; and
(c) Review and update the list of unauthorized soware programs [Assignment:
organizaon-deﬁned frequency].
Discussion: Unauthorized soware programs can be limited to speciﬁc versions or from a speciﬁc
source. The concept of prohibing the execuon of unauthorized soware may also be applied
to user acons, system ports and protocols, IP addresses/ranges, websites, and MAC addresses.
Related controls: CM-6, CM-8, CM-10, PL-9, PM-5.
(5) LEAST FUNCTIONALITY | AUTHORIZED SOFTWARE — ALLOW-BY-EXCEPTION
(a) Idenfy [Assignment: organizaon-deﬁned soware programs authorized to execute on
the system];
(b) Employ a deny-all, permit-by-excepon policy to allow the execuon of authorized
soware programs on the system; and
(c) Review and update the list of authorized soware programs [Assignment: organizaon-
deﬁned frequency].
Discussion: Authorized soware programs can be limited to speciﬁc versions or from a speciﬁc
source. To facilitate a comprehensive authorized soware process and increase the strength
of protecon for aacks that bypass applicaon level authorized soware, soware programs
may be decomposed into and monitored at diﬀerent levels of detail. These levels include
applicaons, applicaon programming interfaces, applicaon modules, scripts, system
processes, system services, kernel funcons, registries, drivers, and dynamic link libraries. The
concept of perming the execuon of authorized soware may also be applied to user acons,
system ports and protocols, IP addresses/ranges, websites, and MAC addresses. Organizaons
consider verifying the integrity of authorized soware programs using digital signatures,
cryptographic checksums, or hash funcons. Veriﬁcaon of authorized soware can occur either
prior to execuon or at system startup. The idenﬁcaon of authorized URLs for websites is
addressed in CA-3(5) and SC-7.
Related controls: CM-2, CM-6, CM-8, CM-10, PL-9, PM-5, SA-10, SC-34, SI-7.
(6) LEAST FUNCTIONALITY | CONFINED ENVIRONMENTS WITH LIMITED PRIVILEGES
Require that the following user-installed soware execute in a conﬁned physical or virtual
machine environment with limited privileges: [Assignment: organizaon-deﬁned user-installed
soware].
Discussion: Organizaons idenfy soware that may be of concern regarding its origin or
potenal for containing malicious code. For this type of soware, user installaons occur in
conﬁned environments of operaon to limit or contain damage from malicious code that may be
executed.
Related controls: CM-11, SC-44.
This document is produced from OSCAL source data
FAMILY: CM PAGE 93NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(7) LEAST FUNCTIONALITY | CODE EXECUTION IN PROTECTED ENVIRONMENTS
Allow execuon of binary or machine-executable code only in conﬁned physical or virtual
machine environments and with the explicit approval of [Assignment: organizaon-deﬁned
personnel or roles] when such code is:
(a) Obtained from sources with limited or no warranty; and/or
(b) Without the provision of source code.
Discussion: Code execuon in protected environments applies to all sources of binary or machine-
executable code, including commercial soware and ﬁrmware and open-source soware.
Related controls: CM-10, SC-44.
(8) LEAST FUNCTIONALITY | BINARY OR MACHINE EXECUTABLE CODE
(a) Prohibit the use of binary or machine-executable code from sources with limited or no
warranty or without the provision of source code; and
(b) Allow excepons only for compelling mission or operaonal requirements and with the
approval of the authorizing oﬃcial.
Discussion: Binary or machine executable code applies to all sources of binary or machine-
executable code, including commercial soware and ﬁrmware and open-source soware.
Organizaons assess soware products without accompanying source code or from sources
with limited or no warranty for potenal security impacts. The assessments address the fact
that soware products without the provision of source code may be diﬃcult to review, repair,
or extend. In addion, there may be no owners to make such repairs on behalf of organizaons.
If open-source soware is used, the assessments address the fact that there is no warranty,
the open-source soware could contain back doors or malware, and there may be no support
available.
Related controls: SA-5, SA-22.
(9) LEAST FUNCTIONALITY | PROHIBITING THE USE OF UNAUTHORIZED HARDWARE
(a) Idenfy [Assignment: organizaon-deﬁned hardware components authorized for system
use];
(b) Prohibit the use or connecon of unauthorized hardware components;
(c) Review and update the list of authorized hardware components [Assignment:
organizaon-deﬁned frequency].
Discussion: Hardware components provide the foundaon for organizaonal systems and
the plaorm for the execuon of authorized soware programs. Managing the inventory
of hardware components and controlling which hardware components are permied to be
installed or connected to organizaonal systems is essenal in order to provide adequate
security.
References: [FIPS 140-3], [FIPS 180-4], [FIPS 186-4], [FIPS 202], [SP 800-167]
This document is produced from OSCAL source data
FAMILY: CM PAGE 94NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
CM-8 SYSTEM COMPONENT INVENTORY
Control:
a. Develop and document an inventory of system components that:
1. Accurately reﬂects the system;
2. Includes all components within the system;
3. Does not include duplicate accounng of components or components assigned to any other
system;
4. Is at the level of granularity deemed necessary for tracking and reporng; and
5. Includes the following informaon to achieve system component accountability:
[Assignment: organizaon-deﬁned informaon deemed necessary to achieve eﬀecve
system component accountability]; and
b. Review and update the system component inventory [Assignment: organizaon-deﬁned
frequency].
Discussion: System components are discrete, idenﬁable informaon technology assets that include
hardware, soware, and ﬁrmware. Organizaons may choose to implement centralized system
component inventories that include components from all organizaonal systems. In such situaons,
organizaons ensure that the inventories include system-speciﬁc informaon required for component
accountability. The informaon necessary for eﬀecve accountability of system components includes
the system name, soware owners, soware version numbers, hardware inventory speciﬁcaons,
soware license informaon, and for networked components, the machine names and network
addresses across all implemented protocols (e.g., IPv4, IPv6). Inventory speciﬁcaons include date of
receipt, cost, model, serial number, manufacturer, supplier informaon, component type, and physical
locaon.
Prevenng duplicate accounng of system components addresses the lack of accountability that
occurs when component ownership and system associaon is not known, especially in large or
complex connected systems. Eﬀecve prevenon of duplicate accounng of system components
necessitates use of a unique idenﬁer for each component. For soware inventory, centrally managed
soware that is accessed via other systems is addressed as a component of the system on which
it is installed and managed. Soware installed on mulple organizaonal systems and managed
at the system level is addressed for each individual system and may appear more than once in a
centralized component inventory, necessitang a system associaon for each soware instance in the
centralized inventory to avoid duplicate accounng of components. Scanning systems implemenng
mulple network protocols (e.g., IPv4 and IPv6) can result in duplicate components being idenﬁed in
diﬀerent address spaces. The implementaon of CM-8(7) can help to eliminate duplicate accounng
of components.
Related controls: CM-2, CM-7, CM-9, CM-10, CM-11, CM-13, CP-2, CP-9, MA-2, MA-6, PE-20, PL-9,
PM-5, SA-4, SA-5, SI-2, SR-4.
(1) SYSTEM COMPONENT INVENTORY | UPDATES DURING INSTALLATION AND REMOVAL
Update the inventory of system components as part of component installaons, removals, and
system updates.
Discussion: Organizaons can improve the accuracy, completeness, and consistency of system
component inventories if the inventories are updated as part of component installaons
or removals or during general system updates. If inventories are not updated at these key
This document is produced from OSCAL source data
FAMILY: CM PAGE 95NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
mes, there is a greater likelihood that the informaon will not be appropriately captured and
documented. System updates include hardware, soware, and ﬁrmware components.
Related control: PM-16.
(2) SYSTEM COMPONENT INVENTORY | AUTOMATED MAINTENANCE
Maintain the currency, completeness, accuracy, and availability of the inventory of system
components using [Assignment: organizaon-deﬁned automated mechanisms].
Discussion: Organizaons maintain system inventories to the extent feasible. For example,
virtual machines can be diﬃcult to monitor because such machines are not visible to the
network when not in use. In such cases, organizaons maintain as up-to-date, complete, and
accurate an inventory as is deemed reasonable. Automated maintenance can be achieved by the
implementaon of CM-2(2) for organizaons that combine system component inventory and
baseline conﬁguraon acvies.
(3) SYSTEM COMPONENT INVENTORY | AUTOMATED UNAUTHORIZED COMPONENT
DETECTION
(a) Detect the presence of unauthorized hardware, soware, and ﬁrmware components
within the system using [Assignment: organizaon-deﬁned automated mechanisms]
[Assignment: organizaon-deﬁned frequency]; and
(b) Take the following acons when unauthorized components are detected: [Selecon (one
or more): disable network access by such components; isolate the components; nofy
[Assignment: organizaon-deﬁned personnel or roles]].
Discussion: Automated unauthorized component detecon is applied in addion to the
monitoring for unauthorized remote connecons and mobile devices. Monitoring for
unauthorized system components may be accomplished on an ongoing basis or by the periodic
scanning of systems for that purpose. Automated mechanisms may also be used to prevent
the connecon of unauthorized components (see CM-7(9)). Automated mechanisms can be
implemented in systems or in separate system components. When acquiring and implemenng
automated mechanisms, organizaons consider whether such mechanisms depend on the ability
of the system component to support an agent or supplicant in order to be detected since some
types of components do not have or cannot support agents (e.g., IoT devices, sensors). Isolaon
can be achieved , for example, by placing unauthorized system components in separate domains
or subnets or quaranning such components. This type of component isolaon is commonly
referred to as sandboxing.
Related controls: AC-19, CA-7, RA-5, SC-3, SC-39, SC-44, SI-3, SI-4, SI-7.
(4) SYSTEM COMPONENT INVENTORY | ACCOUNTABILITY INFORMATION
Include in the system component inventory informaon, a means for idenfying by [Selecon
(one or more): name; posion; role], individuals responsible and accountable for administering
those components.
Discussion: Idenfying individuals who are responsible and accountable for administering
system components ensures that the assigned components are properly administered and that
organizaons can contact those individuals if some acon is required (e.g., when the component
is determined to be the source of a breach, needs to be recalled or replaced, or needs to be
relocated).
Related control: AC-3.
This document is produced from OSCAL source data
FAMILY: CM PAGE 96NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(5) SYSTEM COMPONENT INVENTORY | NO DUPLICATE ACCOUNTING OF COMPONENTS
[Withdrawn: Incorporated into CM-8.]
(6) SYSTEM COMPONENT INVENTORY | ASSESSED CONFIGURATIONS AND APPROVED
DEVIATIONS
Include assessed component conﬁguraons and any approved deviaons to current deployed
conﬁguraons in the system component inventory.
Discussion: Assessed conﬁguraons and approved deviaons focus on conﬁguraon sengs
established by organizaons for system components, the speciﬁc components that have been
assessed to determine compliance with the required conﬁguraon sengs, and any approved
deviaons from established conﬁguraon sengs.
(7) SYSTEM COMPONENT INVENTORY | CENTRALIZED REPOSITORY
Provide a centralized repository for the inventory of system components.
Discussion: Organizaons may implement centralized system component inventories that include
components from all organizaonal systems. Centralized repositories of component inventories
provide opportunies for eﬃciencies in accounng for organizaonal hardware, soware, and
ﬁrmware assets. Such repositories may also help organizaons rapidly idenfy the locaon and
responsible individuals of components that have been compromised, breached, or are otherwise
in need of migaon acons. Organizaons ensure that the resulng centralized inventories
include system-speciﬁc informaon required for proper component accountability.
(8) SYSTEM COMPONENT INVENTORY | AUTOMATED LOCATION TRACKING
Support the tracking of system components by geographic locaon using [Assignment:
organizaon-deﬁned automated mechanisms].
Discussion: The use of automated mechanisms to track the locaon of system components
can increase the accuracy of component inventories. Such capability may help organizaons
rapidly idenfy the locaon and responsible individuals of system components that have been
compromised, breached, or are otherwise in need of migaon acons. The use of tracking
mechanisms can be coordinated with senior agency oﬃcials for privacy if there are implicaons
that aﬀect individual privacy.
(9) SYSTEM COMPONENT INVENTORY | ASSIGNMENT OF COMPONENTS TO SYSTEMS
(a) Assign system components to a system; and
(b) Receive an acknowledgement from [Assignment: organizaon-deﬁned personnel or roles]
of this assignment.
Discussion: System components that are not assigned to a system may be unmanaged, lack the
required protecon, and become an organizaonal vulnerability.
References: [IR 8011-2], [IR 8011-3], [OMB A-130], [SP 800-128], [SP 800-57-1], [SP 800-57-2], [SP
800-57-3]
This document is produced from OSCAL source data
FAMILY: CM PAGE 97NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
CM-9 CONFIGURATION MANAGEMENT PLAN
Control: Develop, document, and implement a conﬁguraon management plan for the system that:
a. Addresses roles, responsibilies, and conﬁguraon management processes and procedures;
b. Establishes a process for idenfying conﬁguraon items throughout the system development life
cycle and for managing the conﬁguraon of the conﬁguraon items;
c. Deﬁnes the conﬁguraon items for the system and places the conﬁguraon items under
conﬁguraon management;
d. Is reviewed and approved by [Assignment: organizaon-deﬁned personnel or roles]; and
e. Protects the conﬁguraon management plan from unauthorized disclosure and modiﬁcaon.
Discussion: Conﬁguraon management acvies occur throughout the system development life
cycle. As such, there are developmental conﬁguraon management acvies (e.g., the control of
code and soware libraries) and operaonal conﬁguraon management acvies (e.g., control of
installed components and how the components are conﬁgured). Conﬁguraon management plans
sasfy the requirements in conﬁguraon management policies while being tailored to individual
systems. Conﬁguraon management plans deﬁne processes and procedures for how conﬁguraon
management is used to support system development life cycle acvies.
Conﬁguraon management plans are generated during the development and acquision stage of
the system development life cycle. The plans describe how to advance changes through change
management processes; update conﬁguraon sengs and baselines; maintain component
inventories; control development, test, and operaonal environments; and develop, release, and
update key documents.
Organizaons can employ templates to help ensure the consistent and mely development and
implementaon of conﬁguraon management plans. Templates can represent a conﬁguraon
management plan for the organizaon with subsets of the plan implemented on a system by system
basis. Conﬁguraon management approval processes include the designaon of key stakeholders
responsible for reviewing and approving proposed changes to systems, and personnel who conduct
security and privacy impact analyses prior to the implementaon of changes to the systems.
Conﬁguraon items are the system components, such as the hardware, soware, ﬁrmware, and
documentaon to be conﬁguraon-managed. As systems connue through the system development
life cycle, new conﬁguraon items may be idenﬁed, and some exisng conﬁguraon items may no
longer need to be under conﬁguraon control.
Related controls: CM-2, CM-3, CM-4, CM-5, CM-8, PL-2, RA-8, SA-10, SI-12.
(1) CONFIGURATION MANAGEMENT PLAN | ASSIGNMENT OF RESPONSIBILITY
Assign responsibility for developing the conﬁguraon management process to organizaonal
personnel that are not directly involved in system development.
Discussion: In the absence of dedicated conﬁguraon management teams assigned within
organizaons, system developers may be tasked with developing conﬁguraon management
processes using personnel who are not directly involved in system development or system
integraon. This separaon of dues ensures that organizaons establish and maintain a
suﬃcient degree of independence between the system development and integraon processes
and conﬁguraon management processes to facilitate quality control and more eﬀecve
oversight.
Reference: [SP 800-128]
This document is produced from OSCAL source data
FAMILY: CM PAGE 98NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
CM-10 SOFTWARE USAGE RESTRICTIONS
Control:
a. Use soware and associated documentaon in accordance with contract agreements and
copyright laws;
b. Track the use of soware and associated documentaon protected by quanty licenses to
control copying and distribuon; and
c. Control and document the use of peer-to-peer ﬁle sharing technology to ensure that this
capability is not used for the unauthorized distribuon, display, performance, or reproducon of
copyrighted work.
Discussion: Soware license tracking can be accomplished by manual or automated methods,
depending on organizaonal needs. Examples of contract agreements include soware license
agreements and non-disclosure agreements.
Related controls: AC-17, AU-6, CM-7, CM-8, PM-30, SC-7.
(1) SOFTWARE USAGE RESTRICTIONS | OPEN-SOURCE SOFTWARE
Establish the following restricons on the use of open-source soware: [Assignment:
organizaon-deﬁned restricons].
Discussion: Open-source soware refers to soware that is available in source code form.
Certain soware rights normally reserved for copyright holders are rounely provided under
soware license agreements that permit individuals to study, change, and improve the soware.
From a security perspecve, the major advantage of open-source soware is that it provides
organizaons with the ability to examine the source code. In some cases, there is an online
community associated with the soware that inspects, tests, updates, and reports on issues
found in soware on an ongoing basis. However, remediang vulnerabilies in open-source
soware may be problemac. There may also be licensing issues associated with open-source
soware, including the constraints on derivave use of such soware. Open-source soware
that is available only in binary form may increase the level of risk in using such soware.
Related control: SI-7.
References: None
CM-11 USER-INSTALLED SOFTWARE
Control:
a. Establish [Assignment: organizaon-deﬁned policies] governing the installaon of soware by
users;
b. Enforce soware installaon policies through the following methods: [Assignment: organizaon-
deﬁned methods]; and
c. Monitor policy compliance [Assignment: organizaon-deﬁned frequency].
Discussion: If provided the necessary privileges, users can install soware in organizaonal systems. To
maintain control over the soware installed, organizaons idenfy permied and prohibited acons
regarding soware installaon. Permied soware installaons include updates and security patches
to exisng soware and downloading new applicaons from organizaon-approved app stores.
Prohibited soware installaons include soware with unknown or suspect pedigrees or soware
that organizaons consider potenally malicious. Policies selected for governing user-installed
This document is produced from OSCAL source data
FAMILY: CM PAGE 99NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
soware are organizaon-developed or provided by some external enty. Policy enforcement
methods can include procedural methods and automated methods.
Related controls: AC-3, AU-6, CM-2, CM-3, CM-5, CM-6, CM-7, CM-8, PL-4, SI-4, SI-7.
(1) USER-INSTALLED SOFTWARE | ALERTS FOR UNAUTHORIZED INSTALLATIONS
[Withdrawn: Incorporated into CM-8(3).]
(2) USER-INSTALLED SOFTWARE | SOFTWARE INSTALLATION WITH PRIVILEGED STATUS
Allow user installaon of soware only with explicit privileged status.
Discussion: Privileged status can be obtained, for example, by serving in the role of system
administrator.
Related controls: AC-5, AC-6.
(3) USER-INSTALLED SOFTWARE | AUTOMATED ENFORCEMENT AND MONITORING
Enforce and monitor compliance with soware installaon policies using [Assignment:
organizaon-deﬁned automated mechanisms].
Discussion: Organizaons enforce and monitor compliance with soware installaon policies
using automated mechanisms to more quickly detect and respond to unauthorized soware
installaon which can be an indicator of an internal or external hosle aack.
References: None
CM-12 INFORMATION LOCATION
Control:
a. Idenfy and document the locaon of [Assignment: organizaon-deﬁned informaon] and the
speciﬁc system components on which the informaon is processed and stored;
b. Idenfy and document the users who have access to the system and system components where
the informaon is processed and stored; and
c. Document changes to the locaon (i.e., system or system components) where the informaon is
processed and stored.
Discussion: Informaon locaon addresses the need to understand where informaon is being
processed and stored. Informaon locaon includes idenfying where speciﬁc informaon types
and informaon reside in system components and how informaon is being processed so that
informaon ﬂow can be understood and adequate protecon and policy management provided for
such informaon and system components. The security category of the informaon is also a factor in
determining the controls necessary to protect the informaon and the system component where the
informaon resides (see FIPS 199). The locaon of the informaon and system components is also a
factor in the architecture and design of the system (see SA-4, SA-8, SA-17).
Related controls: AC-2, AC-3, AC-4, AC-6, AC-23, CM-8, PM-5, RA-2, SA-4, SA-8, SA-17, SC-4, SC-16,
SC-28, SI-4, SI-7.
This document is produced from OSCAL source data
FAMILY: CM PAGE 100NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(1) INFORMATION LOCATION | AUTOMATED TOOLS TO SUPPORT INFORMATION LOCATION
Use automated tools to idenfy [Assignment: organizaon-deﬁned informaon by
informaon type] on [Assignment: organizaon-deﬁned system components] to ensure
controls are in place to protect organizaonal informaon and individual privacy.
Discussion: The use of automated tools helps to increase the eﬀecveness and eﬃciency of
the informaon locaon capability implemented within the system. Automaon also helps
organizaons manage the data produced during informaon locaon acvies and share such
informaon across the organizaon. The output of automated informaon locaon tools can be
used to guide and inform system architecture and design decisions.
References: [FIPS 199], [SP 800-60-1], [SP 800-60-2]
CM-13 DATA ACTION MAPPING
Control: Develop and document a map of system data acons.
Discussion: Data acons are system operaons that process personally idenﬁable informaon. The
processing of such informaon encompasses the full informaon life cycle, which includes collecon,
generaon, transformaon, use, disclosure, retenon, and disposal. A map of system data acons
includes discrete data acons, elements of personally idenﬁable informaon being processed in the
data acons, system components involved in the data acons, and the owners or operators of the
system components. Understanding what personally idenﬁable informaon is being processed (e.g.,
the sensivity of the personally idenﬁable informaon), how personally idenﬁable informaon
is being processed (e.g., if the data acon is visible to the individual or is processed in another part
of the system), and by whom (e.g., individuals may have diﬀerent privacy percepons based on the
enty that is processing the personally idenﬁable informaon) provides a number of contextual
factors that are important to assessing the degree of privacy risk created by the system. Data maps
can be illustrated in diﬀerent ways, and the level of detail may vary based on the mission and business
needs of the organizaon. The data map may be an overlay of any system design arfact that the
organizaon is using. The development of this map may necessitate coordinaon between the privacy
and security programs regarding the covered data acons and the components that are idenﬁed as
part of the system.
Related controls: AC-3, CM-4, CM-12, PM-5, PM-27, PT-2, PT-3, RA-3, RA-8.
References: None
CM-14 SIGNED COMPONENTS
Control: Prevent the installaon of [Assignment: organizaon-deﬁned soware and ﬁrmware
components] without veriﬁcaon that the component has been digitally signed using a cerﬁcate that
is recognized and approved by the organizaon.
Discussion: Soware and ﬁrmware components prevented from installaon unless signed with
recognized and approved cerﬁcates include soware and ﬁrmware version updates, patches, service
packs, device drivers, and basic input/output system updates. Organizaons can idenfy applicable
soware and ﬁrmware components by type, by speciﬁc items, or a combinaon of both. Digital
signatures and organizaonal veriﬁcaon of such signatures is a method of code authencaon.
Related controls: CM-7, SC-12, SC-13, SI-7.
Reference: [IR 8062]
This document is produced from OSCAL source data
FAMILY: CM PAGE 101NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
FAMILY: CONTINGENCY PLANNING
CP-1 POLICY AND PROCEDURES
Control:
a. Develop, document, and disseminate to [Assignment: organizaon-deﬁned personnel or roles]:
1. [Selecon (one or more): Organizaon-level; Mission/business process-level; System-level]
conngency planning policy that:
(a) Addresses purpose, scope, roles, responsibilies, management commitment,
coordinaon among organizaonal enes, and compliance; and
(b) Is consistent with applicable laws, execuve orders, direcves, regulaons, policies,
standards, and guidelines; and
2. Procedures to facilitate the implementaon of the conngency planning policy and the
associated conngency planning controls;
b. Designate an [Assignment: organizaon-deﬁned oﬃcial] to manage the development,
documentaon, and disseminaon of the conngency planning policy and procedures; and
c. Review and update the current conngency planning:
1. Policy [Assignment: organizaon-deﬁned frequency] and following [Assignment:
organizaon-deﬁned events]; and
2. Procedures [Assignment: organizaon-deﬁned frequency] and following [Assignment:
organizaon-deﬁned events].
Discussion: Conngency planning policy and procedures address the controls in the CP family that
are implemented within systems and organizaons. The risk management strategy is an important
factor in establishing such policies and procedures. Policies and procedures contribute to security and
privacy assurance. Therefore, it is important that security and privacy programs collaborate on the
development of conngency planning policy and procedures. Security and privacy program policies
and procedures at the organizaon level are preferable, in general, and may obviate the need for
mission- or system-speciﬁc policies and procedures. The policy can be included as part of the general
security and privacy policy or be represented by mulple policies that reﬂect the complex nature
of organizaons. Procedures can be established for security and privacy programs, for mission or
business processes, and for systems, if needed. Procedures describe how the policies or controls
are implemented and can be directed at the individual or role that is the object of the procedure.
Procedures can be documented in system security and privacy plans or in one or more separate
documents. Events that may precipitate an update to conngency planning policy and procedures
include assessment or audit ﬁndings, security incidents or breaches, or changes in laws, execuve
orders, direcves, regulaons, policies, standards, and guidelines. Simply restang controls does not
constute an organizaonal policy or procedure.
Related controls: PM-9, PS-8, SI-12.
References: [SP 800-100], [SP 800-12], [SP 800-30], [SP 800-34], [SP 800-39], [SP 800-50]
This document is produced from OSCAL source data
FAMILY: CP PAGE 102NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
CP-2 CONTINGENCY PLAN
Control:
a. Develop a conngency plan for the system that:
1. Idenﬁes essenal mission and business funcons and associated conngency
requirements;
2. Provides recovery objecves, restoraon priories, and metrics;
3. Addresses conngency roles, responsibilies, assigned individuals with contact informaon;
4. Addresses maintaining essenal mission and business funcons despite a system disrupon,
compromise, or failure;
5. Addresses eventual, full system restoraon without deterioraon of the controls originally
planned and implemented;
6. Addresses the sharing of conngency informaon; and
7. Is reviewed and approved by [Assignment: organizaon-deﬁned personnel or roles];
b. Distribute copies of the conngency plan to [Assignment: organizaon-deﬁned key conngency
personnel (idenﬁed by name and/or by role) and organizaonal elements];
c. Coordinate conngency planning acvies with incident handling acvies;
d. Review the conngency plan for the system [Assignment: organizaon-deﬁned frequency];
e. Update the conngency plan to address changes to the organizaon, system, or environment
of operaon and problems encountered during conngency plan implementaon, execuon, or
tesng;
f. Communicate conngency plan changes to [Assignment: organizaon-deﬁned key conngency
personnel (idenﬁed by name and/or by role) and organizaonal elements];
g. Incorporate lessons learned from conngency plan tesng, training, or actual conngency
acvies into conngency tesng and training; and
h. Protect the conngency plan from unauthorized disclosure and modiﬁcaon.
Discussion: Conngency planning for systems is part of an overall program for achieving connuity of
operaons for organizaonal mission and business funcons. Conngency planning addresses system
restoraon and implementaon of alternave mission or business processes when systems are
compromised or breached. Conngency planning is considered throughout the system development
life cycle and is a fundamental part of the system design. Systems can be designed for redundancy,
to provide backup capabilies, and for resilience. Conngency plans reﬂect the degree of restoraon
required for organizaonal systems since not all systems need to fully recover to achieve the level of
connuity of operaons desired. System recovery objecves reﬂect applicable laws, execuve orders,
direcves, regulaons, policies, standards, guidelines, organizaonal risk tolerance, and system impact
level.
Acons addressed in conngency plans include orderly system degradaon, system shutdown,
fallback to a manual mode, alternate informaon ﬂows, and operang in modes reserved for when
systems are under aack. By coordinang conngency planning with incident handling acvies,
organizaons ensure that the necessary planning acvies are in place and acvated in the event of
an incident. Organizaons consider whether connuity of operaons during an incident conﬂicts with
the capability to automacally disable the system, as speciﬁed in IR-4(5). Incident response planning is
part of conngency planning for organizaons and is addressed in the IR (Incident Response) family.
This document is produced from OSCAL source data
FAMILY: CP PAGE 103NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
Related controls: CP-3, CP-4, CP-6, CP-7, CP-8, CP-9, CP-10, CP-11, CP-13, IR-4, IR-6, IR-8, IR-9, MA-6,
MP-2, MP-4, MP-5, PL-2, PM-8, PM-11, SA-15, SA-20, SC-7, SC-23, SI-12.
(1) CONTINGENCY PLAN | COORDINATE WITH RELATED PLANS
Coordinate conngency plan development with organizaonal elements responsible for
related plans.
Discussion: Plans that are related to conngency plans include Business Connuity Plans,
Disaster Recovery Plans, Crical Infrastructure Plans, Connuity of Operaons Plans, Crisis
Communicaons Plans, Insider Threat Implementaon Plans, Data Breach Response Plans, Cyber
Incident Response Plans, Breach Response Plans, and Occupant Emergency Plans.
(2) CONTINGENCY PLAN | CAPACITY PLANNING
Conduct capacity planning so that necessary capacity for informaon processing,
telecommunicaons, and environmental support exists during conngency operaons.
Discussion: Capacity planning is needed because diﬀerent threats can result in a reducon
of the available processing, telecommunicaons, and support services intended to support
essenal mission and business funcons. Organizaons ancipate degraded operaons during
conngency operaons and factor the degradaon into capacity planning. For capacity planning,
environmental support refers to any environmental factor for which the organizaon determines
that it needs to provide support in a conngency situaon, even if in a degraded state. Such
determinaons are based on an organizaonal assessment of risk, system categorizaon (impact
level), and organizaonal risk tolerance.
Related controls: PE-11, PE-12, PE-13, PE-14, PE-18, SC-5.
(3) CONTINGENCY PLAN | RESUME MISSION AND BUSINESS FUNCTIONS
Plan for the resumpon of [Selecon: all; essenal] mission and business funcons within
[Assignment: organizaon-deﬁned me period] of conngency plan acvaon.
Discussion: Organizaons may choose to conduct conngency planning acvies to resume
mission and business funcons as part of business connuity planning or as part of business
impact analyses. Organizaons priorize the resumpon of mission and business funcons. The
me period for resuming mission and business funcons may be dependent on the severity and
extent of the disrupons to the system and its supporng infrastructure.
(4) CONTINGENCY PLAN | RESUME ALL MISSION AND BUSINESS FUNCTIONS
[Withdrawn: Incorporated into CP-2(3).]
(5) CONTINGENCY PLAN | CONTINUE MISSION AND BUSINESS FUNCTIONS
Plan for the connuance of [Selecon: all; essenal] mission and business funcons with
minimal or no loss of operaonal connuity and sustains that connuity unl full system
restoraon at primary processing and/or storage sites.
Discussion: Organizaons may choose to conduct the conngency planning acvies to
connue mission and business funcons as part of business connuity planning or business
impact analyses. Primary processing and/or storage sites deﬁned by organizaons as part
of conngency planning may change depending on the circumstances associated with the
conngency.
This document is produced from OSCAL source data
FAMILY: CP PAGE 104NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(6) CONTINGENCY PLAN | ALTERNATE PROCESSING AND STORAGE SITES
Plan for the transfer of [Selecon: all; essenal] mission and business funcons to alternate
processing and/or storage sites with minimal or no loss of operaonal connuity and sustain
that connuity through system restoraon to primary processing and/or storage sites.
Discussion: Organizaons may choose to conduct conngency planning acvies for alternate
processing and storage sites as part of business connuity planning or business impact analyses.
Primary processing and/or storage sites deﬁned by organizaons as part of conngency planning
may change depending on the circumstances associated with the conngency.
(7) CONTINGENCY PLAN | COORDINATE WITH EXTERNAL SERVICE PROVIDERS
Coordinate the conngency plan with the conngency plans of external service providers to
ensure that conngency requirements can be sasﬁed.
Discussion: When the capability of an organizaon to carry out its mission and business funcons
is dependent on external service providers, developing a comprehensive and mely conngency
plan may become more challenging. When mission and business funcons are dependent on
external service providers, organizaons coordinate conngency planning acvies with the
external enes to ensure that the individual plans reﬂect the overall conngency needs of the
organizaon.
Related control: SA-9.
(8) CONTINGENCY PLAN | IDENTIFY CRITICAL ASSETS
Idenfy crical system assets supporng [Selecon: all; essenal] mission and business
funcons.
Discussion: Organizaons may choose to idenfy crical assets as part of cricality analysis,
business connuity planning, or business impact analyses. Organizaons idenfy crical system
assets so that addional controls can be employed (beyond the controls rounely implemented)
to help ensure that organizaonal mission and business funcons can connue to be conducted
during conngency operaons. The idenﬁcaon of crical informaon assets also facilitates the
priorizaon of organizaonal resources. Crical system assets include technical and operaonal
aspects. Technical aspects include system components, informaon technology services,
informaon technology products, and mechanisms. Operaonal aspects include procedures
(i.e., manually executed operaons) and personnel (i.e., individuals operang technical controls
and/or execung manual procedures). Organizaonal program protecon plans can assist in
idenfying crical assets. If crical assets are resident within or supported by external service
providers, organizaons consider implemenng CP-2(7) as a control enhancement.
Related controls: CM-8, RA-9.
References: [IR 8179], [SP 800-34]
This document is produced from OSCAL source data
FAMILY: CP PAGE 105NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
CP-3 CONTINGENCY TRAINING
Control:
a. Provide conngency training to system users consistent with assigned roles and responsibilies:
1. Within [Assignment: organizaon-deﬁned me period] of assuming a conngency role or
responsibility;
2. When required by system changes; and
3. [Assignment: organizaon-deﬁned frequency] thereaer; and
b. Review and update conngency training content [Assignment: organizaon-deﬁned frequency]
and following [Assignment: organizaon-deﬁned events].
Discussion: Conngency training provided by organizaons is linked to the assigned roles and
responsibilies of organizaonal personnel to ensure that the appropriate content and level of detail
is included in such training. For example, some individuals may only need to know when and where to
report for duty during conngency operaons and if normal dues are aﬀected; system administrators
may require addional training on how to establish systems at alternate processing and storage
sites; and organizaonal oﬃcials may receive more speciﬁc training on how to conduct mission-
essenal funcons in designated oﬀ-site locaons and how to establish communicaons with other
governmental enes for purposes of coordinaon on conngency-related acvies. Training for
conngency roles or responsibilies reﬂects the speciﬁc connuity requirements in the conngency
plan. Events that may precipitate an update to conngency training content include, but are not
limited to, conngency plan tesng or an actual conngency (lessons learned), assessment or audit
ﬁndings, security incidents or breaches, or changes in laws, execuve orders, direcves, regulaons,
policies, standards, and guidelines. At the discreon of the organizaon, parcipaon in a conngency
plan test or exercise, including lessons learned sessions subsequent to the test or exercise, may sasfy
conngency plan training requirements.
Related controls: AT-2, AT-3, AT-4, CP-2, CP-4, CP-8, IR-2, IR-4, IR-9.
(1) CONTINGENCY TRAINING | SIMULATED EVENTS
Incorporate simulated events into conngency training to facilitate eﬀecve response by
personnel in crisis situaons.
Discussion: The use of simulated events creates an environment for personnel to experience
actual threat events, including cyber-aacks that disable websites, ransomware aacks that
encrypt organizaonal data on servers, hurricanes that damage or destroy organizaonal
facilies, or hardware or soware failures.
(2) CONTINGENCY TRAINING | MECHANISMS USED IN TRAINING ENVIRONMENTS
Employ mechanisms used in operaons to provide a more thorough and realisc conngency
training environment.
Discussion: Operaonal mechanisms refer to processes that have been established to accomplish
an organizaonal goal or a system that supports a parcular organizaonal mission or business
objecve. Actual mission and business processes, systems, and/or facilies may be used to
generate simulated events and enhance the realism of simulated events during conngency
training.
Reference: [SP 800-50]
This document is produced from OSCAL source data
FAMILY: CP PAGE 106NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
CP-4 CONTINGENCY PLAN TESTING
Control:
a. Test the conngency plan for the system [Assignment: organizaon-deﬁned frequency] using the
following tests to determine the eﬀecveness of the plan and the readiness to execute the plan:
[Assignment: organizaon-deﬁned tests].
b. Review the conngency plan test results; and
c. Iniate correcve acons, if needed.
Discussion: Methods for tesng conngency plans to determine the eﬀecveness of the plans and
idenfy potenal weaknesses include checklists, walk-through and tabletop exercises, simulaons
(parallel or full interrupt), and comprehensive exercises. Organizaons conduct tesng based on
the requirements in conngency plans and include a determinaon of the eﬀects on organizaonal
operaons, assets, and individuals due to conngency operaons. Organizaons have ﬂexibility and
discreon in the breadth, depth, and melines of correcve acons.
Related controls: AT-3, CP-2, CP-3, CP-8, CP-9, IR-3, IR-4, PL-2, PM-14, SR-2.
(1) CONTINGENCY PLAN TESTING | COORDINATE WITH RELATED PLANS
Coordinate conngency plan tesng with organizaonal elements responsible for related
plans.
Discussion: Plans related to conngency planning for organizaonal systems include Business
Connuity Plans, Disaster Recovery Plans, Connuity of Operaons Plans, Crisis Communicaons
Plans, Crical Infrastructure Plans, Cyber Incident Response Plans, and Occupant Emergency
Plans. Coordinaon of conngency plan tesng does not require organizaons to create
organizaonal elements to handle related plans or to align such elements with speciﬁc plans.
However, it does require that if such organizaonal elements are responsible for related plans,
organizaons coordinate with those elements.
Related controls: IR-8, PM-8.
(2) CONTINGENCY PLAN TESTING | ALTERNATE PROCESSING SITE
Test the conngency plan at the alternate processing site:
(a) To familiarize conngency personnel with the facility and available resources; and
(b) To evaluate the capabilies of the alternate processing site to support conngency
operaons.
Discussion: Condions at the alternate processing site may be signiﬁcantly diﬀerent than the
condions at the primary site. Having the opportunity to visit the alternate site and experience
the actual capabilies available at the site can provide valuable informaon on potenal
vulnerabilies that could aﬀect essenal organizaonal mission and business funcons. The
on-site visit can also provide an opportunity to reﬁne the conngency plan to address the
vulnerabilies discovered during tesng.
Related control: CP-7.
(3) CONTINGENCY PLAN TESTING | AUTOMATED TESTING
Test the conngency plan using [Assignment: organizaon-deﬁned automated mechanisms].
Discussion: Automated mechanisms facilitate thorough and eﬀecve tesng of conngency
plans by providing more complete coverage of conngency issues, selecng more realisc test
This document is produced from OSCAL source data
FAMILY: CP PAGE 107NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
scenarios and environments, and eﬀecvely stressing the system and supported mission and
business funcons.
(4) CONTINGENCY PLAN TESTING | FULL RECOVERY AND RECONSTITUTION
Include a full recovery and reconstuon of the system to a known state as part of
conngency plan tesng.
Discussion: Recovery is execung conngency plan acvies to restore organizaonal mission
and business funcons. Reconstuon takes place following recovery and includes acvies
for returning systems to fully operaonal states. Organizaons establish a known state for
systems that includes system state informaon for hardware, soware programs, and data.
Preserving system state informaon facilitates system restart and return to the operaonal
mode of organizaons with less disrupon of mission and business processes.
Related controls: CP-10, SC-24.
(5) CONTINGENCY PLAN TESTING | SELF-CHALLENGE
Employ [Assignment: organizaon-deﬁned mechanisms] to [Assignment: organizaon-
deﬁned system or system component] to disrupt and adversely aﬀect the system or system
component.
Discussion: Oen, the best method of assessing system resilience is to disrupt the system in
some manner. The mechanisms used by the organizaon could disrupt system funcons or
system services in many ways, including terminang or disabling crical system components,
changing the conﬁguraon of system components, degrading crical funconality (e.g.,
restricng network bandwidth), or altering privileges. Automated, on-going, and simulated
cyber-aacks and service disrupons can reveal unexpected funconal dependencies and help
the organizaon determine its ability to ensure resilience in the face of an actual cyber-aack.
References: [FIPS 199], [SP 800-160-2], [SP 800-34], [SP 800-84]
CP-5 Conngency Plan Update
[Withdrawn: Incorporated into CP-2.]
CP-6 ALTERNATE STORAGE SITE
Control:
a. Establish an alternate storage site, including necessary agreements to permit the storage and
retrieval of system backup informaon; and
b. Ensure that the alternate storage site provides controls equivalent to that of the primary site.
Discussion: Alternate storage sites are geographically disnct from primary storage sites and maintain
duplicate copies of informaon and data if the primary storage site is not available. Similarly,
alternate processing sites provide processing capability if the primary processing site is not available.
Geographically distributed architectures that support conngency requirements may be considered
alternate storage sites. Items covered by alternate storage site agreements include environmental
condions at the alternate sites, access rules for systems and facilies, physical and environmental
protecon requirements, and coordinaon of delivery and retrieval of backup media. Alternate
storage sites reﬂect the requirements in conngency plans so that organizaons can maintain
essenal mission and business funcons despite compromise, failure, or disrupon in organizaonal
systems.
This document is produced from OSCAL source data
FAMILY: CP PAGE 108NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
Related controls: CP-2, CP-7, CP-8, CP-9, CP-10, MP-4, MP-5, PE-3, SC-36, SI-13.
(1) ALTERNATE STORAGE SITE | SEPARATION FROM PRIMARY SITE
Idenfy an alternate storage site that is suﬃciently separated from the primary storage site to
reduce suscepbility to the same threats.
Discussion: Threats that aﬀect alternate storage sites are deﬁned in organizaonal risk
assessments and include natural disasters, structural failures, hosle aacks, and errors of
omission or commission. Organizaons determine what is considered a suﬃcient degree of
separaon between primary and alternate storage sites based on the types of threats that are
of concern. For threats such as hosle aacks, the degree of separaon between sites is less
relevant.
Related control: RA-3.
(2) ALTERNATE STORAGE SITE | RECOVERY TIME AND RECOVERY POINT OBJECTIVES
Conﬁgure the alternate storage site to facilitate recovery operaons in accordance with
recovery me and recovery point objecves.
Discussion: Organizaons establish recovery me and recovery point objecves as part of
conngency planning. Conﬁguraon of the alternate storage site includes physical facilies and
the systems supporng recovery operaons that ensure accessibility and correct execuon.
(3) ALTERNATE STORAGE SITE | ACCESSIBILITY
Idenfy potenal accessibility problems to the alternate storage site in the event of an area-
wide disrupon or disaster and outline explicit migaon acons.
Discussion: Area-wide disrupons refer to those types of disrupons that are broad in geographic
scope with such determinaons made by organizaons based on organizaonal assessments of
risk. Explicit migaon acons include duplicang backup informaon at other alternate storage
sites if access problems occur at originally designated alternate sites or planning for physical
access to retrieve backup informaon if electronic accessibility to the alternate site is disrupted.
Related control: RA-3.
Reference: [SP 800-34]
CP-7 ALTERNATE PROCESSING SITE
Control:
a. Establish an alternate processing site, including necessary agreements to permit the transfer and
resumpon of [Assignment: organizaon-deﬁned system operaons] for essenal mission and
business funcons within [Assignment: organizaon-deﬁned me period consistent with recovery
me and recovery point objecves] when the primary processing capabilies are unavailable;
b. Make available at the alternate processing site, the equipment and supplies required to transfer
and resume operaons or put contracts in place to support delivery to the site within the
organizaon-deﬁned me period for transfer and resumpon; and
c. Provide controls at the alternate processing site that are equivalent to those at the primary site.
Discussion: Alternate processing sites are geographically disnct from primary processing sites
and provide processing capability if the primary processing site is not available. The alternate
processing capability may be addressed using a physical processing site or other alternaves, such
This document is produced from OSCAL source data
FAMILY: CP PAGE 109NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
as failover to a cloud-based service provider or other internally or externally provided processing
service. Geographically distributed architectures that support conngency requirements may also
be considered alternate processing sites. Controls that are covered by alternate processing site
agreements include the environmental condions at alternate sites, access rules, physical and
environmental protecon requirements, and the coordinaon for the transfer and assignment of
personnel. Requirements are allocated to alternate processing sites that reﬂect the requirements
in conngency plans to maintain essenal mission and business funcons despite disrupon,
compromise, or failure in organizaonal systems.
Related controls: CP-2, CP-6, CP-8, CP-9, CP-10, MA-6, PE-3, PE-11, PE-12, PE-17, SC-36, SI-13.
(1) ALTERNATE PROCESSING SITE | SEPARATION FROM PRIMARY SITE
Idenfy an alternate processing site that is suﬃciently separated from the primary processing
site to reduce suscepbility to the same threats.
Discussion: Threats that aﬀect alternate processing sites are deﬁned in organizaonal
assessments of risk and include natural disasters, structural failures, hosle aacks, and errors
of omission or commission. Organizaons determine what is considered a suﬃcient degree of
separaon between primary and alternate processing sites based on the types of threats that
are of concern. For threats such as hosle aacks, the degree of separaon between sites is less
relevant.
Related control: RA-3.
(2) ALTERNATE PROCESSING SITE | ACCESSIBILITY
Idenfy potenal accessibility problems to alternate processing sites in the event of an area-
wide disrupon or disaster and outlines explicit migaon acons.
Discussion: Area-wide disrupons refer to those types of disrupons that are broad in geographic
scope with such determinaons made by organizaons based on organizaonal assessments of
risk.
Related control: RA-3.
(3) ALTERNATE PROCESSING SITE | PRIORITY OF SERVICE
Develop alternate processing site agreements that contain priority-of-service provisions in
accordance with availability requirements (including recovery me objecves).
Discussion: Priority of service agreements refer to negoated agreements with service providers
that ensure that organizaons receive priority treatment consistent with their availability
requirements and the availability of informaon resources for logical alternate processing and/or
at the physical alternate processing site. Organizaons establish recovery me objecves as part
of conngency planning.
(4) ALTERNATE PROCESSING SITE | PREPARATION FOR USE
Prepare the alternate processing site so that the site can serve as the operaonal site
supporng essenal mission and business funcons.
Discussion: Site preparaon includes establishing conﬁguraon sengs for systems at the
alternate processing site consistent with the requirements for such sengs at the primary site
and ensuring that essenal supplies and logiscal consideraons are in place.
Related controls: CM-2, CM-6, CP-4.
This document is produced from OSCAL source data
FAMILY: CP PAGE 110NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(5) ALTERNATE PROCESSING SITE | EQUIVALENT INFORMATION SECURITY SAFEGUARDS
[Withdrawn: Incorporated into CP-7.]
(6) ALTERNATE PROCESSING SITE | INABILITY TO RETURN TO PRIMARY SITE
Plan and prepare for circumstances that preclude returning to the primary processing site.
Discussion: There may be situaons that preclude an organizaon from returning to the primary
processing site such as if a natural disaster (e.g., ﬂood or a hurricane) damaged or destroyed a
facility and it was determined that rebuilding in the same locaon was not prudent.
Reference: [SP 800-34]
CP-8 TELECOMMUNICATIONS SERVICES
Control: Establish alternate telecommunicaons services, including necessary agreements to permit
the resumpon of [Assignment: organizaon-deﬁned system operaons] for essenal mission
and business funcons within [Assignment: organizaon-deﬁned me period] when the primary
telecommunicaons capabilies are unavailable at either the primary or alternate processing or
storage sites.
Discussion: Telecommunicaons services (for data and voice) for primary and alternate processing
and storage sites are in scope for CP-8. Alternate telecommunicaons services reﬂect the connuity
requirements in conngency plans to maintain essenal mission and business funcons despite the
loss of primary telecommunicaons services. Organizaons may specify diﬀerent me periods for
primary or alternate sites. Alternate telecommunicaons services include addional organizaonal or
commercial ground-based circuits or lines, network-based approaches to telecommunicaons, or the
use of satellites. Organizaons consider factors such as availability, quality of service, and access when
entering into alternate telecommunicaons agreements.
Related controls: CP-2, CP-6, CP-7, CP-11, SC-7.
(1) TELECOMMUNICATIONS SERVICES | PRIORITY OF SERVICE PROVISIONS
(a) Develop primary and alternate telecommunicaons service agreements that contain
priority-of-service provisions in accordance with availability requirements (including
recovery me objecves); and
(b) Request Telecommunicaons Service Priority for all telecommunicaons services
used for naonal security emergency preparedness if the primary and/or alternate
telecommunicaons services are provided by a common carrier.
Discussion: Organizaons consider the potenal mission or business impact in situaons where
telecommunicaons service providers are servicing other organizaons with similar priority
of service provisions. Telecommunicaons Service Priority (TSP) is a Federal Communicaons
Commission (FCC) program that directs telecommunicaons service providers (e.g., wireline
and wireless phone companies) to give preferenal treatment to users enrolled in the program
when they need to add new lines or have their lines restored following a disrupon of service,
regardless of the cause. The FCC sets the rules and policies for the TSP program, and the
Department of Homeland Security manages the TSP program. The TSP program is always in
eﬀect and not conngent on a major disaster or aack taking place. Federal sponsorship is
required to enroll in the TSP program.
This document is produced from OSCAL source data
FAMILY: CP PAGE 111NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(2) TELECOMMUNICATIONS SERVICES | SINGLE POINTS OF FAILURE
Obtain alternate telecommunicaons services to reduce the likelihood of sharing a single point
of failure with primary telecommunicaons services.
Discussion: In certain circumstances, telecommunicaons service providers or services may
share the same physical lines, which increases the vulnerability of a single failure point. It is
important to have provider transparency for the actual physical transmission capability for
telecommunicaon services.
(3) TELECOMMUNICATIONS SERVICES | SEPARATION OF PRIMARY AND ALTERNATE
PROVIDERS
Obtain alternate telecommunicaons services from providers that are separated from primary
service providers to reduce suscepbility to the same threats.
Discussion: Threats that aﬀect telecommunicaons services are deﬁned in organizaonal
assessments of risk and include natural disasters, structural failures, cyber or physical aacks,
and errors of omission or commission. Organizaons can reduce common suscepbilies
by minimizing shared infrastructure among telecommunicaons service providers and
achieving suﬃcient geographic separaon between services. Organizaons may consider
using a single service provider in situaons where the service provider can provide alternate
telecommunicaons services that meet the separaon needs addressed in the risk assessment.
(4) TELECOMMUNICATIONS SERVICES | PROVIDER CONTINGENCY PLAN
(a) Require primary and alternate telecommunicaons service providers to have conngency
plans;
(b) Review provider conngency plans to ensure that the plans meet organizaonal
conngency requirements; and
(c) Obtain evidence of conngency tesng and training by providers [Assignment:
organizaon-deﬁned frequency].
Discussion: Reviews of provider conngency plans consider the proprietary nature of such plans.
In some situaons, a summary of provider conngency plans may be suﬃcient evidence for
organizaons to sasfy the review requirement. Telecommunicaons service providers may
also parcipate in ongoing disaster recovery exercises in coordinaon with the Department
of Homeland Security and state and local governments. Organizaons may use these types
of acvies to sasfy evidenary requirements related to service provider conngency plan
reviews, tesng, and training.
Related controls: CP-3, CP-4.
(5) TELECOMMUNICATIONS SERVICES | ALTERNATE TELECOMMUNICATION SERVICE
TESTING
Test alternate telecommunicaon services [Assignment: organizaon-deﬁned frequency].
Discussion: Alternate telecommunicaons services tesng is arranged through contractual
agreements with service providers. The tesng may occur in parallel with normal operaons to
ensure that there is no degradaon in organizaonal missions or funcons.
Related control: CP-3.
This document is produced from OSCAL source data
FAMILY: CP PAGE 112NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
Reference: [SP 800-34]
CP-9 SYSTEM BACKUP
Control:
a. Conduct backups of user-level informaon contained in [Assignment: organizaon-deﬁned
system components] [Assignment: organizaon-deﬁned frequency consistent with recovery me
and recovery point objecves];
b. Conduct backups of system-level informaon contained in the system [Assignment: organizaon-
deﬁned frequency consistent with recovery me and recovery point objecves];
c. Conduct backups of system documentaon, including security- and privacy-related
documentaon [Assignment: organizaon-deﬁned frequency consistent with recovery me and
recovery point objecves]; and
d. Protect the conﬁdenality, integrity, and availability of backup informaon.
Discussion: System-level informaon includes system state informaon, operang system soware,
middleware, applicaon soware, and licenses. User-level informaon includes informaon other
than system-level informaon. Mechanisms employed to protect the integrity of system backups
include digital signatures and cryptographic hashes. Protecon of system backup informaon while in
transit is addressed by MP-5 and SC-8. System backups reﬂect the requirements in conngency plans
as well as other organizaonal requirements for backing up informaon. Organizaons may be subject
to laws, execuve orders, direcves, regulaons, or policies with requirements regarding speciﬁc
categories of informaon (e.g., personal health informaon). Organizaonal personnel consult with
the senior agency oﬃcial for privacy and legal counsel regarding such requirements.
Related controls: CP-2, CP-6, CP-10, MP-4, MP-5, SC-8, SC-12, SC-13, SI-4, SI-13.
(1) SYSTEM BACKUP | TESTING FOR RELIABILITY AND INTEGRITY
Test backup informaon [Assignment: organizaon-deﬁned frequency] to verify media
reliability and informaon integrity.
Discussion: Organizaons need assurance that backup informaon can be reliably retrieved.
Reliability pertains to the systems and system components where the backup informaon is
stored, the operaons used to retrieve the informaon, and the integrity of the informaon
being retrieved. Independent and specialized tests can be used for each of the aspects of
reliability. For example, decrypng and transporng (or transming) a random sample of
backup ﬁles from the alternate storage or backup site and comparing the informaon to the
same informaon at the primary processing site can provide such assurance.
Related control: CP-4.
(2) SYSTEM BACKUP | TEST RESTORATION USING SAMPLING
Use a sample of backup informaon in the restoraon of selected system funcons as part of
conngency plan tesng.
Discussion: Organizaons need assurance that system funcons can be restored correctly and
can support established organizaonal missions. To ensure that the selected system funcons
are thoroughly exercised during conngency plan tesng, a sample of backup informaon is
retrieved to determine whether the funcons are operang as intended. Organizaons can
determine the sample size for the funcons and backup informaon based on the level of
assurance needed.
This document is produced from OSCAL source data
FAMILY: CP PAGE 113NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
Related control: CP-4.
(3) SYSTEM BACKUP | SEPARATE STORAGE FOR CRITICAL INFORMATION
Store backup copies of [Assignment: organizaon-deﬁned crical system soware and other
security-related informaon] in a separate facility or in a ﬁre rated container that is not
collocated with the operaonal system.
Discussion: Separate storage for crical informaon applies to all crical informaon regardless
of the type of backup storage media. Crical system soware includes operang systems,
middleware, cryptographic key management systems, and intrusion detecon systems.
Security-related informaon includes inventories of system hardware, soware, and ﬁrmware
components. Alternate storage sites, including geographically distributed architectures, serve
as separate storage facilies for organizaons. Organizaons may provide separate storage by
implemenng automated backup processes at alternave storage sites (e.g., data centers). The
General Services Administraon (GSA) establishes standards and speciﬁcaons for security and
ﬁre rated containers.
Related controls: CM-2, CM-6, CM-8.
(4) SYSTEM BACKUP | PROTECTION FROM UNAUTHORIZED MODIFICATION
[Withdrawn: Incorporated into CP-9.]
(5) SYSTEM BACKUP | TRANSFER TO ALTERNATE STORAGE SITE
Transfer system backup informaon to the alternate storage site [Assignment: organizaon-
deﬁned me period and transfer rate consistent with the recovery me and recovery point
objecves].
Discussion: System backup informaon can be transferred to alternate storage sites either
electronically or by the physical shipment of storage media.
Related controls: CP-7, MP-3, MP-4, MP-5.
(6) SYSTEM BACKUP | REDUNDANT SECONDARY SYSTEM
Conduct system backup by maintaining a redundant secondary system that is not collocated
with the primary system and that can be acvated without loss of informaon or disrupon to
operaons.
Discussion: The eﬀect of system backup can be achieved by maintaining a redundant secondary
system that mirrors the primary system, including the replicaon of informaon. If this type of
redundancy is in place and there is suﬃcient geographic separaon between the two systems,
the secondary system can also serve as the alternate processing site.
Related control: CP-7.
(7) SYSTEM BACKUP | DUAL AUTHORIZATION FOR DELETION OR DESTRUCTION
Enforce dual authorizaon for the deleon or destrucon of [Assignment: organizaon-
deﬁned backup informaon].
Discussion: Dual authorizaon ensures that deleon or destrucon of backup informaon cannot
occur unless two qualiﬁed individuals carry out the task. Individuals deleng or destroying
backup informaon possess the skills or experse to determine if the proposed deleon or
destrucon of informaon reﬂects organizaonal policies and procedures. Dual authorizaon
This document is produced from OSCAL source data
FAMILY: CP PAGE 114NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
may also be known as two-person control. To reduce the risk of collusion, organizaons consider
rotang dual authorizaon dues to other individuals.
Related controls: AC-3, AC-5, MP-2.
(8) SYSTEM BACKUP | CRYPTOGRAPHIC PROTECTION
Implement cryptographic mechanisms to prevent unauthorized disclosure and modiﬁcaon of
[Assignment: organizaon-deﬁned backup informaon].
Discussion: The selecon of cryptographic mechanisms is based on the need to protect the
conﬁdenality and integrity of backup informaon. The strength of mechanisms selected is
commensurate with the security category or classiﬁcaon of the informaon. Cryptographic
protecon applies to system backup informaon in storage at both primary and alternate
locaons. Organizaons that implement cryptographic mechanisms to protect informaon at
rest also consider cryptographic key management soluons.
Related controls: SC-12, SC-13, SC-28.
References: [FIPS 140-3], [FIPS 186-4], [SP 800-130], [SP 800-152], [SP 800-34]
CP-10 SYSTEM RECOVERY AND RECONSTITUTION
Control: Provide for the recovery and reconstuon of the system to a known state within
[Assignment: organizaon-deﬁned me period consistent with recovery me and recovery point
objecves] aer a disrupon, compromise, or failure.
Discussion: Recovery is execung conngency plan acvies to restore organizaonal mission and
business funcons. Reconstuon takes place following recovery and includes acvies for returning
systems to fully operaonal states. Recovery and reconstuon operaons reﬂect mission and
business priories; recovery point, recovery me, and reconstuon objecves; and organizaonal
metrics consistent with conngency plan requirements. Reconstuon includes the deacvaon of
interim system capabilies that may have been needed during recovery operaons. Reconstuon
also includes assessments of fully restored system capabilies, reestablishment of connuous
monitoring acvies, system reauthorizaon (if required), and acvies to prepare the system and
organizaon for future disrupons, breaches, compromises, or failures. Recovery and reconstuon
capabilies can include automated mechanisms and manual procedures. Organizaons establish
recovery me and recovery point objecves as part of conngency planning.
Related controls: CP-2, CP-4, CP-6, CP-7, CP-9, IR-4, SA-8, SC-24, SI-13.
(1) SYSTEM RECOVERY AND RECONSTITUTION | CONTINGENCY PLAN TESTING
[Withdrawn: Incorporated into CP-4.]
(2) SYSTEM RECOVERY AND RECONSTITUTION | TRANSACTION RECOVERY
Implement transacon recovery for systems that are transacon-based.
Discussion: Transacon-based systems include database management systems and transacon
processing systems. Mechanisms supporng transacon recovery include transacon rollback
and transacon journaling.
(3) SYSTEM RECOVERY AND RECONSTITUTION | COMPENSATING SECURITY CONTROLS
[Withdrawn. Addressed through tailoring.]
This document is produced from OSCAL source data
FAMILY: CP PAGE 115NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(4) SYSTEM RECOVERY AND RECONSTITUTION | RESTORE WITHIN TIME PERIOD
Provide the capability to restore system components within [Assignment: organizaon-
deﬁned restoraon me periods] from conﬁguraon-controlled and integrity-protected
informaon represenng a known, operaonal state for the components.
Discussion: Restoraon of system components includes reimaging, which restores the
components to known, operaonal states.
Related controls: CM-2, CM-6.
(5) SYSTEM RECOVERY AND RECONSTITUTION | FAILOVER CAPABILITY
[Withdrawn: Incorporated into SI-13.]
(6) SYSTEM RECOVERY AND RECONSTITUTION | COMPONENT PROTECTION
Protect system components used for recovery and reconstuon.
Discussion: Protecon of system recovery and reconstuon components (i.e., hardware,
ﬁrmware, and soware) includes physical and technical controls. Backup and restoraon
components used for recovery and reconstuon include router tables, compilers, and other
system soware.
Related controls: AC-3, AC-6, MP-2, MP-4, PE-3, PE-6.
Reference: [SP 800-34]
CP-11 ALTERNATE COMMUNICATIONS PROTOCOLS
Control: Provide the capability to employ [Assignment: organizaon-deﬁned alternave
communicaons protocols] in support of maintaining connuity of operaons.
Discussion: Conngency plans and the conngency training or tesng associated with those plans
incorporate an alternate communicaons protocol capability as part of establishing resilience in
organizaonal systems. Switching communicaons protocols may aﬀect soware applicaons and
operaonal aspects of systems. Organizaons assess the potenal side eﬀects of introducing alternate
communicaons protocols prior to implementaon.
Related controls: CP-2, CP-8, CP-13.
References: None
CP-12 SAFE MODE
Control: When [Assignment: organizaon-deﬁned condions] are detected, enter a safe mode of
operaon with [Assignment: organizaon-deﬁned restricons of safe mode of operaon].
Discussion: For systems that support crical mission and business funcons—including military
operaons, civilian space operaons, nuclear power plant operaons, and air traﬃc control
operaons (especially real-me operaonal environments)—organizaons can idenfy certain
condions under which those systems revert to a predeﬁned safe mode of operaon. The safe
mode of operaon, which can be acvated either automacally or manually, restricts the operaons
that systems can execute when those condions are encountered. Restricon includes allowing
only selected funcons to execute that can be carried out under limited power or with reduced
communicaons bandwidth.
Related controls: CM-2, SA-8, SC-24, SI-13, SI-17.
This document is produced from OSCAL source data
FAMILY: CP PAGE 116NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
References: None
CP-13 ALTERNATIVE SECURITY MECHANISMS
Control: Employ [Assignment: organizaon-deﬁned alternave or supplemental security mechanisms]
for sasfying [Assignment: organizaon-deﬁned security funcons] when the primary means of
implemenng the security funcon is unavailable or compromised.
Discussion: Use of alternave security mechanisms supports system resiliency, conngency planning,
and connuity of operaons. To ensure mission and business connuity, organizaons can implement
alternave or supplemental security mechanisms. The mechanisms may be less eﬀecve than the
primary mechanisms. However, having the capability to readily employ alternave or supplemental
mechanisms enhances mission and business connuity that might otherwise be adversely impacted if
operaons had to be curtailed unl the primary means of implemenng the funcons was restored.
Given the cost and level of eﬀort required to provide such alternave capabilies, the alternave
or supplemental mechanisms are only applied to crical security capabilies provided by systems,
system components, or system services. For example, an organizaon may issue one-me pads to
senior execuves, oﬃcials, and system administrators if mul-factor tokens—the standard means for
achieving secure authencaon— are compromised.
Related controls: CP-2, CP-11, SI-13.
References: None
This document is produced from OSCAL source data
FAMILY: CP PAGE 117NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
FAMILY: IDENTIFICATION AND AUTHENTICATION
IA-1 POLICY AND PROCEDURES
Control:
a. Develop, document, and disseminate to [Assignment: organizaon-deﬁned personnel or roles]:
1. [Selecon (one or more): Organizaon-level; Mission/business process-level; System-level]
idenﬁcaon and authencaon policy that:
(a) Addresses purpose, scope, roles, responsibilies, management commitment,
coordinaon among organizaonal enes, and compliance; and
(b) Is consistent with applicable laws, execuve orders, direcves, regulaons, policies,
standards, and guidelines; and
2. Procedures to facilitate the implementaon of the idenﬁcaon and authencaon policy
and the associated idenﬁcaon and authencaon controls;
b. Designate an [Assignment: organizaon-deﬁned oﬃcial] to manage the development,
documentaon, and disseminaon of the idenﬁcaon and authencaon policy and
procedures; and
c. Review and update the current idenﬁcaon and authencaon:
1. Policy [Assignment: organizaon-deﬁned frequency] and following [Assignment:
organizaon-deﬁned events]; and
2. Procedures [Assignment: organizaon-deﬁned frequency] and following [Assignment:
organizaon-deﬁned events].
Discussion: Idenﬁcaon and authencaon policy and procedures address the controls in the IA
family that are implemented within systems and organizaons. The risk management strategy is an
important factor in establishing such policies and procedures. Policies and procedures contribute
to security and privacy assurance. Therefore, it is important that security and privacy programs
collaborate on the development of idenﬁcaon and authencaon policy and procedures. Security
and privacy program policies and procedures at the organizaon level are preferable, in general,
and may obviate the need for mission- or system-speciﬁc policies and procedures. The policy can be
included as part of the general security and privacy policy or be represented by mulple policies that
reﬂect the complex nature of organizaons. Procedures can be established for security and privacy
programs, for mission or business processes, and for systems, if needed. Procedures describe how the
policies or controls are implemented and can be directed at the individual or role that is the object of
the procedure. Procedures can be documented in system security and privacy plans or in one or more
separate documents. Events that may precipitate an update to idenﬁcaon and authencaon policy
and procedures include assessment or audit ﬁndings, security incidents or breaches, or changes in
applicable laws, execuve orders, direcves, regulaons, policies, standards, and guidelines. Simply
restang controls does not constute an organizaonal policy or procedure.
Related controls: AC-1, PM-9, PS-8, SI-12.
References: [FIPS 201-2], [IR 7874], [OMB A-130], [SP 800-100], [SP 800-12], [SP 800-30], [SP 800-39],
[SP 800-63-3], [SP 800-73-4], [SP 800-76-2], [SP 800-78-4]
IA-2 IDENTIFICATION AND AUTHENTICATION (ORGANIZATIONAL USERS)
Control: Uniquely idenfy and authencate organizaonal users and associate that unique
idenﬁcaon with processes acng on behalf of those users.
This document is produced from OSCAL source data
FAMILY: IA PAGE 118NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
Discussion: Organizaons can sasfy the idenﬁcaon and authencaon requirements by complying
with the requirements in HSPD 12. Organizaonal users include employees or individuals who
organizaons consider to have an equivalent status to employees (e.g., contractors and guest
researchers). Unique idenﬁcaon and authencaon of users applies to all accesses other than
those that are explicitly idenﬁed in AC-14 and that occur through the authorized use of group
authencators without individual authencaon. Since processes execute on behalf of groups and
roles, organizaons may require unique idenﬁcaon of individuals in group accounts or for detailed
accountability of individual acvity.
Organizaons employ passwords, physical authencators, or biometrics to authencate user idenes
or, in the case of mul-factor authencaon, some combinaon thereof. Access to organizaonal
systems is deﬁned as either local access or network access. Local access is any access to organizaonal
systems by users or processes acng on behalf of users, where access is obtained through direct
connecons without the use of networks. Network access is access to organizaonal systems by users
(or processes acng on behalf of users) where access is obtained through network connecons (i.e.,
nonlocal accesses). Remote access is a type of network access that involves communicaon through
external networks. Internal networks include local area networks and wide area networks.
The use of encrypted virtual private networks for network connecons between organizaon-
controlled endpoints and non-organizaon-controlled endpoints may be treated as internal networks
with respect to protecng the conﬁdenality and integrity of informaon traversing the network.
Idenﬁcaon and authencaon requirements for non-organizaonal users are described in IA-8.
Related controls: AC-2, AC-3, AC-4, AC-14, AC-17, AC-18, AU-1, AU-6, IA-4, IA-5, IA-8, MA-4, MA-5, PE-2,
PL-4, SA-4, SA-8.
(1) IDENTIFICATION AND AUTHENTICATION (ORGANIZATIONAL USERS) | MULTI-FACTOR
AUTHENTICATION TO PRIVILEGED ACCOUNTS
Implement mul-factor authencaon for access to privileged accounts.
Discussion: Mul-factor authencaon requires the use of two or more diﬀerent factors to
achieve authencaon. The authencaon factors are deﬁned as follows: something you know
(e.g., a personal idenﬁcaon number [PIN]), something you have (e.g., a physical authencator
such as a cryptographic private key), or something you are (e.g., a biometric). Mul-factor
authencaon soluons that feature physical authencators include hardware authencators
that provide me-based or challenge-response outputs and smart cards such as the U.S.
Government Personal Identy Veriﬁcaon (PIV) card or the Department of Defense (DoD)
Common Access Card (CAC). In addion to authencang users at the system level (i.e., at
logon), organizaons may employ authencaon mechanisms at the applicaon level, at their
discreon, to provide increased security. Regardless of the type of access (i.e., local, network,
remote), privileged accounts are authencated using mul-factor opons appropriate for the
level of risk. Organizaons can add addional security measures, such as addional or more
rigorous authencaon mechanisms, for speciﬁc types of access.
Related controls: AC-5, AC-6.
(2) IDENTIFICATION AND AUTHENTICATION (ORGANIZATIONAL USERS) | MULTI-FACTOR
AUTHENTICATION TO NON-PRIVILEGED ACCOUNTS
Implement mul-factor authencaon for access to non-privileged accounts.
Discussion: Mul-factor authencaon requires the use of two or more diﬀerent factors to
achieve authencaon. The authencaon factors are deﬁned as follows: something you know
(e.g., a personal idenﬁcaon number [PIN]), something you have (e.g., a physical authencator
This document is produced from OSCAL source data
FAMILY: IA PAGE 119NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
such as a cryptographic private key), or something you are (e.g., a biometric). Mul-factor
authencaon soluons that feature physical authencators include hardware authencators
that provide me-based or challenge-response outputs and smart cards such as the U.S.
Government Personal Identy Veriﬁcaon card or the DoD Common Access Card. In addion
to authencang users at the system level, organizaons may also employ authencaon
mechanisms at the applicaon level, at their discreon, to provide increased informaon
security. Regardless of the type of access (i.e., local, network, remote), non-privileged accounts
are authencated using mul-factor opons appropriate for the level of risk. Organizaons
can provide addional security measures, such as addional or more rigorous authencaon
mechanisms, for speciﬁc types of access.
Related control: AC-5.
(3) IDENTIFICATION AND AUTHENTICATION (ORGANIZATIONAL USERS) | LOCAL ACCESS TO
PRIVILEGED ACCOUNTS
[Withdrawn: Incorporated into IA-2(1).]
(4) IDENTIFICATION AND AUTHENTICATION (ORGANIZATIONAL USERS) | LOCAL ACCESS TO
NON-PRIVILEGED ACCOUNTS
[Withdrawn: Incorporated into IA-2(2).]
(5) IDENTIFICATION AND AUTHENTICATION (ORGANIZATIONAL USERS) | INDIVIDUAL
AUTHENTICATION WITH GROUP AUTHENTICATION
When shared accounts or authencators are employed, require users to be individually
authencated before granng access to the shared accounts or resources.
Discussion: Individual authencaon prior to shared group authencaon migates the risk of
using group accounts or authencators.
(6) IDENTIFICATION AND AUTHENTICATION (ORGANIZATIONAL USERS) | ACCESS TO
ACCOUNTS —SEPARATE DEVICE
Implement mul-factor authencaon for [Selecon (one or more): local; network; remote]
access to [Selecon (one or more): privileged accounts; non-privileged accounts] such that:
(a) One of the factors is provided by a device separate from the system gaining access; and
(b) The device meets [Assignment: organizaon-deﬁned strength of mechanism
requirements].
Discussion: The purpose of requiring a device that is separate from the system to which the
user is aempng to gain access for one of the factors during mul-factor authencaon is
to reduce the likelihood of compromising authencators or credenals stored on the system.
Adversaries may be able to compromise such authencators or credenals and subsequently
impersonate authorized users. Implemenng one of the factors on a separate device (e.g., a
hardware token), provides a greater strength of mechanism and an increased level of assurance
in the authencaon process.
Related control: AC-6.
This document is produced from OSCAL source data
FAMILY: IA PAGE 120NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(7) IDENTIFICATION AND AUTHENTICATION (ORGANIZATIONAL USERS) | NETWORK ACCESS
TO NON-PRIVILEGED ACCOUNTS — SEPARATE DEVICE
[Withdrawn: Incorporated into IA-2(6).]
(8) IDENTIFICATION AND AUTHENTICATION (ORGANIZATIONAL USERS) | ACCESS TO
ACCOUNTS — REPLAY RESISTANT
Implement replay-resistant authencaon mechanisms for access to [Selecon (one or more):
privileged accounts; non-privileged accounts].
Discussion: Authencaon processes resist replay aacks if it is impraccal to achieve successful
authencaons by replaying previous authencaon messages. Replay-resistant techniques
include protocols that use nonces or challenges such as me synchronous or cryptographic
authencators.
(9) IDENTIFICATION AND AUTHENTICATION (ORGANIZATIONAL USERS) | NETWORK ACCESS
TO NON-PRIVILEGED ACCOUNTS — REPLAY RESISTANT
[Withdrawn: Incorporated into IA-2(8).]
(10) IDENTIFICATION AND AUTHENTICATION (ORGANIZATIONAL USERS) | SINGLE SIGN-ON
Provide a single sign-on capability for [Assignment: organizaon-deﬁned system accounts and
services].
Discussion: Single sign-on enables users to log in once and gain access to mulple system
resources. Organizaons consider the operaonal eﬃciencies provided by single sign-on
capabilies with the risk introduced by allowing access to mulple systems via a single
authencaon event. Single sign-on can present opportunies to improve system security, for
example by providing the ability to add mul-factor authencaon for applicaons and systems
(exisng and new) that may not be able to navely support mul-factor authencaon.
(11) IDENTIFICATION AND AUTHENTICATION (ORGANIZATIONAL USERS) | REMOTE ACCESS
— SEPARATE DEVICE
[Withdrawn: Incorporated into IA-2(6).]
(12) IDENTIFICATION AND AUTHENTICATION (ORGANIZATIONAL USERS) | ACCEPTANCE OF
PIV CREDENTIALS
Accept and electronically verify Personal Identy Veriﬁcaon-compliant credenals.
Discussion: Acceptance of Personal Identy Veriﬁcaon (PIV)-compliant credenals applies to
organizaons implemenng logical access control and physical access control systems. PIV-
compliant credenals are those credenals issued by federal agencies that conform to FIPS
Publicaon 201 and supporng guidance documents. The adequacy and reliability of PIV card
issuers are authorized using SP 800-79-2. Acceptance of PIV-compliant credenals includes
derived PIV credenals, the use of which is addressed in SP 800-166. The DOD Common Access
Card (CAC) is an example of a PIV credenal.
This document is produced from OSCAL source data
FAMILY: IA PAGE 121NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(13) IDENTIFICATION AND AUTHENTICATION (ORGANIZATIONAL USERS) | OUT-OF-BAND
AUTHENTICATION
Implement the following out-of-band authencaon mechanisms under [Assignment:
organizaon-deﬁned condions]: [Assignment: organizaon-deﬁned out-of-band
authencaon].
Discussion: Out-of-band authencaon refers to the use of two separate communicaon paths
to idenfy and authencate users or devices to an informaon system. The ﬁrst path (i.e.,
the in-band path) is used to idenfy and authencate users or devices and is generally the
path through which informaon ﬂows. The second path (i.e., the out-of-band path) is used
to independently verify the authencaon and/or requested acon. For example, a user
authencates via a notebook computer to a remote server to which the user desires access
and requests some acon of the server via that communicaon path. Subsequently, the server
contacts the user via the user’s cell phone to verify that the requested acon originated from
the user. The user may conﬁrm the intended acon to an individual on the telephone or provide
an authencaon code via the telephone. Out-of-band authencaon can be used to migate
actual or suspected man-in the-middle aacks. The condions or criteria for acvaon include
suspicious acvies, new threat indicators, elevated threat levels, or the impact or classiﬁcaon
level of informaon in requested transacons.
Related controls: IA-10, IA-11, SC-37.
References: [FIPS 140-3], [FIPS 201-2], [FIPS 202], [IR 7539], [IR 7676], [IR 7817], [IR 7849], [IR 7870],
[IR 7874], [IR 7966], [SP 800-156], [SP 800-166], [SP 800-63-3], [SP 800-73-4], [SP 800-76-2], [SP
800-78-4], [SP 800-79-2]
IA-3 DEVICE IDENTIFICATION AND AUTHENTICATION
Control: Uniquely idenfy and authencate [Assignment: organizaon-deﬁned devices and/or types of
devices] before establishing a [Selecon (one or more): local; remote; network] connecon.
Discussion: Devices that require unique device-to-device idenﬁcaon and authencaon are deﬁned
by type, device, or a combinaon of type and device. Organizaon-deﬁned device types include
devices that are not owned by the organizaon. Systems use shared known informaon (e.g., Media
Access Control [MAC], Transmission Control Protocol/Internet Protocol [TCP/IP] addresses) for device
idenﬁcaon or organizaonal authencaon soluons (e.g., Instute of Electrical and Electronics
Engineers (IEEE) 802.1x and Extensible Authencaon Protocol [EAP], RADIUS server with EAP-
Transport Layer Security [TLS] authencaon, Kerberos) to idenfy and authencate devices on
local and wide area networks. Organizaons determine the required strength of authencaon
mechanisms based on the security categories of systems and mission or business requirements.
Because of the challenges of implemenng device authencaon on a large scale, organizaons
can restrict the applicaon of the control to a limited number/type of devices based on mission or
business needs.
Related controls: AC-17, AC-18, AC-19, AU-6, CA-3, CA-9, IA-4, IA-5, IA-9, IA-11, SI-4.
This document is produced from OSCAL source data
FAMILY: IA PAGE 122NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(1) DEVICE IDENTIFICATION AND AUTHENTICATION | CRYPTOGRAPHIC BIDIRECTIONAL
AUTHENTICATION
Authencate [Assignment: organizaon-deﬁned devices and/or types of devices] before
establishing [Selecon (one or more): local; remote; network] connecon using bidireconal
authencaon that is cryptographically based.
Discussion: A local connecon is a connecon with a device that communicates without the use
of a network. A network connecon is a connecon with a device that communicates through
a network. A remote connecon is a connecon with a device that communicates through an
external network. Bidireconal authencaon provides stronger protecon to validate the
identy of other devices for connecons that are of greater risk.
Related controls: SC-8, SC-12, SC-13.
(2) DEVICE IDENTIFICATION AND AUTHENTICATION | CRYPTOGRAPHIC BIDIRECTIONAL
NETWORK AUTHENTICATION
[Withdrawn: Incorporated into IA-3(1).]
(3) DEVICE IDENTIFICATION AND AUTHENTICATION | DYNAMIC ADDRESS ALLOCATION
(a) Where addresses are allocated dynamically, standardize dynamic address allocaon lease
informaon and the lease duraon assigned to devices in accordance with [Assignment:
organizaon-deﬁned lease informaon and lease duraon]; and
(b) Audit lease informaon when assigned to a device.
Discussion: The Dynamic Host Conﬁguraon Protocol (DHCP) is an example of a means by which
clients can dynamically receive network address assignments.
Related control: AU-2.
(4) DEVICE IDENTIFICATION AND AUTHENTICATION | DEVICE ATTESTATION
Handle device idenﬁcaon and authencaon based on aestaon by [Assignment:
organizaon-deﬁned conﬁguraon management process].
Discussion: Device aestaon refers to the idenﬁcaon and authencaon of a device based
on its conﬁguraon and known operang state. Device aestaon can be determined via
a cryptographic hash of the device. If device aestaon is the means of idenﬁcaon and
authencaon, then it is important that patches and updates to the device are handled via a
conﬁguraon management process such that the patches and updates are done securely and do
not disrupt idenﬁcaon and authencaon to other devices.
Related controls: CM-2, CM-3, CM-6.
References: None
IA-4 IDENTIFIER MANAGEMENT
Control: Manage system idenﬁers by:
a. Receiving authorizaon from [Assignment: organizaon-deﬁned personnel or roles] to assign an
individual, group, role, service, or device idenﬁer;
b. Selecng an idenﬁer that idenﬁes an individual, group, role, service, or device;
This document is produced from OSCAL source data
FAMILY: IA PAGE 123NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
c. Assigning the idenﬁer to the intended individual, group, role, service, or device; and
d. Prevenng reuse of idenﬁers for [Assignment: organizaon-deﬁned me period].
Discussion: Common device idenﬁers include Media Access Control (MAC) addresses, Internet
Protocol (IP) addresses, or device-unique token idenﬁers. The management of individual idenﬁers
is not applicable to shared system accounts. Typically, individual idenﬁers are the usernames of the
system accounts assigned to those individuals. In such instances, the account management acvies
of AC-2 use account names provided by IA-4. Idenﬁer management also addresses individual
idenﬁers not necessarily associated with system accounts. Prevenng the reuse of idenﬁers implies
prevenng the assignment of previously used individual, group, role, service, or device idenﬁers to
diﬀerent individuals, groups, roles, services, or devices.
Related controls: AC-5, IA-2, IA-3, IA-5, IA-8, IA-9, IA-12, MA-4, PE-2, PE-3, PE-4, PL-4, PM-12, PS-3, PS-4,
PS-5, SC-37.
(1) IDENTIFIER MANAGEMENT | PROHIBIT ACCOUNT IDENTIFIERS AS PUBLIC IDENTIFIERS
Prohibit the use of system account idenﬁers that are the same as public idenﬁers for
individual accounts.
Discussion: Prohibing account idenﬁers as public idenﬁers applies to any publicly disclosed
account idenﬁer used for communicaon such as, electronic mail and instant messaging.
Prohibing the use of systems account idenﬁers that are the same as some public idenﬁer,
such as the individual idenﬁer secon of an electronic mail address, makes it more diﬃcult for
adversaries to guess user idenﬁers. Prohibing account idenﬁers as public idenﬁers without
the implementaon of other supporng controls only complicates guessing of idenﬁers.
Addional protecons are required for authencators and credenals to protect the account.
Related controls: AT-2, PT-7.
(2) IDENTIFIER MANAGEMENT | SUPERVISOR AUTHORIZATION
[Withdrawn: Incorporated into IA-12(1).]
(3) IDENTIFIER MANAGEMENT | MULTIPLE FORMS OF CERTIFICATION
[Withdrawn: Incorporated into IA-12(2).]
(4) IDENTIFIER MANAGEMENT | IDENTIFY USER STATUS
Manage individual idenﬁers by uniquely idenfying each individual as [Assignment:
organizaon-deﬁned characterisc idenfying individual status].
Discussion: Characteriscs that idenfy the status of individuals include contractors, foreign
naonals, and non-organizaonal users. Idenfying the status of individuals by these
characteriscs provides addional informaon about the people with whom organizaonal
personnel are communicang. For example, it might be useful for a government employee to
know that one of the individuals on an email message is a contractor.
This document is produced from OSCAL source data
FAMILY: IA PAGE 124NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(5) IDENTIFIER MANAGEMENT | DYNAMIC MANAGEMENT
Manage individual idenﬁers dynamically in accordance with [Assignment: organizaon-
deﬁned dynamic idenﬁer policy].
Discussion: In contrast to convenonal approaches to idenﬁcaon that presume stac accounts
for preregistered users, many distributed systems establish idenﬁers at runme for enes that
were previously unknown. When idenﬁers are established at runme for previously unknown
enes, organizaons can ancipate and provision for the dynamic establishment of idenﬁers.
Pre-established trust relaonships and mechanisms with appropriate authories to validate
credenals and related idenﬁers are essenal.
Related control: AC-16.
(6) IDENTIFIER MANAGEMENT | CROSS-ORGANIZATION MANAGEMENT
Coordinate with the following external organizaons for cross-organizaon management of
idenﬁers: [Assignment: organizaon-deﬁned external organizaons].
Discussion: Cross-organizaon idenﬁer management provides the capability to idenfy
individuals, groups, roles, or devices when conducng cross-organizaon acvies involving the
processing, storage, or transmission of informaon.
Related controls: AU-16, IA-2, IA-5.
(7) IDENTIFIER MANAGEMENT | IN-PERSON REGISTRATION
[Withdrawn: Incorporated into IA-12(4).]
(8) IDENTIFIER MANAGEMENT | PAIRWISE PSEUDONYMOUS IDENTIFIERS
Generate pairwise pseudonymous idenﬁers.
Discussion: A pairwise pseudonymous idenﬁer is an opaque unguessable subscriber idenﬁer
generated by an identy provider for use at a speciﬁc individual relying party. Generang
disnct pairwise pseudonymous idenﬁers with no idenfying informaon about a subscriber
discourages subscriber acvity tracking and proﬁling beyond the operaonal requirements
established by an organizaon. The pairwise pseudonymous idenﬁers are unique to each
relying party except in situaons where relying pares can show a demonstrable relaonship
jusfying an operaonal need for correlaon, or all pares consent to being correlated in such a
manner.
Related control: IA-5.
(9) IDENTIFIER MANAGEMENT | ATTRIBUTE MAINTENANCE AND PROTECTION
Maintain the aributes for each uniquely idenﬁed individual, device, or service in
[Assignment: organizaon-deﬁned protected central storage].
Discussion: For each of the enes covered in IA-2, IA-3, IA-8, and IA-9, it is important to maintain
the aributes for each authencated enty on an ongoing basis in a central (protected) store.
References: [FIPS 201-2], [SP 800-63-3], [SP 800-73-4], [SP 800-76-2], [SP 800-78-4]
IA-5 AUTHENTICATOR MANAGEMENT
Control: Manage system authencators by:
This document is produced from OSCAL source data
FAMILY: IA PAGE 125NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
a. Verifying, as part of the inial authencator distribuon, the identy of the individual, group,
role, service, or device receiving the authencator;
b. Establishing inial authencator content for any authencators issued by the organizaon;
c. Ensuring that authencators have suﬃcient strength of mechanism for their intended use;
d. Establishing and implemenng administrave procedures for inial authencator distribuon,
for lost or compromised or damaged authencators, and for revoking authencators;
e. Changing default authencators prior to ﬁrst use;
f. Changing or refreshing authencators [Assignment: organizaon-deﬁned me period by
authencator type] or when [Assignment: organizaon-deﬁned events] occur;
g. Protecng authencator content from unauthorized disclosure and modiﬁcaon;
h. Requiring individuals to take, and having devices implement, speciﬁc controls to protect
authencators; and
i. Changing authencators for group or role accounts when membership to those accounts
changes.
Discussion: Authencators include passwords, cryptographic devices, biometrics, cerﬁcates, one-
me password devices, and ID badges. Device authencators include cerﬁcates and passwords.
Inial authencator content is the actual content of the authencator (e.g., the inial password).
In contrast, the requirements for authencator content contain speciﬁc criteria or characteriscs
(e.g., minimum password length). Developers may deliver system components with factory default
authencaon credenals (i.e., passwords) to allow for inial installaon and conﬁguraon. Default
authencaon credenals are oen well known, easily discoverable, and present a signiﬁcant
risk. The requirement to protect individual authencators may be implemented via control PL-4 or
PS-6 for authencators in the possession of individuals and by controls AC-3, AC-6, and SC-28 for
authencators stored in organizaonal systems, including passwords stored in hashed or encrypted
formats or ﬁles containing encrypted or hashed passwords accessible with administrator privileges.
Systems support authencator management by organizaon-deﬁned sengs and restricons for
various authencator characteriscs (e.g., minimum password length, validaon me window for
me synchronous one-me tokens, and number of allowed rejecons during the veriﬁcaon stage
of biometric authencaon). Acons can be taken to safeguard individual authencators, including
maintaining possession of authencators, not sharing authencators with others, and immediately
reporng lost, stolen, or compromised authencators. Authencator management includes issuing
and revoking authencators for temporary access when no longer needed.
Related controls: AC-3, AC-6, CM-6, IA-2, IA-4, IA-7, IA-8, IA-9, MA-4, PE-2, PL-4, SC-12, SC-13.
This document is produced from OSCAL source data
FAMILY: IA PAGE 126NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(1) AUTHENTICATOR MANAGEMENT | PASSWORD-BASED AUTHENTICATION
For password-based authencaon:
(a) Maintain a list of commonly-used, expected, or compromised passwords and update the
list [Assignment: organizaon-deﬁned frequency] and when organizaonal passwords are
suspected to have been compromised directly or indirectly;
(b) Verify, when users create or update passwords, that the passwords are not found on the
list of commonly-used, expected, or compromised passwords in IA-5(1)(a);
(c) Transmit passwords only over cryptographically-protected channels;
(d) Store passwords using an approved salted key derivaon funcon, preferably using a
keyed hash;
(e) Require immediate selecon of a new password upon account recovery;
(f) Allow user selecon of long passwords and passphrases, including spaces and all
printable characters;
(g) Employ automated tools to assist the user in selecng strong password authencators;
and
(h) Enforce the following composion and complexity rules: [Assignment: organizaon-
deﬁned composion and complexity rules].
Discussion: Password-based authencaon applies to passwords regardless of whether they
are used in single-factor or mul-factor authencaon. Long passwords or passphrases are
preferable over shorter passwords. Enforced composion rules provide marginal security
beneﬁts while decreasing usability. However, organizaons may choose to establish certain
rules for password generaon (e.g., minimum character length for long passwords) under
certain circumstances and can enforce this requirement in IA-5(1)(h). Account recovery can
occur, for example, in situaons when a password is forgoen. Cryptographically protected
passwords include salted one-way cryptographic hashes of passwords. The list of commonly
used, compromised, or expected passwords includes passwords obtained from previous breach
corpuses, diconary words, and repeve or sequenal characters. The list includes context-
speciﬁc words, such as the name of the service, username, and derivaves thereof.
Related control: IA-6.
(2) AUTHENTICATOR MANAGEMENT | PUBLIC KEY-BASED AUTHENTICATION
(a) For public key-based authencaon:
(1) Enforce authorized access to the corresponding private key; and
(2) Map the authencated identy to the account of the individual or group; and
(b) When public key infrastructure (PKI) is used:
(1) Validate cerﬁcates by construcng and verifying a cerﬁcaon path to an accepted
trust anchor, including checking cerﬁcate status informaon; and
(2) Implement a local cache of revocaon data to support path discovery and validaon.
Discussion: Public key cryptography is a valid authencaon mechanism for individuals, machines,
and devices. For PKI soluons, status informaon for cerﬁcaon paths includes cerﬁcate
revocaon lists or cerﬁcate status protocol responses. For PIV cards, cerﬁcate validaon
involves the construcon and veriﬁcaon of a cerﬁcaon path to the Common Policy Root trust
This document is produced from OSCAL source data
FAMILY: IA PAGE 127NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
anchor, which includes cerﬁcate policy processing. Implemenng a local cache of revocaon
data to support path discovery and validaon also supports system availability in situaons
where organizaons are unable to access revocaon informaon via the network.
Related controls: IA-3, SC-17.
(3) AUTHENTICATOR MANAGEMENT | IN-PERSON OR TRUSTED EXTERNAL PARTY
REGISTRATION
[Withdrawn: Incorporated into IA-12(4).]
(4) AUTHENTICATOR MANAGEMENT | AUTOMATED SUPPORT FOR PASSWORD STRENGTH
DETERMINATION
[Withdrawn: Incorporated into IA-5(1).]
(5) AUTHENTICATOR MANAGEMENT | CHANGE AUTHENTICATORS PRIOR TO DELIVERY
Require developers and installers of system components to provide unique authencators or
change default authencators prior to delivery and installaon.
Discussion: Changing authencators prior to the delivery and installaon of system components
extends the requirement for organizaons to change default authencators upon system
installaon by requiring developers and/or installers to provide unique authencators or change
default authencators for system components prior to delivery and/or installaon. However,
it typically does not apply to developers of commercial oﬀ-the-shelf informaon technology
products. Requirements for unique authencators can be included in acquision documents
prepared by organizaons when procuring systems or system components.
(6) AUTHENTICATOR MANAGEMENT | PROTECTION OF AUTHENTICATORS
Protect authencators commensurate with the security category of the informaon to which
use of the authencator permits access.
Discussion: For systems that contain mulple security categories of informaon without reliable
physical or logical separaon between categories, authencators used to grant access to the
systems are protected commensurate with the highest security category of informaon on the
systems. Security categories of informaon are determined as part of the security categorizaon
process.
Related control: RA-2.
(7) AUTHENTICATOR MANAGEMENT | NO EMBEDDED UNENCRYPTED STATIC
AUTHENTICATORS
Ensure that unencrypted stac authencators are not embedded in applicaons or other
forms of stac storage.
Discussion: In addion to applicaons, other forms of stac storage include access scripts and
funcon keys. Organizaons exercise cauon when determining whether embedded or stored
authencators are in encrypted or unencrypted form. If authencators are used in the manner
stored, then those representaons are considered unencrypted authencators.
This document is produced from OSCAL source data
FAMILY: IA PAGE 128NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(8) AUTHENTICATOR MANAGEMENT | MULTIPLE SYSTEM ACCOUNTS
Implement [Assignment: organizaon-deﬁned security controls] to manage the risk of
compromise due to individuals having accounts on mulple systems.
Discussion: When individuals have accounts on mulple systems and use the same authencators
such as passwords, there is the risk that a compromise of one account may lead to the
compromise of other accounts. Alternave approaches include having diﬀerent authencators
(passwords) on all systems, employing a single sign-on or federaon mechanism, or using some
form of one-me passwords on all systems. Organizaons can also use rules of behavior (see
PL-4) and access agreements (see PS-6) to migate the risk of mulple system accounts.
Related control: PS-6.
(9) AUTHENTICATOR MANAGEMENT | FEDERATED CREDENTIAL MANAGEMENT
Use the following external organizaons to federate credenals: [Assignment: organizaon-
deﬁned external organizaons].
Discussion: Federaon provides organizaons with the capability to authencate individuals
and devices when conducng cross-organizaon acvies involving the processing, storage,
or transmission of informaon. Using a speciﬁc list of approved external organizaons for
authencaon helps to ensure that those organizaons are veed and trusted.
Related controls: AU-7, AU-16.
(10) AUTHENTICATOR MANAGEMENT | DYNAMIC CREDENTIAL BINDING
Bind idenes and authencators dynamically using the following rules: [Assignment:
organizaon-deﬁned binding rules].
Discussion: Authencaon requires some form of binding between an identy and the
authencator that is used to conﬁrm the identy. In convenonal approaches, binding is
established by pre-provisioning both the identy and the authencator to the system. For
example, the binding between a username (i.e., identy) and a password (i.e., authencator)
is accomplished by provisioning the identy and authencator as a pair in the system. New
authencaon techniques allow the binding between the identy and the authencator to
be implemented external to a system. For example, with smartcard credenals, the identy
and authencator are bound together on the smartcard. Using these credenals, systems can
authencate idenes that have not been pre-provisioned, dynamically provisioning the identy
aer authencaon. In these situaons, organizaons can ancipate the dynamic provisioning
of idenes. Pre-established trust relaonships and mechanisms with appropriate authories to
validate idenes and related credenals are essenal.
Related controls: AU-16, IA-5.
(11) AUTHENTICATOR MANAGEMENT | HARDWARE TOKEN-BASED AUTHENTICATION
[Withdrawn: Incorporated into IA-2(1), IA-2(2).]
(12) AUTHENTICATOR MANAGEMENT | BIOMETRIC AUTHENTICATION PERFORMANCE
For biometric-based authencaon, employ mechanisms that sasfy the following biometric
quality requirements [Assignment: organizaon-deﬁned biometric quality requirements].
Discussion: Unlike password-based authencaon, which provides exact matches of user-input
passwords to stored passwords, biometric authencaon does not provide exact matches.
This document is produced from OSCAL source data
FAMILY: IA PAGE 129NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
Depending on the type of biometric and the type of collecon mechanism, there is likely to
be some divergence from the presented biometric and the stored biometric that serves as
the basis for comparison. Matching performance is the rate at which a biometric algorithm
correctly results in a match for a genuine user and rejects other users. Biometric performance
requirements include the match rate, which reﬂects the accuracy of the biometric matching
algorithm used by a system.
Related control: AC-7.
(13) AUTHENTICATOR MANAGEMENT | EXPIRATION OF CACHED AUTHENTICATORS
Prohibit the use of cached authencators aer [Assignment: organizaon-deﬁned me
period].
Discussion: Cached authencators are used to authencate to the local machine when the
network is not available. If cached authencaon informaon is out of date, the validity of the
authencaon informaon may be quesonable.
(14) AUTHENTICATOR MANAGEMENT | MANAGING CONTENT OF PKI TRUST STORES
For PKI-based authencaon, employ an organizaon-wide methodology for managing
the content of PKI trust stores installed across all plaorms, including networks, operang
systems, browsers, and applicaons.
Discussion: An organizaon-wide methodology for managing the content of PKI trust stores
helps improve the accuracy and currency of PKI-based authencaon credenals across the
organizaon.
(15) AUTHENTICATOR MANAGEMENT | GSA-APPROVED PRODUCTS AND SERVICES
Use only General Services Administraon-approved products and services for identy,
credenal, and access management.
Discussion: General Services Administraon (GSA)-approved products and services are products
and services that have been approved through the GSA conformance program, where applicable,
and posted to the GSA Approved Products List. GSA provides guidance for teams to design and
build funconal and secure systems that comply with Federal Identy, Credenal, and Access
Management (FICAM) policies, technologies, and implementaon paerns.
(16) AUTHENTICATOR MANAGEMENT | IN-PERSON OR TRUSTED EXTERNAL PARTY
AUTHENTICATOR ISSUANCE
Require that the issuance of [Assignment: organizaon-deﬁned types of and/or speciﬁc
authencators] be conducted [Selecon: in person; by a trusted external party] before
[Assignment: organizaon-deﬁned registraon authority] with authorizaon by [Assignment:
organizaon-deﬁned personnel or roles].
Discussion: Issuing authencators in person or by a trusted external party enhances and
reinforces the trustworthiness of the identy prooﬁng process.
Related control: IA-12.
This document is produced from OSCAL source data
FAMILY: IA PAGE 130NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(17) AUTHENTICATOR MANAGEMENT | PRESENTATION ATTACK DETECTION FOR BIOMETRIC
AUTHENTICATORS
Employ presentaon aack detecon mechanisms for biometric-based authencaon.
Discussion: Biometric characteriscs do not constute secrets. Such characteriscs can be
obtained by online web accesses, taking a picture of someone with a camera phone to
obtain facial images with or without their knowledge, liing from objects that someone has
touched (e.g., a latent ﬁngerprint), or capturing a high-resoluon image (e.g., an iris paern).
Presentaon aack detecon technologies including liveness detecon, can migate the risk of
these types of aacks by making it diﬃcult to produce arfacts intended to defeat the biometric
sensor.
Related control: AC-7.
(18) AUTHENTICATOR MANAGEMENT | PASSWORD MANAGERS
(a) Employ [Assignment: organizaon-deﬁned password managers] to generate and manage
passwords; and
(b) Protect the passwords using [Assignment: organizaon-deﬁned controls].
Discussion: For systems where stac passwords are employed, it is oen a challenge to ensure
that the passwords are suitably complex and that the same passwords are not employed
on mulple systems. A password manager is a soluon to this problem as it automacally
generates and stores strong and diﬀerent passwords for various accounts. A potenal risk of
using password managers is that adversaries can target the collecon of passwords generated
by the password manager. Therefore, the collecon of passwords requires protecon including
encrypng the passwords (see IA-5(1)(d)) and storing the collecon oﬄine in a token.
References: [FIPS 140-3], [FIPS 180-4], [FIPS 201-2], [FIPS 202], [IR 7539], [IR 7817], [IR 7849], [IR 7870],
[IR 8040], [SP 800-63-3], [SP 800-73-4], [SP 800-76-2], [SP 800-78-4]
IA-6 AUTHENTICATION FEEDBACK
Control: Obscure feedback of authencaon informaon during the authencaon process to protect
the informaon from possible exploitaon and use by unauthorized individuals.
Discussion: Authencaon feedback from systems does not provide informaon that would allow
unauthorized individuals to compromise authencaon mechanisms. For some types of systems,
such as desktops or notebooks with relavely large monitors, the threat (referred to as shoulder
surﬁng) may be signiﬁcant. For other types of systems, such as mobile devices with small displays,
the threat may be less signiﬁcant and is balanced against the increased likelihood of typographic
input errors due to small keyboards. Thus, the means for obscuring authencaon feedback is
selected accordingly. Obscuring authencaon feedback includes displaying asterisks when users type
passwords into input devices or displaying feedback for a very limited me before obscuring it.
Related control: AC-3.
References: None
IA-7 CRYPTOGRAPHIC MODULE AUTHENTICATION
Control: Implement mechanisms for authencaon to a cryptographic module that meet the
requirements of applicable laws, execuve orders, direcves, policies, regulaons, standards, and
guidelines for such authencaon.
This document is produced from OSCAL source data
FAMILY: IA PAGE 131NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
Discussion: Authencaon mechanisms may be required within a cryptographic module to
authencate an operator accessing the module and to verify that the operator is authorized to
assume the requested role and perform services within that role.
Related controls: AC-3, IA-5, SA-4, SC-12, SC-13.
Reference: [FIPS 140-3]
IA-8 IDENTIFICATION AND AUTHENTICATION (NON-ORGANIZATIONAL USERS)
Control: Uniquely idenfy and authencate non-organizaonal users or processes acng on behalf of
non-organizaonal users.
Discussion: Non-organizaonal users include system users other than organizaonal users explicitly
covered by IA-2. Non-organizaonal users are uniquely idenﬁed and authencated for accesses
other than those explicitly idenﬁed and documented in AC-14. Idenﬁcaon and authencaon of
non-organizaonal users accessing federal systems may be required to protect federal, proprietary,
or privacy-related informaon (with excepons noted for naonal security systems). Organizaons
consider many factors—including security, privacy, scalability, and praccality—when balancing the
need to ensure ease of use for access to federal informaon and systems with the need to protect and
adequately migate risk.
Related controls: AC-2, AC-6, AC-14, AC-17, AC-18, AU-6, IA-2, IA-4, IA-5, IA-10, IA-11, MA-4, RA-3, SA-4,
SC-8.
(1) IDENTIFICATION AND AUTHENTICATION (NON-ORGANIZATIONAL USERS) | ACCEPTANCE
OF PIV CREDENTIALS FROM OTHER AGENCIES
Accept and electronically verify Personal Identy Veriﬁcaon-compliant credenals from other
federal agencies.
Discussion: Acceptance of Personal Identy Veriﬁcaon (PIV) credenals from other federal
agencies applies to both logical and physical access control systems. PIV credenals are those
credenals issued by federal agencies that conform to FIPS Publicaon 201 and supporng
guidelines. The adequacy and reliability of PIV card issuers are addressed and authorized using
SP 800-79-2.
Related control: PE-3.
(2) IDENTIFICATION AND AUTHENTICATION (NON-ORGANIZATIONAL USERS) | ACCEPTANCE
OF EXTERNAL AUTHENTICATORS
(a) Accept only external authencators that are NIST-compliant; and
(b) Document and maintain a list of accepted external authencators.
Discussion: Acceptance of only NIST-compliant external authencators applies to organizaonal
systems that are accessible to the public (e.g., public-facing websites). External authencators
are issued by nonfederal government enes and are compliant with SP 800-63B. Approved
external authencators meet or exceed the minimum Federal Government-wide technical,
security, privacy, and organizaonal maturity requirements. Meeng or exceeding Federal
requirements allows Federal Government relying pares to trust external authencators in
connecon with an authencaon transacon at a speciﬁed authencator assurance level.
This document is produced from OSCAL source data
FAMILY: IA PAGE 132NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(3) IDENTIFICATION AND AUTHENTICATION (NON-ORGANIZATIONAL USERS) | USE OF
FICAM-APPROVED PRODUCTS
[Withdrawn: Incorporated into IA-8(2).]
(4) IDENTIFICATION AND AUTHENTICATION (NON-ORGANIZATIONAL USERS) | USE OF
DEFINED PROFILES
Conform to the following proﬁles for identy management [Assignment: organizaon-deﬁned
identy management proﬁles].
Discussion: Organizaons deﬁne proﬁles for identy management based on open identy
management standards. To ensure that open identy management standards are viable, robust,
reliable, sustainable, and interoperable as documented, the Federal Government assesses and
scopes the standards and technology implementaons against applicable laws, execuve orders,
direcves, policies, regulaons, standards, and guidelines.
(5) IDENTIFICATION AND AUTHENTICATION (NON-ORGANIZATIONAL USERS) | ACCEPTANCE
OF PIV-I CREDENTIALS
Accept and verify federated or PKI credenals that meet [Assignment: organizaon-deﬁned
policy].
Discussion: Acceptance of PIV-I credenals can be implemented by PIV, PIV-I, and other
commercial or external identy providers. The acceptance and veriﬁcaon of PIV-I-compliant
credenals apply to both logical and physical access control systems. The acceptance and
veriﬁcaon of PIV-I credenals address nonfederal issuers of identy cards that desire to
interoperate with United States Government PIV systems and that can be trusted by Federal
Government-relying pares. The X.509 cerﬁcate policy for the Federal Bridge Cerﬁcaon
Authority (FBCA) addresses PIV-I requirements. The PIV-I card is commensurate with the PIV
credenals as deﬁned in cited references. PIV-I credenals are the credenals issued by a PIV-I
provider whose PIV-I cerﬁcate policy maps to the Federal Bridge PIV-I Cerﬁcate Policy. A PIV-
I provider is cross-cerﬁed with the FBCA (directly or through another PKI bridge) with policies
that have been mapped and approved as meeng the requirements of the PIV-I policies deﬁned
in the FBCA cerﬁcate policy.
(6) IDENTIFICATION AND AUTHENTICATION (NON-ORGANIZATIONAL USERS) |
DISASSOCIABILITY
Implement the following measures to disassociate user aributes or idenﬁer asseron
relaonships among individuals, credenal service providers, and relying pares: [Assignment:
organizaon-deﬁned measures].
Discussion: Federated identy soluons can create increased privacy risks due to the tracking
and proﬁling of individuals. Using idenﬁer mapping tables or cryptographic techniques to blind
credenal service providers and relying pares from each other or to make identy aributes
less visible to transming pares can reduce these privacy risks.
References: [FED PKI], [FIPS 201-2], [IR 8062], [OMB A-130], [SP 800-116], [SP 800-63-3], [SP 800-79-2]
This document is produced from OSCAL source data
FAMILY: IA PAGE 133NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
IA-9 SERVICE IDENTIFICATION AND AUTHENTICATION
Control: Uniquely idenfy and authencate [Assignment: organizaon-deﬁned system services
and applicaons] before establishing communicaons with devices, users, or other services or
applicaons.
Discussion: Services that may require idenﬁcaon and authencaon include web applicaons using
digital cerﬁcates or services or applicaons that query a database. Idenﬁcaon and authencaon
methods for system services and applicaons include informaon or code signing, provenance
graphs, and electronic signatures that indicate the sources of services. Decisions regarding the validity
of idenﬁcaon and authencaon claims can be made by services separate from the services
acng on those decisions. This can occur in distributed system architectures. In such situaons, the
idenﬁcaon and authencaon decisions (instead of actual idenﬁers and authencaon data) are
provided to the services that need to act on those decisions.
Related controls: IA-3, IA-4, IA-5, SC-8.
(1) SERVICE IDENTIFICATION AND AUTHENTICATION | INFORMATION EXCHANGE
[Withdrawn: Incorporated into IA-9.]
(2) SERVICE IDENTIFICATION AND AUTHENTICATION | TRANSMISSION OF DECISIONS
[Withdrawn: Incorporated into IA-9.]
References: None
IA-10 ADAPTIVE AUTHENTICATION
Control: Require individuals accessing the system to employ [Assignment: organizaon-deﬁned
supplemental authencaon techniques or mechanisms] under speciﬁc [Assignment: organizaon-
deﬁned circumstances or situaons].
Discussion: Adversaries may compromise individual authencaon mechanisms employed by
organizaons and subsequently aempt to impersonate legimate users. To address this threat,
organizaons may employ speciﬁc techniques or mechanisms and establish protocols to assess
suspicious behavior. Suspicious behavior may include accessing informaon that individuals do
not typically access as part of their dues, roles, or responsibilies; accessing greater quanes
of informaon than individuals would rounely access; or aempng to access informaon from
suspicious network addresses. When pre-established condions or triggers occur, organizaons
can require individuals to provide addional authencaon informaon. Another potenal use for
adapve authencaon is to increase the strength of mechanism based on the number or types
of records being accessed. Adapve authencaon does not replace and is not used to avoid the
use of mul-factor authencaon mechanisms but can augment implementaons of mul-factor
authencaon.
Related controls: IA-2, IA-8.
Reference: [SP 800-63-3]
IA-11 RE-AUTHENTICATION
Control: Require users to re-authencate when [Assignment: organizaon-deﬁned circumstances or
situaons requiring re-authencaon].
Discussion: In addion to the re-authencaon requirements associated with device locks,
organizaons may require re-authencaon of individuals in certain situaons, including when
This document is produced from OSCAL source data
FAMILY: IA PAGE 134NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
roles, authencators or credenals change, when security categories of systems change, when the
execuon of privileged funcons occurs, aer a ﬁxed me period, or periodically.
Related controls: AC-3, AC-11, IA-2, IA-3, IA-4, IA-8.
References: None
IA-12 IDENTITY PROOFING
Control:
a. Identy proof users that require accounts for logical access to systems based on appropriate
identy assurance level requirements as speciﬁed in applicable standards and guidelines;
b. Resolve user idenes to a unique individual; and
c. Collect, validate, and verify identy evidence.
Discussion: Identy prooﬁng is the process of collecng, validang, and verifying a user’s identy
informaon for the purposes of establishing credenals for accessing a system. Identy prooﬁng is
intended to migate threats to the registraon of users and the establishment of their accounts.
Standards and guidelines specifying identy assurance levels for identy prooﬁng include SP 800-63-3
and SP 800-63A. Organizaons may be subject to laws, execuve orders, direcves, regulaons, or
policies that address the collecon of identy evidence. Organizaonal personnel consult with the
senior agency oﬃcial for privacy and legal counsel regarding such requirements.
Related controls: AC-5, IA-1, IA-2, IA-3, IA-4, IA-5, IA-6, IA-8.
(1) IDENTITY PROOFING | SUPERVISOR AUTHORIZATION
Require that the registraon process to receive an account for logical access includes
supervisor or sponsor authorizaon.
Discussion: Including supervisor or sponsor authorizaon as part of the registraon process
provides an addional level of scruny to ensure that the user’s management chain is aware of
the account, the account is essenal to carry out organizaonal missions and funcons, and the
user’s privileges are appropriate for the ancipated responsibilies and authories within the
organizaon.
(2) IDENTITY PROOFING | IDENTITY EVIDENCE
Require evidence of individual idenﬁcaon be presented to the registraon authority.
Discussion: Identy evidence, such as documentary evidence or a combinaon of documents and
biometrics, reduces the likelihood of individuals using fraudulent idenﬁcaon to establish an
identy or at least increases the work factor of potenal adversaries. The forms of acceptable
evidence are consistent with the risks to the systems, roles, and privileges associated with the
user’s account.
(3) IDENTITY PROOFING | IDENTITY EVIDENCE VALIDATION AND VERIFICATION
Require that the presented identy evidence be validated and veriﬁed through [Assignment:
organizaonal deﬁned methods of validaon and veriﬁcaon].
Discussion: Validaon and veriﬁcaon of identy evidence increases the assurance that accounts
and idenﬁers are being established for the correct user and authencators are being bound
to that user. Validaon refers to the process of conﬁrming that the evidence is genuine
and authenc, and the data contained in the evidence is correct, current, and related to an
This document is produced from OSCAL source data
FAMILY: IA PAGE 135NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
individual. Veriﬁcaon conﬁrms and establishes a linkage between the claimed identy and the
actual existence of the user presenng the evidence. Acceptable methods for validang and
verifying identy evidence are consistent with the risks to the systems, roles, and privileges
associated with the users account.
(4) IDENTITY PROOFING | IN-PERSON VALIDATION AND VERIFICATION
Require that the validaon and veriﬁcaon of identy evidence be conducted in person before
a designated registraon authority.
Discussion: In-person prooﬁng reduces the likelihood of fraudulent credenals being issued
because it requires the physical presence of individuals, the presentaon of physical identy
documents, and actual face-to-face interacons with designated registraon authories.
(5) IDENTITY PROOFING | ADDRESS CONFIRMATION
Require that a [Selecon: registraon code; noce of prooﬁng] be delivered through an out-of-
band channel to verify the users address (physical or digital) of record.
Discussion: To make it more diﬃcult for adversaries to pose as legimate users during the identy
prooﬁng process, organizaons can use out-of-band methods to ensure that the individual
associated with an address of record is the same individual that parcipated in the registraon.
Conﬁrmaon can take the form of a temporary enrollment code or a noce of prooﬁng. The
delivery address for these arfacts is obtained from records and not self-asserted by the user.
The address can include a physical or digital address. A home address is an example of a physical
address. Email addresses and telephone numbers are examples of digital addresses.
Related control: IA-12.
(6) IDENTITY PROOFING | ACCEPT EXTERNALLY-PROOFED IDENTITIES
Accept externally-proofed idenes at [Assignment: organizaon-deﬁned identy assurance
level].
Discussion: To limit unnecessary re-prooﬁng of idenes, parcularly of non-PIV users,
organizaons accept prooﬁng conducted at a commensurate level of assurance by other
agencies or organizaons. Prooﬁng is consistent with organizaonal security policy and the
identy assurance level appropriate for the system, applicaon, or informaon accessed.
Accepng externally-proofed idenes is a fundamental component of managing federated
idenes across agencies and organizaons.
Related controls: IA-3, IA-4, IA-5, IA-8.
References: [FIPS 201-2], [SP 800-63-3], [SP 800-63A], [SP 800-79-2]
This document is produced from OSCAL source data
FAMILY: IA PAGE 136NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
FAMILY: INCIDENT RESPONSE
IR-1 POLICY AND PROCEDURES
Control:
a. Develop, document, and disseminate to [Assignment: organizaon-deﬁned personnel or roles]:
1. [Selecon (one or more): Organizaon-level; Mission/business process-level; System-level]
incident response policy that:
(a) Addresses purpose, scope, roles, responsibilies, management commitment,
coordinaon among organizaonal enes, and compliance; and
(b) Is consistent with applicable laws, execuve orders, direcves, regulaons, policies,
standards, and guidelines; and
2. Procedures to facilitate the implementaon of the incident response policy and the
associated incident response controls;
b. Designate an [Assignment: organizaon-deﬁned oﬃcial] to manage the development,
documentaon, and disseminaon of the incident response policy and procedures; and
c. Review and update the current incident response:
1. Policy [Assignment: organizaon-deﬁned frequency] and following [Assignment:
organizaon-deﬁned events]; and
2. Procedures [Assignment: organizaon-deﬁned frequency] and following [Assignment:
organizaon-deﬁned events].
Discussion: Incident response policy and procedures address the controls in the IR family that are
implemented within systems and organizaons. The risk management strategy is an important factor
in establishing such policies and procedures. Policies and procedures contribute to security and
privacy assurance. Therefore, it is important that security and privacy programs collaborate on the
development of incident response policy and procedures. Security and privacy program policies
and procedures at the organizaon level are preferable, in general, and may obviate the need for
mission- or system-speciﬁc policies and procedures. The policy can be included as part of the general
security and privacy policy or be represented by mulple policies that reﬂect the complex nature
of organizaons. Procedures can be established for security and privacy programs, for mission or
business processes, and for systems, if needed. Procedures describe how the policies or controls
are implemented and can be directed at the individual or role that is the object of the procedure.
Procedures can be documented in system security and privacy plans or in one or more separate
documents. Events that may precipitate an update to incident response policy and procedures
include assessment or audit ﬁndings, security incidents or breaches, or changes in laws, execuve
orders, direcves, regulaons, policies, standards, and guidelines. Simply restang controls does not
constute an organizaonal policy or procedure.
Related controls: PM-9, PS-8, SI-12.
References: [OMB A-130], [SP 800-100], [SP 800-12], [SP 800-30], [SP 800-39], [SP 800-50], [SP 800-61],
[SP 800-83]
This document is produced from OSCAL source data
FAMILY: IR PAGE 137NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
IR-2 INCIDENT RESPONSE TRAINING
Control:
a. Provide incident response training to system users consistent with assigned roles and
responsibilies:
1. Within [Assignment: organizaon-deﬁned me period] of assuming an incident response
role or responsibility or acquiring system access;
2. When required by system changes; and
3. [Assignment: organizaon-deﬁned frequency] thereaer; and
b. Review and update incident response training content [Assignment: organizaon-deﬁned
frequency] and following [Assignment: organizaon-deﬁned events].
Discussion: Incident response training is associated with the assigned roles and responsibilies of
organizaonal personnel to ensure that the appropriate content and level of detail are included
in such training. For example, users may only need to know who to call or how to recognize an
incident; system administrators may require addional training on how to handle incidents; and
incident responders may receive more speciﬁc training on forensics, data collecon techniques,
reporng, system recovery, and system restoraon. Incident response training includes user training
in idenfying and reporng suspicious acvies from external and internal sources. Incident response
training for users may be provided as part of AT-2 or AT-3. Events that may precipitate an update to
incident response training content include, but are not limited to, incident response plan tesng
or response to an actual incident (lessons learned), assessment or audit ﬁndings, or changes in
applicable laws, execuve orders, direcves, regulaons, policies, standards, and guidelines.
Related controls: AT-2, AT-3, AT-4, CP-3, IR-3, IR-4, IR-8, IR-9.
(1) INCIDENT RESPONSE TRAINING | SIMULATED EVENTS
Incorporate simulated events into incident response training to facilitate the required
response by personnel in crisis situaons.
Discussion: Organizaons establish requirements for responding to incidents in incident response
plans. Incorporang simulated events into incident response training helps to ensure that
personnel understand their individual responsibilies and what speciﬁc acons to take in crisis
situaons.
(2) INCIDENT RESPONSE TRAINING | AUTOMATED TRAINING ENVIRONMENTS
Provide an incident response training environment using [Assignment: organizaon-deﬁned
automated mechanisms].
Discussion: Automated mechanisms can provide a more thorough and realisc incident
response training environment. This can be accomplished, for example, by providing more
complete coverage of incident response issues, selecng more realisc training scenarios and
environments, and stressing the response capability.
(3) INCIDENT RESPONSE TRAINING | BREACH
Provide incident response training on how to idenfy and respond to a breach, including the
organizaon’s process for reporng a breach.
Discussion: For federal agencies, an incident that involves personally idenﬁable informaon
is considered a breach. A breach results in the loss of control, compromise, unauthorized
This document is produced from OSCAL source data
FAMILY: IR PAGE 138NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
disclosure, unauthorized acquision, or a similar occurrence where a person other than an
authorized user accesses or potenally accesses personally idenﬁable informaon or an
authorized user accesses or potenally accesses such informaon for other than authorized
purposes. The incident response training emphasizes the obligaon of individuals to report
both conﬁrmed and suspected breaches involving informaon in any medium or form, including
paper, oral, and electronic. Incident response training includes tabletop exercises that simulate a
breach. See IR-2(1).
References: [OMB M-17-12], [SP 800-50]
IR-3 INCIDENT RESPONSE TESTING
Control: Test the eﬀecveness of the incident response capability for the system [Assignment:
organizaon-deﬁned frequency] using the following tests: [Assignment: organizaon-deﬁned tests].
Discussion: Organizaons test incident response capabilies to determine their eﬀecveness and
idenfy potenal weaknesses or deﬁciencies. Incident response tesng includes the use of checklists,
walk-through or tabletop exercises, and simulaons (parallel or full interrupt). Incident response
tesng can include a determinaon of the eﬀects on organizaonal operaons and assets and
individuals due to incident response. The use of qualitave and quantave data aids in determining
the eﬀecveness of incident response processes.
Related controls: CP-3, CP-4, IR-2, IR-4, IR-8, PM-14.
(1) INCIDENT RESPONSE TESTING | AUTOMATED TESTING
Test the incident response capability using [Assignment: organizaon-deﬁned automated
mechanisms].
Discussion: Organizaons use automated mechanisms to more thoroughly and eﬀecvely test
incident response capabilies. This can be accomplished by providing more complete coverage
of incident response issues, selecng realisc test scenarios and environments, and stressing the
response capability.
(2) INCIDENT RESPONSE TESTING | COORDINATION WITH RELATED PLANS
Coordinate incident response tesng with organizaonal elements responsible for related
plans.
Discussion: Organizaonal plans related to incident response tesng include business connuity
plans, disaster recovery plans, connuity of operaons plans, conngency plans, crisis
communicaons plans, crical infrastructure plans, and occupant emergency plans.
(3) INCIDENT RESPONSE TESTING | CONTINUOUS IMPROVEMENT
Use qualitave and quantave data from tesng to:
(a) Determine the eﬀecveness of incident response processes;
(b) Connuously improve incident response processes; and
(c) Provide incident response measures and metrics that are accurate, consistent, and in a
reproducible format.
Discussion: To help incident response acvies funcon as intended, organizaons may use
metrics and evaluaon criteria to assess incident response programs as part of an eﬀort to
This document is produced from OSCAL source data
FAMILY: IR PAGE 139NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
connually improve response performance. These eﬀorts facilitate improvement in incident
response eﬃcacy and lessen the impact of incidents.
References: [OMB A-130], [SP 800-115], [SP 800-84]
IR-4 INCIDENT HANDLING
Control:
a. Implement an incident handling capability for incidents that is consistent with the incident
response plan and includes preparaon, detecon and analysis, containment, eradicaon, and
recovery;
b. Coordinate incident handling acvies with conngency planning acvies;
c. Incorporate lessons learned from ongoing incident handling acvies into incident response
procedures, training, and tesng, and implement the resulng changes accordingly; and
d. Ensure the rigor, intensity, scope, and results of incident handling acvies are comparable and
predictable across the organizaon.
Discussion: Organizaons recognize that incident response capabilies are dependent on the
capabilies of organizaonal systems and the mission and business processes being supported
by those systems. Organizaons consider incident response as part of the deﬁnion, design, and
development of mission and business processes and systems. Incident-related informaon can
be obtained from a variety of sources, including audit monitoring, physical access monitoring,
and network monitoring; user or administrator reports; and reported supply chain events. An
eﬀecve incident handling capability includes coordinaon among many organizaonal enes
(e.g., mission or business owners, system owners, authorizing oﬃcials, human resources oﬃces,
physical security oﬃces, personnel security oﬃces, legal departments, risk execuve [funcon],
operaons personnel, procurement oﬃces). Suspected security incidents include the receipt of
suspicious email communicaons that can contain malicious code. Suspected supply chain incidents
include the inseron of counterfeit hardware or malicious code into organizaonal systems or system
components. For federal agencies, an incident that involves personally idenﬁable informaon is
considered a breach. A breach results in unauthorized disclosure, the loss of control, unauthorized
acquision, compromise, or a similar occurrence where a person other than an authorized user
accesses or potenally accesses personally idenﬁable informaon or an authorized user accesses or
potenally accesses such informaon for other than authorized purposes.
Related controls: AC-19, AU-6, AU-7, CM-6, CP-2, CP-3, CP-4, IR-2, IR-3, IR-5, IR-6, IR-8, PE-6, PL-2,
PM-12, SA-8, SC-5, SC-7, SI-3, SI-4, SI-7.
(1) INCIDENT HANDLING | AUTOMATED INCIDENT HANDLING PROCESSES
Support the incident handling process using [Assignment: organizaon-deﬁned automated
mechanisms].
Discussion: Automated mechanisms that support incident handling processes include online
incident management systems and tools that support the collecon of live response data, full
network packet capture, and forensic analysis.
This document is produced from OSCAL source data
FAMILY: IR PAGE 140NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(2) INCIDENT HANDLING | DYNAMIC RECONFIGURATION
Include the following types of dynamic reconﬁguraon for [Assignment: organizaon-deﬁned
system components] as part of the incident response capability: [Assignment: organizaon-
deﬁned types of dynamic reconﬁguraon].
Discussion: Dynamic reconﬁguraon includes changes to router rules, access control lists,
intrusion detecon or prevenon system parameters, and ﬁlter rules for guards or ﬁrewalls.
Organizaons may perform dynamic reconﬁguraon of systems to stop aacks, misdirect
aackers, and isolate components of systems, thus liming the extent of the damage from
breaches or compromises. Organizaons include speciﬁc me frames for achieving the
reconﬁguraon of systems in the deﬁnion of the reconﬁguraon capability, considering the
potenal need for rapid response to eﬀecvely address cyber threats.
Related controls: AC-2, AC-4, CM-2.
(3) INCIDENT HANDLING | CONTINUITY OF OPERATIONS
Idenfy [Assignment: organizaon-deﬁned classes of incidents] and take the following
acons in response to those incidents to ensure connuaon of organizaonal mission and
business funcons: [Assignment: organizaon-deﬁned acons to take in response to classes of
incidents].
Discussion: Classes of incidents include malfuncons due to design or implementaon errors
and omissions, targeted malicious aacks, and untargeted malicious aacks. Incident response
acons include orderly system degradaon, system shutdown, fall back to manual mode
or acvaon of alternave technology whereby the system operates diﬀerently, employing
decepve measures, alternate informaon ﬂows, or operang in a mode that is reserved
for when systems are under aack. Organizaons consider whether connuity of operaons
requirements during an incident conﬂict with the capability to automacally disable the system
as speciﬁed as part of IR-4(5).
(4) INCIDENT HANDLING | INFORMATION CORRELATION
Correlate incident informaon and individual incident responses to achieve an organizaon-
wide perspecve on incident awareness and response.
Discussion: Somemes, a threat event, such as a hosle cyber-aack, can only be observed by
bringing together informaon from diﬀerent sources, including various reports and reporng
procedures established by organizaons.
(5) INCIDENT HANDLING | AUTOMATIC DISABLING OF SYSTEM
Implement a conﬁgurable capability to automacally disable the system if [Assignment:
organizaon-deﬁned security violaons] are detected.
Discussion: Organizaons consider whether the capability to automacally disable the system
conﬂicts with connuity of operaons requirements speciﬁed as part of CP-2 or IR-4(3). Security
violaons include cyber-aacks that have compromised the integrity of the system or exﬁltrated
organizaonal informaon and serious errors in soware programs that could adversely impact
organizaonal missions or funcons or jeopardize the safety of individuals.
This document is produced from OSCAL source data
FAMILY: IR PAGE 141NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(6) INCIDENT HANDLING | INSIDER THREATS
Implement an incident handling capability for incidents involving insider threats.
Discussion: Explicit focus on handling incidents involving insider threats provides addional
emphasis on this type of threat and the need for speciﬁc incident handling capabilies to
provide appropriate and mely responses.
(7) INCIDENT HANDLING | INSIDER THREATS — INTRA-ORGANIZATION COORDINATION
Coordinate an incident handling capability for insider threats that includes the following
organizaonal enes [Assignment: organizaon-deﬁned enes].
Discussion: Incident handling for insider threat incidents (e.g., preparaon, detecon and
analysis, containment, eradicaon, and recovery) requires coordinaon among many
organizaonal enes, including mission or business owners, system owners, human resources
oﬃces, procurement oﬃces, personnel oﬃces, physical security oﬃces, senior agency
informaon security oﬃcer, operaons personnel, risk execuve (funcon), senior agency oﬃcial
for privacy, and legal counsel. In addion, organizaons may require external support from
federal, state, and local law enforcement agencies.
(8) INCIDENT HANDLING | CORRELATION WITH EXTERNAL ORGANIZATIONS
Coordinate with [Assignment: organizaon-deﬁned external organizaons] to correlate and
share [Assignment: organizaon-deﬁned incident informaon] to achieve a cross-organizaon
perspecve on incident awareness and more eﬀecve incident responses.
Discussion: The coordinaon of incident informaon with external organizaons—including
mission or business partners, military or coalion partners, customers, and developers—can
provide signiﬁcant beneﬁts. Cross-organizaonal coordinaon can serve as an important risk
management capability. This capability allows organizaons to leverage informaon from a
variety of sources to eﬀecvely respond to incidents and breaches that could potenally aﬀect
the organizaon’s operaons, assets, and individuals.
Related controls: AU-16, PM-16.
(9) INCIDENT HANDLING | DYNAMIC RESPONSE CAPABILITY
Employ [Assignment: organizaon-deﬁned dynamic response capabilies] to respond to
incidents.
Discussion: The dynamic response capability addresses the mely deployment of new or
replacement organizaonal capabilies in response to incidents. This includes capabilies
implemented at the mission and business process level and at the system level.
(10) INCIDENT HANDLING | SUPPLY CHAIN COORDINATION
Coordinate incident handling acvies involving supply chain events with other organizaons
involved in the supply chain.
Discussion: Organizaons involved in supply chain acvies include product developers, system
integrators, manufacturers, packagers, assemblers, distributors, vendors, and resellers. Supply
chain incidents can occur anywhere through or to the supply chain and include compromises or
breaches that involve primary or sub-er providers, informaon technology products, system
components, development processes or personnel, and distribuon processes or warehousing
This document is produced from OSCAL source data
FAMILY: IR PAGE 142NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
facilies. Organizaons consider including processes for protecng and sharing incident
informaon in informaon exchange agreements and their obligaons for reporng incidents to
government oversight bodies (e.g., Federal Acquision Security Council).
Related controls: CA-3, MA-2, SA-9, SR-8.
(11) INCIDENT HANDLING | INTEGRATED INCIDENT RESPONSE TEAM
Establish and maintain an integrated incident response team that can be deployed to any
locaon idenﬁed by the organizaon in [Assignment: organizaon-deﬁned me period].
Discussion: An integrated incident response team is a team of experts that assesses, documents,
and responds to incidents so that organizaonal systems and networks can recover quickly and
implement the necessary controls to avoid future incidents. Incident response team personnel
include forensic and malicious code analysts, tool developers, systems security and privacy
engineers, and real-me operaons personnel. The incident handling capability includes
performing rapid forensic preservaon of evidence and analysis of and response to intrusions.
For some organizaons, the incident response team can be a cross-organizaonal enty.
An integrated incident response team facilitates informaon sharing and allows organizaonal
personnel (e.g., developers, implementers, and operators) to leverage team knowledge of
the threat and implement defensive measures that enable organizaons to deter intrusions
more eﬀecvely. Moreover, integrated teams promote the rapid detecon of intrusions, the
development of appropriate migaons, and the deployment of eﬀecve defensive measures.
For example, when an intrusion is detected, the integrated team can rapidly develop an
appropriate response for operators to implement, correlate the new incident with informaon
on past intrusions, and augment ongoing cyber intelligence development. Integrated incident
response teams are beer able to idenfy adversary taccs, techniques, and procedures that
are linked to the operaons tempo or speciﬁc mission and business funcons and to deﬁne
responsive acons in a way that does not disrupt those mission and business funcons. Incident
response teams can be distributed within organizaons to make the capability resilient.
Related control: AT-3.
(12) INCIDENT HANDLING | MALICIOUS CODE AND FORENSIC ANALYSIS
Analyze malicious code and/or other residual arfacts remaining in the system aer the
incident.
Discussion: When conducted carefully in an isolated environment, analysis of malicious code and
other residual arfacts of a security incident or breach can give the organizaon insight into
adversary taccs, techniques, and procedures. It can also indicate the identy or some deﬁning
characteriscs of the adversary. In addion, malicious code analysis can help the organizaon
develop responses to future incidents.
(13) INCIDENT HANDLING | BEHAVIOR ANALYSIS
Analyze anomalous or suspected adversarial behavior in or related to [Assignment:
organizaon-deﬁned environments or resources].
Discussion: If the organizaon maintains a decepon environment, an analysis of behaviors in
that environment, including resources targeted by the adversary and ming of the incident or
event, can provide insight into adversarial taccs, techniques, and procedures. External to a
decepon environment, the analysis of anomalous adversarial behavior (e.g., changes in system
performance or usage paerns) or suspected behavior (e.g., changes in searches for the locaon
of speciﬁc resources) can give the organizaon such insight.
This document is produced from OSCAL source data
FAMILY: IR PAGE 143NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(14) INCIDENT HANDLING | SECURITY OPERATIONS CENTER
Establish and maintain a security operaons center.
Discussion: A security operaons center (SOC) is the focal point for security operaons and
computer network defense for an organizaon. The purpose of the SOC is to defend and monitor
an organizaon’s systems and networks (i.e., cyber infrastructure) on an ongoing basis. The SOC
is also responsible for detecng, analyzing, and responding to cybersecurity incidents in a mely
manner. The organizaon staﬀs the SOC with skilled technical and operaonal personnel (e.g.,
security analysts, incident response personnel, systems security engineers) and implements
a combinaon of technical, management, and operaonal controls (including monitoring,
scanning, and forensics tools) to monitor, fuse, correlate, analyze, and respond to threat and
security-relevant event data from mulple sources. These sources include perimeter defenses,
network devices (e.g., routers, switches), and endpoint agent data feeds. The SOC provides a
holisc situaonal awareness capability to help organizaons determine the security posture
of the system and organizaon. A SOC capability can be obtained in a variety of ways. Larger
organizaons may implement a dedicated SOC while smaller organizaons may employ third-
party organizaons to provide such a capability.
(15) INCIDENT HANDLING | PUBLIC RELATIONS AND REPUTATION REPAIR
(a) Manage public relaons associated with an incident; and
(b) Employ measures to repair the reputaon of the organizaon.
Discussion: It is important for an organizaon to have a strategy in place for addressing incidents
that have been brought to the aenon of the general public, have cast the organizaon in
a negave light, or have aﬀected the organizaon’s constuents (e.g., partners, customers).
Such publicity can be extremely harmful to the organizaon and aﬀect its ability to carry out its
mission and business funcons. Taking proacve steps to repair the organizaon’s reputaon is
an essenal aspect of reestablishing the trust and conﬁdence of its constuents.
References: [41 CFR 201], [FASC18], [IR 7559], [OMB M-17-12], [SP 800-101], [SP 800-150], [SP
800-160-2], [SP 800-184], [SP 800-61], [SP 800-86]
IR-5 INCIDENT MONITORING
Control: Track and document incidents.
Discussion: Documenng incidents includes maintaining records about each incident, the status of the
incident, and other pernent informaon necessary for forensics as well as evaluang incident details,
trends, and handling. Incident informaon can be obtained from a variety of sources, including
network monitoring, incident reports, incident response teams, user complaints, supply chain
partners, audit monitoring, physical access monitoring, and user and administrator reports. IR-4
provides informaon on the types of incidents that are appropriate for monitoring.
Related controls: AU-6, AU-7, IR-4, IR-6, IR-8, PE-6, PM-5, SC-5, SC-7, SI-3, SI-4, SI-7.
This document is produced from OSCAL source data
FAMILY: IR PAGE 144NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(1) INCIDENT MONITORING | AUTOMATED TRACKING, DATA COLLECTION, AND ANALYSIS
Track incidents and collect and analyze incident informaon using [Assignment: organizaon-
deﬁned automated mechanisms].
Discussion: Automated mechanisms for tracking incidents and collecng and analyzing incident
informaon include Computer Incident Response Centers or other electronic databases of
incidents and network monitoring devices.
Reference: [SP 800-61]
IR-6 INCIDENT REPORTING
Control:
a. Require personnel to report suspected incidents to the organizaonal incident response
capability within [Assignment: organizaon-deﬁned me period]; and
b. Report incident informaon to [Assignment: organizaon-deﬁned authories].
Discussion: The types of incidents reported, the content and meliness of the reports, and the
designated reporng authories reﬂect applicable laws, execuve orders, direcves, regulaons,
policies, standards, and guidelines. Incident informaon can inform risk assessments, control
eﬀecveness assessments, security requirements for acquisions, and selecon criteria for
technology products.
Related controls: CM-6, CP-2, IR-4, IR-5, IR-8, IR-9.
(1) INCIDENT REPORTING | AUTOMATED REPORTING
Report incidents using [Assignment: organizaon-deﬁned automated mechanisms].
Discussion: The recipients of incident reports are speciﬁed in IR-6b. Automated reporng
mechanisms include email, posng on websites (with automac updates), and automated
incident response tools and programs.
Related control: IR-7.
(2) INCIDENT REPORTING | VULNERABILITIES RELATED TO INCIDENTS
Report system vulnerabilies associated with reported incidents to [Assignment: organizaon-
deﬁned personnel or roles].
Discussion: Reported incidents that uncover system vulnerabilies are analyzed by organizaonal
personnel including system owners, mission and business owners, senior agency informaon
security oﬃcers, senior agency oﬃcials for privacy, authorizing oﬃcials, and the risk execuve
(funcon). The analysis can serve to priorize and iniate migaon acons to address the
discovered system vulnerability.
(3) INCIDENT REPORTING | SUPPLY CHAIN COORDINATION
Provide incident informaon to the provider of the product or service and other organizaons
involved in the supply chain or supply chain governance for systems or system components
related to the incident.
Discussion: Organizaons involved in supply chain acvies include product developers, system
integrators, manufacturers, packagers, assemblers, distributors, vendors, and resellers. Enes
that provide supply chain governance include the Federal Acquision Security Council (FASC).
This document is produced from OSCAL source data
FAMILY: IR PAGE 145NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
Supply chain incidents include compromises or breaches that involve informaon technology
products, system components, development processes or personnel, distribuon processes,
or warehousing facilies. Organizaons determine the appropriate informaon to share and
consider the value gained from informing external organizaons about supply chain incidents,
including the ability to improve processes or to idenfy the root cause of an incident.
Related control: SR-8.
References: [41 CFR 201], [FASC18], [SP 800-61], [USCERT IR]
IR-7 INCIDENT RESPONSE ASSISTANCE
Control: Provide an incident response support resource, integral to the organizaonal incident
response capability, that oﬀers advice and assistance to users of the system for the handling and
reporng of incidents.
Discussion: Incident response support resources provided by organizaons include help desks,
assistance groups, automated ckeng systems to open and track incident response ckets, and
access to forensics services or consumer redress services, when required.
Related controls: AT-2, AT-3, IR-4, IR-6, IR-8, PM-22, PM-26, SA-9, SI-18.
(1) INCIDENT RESPONSE ASSISTANCE | AUTOMATION SUPPORT FOR AVAILABILITY OF
INFORMATION AND SUPPORT
Increase the availability of incident response informaon and support using [Assignment:
organizaon-deﬁned automated mechanisms].
Discussion: Automated mechanisms can provide a push or pull capability for users to obtain
incident response assistance. For example, individuals may have access to a website to query
the assistance capability, or the assistance capability can proacvely send incident response
informaon to users (general distribuon or targeted) as part of increasing understanding of
current response capabilies and support.
(2) INCIDENT RESPONSE ASSISTANCE | COORDINATION WITH EXTERNAL PROVIDERS
(a) Establish a direct, cooperave relaonship between its incident response capability and
external providers of system protecon capability; and
(b) Idenfy organizaonal incident response team members to the external providers.
Discussion: External providers of a system protecon capability include the Computer Network
Defense program within the U.S. Department of Defense. External providers help to protect,
monitor, analyze, detect, and respond to unauthorized acvity within organizaonal informaon
systems and networks. It may be beneﬁcial to have agreements in place with external providers
to clarify the roles and responsibilies of each party before an incident occurs.
References: [IR 7559], [OMB A-130]
This document is produced from OSCAL source data
FAMILY: IR PAGE 146NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
IR-8 INCIDENT RESPONSE PLAN
Control:
a. Develop an incident response plan that:
1. Provides the organizaon with a roadmap for implemenng its incident response capability;
2. Describes the structure and organizaon of the incident response capability;
3. Provides a high-level approach for how the incident response capability ﬁts into the overall
organizaon;
4. Meets the unique requirements of the organizaon, which relate to mission, size, structure,
and funcons;
5. Deﬁnes reportable incidents;
6. Provides metrics for measuring the incident response capability within the organizaon;
7. Deﬁnes the resources and management support needed to eﬀecvely maintain and mature
an incident response capability;
8. Addresses the sharing of incident informaon;
9. Is reviewed and approved by [Assignment: organizaon-deﬁned personnel or roles]
[Assignment: organizaon-deﬁned frequency]; and
10. Explicitly designates responsibility for incident response to [Assignment: organizaon-
deﬁned enes, personnel, or roles].
b. Distribute copies of the incident response plan to [Assignment: organizaon-deﬁned incident
response personnel (idenﬁed by name and/or by role) and organizaonal elements];
c. Update the incident response plan to address system and organizaonal changes or problems
encountered during plan implementaon, execuon, or tesng;
d. Communicate incident response plan changes to [Assignment: organizaon-deﬁned incident
response personnel (idenﬁed by name and/or by role) and organizaonal elements]; and
e. Protect the incident response plan from unauthorized disclosure and modiﬁcaon.
Discussion: It is important that organizaons develop and implement a coordinated approach to
incident response. Organizaonal mission and business funcons determine the structure of incident
response capabilies. As part of the incident response capabilies, organizaons consider the
coordinaon and sharing of informaon with external organizaons, including external service
providers and other organizaons involved in the supply chain. For incidents involving personally
idenﬁable informaon (i.e., breaches), include a process to determine whether noce to oversight
organizaons or aﬀected individuals is appropriate and provide that noce accordingly.
Related controls: AC-2, CP-2, CP-4, IR-4, IR-7, IR-9, PE-6, PL-2, SA-15, SI-12, SR-8.
This document is produced from OSCAL source data
FAMILY: IR PAGE 147NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(1) INCIDENT RESPONSE PLAN | BREACHES
Include the following in the Incident Response Plan for breaches involving personally
idenﬁable informaon:
(a) A process to determine if noce to individuals or other organizaons, including oversight
organizaons, is needed;
(b) An assessment process to determine the extent of the harm, embarrassment,
inconvenience, or unfairness to aﬀected individuals and any mechanisms to migate such
harms; and
(c) Idenﬁcaon of applicable privacy requirements.
Discussion: Organizaons may be required by law, regulaon, or policy to follow speciﬁc
procedures relang to breaches, including noce to individuals, aﬀected organizaons, and
oversight bodies; standards of harm; and migaon or other speciﬁc requirements.
Related controls: PT-1, PT-2, PT-3, PT-4, PT-5, PT-7.
References: [OMB A-130], [OMB M-17-12], [SP 800-61]
IR-9 INFORMATION SPILLAGE RESPONSE
Control: Respond to informaon spills by:
a. Assigning [Assignment: organizaon-deﬁned personnel or roles] with responsibility for
responding to informaon spills;
b. Idenfying the speciﬁc informaon involved in the system contaminaon;
c. Alerng [Assignment: organizaon-deﬁned personnel or roles] of the informaon spill using a
method of communicaon not associated with the spill;
d. Isolang the contaminated system or system component;
e. Eradicang the informaon from the contaminated system or component;
f. Idenfying other systems or system components that may have been subsequently
contaminated; and
g. Performing the following addional acons: [Assignment: organizaon-deﬁned acons].
Discussion: Informaon spillage refers to instances where informaon is placed on systems that
are not authorized to process such informaon. Informaon spills occur when informaon that is
thought to be a certain classiﬁcaon or impact level is transmied to a system and subsequently is
determined to be of a higher classiﬁcaon or impact level. At that point, correcve acon is required.
The nature of the response is based on the classiﬁcaon or impact level of the spilled informaon,
the security capabilies of the system, the speciﬁc nature of the contaminated storage media, and
the access authorizaons of individuals with authorized access to the contaminated system. The
methods used to communicate informaon about the spill aer the fact do not involve methods
directly associated with the actual spill to minimize the risk of further spreading the contaminaon
before such contaminaon is isolated and eradicated.
Related controls: CP-2, IR-6, PM-26, PM-27, PT-2, PT-3, PT-7, RA-7.
(1) INFORMATION SPILLAGE RESPONSE | RESPONSIBLE PERSONNEL
[Withdrawn: Incorporated into IR-9.]
This document is produced from OSCAL source data
FAMILY: IR PAGE 148NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(2) INFORMATION SPILLAGE RESPONSE | TRAINING
Provide informaon spillage response training [Assignment: organizaon-deﬁned frequency].
Discussion: Organizaons establish requirements for responding to informaon spillage incidents
in incident response plans. Incident response training on a regular basis helps to ensure that
organizaonal personnel understand their individual responsibilies and what speciﬁc acons to
take when spillage incidents occur.
Related controls: AT-2, AT-3, CP-3, IR-2.
(3) INFORMATION SPILLAGE RESPONSE | POST-SPILL OPERATIONS
Implement the following procedures to ensure that organizaonal personnel impacted by
informaon spills can connue to carry out assigned tasks while contaminated systems are
undergoing correcve acons: [Assignment: organizaon-deﬁned procedures].
Discussion: Correcve acons for systems contaminated due to informaon spillages may be
me-consuming. Personnel may not have access to the contaminated systems while correcve
acons are being taken, which may potenally aﬀect their ability to conduct organizaonal
business.
(4) INFORMATION SPILLAGE RESPONSE | EXPOSURE TO UNAUTHORIZED PERSONNEL
Employ the following controls for personnel exposed to informaon not within assigned
access authorizaons: [Assignment: organizaon-deﬁned controls].
Discussion: Controls include ensuring that personnel who are exposed to spilled informaon
are made aware of the laws, execuve orders, direcves, regulaons, policies, standards, and
guidelines regarding the informaon and the restricons imposed based on exposure to such
informaon.
References: None
IR-10 Integrated Informaon Security Analysis Team
[Withdrawn: Moved to IR-4(11).]
This document is produced from OSCAL source data
FAMILY: IR PAGE 149NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
FAMILY: MAINTENANCE
MA-1 POLICY AND PROCEDURES
Control:
a. Develop, document, and disseminate to [Assignment: organizaon-deﬁned personnel or roles]:
1. [Selecon (one or more): Organizaon-level; Mission/business process-level; System-level]
maintenance policy that:
(a) Addresses purpose, scope, roles, responsibilies, management commitment,
coordinaon among organizaonal enes, and compliance; and
(b) Is consistent with applicable laws, execuve orders, direcves, regulaons, policies,
standards, and guidelines; and
2. Procedures to facilitate the implementaon of the maintenance policy and the associated
maintenance controls;
b. Designate an [Assignment: organizaon-deﬁned oﬃcial] to manage the development,
documentaon, and disseminaon of the maintenance policy and procedures; and
c. Review and update the current maintenance:
1. Policy [Assignment: organizaon-deﬁned frequency] and following [Assignment:
organizaon-deﬁned events]; and
2. Procedures [Assignment: organizaon-deﬁned frequency] and following [Assignment:
organizaon-deﬁned events].
Discussion: Maintenance policy and procedures address the controls in the MA family that are
implemented within systems and organizaons. The risk management strategy is an important
factor in establishing such policies and procedures. Policies and procedures contribute to security
and privacy assurance. Therefore, it is important that security and privacy programs collaborate
on the development of maintenance policy and procedures. Security and privacy program policies
and procedures at the organizaon level are preferable, in general, and may obviate the need for
mission- or system-speciﬁc policies and procedures. The policy can be included as part of the general
security and privacy policy or be represented by mulple policies that reﬂect the complex nature
of organizaons. Procedures can be established for security and privacy programs, for mission or
business processes, and for systems, if needed. Procedures describe how the policies or controls
are implemented and can be directed at the individual or role that is the object of the procedure.
Procedures can be documented in system security and privacy plans or in one or more separate
documents. Events that may precipitate an update to maintenance policy and procedures assessment
or audit ﬁndings, security incidents or breaches, or changes in applicable laws, execuve orders,
direcves, regulaons, policies, standards, and guidelines. Simply restang controls does not
constute an organizaonal policy or procedure.
Related controls: PM-9, PS-8, SI-12.
References: [OMB A-130], [SP 800-100], [SP 800-12], [SP 800-30], [SP 800-39]
MA-2 CONTROLLED MAINTENANCE
Control:
a. Schedule, document, and review records of maintenance, repair, and replacement on system
components in accordance with manufacturer or vendor speciﬁcaons and/or organizaonal
requirements;
This document is produced from OSCAL source data
FAMILY: MA PAGE 150NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
b. Approve and monitor all maintenance acvies, whether performed on site or remotely and
whether the system or system components are serviced on site or removed to another locaon;
c. Require that [Assignment: organizaon-deﬁned personnel or roles] explicitly approve the
removal of the system or system components from organizaonal facilies for oﬀ-site
maintenance, repair, or replacement;
d. Sanize equipment to remove the following informaon from associated media prior to removal
from organizaonal facilies for oﬀ-site maintenance, repair, or replacement: [Assignment:
organizaon-deﬁned informaon];
e. Check all potenally impacted controls to verify that the controls are sll funconing properly
following maintenance, repair, or replacement acons; and
f. Include the following informaon in organizaonal maintenance records: [Assignment:
organizaon-deﬁned informaon].
Discussion: Controlling system maintenance addresses the informaon security aspects of the system
maintenance program and applies to all types of maintenance to system components conducted by
local or nonlocal enes. Maintenance includes peripherals such as scanners, copiers, and printers.
Informaon necessary for creang eﬀecve maintenance records includes the date and me of
maintenance, a descripon of the maintenance performed, names of the individuals or group
performing the maintenance, name of the escort, and system components or equipment that are
removed or replaced. Organizaons consider supply chain-related risks associated with replacement
components for systems.
Related controls: CM-2, CM-3, CM-4, CM-5, CM-8, MA-4, MP-6, PE-16, SI-2, SR-3, SR-4, SR-11.
(1) CONTROLLED MAINTENANCE | RECORD CONTENT
[Withdrawn: Incorporated into MA-2.]
(2) CONTROLLED MAINTENANCE | AUTOMATED MAINTENANCE ACTIVITIES
(a) Schedule, conduct, and document maintenance, repair, and replacement acons for the
system using [Assignment: organizaon-deﬁned automated mechanisms]; and
(b) Produce up-to date, accurate, and complete records of all maintenance, repair, and
replacement acons requested, scheduled, in process, and completed.
Discussion: The use of automated mechanisms to manage and control system maintenance
programs and acvies helps to ensure the generaon of mely, accurate, complete, and
consistent maintenance records.
Related control: MA-3.
References: [IR 8023], [OMB A-130]
MA-3 MAINTENANCE TOOLS
Control:
a. Approve, control, and monitor the use of system maintenance tools; and
b. Review previously approved system maintenance tools [Assignment: organizaon-deﬁned
frequency].
Discussion: Approving, controlling, monitoring, and reviewing maintenance tools address security-
related issues associated with maintenance tools that are not within system authorizaon boundaries
This document is produced from OSCAL source data
FAMILY: MA PAGE 151NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
and are used speciﬁcally for diagnosc and repair acons on organizaonal systems. Organizaons
have ﬂexibility in determining roles for the approval of maintenance tools and how that approval
is documented. A periodic review of maintenance tools facilitates the withdrawal of approval for
outdated, unsupported, irrelevant, or no-longer-used tools. Maintenance tools can include hardware,
soware, and ﬁrmware items and may be pre-installed, brought in with maintenance personnel
on media, cloud-based, or downloaded from a website. Such tools can be vehicles for transporng
malicious code, either intenonally or unintenonally, into a facility and subsequently into systems.
Maintenance tools can include hardware and soware diagnosc test equipment and packet sniﬀers.
The hardware and soware components that support maintenance and are a part of the system
(including the soware implemenng ulies such as ping, ls, ipconﬁg, or the hardware and soware
implemenng the monitoring port of an Ethernet switch) are not addressed by maintenance tools.
Related controls: MA-2, PE-16.
(1) MAINTENANCE TOOLS | INSPECT TOOLS
Inspect the maintenance tools used by maintenance personnel for improper or unauthorized
modiﬁcaons.
Discussion: Maintenance tools can be directly brought into a facility by maintenance personnel
or downloaded from a vendor’s website. If, upon inspecon of the maintenance tools,
organizaons determine that the tools have been modiﬁed in an improper manner or the tools
contain malicious code, the incident is handled consistent with organizaonal policies and
procedures for incident handling.
Related control: SI-7.
(2) MAINTENANCE TOOLS | INSPECT MEDIA
Check media containing diagnosc and test programs for malicious code before the media are
used in the system.
Discussion: If, upon inspecon of media containing maintenance, diagnosc, and test programs,
organizaons determine that the media contains malicious code, the incident is handled
consistent with organizaonal incident handling policies and procedures.
Related control: SI-3.
(3) MAINTENANCE TOOLS | PREVENT UNAUTHORIZED REMOVAL
Prevent the removal of maintenance equipment containing organizaonal informaon by:
(a) Verifying that there is no organizaonal informaon contained on the equipment;
(b) Sanizing or destroying the equipment;
(c) Retaining the equipment within the facility; or
(d) Obtaining an exempon from [Assignment: organizaon-deﬁned personnel or roles]
explicitly authorizing removal of the equipment from the facility.
Discussion: Organizaonal informaon includes all informaon owned by organizaons and any
informaon provided to organizaons for which the organizaons serve as informaon stewards.
Related control: MP-6.
This document is produced from OSCAL source data
FAMILY: MA PAGE 152NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(4) MAINTENANCE TOOLS | RESTRICTED TOOL USE
Restrict the use of maintenance tools to authorized personnel only.
Discussion: Restricng the use of maintenance tools to only authorized personnel applies to
systems that are used to carry out maintenance funcons.
Related controls: AC-3, AC-5, AC-6.
(5) MAINTENANCE TOOLS | EXECUTION WITH PRIVILEGE
Monitor the use of maintenance tools that execute with increased privilege.
Discussion: Maintenance tools that execute with increased system privilege can result in
unauthorized access to organizaonal informaon and assets that would otherwise be
inaccessible.
Related controls: AC-3, AC-6.
(6) MAINTENANCE TOOLS | SOFTWARE UPDATES AND PATCHES
Inspect maintenance tools to ensure the latest soware updates and patches are installed.
Discussion: Maintenance tools using outdated and/or unpatched soware can provide a threat
vector for adversaries and result in a signiﬁcant vulnerability for organizaons.
Related controls: AC-3, AC-6.
Reference: [SP 800-88]
MA-4 NONLOCAL MAINTENANCE
Control:
a. Approve and monitor nonlocal maintenance and diagnosc acvies;
b. Allow the use of nonlocal maintenance and diagnosc tools only as consistent with
organizaonal policy and documented in the security plan for the system;
c. Employ strong authencaon in the establishment of nonlocal maintenance and diagnosc
sessions;
d. Maintain records for nonlocal maintenance and diagnosc acvies; and
e. Terminate session and network connecons when nonlocal maintenance is completed.
Discussion: Nonlocal maintenance and diagnosc acvies are conducted by individuals who
communicate through either an external or internal network. Local maintenance and diagnosc
acvies are carried out by individuals who are physically present at the system locaon and not
communicang across a network connecon. Authencaon techniques used to establish nonlocal
maintenance and diagnosc sessions reﬂect the network access requirements in IA-2. Strong
authencaon requires authencators that are resistant to replay aacks and employ mul-factor
authencaon. Strong authencators include PKI where cerﬁcates are stored on a token protected
by a password, passphrase, or biometric. Enforcing requirements in MA-4 is accomplished, in part, by
other controls. SP 800-63B provides addional guidance on strong authencaon and authencators.
Related controls: AC-2, AC-3, AC-6, AC-17, AU-2, AU-3, IA-2, IA-4, IA-5, IA-8, MA-2, MA-5, PL-2, SC-7,
SC-10.
This document is produced from OSCAL source data
FAMILY: MA PAGE 153NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(1) NONLOCAL MAINTENANCE | LOGGING AND REVIEW
(a) Log [Assignment: organizaon-deﬁned audit events] for nonlocal maintenance and
diagnosc sessions; and
(b) Review the audit records of the maintenance and diagnosc sessions to detect
anomalous behavior.
Discussion: Audit logging for nonlocal maintenance is enforced by AU-2. Audit events are deﬁned
in AU-2a.
Related controls: AU-6, AU-12.
(2) NONLOCAL MAINTENANCE | DOCUMENT NONLOCAL MAINTENANCE
[Withdrawn: Incorporated into MA-1, MA-4.]
(3) NONLOCAL MAINTENANCE | COMPARABLE SECURITY AND SANITIZATION
(a) Require that nonlocal maintenance and diagnosc services be performed from a system
that implements a security capability comparable to the capability implemented on the
system being serviced; or
(b) Remove the component to be serviced from the system prior to nonlocal maintenance
or diagnosc services; sanize the component (for organizaonal informaon); and aer
the service is performed, inspect and sanize the component (for potenally malicious
soware) before reconnecng the component to the system.
Discussion: Comparable security capability on systems, diagnosc tools, and equipment providing
maintenance services implies that the implemented controls on those systems, tools, and
equipment are at least as comprehensive as the controls on the system being serviced.
Related controls: MP-6, SI-3, SI-7.
(4) NONLOCAL MAINTENANCE | AUTHENTICATION AND SEPARATION OF MAINTENANCE
SESSIONS
Protect nonlocal maintenance sessions by:
(a) Employing [Assignment: organizaon-deﬁned authencators that are replay resistant];
and
(b) Separang the maintenance sessions from other network sessions with the system by
either:
(1) Physically separated communicaons paths; or
(2) Logically separated communicaons paths.
Discussion: Communicaons paths can be logically separated using encrypon.
This document is produced from OSCAL source data
FAMILY: MA PAGE 154NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(5) NONLOCAL MAINTENANCE | APPROVALS AND NOTIFICATIONS
(a) Require the approval of each nonlocal maintenance session by [Assignment:
organizaon-deﬁned personnel or roles]; and
(b) Nofy the following personnel or roles of the date and me of planned nonlocal
maintenance: [Assignment: organizaon-deﬁned personnel or roles].
Discussion: Noﬁcaon may be performed by maintenance personnel. Approval of nonlocal
maintenance is accomplished by personnel with suﬃcient informaon security and system
knowledge to determine the appropriateness of the proposed maintenance.
(6) NONLOCAL MAINTENANCE | CRYPTOGRAPHIC PROTECTION
Implement the following cryptographic mechanisms to protect the integrity and conﬁdenality
of nonlocal maintenance and diagnosc communicaons: [Assignment: organizaon-deﬁned
cryptographic mechanisms].
Discussion: Failure to protect nonlocal maintenance and diagnosc communicaons can
result in unauthorized individuals gaining access to organizaonal informaon. Unauthorized
access during remote maintenance sessions can result in a variety of hosle acons, including
malicious code inseron, unauthorized changes to system parameters, and exﬁltraon of
organizaonal informaon. Such acons can result in the loss or degradaon of mission or
business capabilies.
Related controls: SC-8, SC-12, SC-13.
(7) NONLOCAL MAINTENANCE | DISCONNECT VERIFICATION
Verify session and network connecon terminaon aer the compleon of nonlocal
maintenance and diagnosc sessions.
Discussion: Verifying the terminaon of a connecon once maintenance is completed ensures
that connecons established during nonlocal maintenance and diagnosc sessions have been
terminated and are no longer available for use.
Related control: AC-12.
References: [FIPS 140-3], [FIPS 197], [FIPS 201-2], [SP 800-63-3], [SP 800-88]
MA-5 MAINTENANCE PERSONNEL
Control:
a. Establish a process for maintenance personnel authorizaon and maintain a list of authorized
maintenance organizaons or personnel;
b. Verify that non-escorted personnel performing maintenance on the system possess the required
access authorizaons; and
c. Designate organizaonal personnel with required access authorizaons and technical
competence to supervise the maintenance acvies of personnel who do not possess the
required access authorizaons.
Discussion: Maintenance personnel refers to individuals who perform hardware or soware
maintenance on organizaonal systems, while PE-2 addresses physical access for individuals whose
maintenance dues place them within the physical protecon perimeter of the systems. Technical
competence of supervising individuals relates to the maintenance performed on the systems, while
This document is produced from OSCAL source data
FAMILY: MA PAGE 155NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
having required access authorizaons refers to maintenance on and near the systems. Individuals
not previously idenﬁed as authorized maintenance personnel—such as informaon technology
manufacturers, vendors, systems integrators, and consultants—may require privileged access to
organizaonal systems, such as when they are required to conduct maintenance acvies with lile or
no noce. Based on organizaonal assessments of risk, organizaons may issue temporary credenals
to these individuals. Temporary credenals may be for one-me use or for very limited me periods.
Related controls: AC-2, AC-3, AC-5, AC-6, IA-2, IA-8, MA-4, MP-2, PE-2, PE-3, PS-7, RA-3.
(1) MAINTENANCE PERSONNEL | INDIVIDUALS WITHOUT APPROPRIATE ACCESS
(a) Implement procedures for the use of maintenance personnel that lack appropriate
security clearances or are not U.S. cizens, that include the following requirements:
(1) Maintenance personnel who do not have needed access authorizaons, clearances,
or formal access approvals are escorted and supervised during the performance of
maintenance and diagnosc acvies o
(2) Prior to iniang maintenance or diagnosc acvies by personnel who do not have
needed access authorizaons, clearances or formal access approvals, all volale
informaon storage components w
(b) Develop and implement [Assignment: organizaon-deﬁned alternate controls] in the
event a system component cannot be sanized, removed, or disconnected from the
system.
Discussion: Procedures for individuals who lack appropriate security clearances or who are
not U.S. cizens are intended to deny visual and electronic access to classiﬁed or controlled
unclassiﬁed informaon contained on organizaonal systems. Procedures for the use of
maintenance personnel can be documented in security plans for the systems.
Related controls: MP-6, PL-2.
(2) MAINTENANCE PERSONNEL | SECURITY CLEARANCES FOR CLASSIFIED SYSTEMS
Verify that personnel performing maintenance and diagnosc acvies on a system
processing, storing, or transming classiﬁed informaon possess security clearances and
formal access approvals for at least the highest classiﬁcaon level and for compartments of
informaon on the system.
Discussion: Personnel who conduct maintenance on organizaonal systems may be exposed to
classiﬁed informaon during the course of their maintenance acvies. To migate the inherent
risk of such exposure, organizaons use maintenance personnel that are cleared (i.e., possess
security clearances) to the classiﬁcaon level of the informaon stored on the system.
Related control: PS-3.
(3) MAINTENANCE PERSONNEL | CITIZENSHIP REQUIREMENTS FOR CLASSIFIED SYSTEMS
Verify that personnel performing maintenance and diagnosc acvies on a system
processing, storing, or transming classiﬁed informaon are U.S. cizens.
Discussion: Personnel who conduct maintenance on organizaonal systems may be exposed to
classiﬁed informaon during the course of their maintenance acvies. If access to classiﬁed
informaon on organizaonal systems is restricted to U.S. cizens, the same restricon is applied
to personnel performing maintenance on those systems.
Related control: PS-3.
This document is produced from OSCAL source data
FAMILY: MA PAGE 156NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(4) MAINTENANCE PERSONNEL | FOREIGN NATIONALS
Ensure that:
(a) Foreign naonals with appropriate security clearances are used to conduct maintenance
and diagnosc acvies on classiﬁed systems only when the systems are jointly owned
and operated by the United States and foreign allied governments, or owned and
operated solely by foreign allied governments; and
(b) Approvals, consents, and detailed operaonal condions regarding the use of foreign
naonals to conduct maintenance and diagnosc acvies on classiﬁed systems are fully
documented within Memoranda of Agreements.
Discussion: Personnel who conduct maintenance and diagnosc acvies on organizaonal
systems may be exposed to classiﬁed informaon. If non-U.S. cizens are permied to perform
maintenance and diagnoscs acvies on classiﬁed systems, then addional veng is required
to ensure agreements and restricons are not being violated.
Related control: PS-3.
(5) MAINTENANCE PERSONNEL | NON-SYSTEM MAINTENANCE
Ensure that non-escorted personnel performing maintenance acvies not directly
associated with the system but in the physical proximity of the system, have required access
authorizaons.
Discussion: Personnel who perform maintenance acvies in other capacies not directly related
to the system include physical plant personnel and custodial personnel.
References: None
MA-6 TIMELY MAINTENANCE
Control: Obtain maintenance support and/or spare parts for [Assignment: organizaon-deﬁned system
components] within [Assignment: organizaon-deﬁned me period] of failure.
Discussion: Organizaons specify the system components that result in increased risk to organizaonal
operaons and assets, individuals, other organizaons, or the Naon when the funconality provided
by those components is not operaonal. Organizaonal acons to obtain maintenance support
include having appropriate contracts in place.
Related controls: CM-8, CP-2, CP-7, RA-7, SA-15, SI-13, SR-2, SR-3, SR-4.
(1) TIMELY MAINTENANCE | PREVENTIVE MAINTENANCE
Perform prevenve maintenance on [Assignment: organizaon-deﬁned system components]
at [Assignment: organizaon-deﬁned me intervals].
Discussion: Prevenve maintenance includes proacve care and the servicing of system
components to maintain organizaonal equipment and facilies in sasfactory operang
condion. Such maintenance provides for the systemac inspecon, tests, measurements,
adjustments, parts replacement, detecon, and correcon of incipient failures either before they
occur or before they develop into major defects. The primary goal of prevenve maintenance
is to avoid or migate the consequences of equipment failures. Prevenve maintenance
is designed to preserve and restore equipment reliability by replacing worn components
before they fail. Methods of determining what prevenve (or other) failure management
policies to apply include original equipment manufacturer recommendaons; stascal failure
This document is produced from OSCAL source data
FAMILY: MA PAGE 157NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
records; expert opinion; maintenance that has already been conducted on similar equipment;
requirements of codes, laws, or regulaons within a jurisdicon; or measured values and
performance indicaons.
(2) TIMELY MAINTENANCE | PREDICTIVE MAINTENANCE
Perform predicve maintenance on [Assignment: organizaon-deﬁned system components] at
[Assignment: organizaon-deﬁned me intervals].
Discussion: Predicve maintenance evaluates the condion of equipment by performing periodic
or connuous (online) equipment condion monitoring. The goal of predicve maintenance
is to perform maintenance at a scheduled me when the maintenance acvity is most cost-
eﬀecve and before the equipment loses performance within a threshold. The predicve
component of predicve maintenance stems from the objecve of predicng the future trend
of the equipment's condion. The predicve maintenance approach employs principles of
stascal process control to determine at what point in the future maintenance acvies will
be appropriate. Most predicve maintenance inspecons are performed while equipment is in
service, thus minimizing disrupon of normal system operaons. Predicve maintenance can
result in substanal cost savings and higher system reliability.
(3) TIMELY MAINTENANCE | AUTOMATED SUPPORT FOR PREDICTIVE MAINTENANCE
Transfer predicve maintenance data to a maintenance management system using
[Assignment: organizaon-deﬁned automated mechanisms].
Discussion: A computerized maintenance management system maintains a database of
informaon about the maintenance operaons of organizaons and automates the processing
of equipment condion data to trigger maintenance planning, execuon, and reporng.
References: None
MA-7 FIELD MAINTENANCE
Control: Restrict or prohibit ﬁeld maintenance on [Assignment: organizaon-deﬁned systems or system
components] to [Assignment: organizaon-deﬁned trusted maintenance facilies].
Discussion: Field maintenance is the type of maintenance conducted on a system or system component
aer the system or component has been deployed to a speciﬁc site (i.e., operaonal environment).
In certain instances, ﬁeld maintenance (i.e., local maintenance at the site) may not be executed
with the same degree of rigor or with the same quality control checks as depot maintenance. For
crical systems designated as such by the organizaon, it may be necessary to restrict or prohibit ﬁeld
maintenance at the local site and require that such maintenance be conducted in trusted facilies
with addional controls.
Related controls: MA-2, MA-4, MA-5.
References: None
This document is produced from OSCAL source data
FAMILY: MA PAGE 158NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
FAMILY: MEDIA PROTECTION
MP-1 POLICY AND PROCEDURES
Control:
a. Develop, document, and disseminate to [Assignment: organizaon-deﬁned personnel or roles]:
1. [Selecon (one or more): Organizaon-level; Mission/business process-level; System-level]
media protecon policy that:
(a) Addresses purpose, scope, roles, responsibilies, management commitment,
coordinaon among organizaonal enes, and compliance; and
(b) Is consistent with applicable laws, execuve orders, direcves, regulaons, policies,
standards, and guidelines; and
2. Procedures to facilitate the implementaon of the media protecon policy and the
associated media protecon controls;
b. Designate an [Assignment: organizaon-deﬁned oﬃcial] to manage the development,
documentaon, and disseminaon of the media protecon policy and procedures; and
c. Review and update the current media protecon:
1. Policy [Assignment: organizaon-deﬁned frequency] and following [Assignment:
organizaon-deﬁned events]; and
2. Procedures [Assignment: organizaon-deﬁned frequency] and following [Assignment:
organizaon-deﬁned events].
Discussion: Media protecon policy and procedures address the controls in the MP family that are
implemented within systems and organizaons. The risk management strategy is an important
factor in establishing such policies and procedures. Policies and procedures contribute to security
and privacy assurance. Therefore, it is important that security and privacy programs collaborate on
the development of media protecon policy and procedures. Security and privacy program policies
and procedures at the organizaon level are preferable, in general, and may obviate the need for
mission- or system-speciﬁc policies and procedures. The policy can be included as part of the general
security and privacy policy or be represented by mulple policies that reﬂect the complex nature
of organizaons. Procedures can be established for security and privacy programs, for mission or
business processes, and for systems, if needed. Procedures describe how the policies or controls
are implemented and can be directed at the individual or role that is the object of the procedure.
Procedures can be documented in system security and privacy plans or in one or more separate
documents. Events that may precipitate an update to media protecon policy and procedures include
assessment or audit ﬁndings, security incidents or breaches, or changes in applicable laws, execuve
orders, direcves, regulaons, policies, standards, and guidelines. Simply restang controls does not
constute an organizaonal policy or procedure.
Related controls: PM-9, PS-8, SI-12.
References: [OMB A-130], [SP 800-100], [SP 800-12], [SP 800-30], [SP 800-39]
MP-2 MEDIA ACCESS
Control: Restrict access to [Assignment: organizaon-deﬁned types of digital and/or non-digital media]
to [Assignment: organizaon-deﬁned personnel or roles].
Discussion: System media includes digital and non-digital media. Digital media includes ﬂash drives,
diskees, magnec tapes, external or removable hard disk drives (e.g., solid state, magnec), compact
This document is produced from OSCAL source data
FAMILY: MP PAGE 159NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
discs, and digital versale discs. Non-digital media includes paper and microﬁlm. Denying access to
paent medical records in a community hospital unless the individuals seeking access to such records
are authorized healthcare providers is an example of restricng access to non-digital media. Liming
access to the design speciﬁcaons stored on compact discs in the media library to individuals on the
system development team is an example of restricng access to digital media.
Related controls: AC-19, AU-9, CP-2, CP-9, CP-10, MA-5, MP-4, MP-6, PE-2, PE-3, SC-12, SC-13, SC-34,
SI-12.
(1) MEDIA ACCESS | AUTOMATED RESTRICTED ACCESS
[Withdrawn: Incorporated into MP-4(2).]
(2) MEDIA ACCESS | CRYPTOGRAPHIC PROTECTION
[Withdrawn: Incorporated into SC-28(1).]
References: [FIPS 199], [OMB A-130], [SP 800-111]
MP-3 MEDIA MARKING
Control:
a. Mark system media indicang the distribuon limitaons, handling caveats, and applicable
security markings (if any) of the informaon; and
b. Exempt [Assignment: organizaon-deﬁned types of system media] from marking if the media
remain within [Assignment: organizaon-deﬁned controlled areas].
Discussion: Security marking refers to the applicaon or use of human-readable security aributes.
Digital media includes diskees, magnec tapes, external or removable hard disk drives (e.g., solid
state, magnec), ﬂash drives, compact discs, and digital versale discs. Non-digital media includes
paper and microﬁlm. Controlled unclassiﬁed informaon is deﬁned by the Naonal Archives and
Records Administraon along with the appropriate safeguarding and disseminaon requirements
for such informaon and is codiﬁed in 32 CFR 2002. Security markings are generally not required
for media that contains informaon determined by organizaons to be in the public domain or to
be publicly releasable. Some organizaons may require markings for public informaon indicang
that the informaon is publicly releasable. System media marking reﬂects applicable laws, execuve
orders, direcves, policies, regulaons, standards, and guidelines.
Related controls: AC-16, CP-9, MP-5, PE-22, SI-12.
References: [32 CFR 2002], [EO 13556], [FIPS 199]
MP-4 MEDIA STORAGE
Control:
a. Physically control and securely store [Assignment: organizaon-deﬁned types of digital and/or
non-digital media] within [Assignment: organizaon-deﬁned controlled areas]; and
b. Protect system media types deﬁned in MP-4a unl the media are destroyed or sanized using
approved equipment, techniques, and procedures.
Discussion: System media includes digital and non-digital media. Digital media includes ﬂash drives,
diskees, magnec tapes, external or removable hard disk drives (e.g., solid state, magnec), compact
discs, and digital versale discs. Non-digital media includes paper and microﬁlm. Physically controlling
stored media includes conducng inventories, ensuring procedures are in place to allow individuals
This document is produced from OSCAL source data
FAMILY: MP PAGE 160NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
to check out and return media to the library, and maintaining accountability for stored media. Secure
storage includes a locked drawer, desk, or cabinet or a controlled media library. The type of media
storage is commensurate with the security category or classiﬁcaon of the informaon on the media.
Controlled areas are spaces that provide physical and procedural controls to meet the requirements
established for protecng informaon and systems. Fewer controls may be needed for media that
contains informaon determined to be in the public domain, publicly releasable, or have limited
adverse impacts on organizaons, operaons, or individuals if accessed by other than authorized
personnel. In these situaons, physical access controls provide adequate protecon.
Related controls: AC-19, CP-2, CP-6, CP-9, CP-10, MP-2, MP-7, PE-3, PL-2, SC-12, SC-13, SC-28, SC-34,
SI-12.
(1) MEDIA STORAGE | CRYPTOGRAPHIC PROTECTION
[Withdrawn: Incorporated into SC-28(1).]
(2) MEDIA STORAGE | AUTOMATED RESTRICTED ACCESS
Restrict access to media storage areas and log access aempts and access granted using
[Assignment: organizaon-deﬁned automated mechanisms].
Discussion: Automated mechanisms include keypads, biometric readers, or card readers on the
external entries to media storage areas.
Related controls: AC-3, AU-2, AU-6, AU-9, AU-12, PE-3.
References: [FIPS 199], [SP 800-111], [SP 800-56A], [SP 800-56B], [SP 800-56C], [SP 800-57-1], [SP
800-57-2], [SP 800-57-3]
MP-5 MEDIA TRANSPORT
Control:
a. Protect and control [Assignment: organizaon-deﬁned types of system media] during transport
outside of controlled areas using [Assignment: organizaon-deﬁned controls];
b. Maintain accountability for system media during transport outside of controlled areas;
c. Document acvies associated with the transport of system media; and
d. Restrict the acvies associated with the transport of system media to authorized personnel.
Discussion: System media includes digital and non-digital media. Digital media includes ﬂash drives,
diskees, magnec tapes, external or removable hard disk drives (e.g., solid state and magnec),
compact discs, and digital versale discs. Non-digital media includes microﬁlm and paper. Controlled
areas are spaces for which organizaons provide physical or procedural controls to meet requirements
established for protecng informaon and systems. Controls to protect media during transport
include cryptography and locked containers. Cryptographic mechanisms can provide conﬁdenality
and integrity protecons depending on the mechanisms implemented. Acvies associated with
media transport include releasing media for transport, ensuring that media enters the appropriate
transport processes, and the actual transport. Authorized transport and courier personnel may
include individuals external to the organizaon. Maintaining accountability of media during transport
includes restricng transport acvies to authorized personnel and tracking and/or obtaining records
of transport acvies as the media moves through the transportaon system to prevent and detect
loss, destrucon, or tampering. Organizaons establish documentaon requirements for acvies
associated with the transport of system media in accordance with organizaonal assessments of risk.
This document is produced from OSCAL source data
FAMILY: MP PAGE 161NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
Organizaons maintain the ﬂexibility to deﬁne record-keeping methods for the diﬀerent types of
media transport as part of a system of transport-related records.
Related controls: AC-7, AC-19, CP-2, CP-9, MP-3, MP-4, PE-16, PL-2, SC-12, SC-13, SC-28, SC-34.
(1) MEDIA TRANSPORT | PROTECTION OUTSIDE OF CONTROLLED AREAS
[Withdrawn: Incorporated into MP-5.]
(2) MEDIA TRANSPORT | DOCUMENTATION OF ACTIVITIES
[Withdrawn: Incorporated into MP-5.]
(3) MEDIA TRANSPORT | CUSTODIANS
Employ an idenﬁed custodian during transport of system media outside of controlled areas.
Discussion: Idenﬁed custodians provide organizaons with speciﬁc points of contact during the
media transport process and facilitate individual accountability. Custodial responsibilies can be
transferred from one individual to another if an unambiguous custodian is idenﬁed.
(4) MEDIA TRANSPORT | CRYPTOGRAPHIC PROTECTION
[Withdrawn: Incorporated into SC-28(1).]
References: [FIPS 199], [SP 800-60-1], [SP 800-60-2]
MP-6 MEDIA SANITIZATION
Control:
a. Sanize [Assignment: organizaon-deﬁned system media] prior to disposal, release out of
organizaonal control, or release for reuse using [Assignment: organizaon-deﬁned sanizaon
techniques and procedures]; and
b. Employ sanizaon mechanisms with the strength and integrity commensurate with the security
category or classiﬁcaon of the informaon.
Discussion: Media sanizaon applies to all digital and non-digital system media subject to disposal or
reuse, whether or not the media is considered removable. Examples include digital media in scanners,
copiers, printers, notebook computers, workstaons, network components, mobile devices, and
non-digital media (e.g., paper and microﬁlm). The sanizaon process removes informaon from
system media such that the informaon cannot be retrieved or reconstructed. Sanizaon techniques
—including clearing, purging, cryptographic erase, de-idenﬁcaon of personally idenﬁable
informaon, and destrucon—prevent the disclosure of informaon to unauthorized individuals
when such media is reused or released for disposal. Organizaons determine the appropriate
sanizaon methods, recognizing that destrucon is somemes necessary when other methods
cannot be applied to media requiring sanizaon. Organizaons use discreon on the employment
of approved sanizaon techniques and procedures for media that contains informaon deemed to
be in the public domain or publicly releasable or informaon deemed to have no adverse impact on
organizaons or individuals if released for reuse or disposal. Sanizaon of non-digital media includes
destrucon, removing a classiﬁed appendix from an otherwise unclassiﬁed document, or redacng
selected secons or words from a document by obscuring the redacted secons or words in a manner
equivalent in eﬀecveness to removing them from the document. NSA standards and policies control
the sanizaon process for media that contains classiﬁed informaon. NARA policies control the
sanizaon process for controlled unclassiﬁed informaon.
This document is produced from OSCAL source data
FAMILY: MP PAGE 162NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
Related controls: AC-3, AC-7, AU-11, MA-2, MA-3, MA-4, MA-5, PM-22, SI-12, SI-18, SI-19, SR-11.
(1) MEDIA SANITIZATION | REVIEW, APPROVE, TRACK, DOCUMENT, AND VERIFY
Review, approve, track, document, and verify media sanizaon and disposal acons.
Discussion: Organizaons review and approve media to be sanized to ensure compliance with
records retenon policies. Tracking and documenng acons include lisng personnel who
reviewed and approved sanizaon and disposal acons, types of media sanized, ﬁles stored
on the media, sanizaon methods used, date and me of the sanizaon acons, personnel
who performed the sanizaon, veriﬁcaon acons taken and personnel who performed the
veriﬁcaon, and the disposal acons taken. Organizaons verify that the sanizaon of the
media was eﬀecve prior to disposal.
(2) MEDIA SANITIZATION | EQUIPMENT TESTING
Test sanizaon equipment and procedures [Assignment: organizaon-deﬁned frequency] to
ensure that the intended sanizaon is being achieved.
Discussion: Tesng of sanizaon equipment and procedures may be conducted by qualiﬁed and
authorized external enes, including federal agencies or external service providers.
(3) MEDIA SANITIZATION | NONDESTRUCTIVE TECHNIQUES
Apply nondestrucve sanizaon techniques to portable storage devices prior to connecng
such devices to the system under the following circumstances: [Assignment: organizaon-
deﬁned circumstances requiring sanizaon of portable storage devices].
Discussion: Portable storage devices include external or removable hard disk drives (e.g., solid
state, magnec), opcal discs, magnec or opcal tapes, ﬂash memory devices, ﬂash memory
cards, and other external or removable disks. Portable storage devices can be obtained from
untrustworthy sources and contain malicious code that can be inserted into or transferred
to organizaonal systems through USB ports or other entry portals. While scanning storage
devices is recommended, sanizaon provides addional assurance that such devices are free of
malicious code. Organizaons consider nondestrucve sanizaon of portable storage devices
when the devices are purchased from manufacturers or vendors prior to inial use or when
organizaons cannot maintain a posive chain of custody for the devices.
(4) MEDIA SANITIZATION | CONTROLLED UNCLASSIFIED INFORMATION
[Withdrawn: Incorporated into MP-6.]
(5) MEDIA SANITIZATION | CLASSIFIED INFORMATION
[Withdrawn: Incorporated into MP-6.]
(6) MEDIA SANITIZATION | MEDIA DESTRUCTION
[Withdrawn: Incorporated into MP-6.]
This document is produced from OSCAL source data
FAMILY: MP PAGE 163NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(7) MEDIA SANITIZATION | DUAL AUTHORIZATION
Enforce dual authorizaon for the sanizaon of [Assignment: organizaon-deﬁned system
media].
Discussion: Organizaons employ dual authorizaon to help ensure that system media
sanizaon cannot occur unless two technically qualiﬁed individuals conduct the designated
task. Individuals who sanize system media possess suﬃcient skills and experse to determine
if the proposed sanizaon reﬂects applicable federal and organizaonal standards, policies,
and procedures. Dual authorizaon also helps to ensure that sanizaon occurs as intended,
protecng against errors and false claims of having performed the sanizaon acons. Dual
authorizaon may also be known as two-person control. To reduce the risk of collusion,
organizaons consider rotang dual authorizaon dues to other individuals.
Related controls: AC-3, MP-2.
(8) MEDIA SANITIZATION | REMOTE PURGING OR WIPING OF INFORMATION
Provide the capability to purge or wipe informaon from [Assignment: organizaon-deﬁned
systems or system components] [Selecon: remotely; under the following condions:
[Assignment: organizaon-deﬁned condions]].
Discussion: Remote purging or wiping of informaon protects informaon on organizaonal
systems and system components if systems or components are obtained by unauthorized
individuals. Remote purge or wipe commands require strong authencaon to help migate
the risk of unauthorized individuals purging or wiping the system, component, or device. The
purge or wipe funcon can be implemented in a variety of ways, including by overwring data or
informaon mulple mes or by destroying the key necessary to decrypt encrypted data.
References: [32 CFR 2002], [FIPS 199], [IR 8023], [NARA CUI], [NSA MEDIA], [OMB A-130], [SP 800-124],
[SP 800-60-1], [SP 800-60-2], [SP 800-88]
MP-7 MEDIA USE
Control:
a. [Selecon: Restrict; Prohibit] the use of [Assignment: organizaon-deﬁned types of system
media] on [Assignment: organizaon-deﬁned systems or system components] using [Assignment:
organizaon-deﬁned controls]; and
b. Prohibit the use of portable storage devices in organizaonal systems when such devices have no
idenﬁable owner.
Discussion: System media includes both digital and non-digital media. Digital media includes diskees,
magnec tapes, ﬂash drives, compact discs, digital versale discs, and removable hard disk drives.
Non-digital media includes paper and microﬁlm. Media use protecons also apply to mobile devices
with informaon storage capabilies. In contrast to MP-2, which restricts user access to media, MP-7
restricts the use of certain types of media on systems, for example, restricng or prohibing the use
of ﬂash drives or external hard disk drives. Organizaons use technical and nontechnical controls
to restrict the use of system media. Organizaons may restrict the use of portable storage devices,
for example, by using physical cages on workstaons to prohibit access to certain external ports or
disabling or removing the ability to insert, read, or write to such devices. Organizaons may also
limit the use of portable storage devices to only approved devices, including devices provided by the
organizaon, devices provided by other approved organizaons, and devices that are not personally
owned. Finally, organizaons may restrict the use of portable storage devices based on the type of
This document is produced from OSCAL source data
FAMILY: MP PAGE 164NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
device, such as by prohibing the use of writeable, portable storage devices and implemenng this
restricon by disabling or removing the capability to write to such devices. Requiring idenﬁable
owners for storage devices reduces the risk of using such devices by allowing organizaons to assign
responsibility for addressing known vulnerabilies in the devices.
Related controls: AC-19, AC-20, PL-4, PM-12, SC-34, SC-41.
(1) MEDIA USE | PROHIBIT USE WITHOUT OWNER
[Withdrawn: Incorporated into MP-7.]
(2) MEDIA USE | PROHIBIT USE OF SANITIZATION-RESISTANT MEDIA
Prohibit the use of sanizaon-resistant media in organizaonal systems.
Discussion: Sanizaon resistance refers to how resistant media are to non-destrucve
sanizaon techniques with respect to the capability to purge informaon from media. Certain
types of media do not support sanizaon commands, or if supported, the interfaces are not
supported in a standardized way across these devices. Sanizaon-resistant media includes
compact ﬂash, embedded ﬂash on boards and devices, solid state drives, and USB removable
media.
Related control: MP-6.
References: [FIPS 199], [SP 800-111]
MP-8 MEDIA DOWNGRADING
Control:
a. Establish [Assignment: organizaon-deﬁned system media downgrading process] that includes
employing downgrading mechanisms with strength and integrity commensurate with the
security category or classiﬁcaon of the informaon;
b. Verify that the system media downgrading process is commensurate with the security category
and/or classiﬁcaon level of the informaon to be removed and the access authorizaons of the
potenal recipients of the downgraded informaon;
c. Idenfy [Assignment: organizaon-deﬁned system media requiring downgrading]; and
d. Downgrade the idenﬁed system media using the established process.
Discussion: Media downgrading applies to digital and non-digital media subject to release outside
of the organizaon, whether the media is considered removable or not. When applied to system
media, the downgrading process removes informaon from the media, typically by security category
or classiﬁcaon level, such that the informaon cannot be retrieved or reconstructed. Downgrading of
media includes redacng informaon to enable wider release and distribuon. Downgrading ensures
that empty space on the media is devoid of informaon.
(1) MEDIA DOWNGRADING | DOCUMENTATION OF PROCESS
Document system media downgrading acons.
Discussion: Organizaons can document the media downgrading process by providing
informaon, such as the downgrading technique employed, the idenﬁcaon number of the
downgraded media, and the identy of the individual that authorized and/or performed the
downgrading acon.
This document is produced from OSCAL source data
FAMILY: MP PAGE 165NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(2) MEDIA DOWNGRADING | EQUIPMENT TESTING
Test downgrading equipment and procedures [Assignment: organizaon-deﬁned frequency] to
ensure that downgrading acons are being achieved.
Discussion: None.
(3) MEDIA DOWNGRADING | CONTROLLED UNCLASSIFIED INFORMATION
Downgrade system media containing controlled unclassiﬁed informaon prior to public
release.
Discussion: The downgrading of controlled unclassiﬁed informaon uses approved sanizaon
tools, techniques, and procedures.
(4) MEDIA DOWNGRADING | CLASSIFIED INFORMATION
Downgrade system media containing classiﬁed informaon prior to release to individuals
without required access authorizaons.
Discussion: Downgrading of classiﬁed informaon uses approved sanizaon tools, techniques,
and procedures to transfer informaon conﬁrmed to be unclassiﬁed from classiﬁed systems to
unclassiﬁed media.
References: [32 CFR 2002], [NSA MEDIA]
This document is produced from OSCAL source data
FAMILY: MP PAGE 166NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
FAMILY: PHYSICAL AND ENVIRONMENTAL PROTECTION
PE-1 POLICY AND PROCEDURES
Control:
a. Develop, document, and disseminate to [Assignment: organizaon-deﬁned personnel or roles]:
1. [Selecon (one or more): Organizaon-level; Mission/business process-level; System-level]
physical and environmental protecon policy that:
(a) Addresses purpose, scope, roles, responsibilies, management commitment,
coordinaon among organizaonal enes, and compliance; and
(b) Is consistent with applicable laws, execuve orders, direcves, regulaons, policies,
standards, and guidelines; and
2. Procedures to facilitate the implementaon of the physical and environmental protecon
policy and the associated physical and environmental protecon controls;
b. Designate an [Assignment: organizaon-deﬁned oﬃcial] to manage the development,
documentaon, and disseminaon of the physical and environmental protecon policy and
procedures; and
c. Review and update the current physical and environmental protecon:
1. Policy [Assignment: organizaon-deﬁned frequency] and following [Assignment:
organizaon-deﬁned events]; and
2. Procedures [Assignment: organizaon-deﬁned frequency] and following [Assignment:
organizaon-deﬁned events].
Discussion: Physical and environmental protecon policy and procedures address the controls in the
PE family that are implemented within systems and organizaons. The risk management strategy is
an important factor in establishing such policies and procedures. Policies and procedures contribute
to security and privacy assurance. Therefore, it is important that security and privacy programs
collaborate on the development of physical and environmental protecon policy and procedures.
Security and privacy program policies and procedures at the organizaon level are preferable, in
general, and may obviate the need for mission- or system-speciﬁc policies and procedures. The policy
can be included as part of the general security and privacy policy or be represented by mulple
policies that reﬂect the complex nature of organizaons. Procedures can be established for security
and privacy programs, for mission or business processes, and for systems, if needed. Procedures
describe how the policies or controls are implemented and can be directed at the individual or role
that is the object of the procedure. Procedures can be documented in system security and privacy
plans or in one or more separate documents. Events that may precipitate an update to physical
and environmental protecon policy and procedures include assessment or audit ﬁndings, security
incidents or breaches, or changes in applicable laws, execuve orders, direcves, regulaons, policies,
standards, and guidelines. Simply restang controls does not constute an organizaonal policy or
procedure.
Related controls: AT-3, PM-9, PS-8, SI-12.
References: [SP 800-100], [SP 800-12], [SP 800-30], [SP 800-39]
This document is produced from OSCAL source data
FAMILY: PE PAGE 167NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
PE-2 PHYSICAL ACCESS AUTHORIZATIONS
Control:
a. Develop, approve, and maintain a list of individuals with authorized access to the facility where
the system resides;
b. Issue authorizaon credenals for facility access;
c. Review the access list detailing authorized facility access by individuals [Assignment:
organizaon-deﬁned frequency]; and
d. Remove individuals from the facility access list when access is no longer required.
Discussion: Physical access authorizaons apply to employees and visitors. Individuals with permanent
physical access authorizaon credenals are not considered visitors. Authorizaon credenals
include ID badges, idenﬁcaon cards, and smart cards. Organizaons determine the strength
of authorizaon credenals needed consistent with applicable laws, execuve orders, direcves,
regulaons, policies, standards, and guidelines. Physical access authorizaons may not be necessary
to access certain areas within facilies that are designated as publicly accessible.
Related controls: AT-3, AU-9, IA-4, MA-5, MP-2, PE-3, PE-4, PE-5, PE-8, PM-12, PS-3, PS-4, PS-5, PS-6.
(1) PHYSICAL ACCESS AUTHORIZATIONS | ACCESS BY POSITION OR ROLE
Authorize physical access to the facility where the system resides based on posion or role.
Discussion: Role-based facility access includes access by authorized permanent and regular/
roune maintenance personnel, duty oﬃcers, and emergency medical staﬀ.
Related controls: AC-2, AC-3, AC-6.
(2) PHYSICAL ACCESS AUTHORIZATIONS | TWO FORMS OF IDENTIFICATION
Require two forms of idenﬁcaon from the following forms of idenﬁcaon for visitor access
to the facility where the system resides: [Assignment: organizaon-deﬁned list of acceptable
forms of idenﬁcaon].
Discussion: Acceptable forms of idenﬁcaon include passports, REAL ID-compliant drivers’
licenses, and Personal Identy Veriﬁcaon (PIV) cards. For gaining access to facilies using
automated mechanisms, organizaons may use PIV cards, key cards, PINs, and biometrics.
Related controls: IA-2, IA-4, IA-5.
(3) PHYSICAL ACCESS AUTHORIZATIONS | RESTRICT UNESCORTED ACCESS
Restrict unescorted access to the facility where the system resides to personnel with [Selecon
(one or more): security clearances for all informaon contained within the system; formal
access authorizaons for all informaon contained within the system; need for access to all
informaon contained within the system; [Assignment: organizaon-deﬁned physical access
authorizaons]].
Discussion: Individuals without required security clearances, access approvals, or need to know
are escorted by individuals with appropriate physical access authorizaons to ensure that
informaon is not exposed or otherwise compromised.
Related controls: PS-2, PS-6.
References: [FIPS 201-2], [SP 800-73-4], [SP 800-76-2], [SP 800-78-4]
This document is produced from OSCAL source data
FAMILY: PE PAGE 168NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
PE-3 PHYSICAL ACCESS CONTROL
Control:
a. Enforce physical access authorizaons at [Assignment: organizaon-deﬁned entry and exit points
to the facility where the system resides] by:
1. Verifying individual access authorizaons before granng access to the facility; and
2. Controlling ingress and egress to the facility using [Selecon (one or more): [Assignment:
organizaon-deﬁned physical access control systems or devices]; guards];
b. Maintain physical access audit logs for [Assignment: organizaon-deﬁned entry or exit points];
c. Control access to areas within the facility designated as publicly accessible by implemenng the
following controls: [Assignment: organizaon-deﬁned physical access controls];
d. Escort visitors and control visitor acvity [Assignment: organizaon-deﬁned circumstances
requiring visitor escorts and control of visitor acvity];
e. Secure keys, combinaons, and other physical access devices;
f. Inventory [Assignment: organizaon-deﬁned physical access devices] every [Assignment:
organizaon-deﬁned frequency]; and
g. Change combinaons and keys [Assignment: organizaon-deﬁned frequency] and/or when
keys are lost, combinaons are compromised, or when individuals possessing the keys or
combinaons are transferred or terminated.
Discussion: Physical access control applies to employees and visitors. Individuals with permanent
physical access authorizaons are not considered visitors. Physical access controls for publicly
accessible areas may include physical access control logs/records, guards, or physical access devices
and barriers to prevent movement from publicly accessible areas to non-public areas. Organizaons
determine the types of guards needed, including professional security staﬀ, system users, or
administrave staﬀ. Physical access devices include keys, locks, combinaons, biometric readers,
and card readers. Physical access control systems comply with applicable laws, execuve orders,
direcves, policies, regulaons, standards, and guidelines. Organizaons have ﬂexibility in the types
of audit logs employed. Audit logs can be procedural, automated, or some combinaon thereof.
Physical access points can include facility access points, interior access points to systems that require
supplemental access controls, or both. Components of systems may be in areas designated as publicly
accessible with organizaons controlling access to the components.
Related controls: AT-3, AU-2, AU-6, AU-9, AU-13, CP-10, IA-3, IA-8, MA-5, MP-2, MP-4, PE-2, PE-4, PE-5,
PE-8, PS-2, PS-3, PS-6, PS-7, RA-3, SC-28, SI-4, SR-3.
(1) PHYSICAL ACCESS CONTROL | SYSTEM ACCESS
Enforce physical access authorizaons to the system in addion to the physical access controls
for the facility at [Assignment: organizaon-deﬁned physical spaces containing one or more
components of the system].
Discussion: Control of physical access to the system provides addional physical security for those
areas within facilies where there is a concentraon of system components.
This document is produced from OSCAL source data
FAMILY: PE PAGE 169NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(2) PHYSICAL ACCESS CONTROL | FACILITY AND SYSTEMS
Perform security checks [Assignment: organizaon-deﬁned frequency] at the physical
perimeter of the facility or system for exﬁltraon of informaon or removal of system
components.
Discussion: Organizaons determine the extent, frequency, and/or randomness of security checks
to adequately migate risk associated with exﬁltraon.
Related controls: AC-4, SC-7.
(3) PHYSICAL ACCESS CONTROL | CONTINUOUS GUARDS
Employ guards to control [Assignment: organizaon-deﬁned physical access points] to the
facility where the system resides 24 hours per day, 7 days per week.
Discussion: Employing guards at selected physical access points to the facility provides a more
rapid response capability for organizaons. Guards also provide the opportunity for human
surveillance in areas of the facility not covered by video surveillance.
Related controls: CP-6, CP-7, PE-6.
(4) PHYSICAL ACCESS CONTROL | LOCKABLE CASINGS
Use lockable physical casings to protect [Assignment: organizaon-deﬁned system
components] from unauthorized physical access.
Discussion: The greatest risk from the use of portable devices—such as smart phones, tablets,
and notebook computers—is the. Organizaons can employ lockable, physical casings to
reduce or eliminate the risk of equipment the. Such casings come in a variety of sizes, from
units that protect a single notebook computer to full cabinets that can protect mulple servers,
computers, and peripherals. Lockable physical casings can be used in conjuncon with cable
locks or lockdown plates to prevent the the of the locked casing containing the computer
equipment.
(5) PHYSICAL ACCESS CONTROL | TAMPER PROTECTION
Employ [Assignment: organizaon-deﬁned an-tamper technologies] to [Selecon (one or
more): detect; prevent] physical tampering or alteraon of [Assignment: organizaon-deﬁned
hardware components] within the system.
Discussion: Organizaons can implement tamper detecon and prevenon at selected hardware
components or implement tamper detecon at some components and tamper prevenon at
other components. Detecon and prevenon acvies can employ many types of an-tamper
technologies, including tamper-detecon seals and an-tamper coangs. An-tamper programs
help to detect hardware alteraons through counterfeing and other supply chain-related risks.
Related controls: SA-16, SR-9, SR-11.
(6) PHYSICAL ACCESS CONTROL | FACILITY PENETRATION TESTING
[Withdrawn: Incorporated into CA-8.]
This document is produced from OSCAL source data
FAMILY: PE PAGE 170NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(7) PHYSICAL ACCESS CONTROL | PHYSICAL BARRIERS
Limit access using physical barriers.
Discussion: Physical barriers include bollards, concrete slabs, jersey walls, and hydraulic acve
vehicle barriers.
(8) PHYSICAL ACCESS CONTROL | ACCESS CONTROL VESTIBULES
Employ access control vesbules at [Assignment: organizaon-deﬁned locaons within the
facility].
Discussion: An access control vesbule is part of a physical access control system that typically
provides a space between two sets of interlocking doors. Vesbules are designed to prevent
unauthorized individuals from following authorized individuals into facilies with controlled
access. This acvity, also known as piggybacking or tailgang, results in unauthorized access
to the facility. Interlocking door controllers can be used to limit the number of individuals who
enter controlled access points and to provide containment areas while authorizaon for physical
access is veriﬁed. Interlocking door controllers can be fully automated (i.e., controlling the
opening and closing of the doors) or parally automated (i.e., using security guards to control
the number of individuals entering the containment area).
References: [FIPS 201-2], [SP 800-116], [SP 800-73-4], [SP 800-76-2], [SP 800-78-4]
PE-4 ACCESS CONTROL FOR TRANSMISSION
Control: Control physical access to [Assignment: organizaon-deﬁned system distribuon and
transmission lines] within organizaonal facilies using [Assignment: organizaon-deﬁned security
controls].
Discussion: Security controls applied to system distribuon and transmission lines prevent accidental
damage, disrupon, and physical tampering. Such controls may also be necessary to prevent
eavesdropping or modiﬁcaon of unencrypted transmissions. Security controls used to control
physical access to system distribuon and transmission lines include disconnected or locked spare
jacks, locked wiring closets, protecon of cabling by conduit or cable trays, and wiretapping sensors.
Related controls: AT-3, IA-4, MP-2, MP-4, PE-2, PE-3, PE-5, PE-9, SC-7, SC-8.
References: None
PE-5 ACCESS CONTROL FOR OUTPUT DEVICES
Control: Control physical access to output from [Assignment: organizaon-deﬁned output devices] to
prevent unauthorized individuals from obtaining the output.
Discussion: Controlling physical access to output devices includes placing output devices in locked
rooms or other secured areas with keypad or card reader access controls and allowing access to
authorized individuals only, placing output devices in locaons that can be monitored by personnel,
installing monitor or screen ﬁlters, and using headphones. Examples of output devices include
monitors, printers, scanners, audio devices, facsimile machines, and copiers.
Related controls: PE-2, PE-3, PE-4, PE-18.
(1) ACCESS CONTROL FOR OUTPUT DEVICES | ACCESS TO OUTPUT BY AUTHORIZED
INDIVIDUALS
[Withdrawn: Incorporated into PE-5.]
This document is produced from OSCAL source data
FAMILY: PE PAGE 171NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(2) ACCESS CONTROL FOR OUTPUT DEVICES | LINK TO INDIVIDUAL IDENTITY
Link individual identy to receipt of output from output devices.
Discussion: Methods for linking individual identy to the receipt of output from output devices
include installing security funconality on facsimile machines, copiers, and printers. Such
funconality allows organizaons to implement authencaon on output devices prior to the
release of output to individuals.
(3) ACCESS CONTROL FOR OUTPUT DEVICES | MARKING OUTPUT DEVICES
[Withdrawn: Incorporated into PE-22.]
Reference: [IR 8023]
PE-6 MONITORING PHYSICAL ACCESS
Control:
a. Monitor physical access to the facility where the system resides to detect and respond to physical
security incidents;
b. Review physical access logs [Assignment: organizaon-deﬁned frequency] and upon occurrence
of [Assignment: organizaon-deﬁned events or potenal indicaons of events]; and
c. Coordinate results of reviews and invesgaons with the organizaonal incident response
capability.
Discussion: Physical access monitoring includes publicly accessible areas within organizaonal facilies.
Examples of physical access monitoring include the employment of guards, video surveillance
equipment (i.e., cameras), and sensor devices. Reviewing physical access logs can help idenfy
suspicious acvity, anomalous events, or potenal threats. The reviews can be supported by audit
logging controls, such as AU-2, if the access logs are part of an automated system. Organizaonal
incident response capabilies include invesgaons of physical security incidents and responses to
the incidents. Incidents include security violaons or suspicious physical access acvies. Suspicious
physical access acvies include accesses outside of normal work hours, repeated accesses to areas
not normally accessed, accesses for unusual lengths of me, and out-of-sequence accesses.
Related controls: AU-2, AU-6, AU-9, AU-12, CA-7, CP-10, IR-4, IR-8.
(1) MONITORING PHYSICAL ACCESS | INTRUSION ALARMS AND SURVEILLANCE EQUIPMENT
Monitor physical access to the facility where the system resides using physical intrusion alarms
and surveillance equipment.
Discussion: Physical intrusion alarms can be employed to alert security personnel when
unauthorized access to the facility is aempted. Alarm systems work in conjuncon with physical
barriers, physical access control systems, and security guards by triggering a response when
these other forms of security have been compromised or breached. Physical intrusion alarms can
include diﬀerent types of sensor devices, such as moon sensors, contact sensors, and broken
glass sensors. Surveillance equipment includes video cameras installed at strategic locaons
throughout the facility.
This document is produced from OSCAL source data
FAMILY: PE PAGE 172NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(2) MONITORING PHYSICAL ACCESS | AUTOMATED INTRUSION RECOGNITION AND
RESPONSES
Recognize [Assignment: organizaon-deﬁned classes or types of intrusions] and iniate
[Assignment: organizaon-deﬁned response acons] using [Assignment: organizaon-deﬁned
automated mechanisms].
Discussion: Response acons can include nofying selected organizaonal personnel or law
enforcement personnel. Automated mechanisms implemented to iniate response acons
include system alert noﬁcaons, email and text messages, and acvang door locking
mechanisms. Physical access monitoring can be coordinated with intrusion detecon systems
and system monitoring capabilies to provide integrated threat coverage for the organizaon.
Related control: SI-4.
(3) MONITORING PHYSICAL ACCESS | VIDEO SURVEILLANCE
(a) Employ video surveillance of [Assignment: organizaon-deﬁned operaonal areas];
(b) Review video recordings [Assignment: organizaon-deﬁned frequency]; and
(c) Retain video recordings for [Assignment: organizaon-deﬁned me period].
Discussion: Video surveillance focuses on recording acvity in speciﬁed areas for the purposes
of subsequent review, if circumstances so warrant. Video recordings are typically reviewed
to detect anomalous events or incidents. Monitoring the surveillance video is not required,
although organizaons may choose to do so. There may be legal consideraons when
performing and retaining video surveillance, especially if such surveillance is in a public locaon.
(4) MONITORING PHYSICAL ACCESS | MONITORING PHYSICAL ACCESS TO SYSTEMS
Monitor physical access to the system in addion to the physical access monitoring of
the facility at [Assignment: organizaon-deﬁned physical spaces containing one or more
components of the system].
Discussion: Monitoring physical access to systems provides addional monitoring for those
areas within facilies where there is a concentraon of system components, including server
rooms, media storage areas, and communicaons centers. Physical access monitoring can be
coordinated with intrusion detecon systems and system monitoring capabilies to provide
comprehensive and integrated threat coverage for the organizaon.
References: None
PE-7 Visitor Control
[Withdrawn: Incorporated into PE-2, PE-3.]
PE-8 VISITOR ACCESS RECORDS
Control:
a. Maintain visitor access records to the facility where the system resides for [Assignment:
organizaon-deﬁned me period];
b. Review visitor access records [Assignment: organizaon-deﬁned frequency]; and
c. Report anomalies in visitor access records to [Assignment: organizaon-deﬁned personnel].
This document is produced from OSCAL source data
FAMILY: PE PAGE 173NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
Discussion: Visitor access records include the names and organizaons of individuals vising, visitor
signatures, forms of idenﬁcaon, dates of access, entry and departure mes, purpose of visits,
and the names and organizaons of individuals visited. Access record reviews determine if access
authorizaons are current and are sll required to support organizaonal mission and business
funcons. Access records are not required for publicly accessible areas.
Related controls: PE-2, PE-3, PE-6.
(1) VISITOR ACCESS RECORDS | AUTOMATED RECORDS MAINTENANCE AND REVIEW
Maintain and review visitor access records using [Assignment: organizaon-deﬁned
automated mechanisms].
Discussion: Visitor access records may be stored and maintained in a database management
system that is accessible by organizaonal personnel. Automated access to such records
facilitates record reviews on a regular basis to determine if access authorizaons are current and
sll required to support organizaonal mission and business funcons.
(2) VISITOR ACCESS RECORDS | PHYSICAL ACCESS RECORDS
[Withdrawn: Incorporated into PE-2.]
(3) VISITOR ACCESS RECORDS | LIMIT PERSONALLY IDENTIFIABLE INFORMATION ELEMENTS
Limit personally idenﬁable informaon contained in visitor access records to the following
elements idenﬁed in the privacy risk assessment: [Assignment: organizaon-deﬁned
elements].
Discussion: Organizaons may have requirements that specify the contents of visitor access
records. Liming personally idenﬁable informaon in visitor access records when such
informaon is not needed for operaonal purposes helps reduce the level of privacy risk created
by a system.
Related controls: RA-3, SA-8.
References: None
PE-9 POWER EQUIPMENT AND CABLING
Control: Protect power equipment and power cabling for the system from damage and destrucon.
Discussion: Organizaons determine the types of protecon necessary for the power equipment and
cabling employed at diﬀerent locaons that are both internal and external to organizaonal facilies
and environments of operaon. Types of power equipment and cabling include internal cabling and
uninterruptable power sources in oﬃces or data centers, generators and power cabling outside of
buildings, and power sources for self-contained components such as satellites, vehicles, and other
deployable systems.
Related control: PE-4.
(1) POWER EQUIPMENT AND CABLING | REDUNDANT CABLING
Employ redundant power cabling paths that are physically separated by [Assignment:
organizaon-deﬁned distance].
Discussion: Physically separate and redundant power cables ensure that power connues to ﬂow
in the event that one of the cables is cut or otherwise damaged.
This document is produced from OSCAL source data
FAMILY: PE PAGE 174NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(2) POWER EQUIPMENT AND CABLING | AUTOMATIC VOLTAGE CONTROLS
Employ automac voltage controls for [Assignment: organizaon-deﬁned crical system
components].
Discussion: Automac voltage controls can monitor and control voltage. Such controls include
voltage regulators, voltage condioners, and voltage stabilizers.
References: None
PE-10 EMERGENCY SHUTOFF
Control:
a. Provide the capability of shung oﬀ power to [Assignment: organizaon-deﬁned system or
individual system components] in emergency situaons;
b. Place emergency shutoﬀ switches or devices in [Assignment: organizaon-deﬁned locaon by
system or system component] to facilitate access for authorized personnel; and
c. Protect emergency power shutoﬀ capability from unauthorized acvaon.
Discussion: Emergency power shutoﬀ primarily applies to organizaonal facilies that contain
concentraons of system resources, including data centers, mainframe computer rooms, server
rooms, and areas with computer-controlled machinery.
Related control: PE-15.
(1) EMERGENCY SHUTOFF | ACCIDENTAL AND UNAUTHORIZED ACTIVATION
[Withdrawn: Incorporated into PE-10.]
References: None
PE-11 EMERGENCY POWER
Control: Provide an uninterrupble power supply to facilitate [Selecon (one or more): an orderly
shutdown of the system; transion of the system to long-term alternate power] in the event of a
primary power source loss.
Discussion: An uninterrupble power supply (UPS) is an electrical system or mechanism that provides
emergency power when there is a failure of the main power source. A UPS is typically used to protect
computers, data centers, telecommunicaon equipment, or other electrical equipment where an
unexpected power disrupon could cause injuries, fatalies, serious mission or business disrupon,
or loss of data or informaon. A UPS diﬀers from an emergency power system or backup generator
in that the UPS provides near-instantaneous protecon from unancipated power interrupons from
the main power source by providing energy stored in baeries, supercapacitors, or ﬂywheels. The
baery duraon of a UPS is relavely short but provides suﬃcient me to start a standby power
source, such as a backup generator, or properly shut down the system.
Related controls: AT-3, CP-2, CP-7.
This document is produced from OSCAL source data
FAMILY: PE PAGE 175NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(1) EMERGENCY POWER | ALTERNATE POWER SUPPLY — MINIMAL OPERATIONAL
CAPABILITY
Provide an alternate power supply for the system that is acvated [Selecon: manually;
automacally] and that can maintain minimally required operaonal capability in the event of
an extended loss of the primary power source.
Discussion: Provision of an alternate power supply with minimal operang capability can be
sasﬁed by accessing a secondary commercial power supply or other external power supply.
(2) EMERGENCY POWER | ALTERNATE POWER SUPPLY — SELF-CONTAINED
Provide an alternate power supply for the system that is acvated [Selecon: manually;
automacally] and that is:
(a) Self-contained;
(b) Not reliant on external power generaon; and
(c) Capable of maintaining [Selecon: minimally required operaonal capability; full
operaonal capability] in the event of an extended loss of the primary power source.
Discussion: The provision of a long-term, self-contained power supply can be sasﬁed by using
one or more generators with suﬃcient capacity to meet the needs of the organizaon.
References: None
PE-12 EMERGENCY LIGHTING
Control: Employ and maintain automac emergency lighng for the system that acvates in the event
of a power outage or disrupon and that covers emergency exits and evacuaon routes within the
facility.
Discussion: The provision of emergency lighng applies primarily to organizaonal facilies that
contain concentraons of system resources, including data centers, server rooms, and mainframe
computer rooms. Emergency lighng provisions for the system are described in the conngency plan
for the organizaon. If emergency lighng for the system fails or cannot be provided, organizaons
consider alternate processing sites for power-related conngencies.
Related controls: CP-2, CP-7.
(1) EMERGENCY LIGHTING | ESSENTIAL MISSION AND BUSINESS FUNCTIONS
Provide emergency lighng for all areas within the facility supporng essenal mission and
business funcons.
Discussion: Organizaons deﬁne their essenal missions and funcons.
References: None
PE-13 FIRE PROTECTION
Control: Employ and maintain ﬁre detecon and suppression systems that are supported by an
independent energy source.
Discussion: The provision of ﬁre detecon and suppression systems applies primarily to organizaonal
facilies that contain concentraons of system resources, including data centers, server rooms,
and mainframe computer rooms. Fire detecon and suppression systems that may require an
This document is produced from OSCAL source data
FAMILY: PE PAGE 176NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
independent energy source include sprinkler systems and smoke detectors. An independent energy
source is an energy source, such as a microgrid, that is separate, or can be separated, from the energy
sources providing power for the other parts of the facility.
Related control: AT-3.
(1) FIRE PROTECTION | DETECTION SYSTEMS — AUTOMATIC ACTIVATION AND
NOTIFICATION
Employ ﬁre detecon systems that acvate automacally and nofy [Assignment:
organizaon-deﬁned personnel or roles] and [Assignment: organizaon-deﬁned emergency
responders] in the event of a ﬁre.
Discussion: Organizaons can idenfy personnel, roles, and emergency responders if individuals
on the noﬁcaon list need to have access authorizaons or clearances (e.g., to enter to facilies
where access is restricted due to the classiﬁcaon or impact level of informaon within the
facility). Noﬁcaon mechanisms may require independent energy sources to ensure that the
noﬁcaon capability is not adversely aﬀected by the ﬁre.
(2) FIRE PROTECTION | SUPPRESSION SYSTEMS — AUTOMATIC ACTIVATION AND
NOTIFICATION
(a) Employ ﬁre suppression systems that acvate automacally and nofy [Assignment:
organizaon-deﬁned personnel or roles] and [Assignment: organizaon-deﬁned
emergency responders]; and
(b) Employ an automac ﬁre suppression capability when the facility is not staﬀed on a
connuous basis.
Discussion: Organizaons can idenfy speciﬁc personnel, roles, and emergency responders
if individuals on the noﬁcaon list need to have appropriate access authorizaons and/
or clearances (e.g., to enter to facilies where access is restricted due to the impact level
or classiﬁcaon of informaon within the facility). Noﬁcaon mechanisms may require
independent energy sources to ensure that the noﬁcaon capability is not adversely aﬀected
by the ﬁre.
(3) FIRE PROTECTION | AUTOMATIC FIRE SUPPRESSION
[Withdrawn: Incorporated into PE-13(2).]
(4) FIRE PROTECTION | INSPECTIONS
Ensure that the facility undergoes [Assignment: organizaon-deﬁned frequency] ﬁre
protecon inspecons by authorized and qualiﬁed inspectors and idenﬁed deﬁciencies are
resolved within [Assignment: organizaon-deﬁned me period].
Discussion: Authorized and qualiﬁed personnel within the jurisdicon of the organizaon include
state, county, and city ﬁre inspectors and ﬁre marshals. Organizaons provide escorts during
inspecons in situaons where the systems that reside within the facilies contain sensive
informaon.
References: None
This document is produced from OSCAL source data
FAMILY: PE PAGE 177NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
PE-14 ENVIRONMENTAL CONTROLS
Control:
a. Maintain [Selecon (one or more): temperature; humidity; pressure; radiaon; [Assignment:
organizaon-deﬁned environmental control]] levels within the facility where the system resides
at [Assignment: organizaon-deﬁned acceptable levels]; and
b. Monitor environmental control levels [Assignment: organizaon-deﬁned frequency].
Discussion: The provision of environmental controls applies primarily to organizaonal facilies that
contain concentraons of system resources (e.g., data centers, mainframe computer rooms, and
server rooms). Insuﬃcient environmental controls, especially in very harsh environments, can have a
signiﬁcant adverse impact on the availability of systems and system components that are needed to
support organizaonal mission and business funcons.
Related controls: AT-3, CP-2.
(1) ENVIRONMENTAL CONTROLS | AUTOMATIC CONTROLS
Employ the following automac environmental controls in the facility to prevent
ﬂuctuaons potenally harmful to the system: [Assignment: organizaon-deﬁned automac
environmental controls].
Discussion: The implementaon of automac environmental controls provides an immediate
response to environmental condions that can damage, degrade, or destroy organizaonal
systems or systems components.
(2) ENVIRONMENTAL CONTROLS | MONITORING WITH ALARMS AND NOTIFICATIONS
Employ environmental control monitoring that provides an alarm or noﬁcaon of changes
potenally harmful to personnel or equipment to [Assignment: organizaon-deﬁned
personnel or roles].
Discussion: The alarm or noﬁcaon may be an audible alarm or a visual message in real me to
personnel or roles deﬁned by the organizaon. Such alarms and noﬁcaons can help minimize
harm to individuals and damage to organizaonal assets by facilitang a mely incident
response.
References: None
PE-15 WATER DAMAGE PROTECTION
Control: Protect the system from damage resulng from water leakage by providing master shutoﬀ or
isolaon valves that are accessible, working properly, and known to key personnel.
Discussion: The provision of water damage protecon primarily applies to organizaonal facilies that
contain concentraons of system resources, including data centers, server rooms, and mainframe
computer rooms. Isolaon valves can be employed in addion to or in lieu of master shutoﬀ valves to
shut oﬀ water supplies in speciﬁc areas of concern without aﬀecng enre organizaons.
Related controls: AT-3, PE-10.
This document is produced from OSCAL source data
FAMILY: PE PAGE 178NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(1) WATER DAMAGE PROTECTION | AUTOMATION SUPPORT
Detect the presence of water near the system and alert [Assignment: organizaon-deﬁned
personnel or roles] using [Assignment: organizaon-deﬁned automated mechanisms].
Discussion: Automated mechanisms include noﬁcaon systems, water detecon sensors, and
alarms.
References: None
PE-16 DELIVERY AND REMOVAL
Control:
a. Authorize and control [Assignment: organizaon-deﬁned types of system components] entering
and exing the facility; and
b. Maintain records of the system components.
Discussion: Enforcing authorizaons for entry and exit of system components may require restricng
access to delivery areas and isolang the areas from the system and media libraries.
Related controls: CM-3, CM-8, MA-2, MA-3, MP-5, PE-20, SR-2, SR-3, SR-4, SR-6.
References: None
PE-17 ALTERNATE WORK SITE
Control:
a. Determine and document the [Assignment: organizaon-deﬁned alternate work sites] allowed
for use by employees;
b. Employ the following controls at alternate work sites: [Assignment: organizaon-deﬁned
controls];
c. Assess the eﬀecveness of controls at alternate work sites; and
d. Provide a means for employees to communicate with informaon security and privacy personnel
in case of incidents.
Discussion: Alternate work sites include government facilies or the private residences of employees.
While disnct from alternave processing sites, alternate work sites can provide readily available
alternate locaons during conngency operaons. Organizaons can deﬁne diﬀerent sets of controls
for speciﬁc alternate work sites or types of sites depending on the work-related acvies conducted
at the sites. Implemenng and assessing the eﬀecveness of organizaon-deﬁned controls and
providing a means to communicate incidents at alternate work sites supports the conngency
planning acvies of organizaons.
Related controls: AC-17, AC-18, CP-7.
Reference: [SP 800-46]
PE-18 LOCATION OF SYSTEM COMPONENTS
Control: Posion system components within the facility to minimize potenal damage from
[Assignment: organizaon-deﬁned physical and environmental hazards] and to minimize the
opportunity for unauthorized access.
This document is produced from OSCAL source data
FAMILY: PE PAGE 179NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
Discussion: Physical and environmental hazards include ﬂoods, ﬁres, tornadoes, earthquakes,
hurricanes, terrorism, vandalism, an electromagnec pulse, electrical interference, and other forms
of incoming electromagnec radiaon. Organizaons consider the locaon of entry points where
unauthorized individuals, while not being granted access, might nonetheless be near systems. Such
proximity can increase the risk of unauthorized access to organizaonal communicaons using
wireless packet sniﬀers or microphones, or unauthorized disclosure of informaon.
Related controls: CP-2, PE-5, PE-19, PE-20, RA-3.
(1) LOCATION OF SYSTEM COMPONENTS | FACILITY SITE
[Withdrawn: Incorporated into PE-23.]
References: None
PE-19 INFORMATION LEAKAGE
Control: Protect the system from informaon leakage due to electromagnec signals emanaons.
Discussion: Informaon leakage is the intenonal or unintenonal release of data or informaon
to an untrusted environment from electromagnec signals emanaons. The security categories or
classiﬁcaons of systems (with respect to conﬁdenality), organizaonal security policies, and risk
tolerance guide the selecon of controls employed to protect systems against informaon leakage
due to electromagnec signals emanaons.
Related controls: AC-18, PE-18, PE-20.
(1) INFORMATION LEAKAGE | NATIONAL EMISSIONS POLICIES AND PROCEDURES
Protect system components, associated data communicaons, and networks in accordance
with naonal Emissions Security policies and procedures based on the security category or
classiﬁcaon of the informaon.
Discussion: Emissions Security (EMSEC) policies include the former TEMPEST policies.
Reference: [FIPS 199]
PE-20 ASSET MONITORING AND TRACKING
Control: Employ [Assignment: organizaon-deﬁned asset locaon technologies] to track and monitor
the locaon and movement of [Assignment: organizaon-deﬁned assets] within [Assignment:
organizaon-deﬁned controlled areas].
Discussion: Asset locaon technologies can help ensure that crical assets—including vehicles,
equipment, and system components—remain in authorized locaons. Organizaons consult with the
Oﬃce of the General Counsel and senior agency oﬃcial for privacy regarding the deployment and use
of asset locaon technologies to address potenal privacy concerns.
Related controls: CM-8, PE-16, PM-8.
References: None
PE-21 ELECTROMAGNETIC PULSE PROTECTION
Control: Employ [Assignment: organizaon-deﬁned protecve measures] against electromagnec
pulse damage for [Assignment: organizaon-deﬁned systems and system components].
This document is produced from OSCAL source data
FAMILY: PE PAGE 180NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
Discussion: An electromagnec pulse (EMP) is a short burst of electromagnec energy that is spread
over a range of frequencies. Such energy bursts may be natural or man-made. EMP interference
may be disrupve or damaging to electronic equipment. Protecve measures used to migate EMP
risk include shielding, surge suppressors, ferro-resonant transformers, and earth grounding. EMP
protecon may be especially signiﬁcant for systems and applicaons that are part of the U.S. crical
infrastructure.
Related controls: PE-18, PE-19.
References: None
PE-22 COMPONENT MARKING
Control: Mark [Assignment: organizaon-deﬁned system hardware components] indicang the impact
level or classiﬁcaon level of the informaon permied to be processed, stored, or transmied by the
hardware component.
Discussion: Hardware components that may require marking include input and output devices.
Input devices include desktop and notebook computers, keyboards, tablets, and smart phones.
Output devices include printers, monitors/video displays, facsimile machines, scanners, copiers, and
audio devices. Permissions controlling output to the output devices are addressed in AC-3 or AC-4.
Components are marked to indicate the impact level or classiﬁcaon level of the system to which
the devices are connected, or the impact level or classiﬁcaon level of the informaon permied
to be output. Security marking refers to the use of human-readable security aributes. Security
labeling refers to the use of security aributes for internal system data structures. Security marking
is generally not required for hardware components that process, store, or transmit informaon
determined by organizaons to be in the public domain or to be publicly releasable. However,
organizaons may require markings for hardware components that process, store, or transmit public
informaon in order to indicate that such informaon is publicly releasable. Marking of system
hardware components reﬂects applicable laws, execuve orders, direcves, policies, regulaons, and
standards.
Related controls: AC-3, AC-4, AC-16, MP-3.
Reference: [IR 8023]
PE-23 FACILITY LOCATION
Control:
a. Plan the locaon or site of the facility where the system resides considering physical and
environmental hazards; and
b. For exisng facilies, consider the physical and environmental hazards in the organizaonal risk
management strategy.
Discussion: Physical and environmental hazards include ﬂoods, ﬁres, tornadoes, earthquakes,
hurricanes, terrorism, vandalism, an electromagnec pulse, electrical interference, and other forms
of incoming electromagnec radiaon. The locaon of system components within the facility is
addressed in PE-18.
Related controls: CP-2, PE-18, PE-19, PM-8, PM-9, RA-3.
References: None
This document is produced from OSCAL source data
FAMILY: PE PAGE 181NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
FAMILY: PLANNING
PL-1 POLICY AND PROCEDURES
Control:
a. Develop, document, and disseminate to [Assignment: organizaon-deﬁned personnel or roles]:
1. [Selecon (one or more): Organizaon-level; Mission/business process-level; System-level]
planning policy that:
(a) Addresses purpose, scope, roles, responsibilies, management commitment,
coordinaon among organizaonal enes, and compliance; and
(b) Is consistent with applicable laws, execuve orders, direcves, regulaons, policies,
standards, and guidelines; and
2. Procedures to facilitate the implementaon of the planning policy and the associated
planning controls;
b. Designate an [Assignment: organizaon-deﬁned oﬃcial] to manage the development,
documentaon, and disseminaon of the planning policy and procedures; and
c. Review and update the current planning:
1. Policy [Assignment: organizaon-deﬁned frequency] and following [Assignment:
organizaon-deﬁned events]; and
2. Procedures [Assignment: organizaon-deﬁned frequency] and following [Assignment:
organizaon-deﬁned events].
Discussion: Planning policy and procedures for the controls in the PL family implemented within
systems and organizaons. The risk management strategy is an important factor in establishing
such policies and procedures. Policies and procedures contribute to security and privacy assurance.
Therefore, it is important that security and privacy programs collaborate on their development.
Security and privacy program policies and procedures at the organizaon level are preferable, in
general, and may obviate the need for mission level or system-speciﬁc policies and procedures.
The policy can be included as part of the general security and privacy policy or be represented by
mulple policies that reﬂect the complex nature of organizaons. Procedures can be established for
security and privacy programs, for mission/business processes, and for systems, if needed. Procedures
describe how the policies or controls are implemented and can be directed at the individual or role
that is the object of the procedure. Procedures can be documented in system security and privacy
plans or in one or more separate documents. Events that may precipitate an update to planning
policy and procedures include, but are not limited to, assessment or audit ﬁndings, security incidents
or breaches, or changes in laws, execuve orders, direcves, regulaons, policies, standards, and
guidelines. Simply restang controls does not constute an organizaonal policy or procedure.
Related controls: PM-9, PS-8, SI-12.
References: [OMB A-130], [SP 800-100], [SP 800-12], [SP 800-18], [SP 800-30], [SP 800-39]
This document is produced from OSCAL source data
FAMILY: PL PAGE 182NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
PL-2 SYSTEM SECURITY AND PRIVACY PLANS
Control:
a. Develop security and privacy plans for the system that:
1. Are consistent with the organizaon’s enterprise architecture;
2. Explicitly deﬁne the constuent system components;
3. Describe the operaonal context of the system in terms of mission and business processes;
4. Idenfy the individuals that fulﬁll system roles and responsibilies;
5. Idenfy the informaon types processed, stored, and transmied by the system;
6. Provide the security categorizaon of the system, including supporng raonale;
7. Describe any speciﬁc threats to the system that are of concern to the organizaon;
8. Provide the results of a privacy risk assessment for systems processing personally
idenﬁable informaon;
9. Describe the operaonal environment for the system and any dependencies on or
connecons to other systems or system components;
10. Provide an overview of the security and privacy requirements for the system;
11. Idenfy any relevant control baselines or overlays, if applicable;
12. Describe the controls in place or planned for meeng the security and privacy requirements,
including a raonale for any tailoring decisions;
13. Include risk determinaons for security and privacy architecture and design decisions;
14. Include security- and privacy-related acvies aﬀecng the system that require planning
and coordinaon with [Assignment: organizaon-deﬁned individuals or groups]; and
15. Are reviewed and approved by the authorizing oﬃcial or designated representave prior to
plan implementaon.
b. Distribute copies of the plans and communicate subsequent changes to the plans to
[Assignment: organizaon-deﬁned personnel or roles];
c. Review the plans [Assignment: organizaon-deﬁned frequency];
d. Update the plans to address changes to the system and environment of operaon or problems
idenﬁed during plan implementaon or control assessments; and
e. Protect the plans from unauthorized disclosure and modiﬁcaon.
Discussion: System security and privacy plans are scoped to the system and system components within
the deﬁned authorizaon boundary and contain an overview of the security and privacy requirements
for the system and the controls selected to sasfy the requirements. The plans describe the intended
applicaon of each selected control in the context of the system with a suﬃcient level of detail to
correctly implement the control and to subsequently assess the eﬀecveness of the control. The
control documentaon describes how system-speciﬁc and hybrid controls are implemented and
the plans and expectaons regarding the funconality of the system. System security and privacy
plans can also be used in the design and development of systems in support of life cycle-based
security and privacy engineering processes. System security and privacy plans are living documents
that are updated and adapted throughout the system development life cycle (e.g., during capability
determinaon, analysis of alternaves, requests for proposal, and design reviews). Secon 2.1
This document is produced from OSCAL source data
FAMILY: PL PAGE 183NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
describes the diﬀerent types of requirements that are relevant to organizaons during the system
development life cycle and the relaonship between requirements and controls.
Organizaons may develop a single, integrated security and privacy plan or maintain separate
plans. Security and privacy plans relate security and privacy requirements to a set of controls and
control enhancements. The plans describe how the controls and control enhancements meet
the security and privacy requirements but do not provide detailed, technical descripons of the
design or implementaon of the controls and control enhancements. Security and privacy plans
contain suﬃcient informaon (including speciﬁcaons of control parameter values for selecon
and assignment operaons explicitly or by reference) to enable a design and implementaon that
is unambiguously compliant with the intent of the plans and subsequent determinaons of risk to
organizaonal operaons and assets, individuals, other organizaons, and the Naon if the plan is
implemented.
Security and privacy plans need not be single documents. The plans can be a collecon of various
documents, including documents that already exist. Eﬀecve security and privacy plans make
extensive use of references to policies, procedures, and addional documents, including design
and implementaon speciﬁcaons where more detailed informaon can be obtained. The use
of references helps reduce the documentaon associated with security and privacy programs
and maintains the security- and privacy-related informaon in other established management
and operaonal areas, including enterprise architecture, system development life cycle, systems
engineering, and acquision. Security and privacy plans need not contain detailed conngency plan
or incident response plan informaon but can instead provide—explicitly or by reference—suﬃcient
informaon to deﬁne what needs to be accomplished by those plans.
Security- and privacy-related acvies that may require coordinaon and planning with other
individuals or groups within the organizaon include assessments, audits, inspecons, hardware
and soware maintenance, acquision and supply chain risk management, patch management,
and conngency plan tesng. Planning and coordinaon include emergency and nonemergency
(i.e., planned or non-urgent unplanned) situaons. The process deﬁned by organizaons to plan
and coordinate security- and privacy-related acvies can also be included in other documents, as
appropriate.
Related controls: AC-2, AC-6, AC-14, AC-17, AC-20, CA-2, CA-3, CA-7, CM-9, CM-13, CP-2, CP-4, IR-4,
IR-8, MA-4, MA-5, MP-4, MP-5, PL-7, PL-8, PL-10, PL-11, PM-1, PM-7, PM-8, PM-9, PM-10, PM-11,
RA-3, RA-8, RA-9, SA-5, SA-17, SA-22, SI-12, SR-2, SR-4.
(1) SYSTEM SECURITY AND PRIVACY PLANS | CONCEPT OF OPERATIONS
[Withdrawn: Incorporated into PL-7.]
(2) SYSTEM SECURITY AND PRIVACY PLANS | FUNCTIONAL ARCHITECTURE
[Withdrawn: Incorporated into PL-8.]
(3) SYSTEM SECURITY AND PRIVACY PLANS | PLAN AND COORDINATE WITH OTHER
ORGANIZATIONAL ENTITIES
[Withdrawn: Incorporated into PL-2.]
References: [OMB A-130], [SP 800-160-1], [SP 800-160-2], [SP 800-18], [SP 800-37]
PL-3 System Security Plan Update
[Withdrawn: Incorporated into PL-2.]
This document is produced from OSCAL source data
FAMILY: PL PAGE 184NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
PL-4 RULES OF BEHAVIOR
Control:
a. Establish and provide to individuals requiring access to the system, the rules that describe their
responsibilies and expected behavior for informaon and system usage, security, and privacy;
b. Receive a documented acknowledgment from such individuals, indicang that they have read,
understand, and agree to abide by the rules of behavior, before authorizing access to informaon
and the system;
c. Review and update the rules of behavior [Assignment: organizaon-deﬁned frequency]; and
d. Require individuals who have acknowledged a previous version of the rules of behavior to read
and re-acknowledge [Selecon (one or more): [Assignment: organizaon-deﬁned frequency];
when the rules are revised or updated].
Discussion: Rules of behavior represent a type of access agreement for organizaonal users. Other
types of access agreements include nondisclosure agreements, conﬂict-of-interest agreements, and
acceptable use agreements (see PS-6). Organizaons consider rules of behavior based on individual
user roles and responsibilies and diﬀerenate between rules that apply to privileged users and rules
that apply to general users. Establishing rules of behavior for some types of non-organizaonal users,
including individuals who receive informaon from federal systems, is oen not feasible given the
large number of such users and the limited nature of their interacons with the systems. Rules of
behavior for organizaonal and non-organizaonal users can also be established in AC-8. The related
controls secon provides a list of controls that are relevant to organizaonal rules of behavior. PL-4b,
the documented acknowledgment poron of the control, may be sasﬁed by the literacy training
and awareness and role-based training programs conducted by organizaons if such training includes
rules of behavior. Documented acknowledgements for rules of behavior include electronic or physical
signatures and electronic agreement check boxes or radio buons.
Related controls: AC-2, AC-6, AC-8, AC-9, AC-17, AC-18, AC-19, AC-20, AT-2, AT-3, CM-11, IA-2, IA-4, IA-5,
MP-7, PS-6, PS-8, SA-5, SI-12.
(1) RULES OF BEHAVIOR | SOCIAL MEDIA AND EXTERNAL SITE/APPLICATION USAGE
RESTRICTIONS
Include in the rules of behavior, restricons on:
(a) Use of social media, social networking sites, and external sites/applicaons;
(b) Posng organizaonal informaon on public websites; and
(c) Use of organizaon-provided idenﬁers (e.g., email addresses) and authencaon secrets
(e.g., passwords) for creang accounts on external sites/applicaons.
Discussion: Social media, social networking, and external site/applicaon usage restricons
address rules of behavior related to the use of social media, social networking, and external
sites when organizaonal personnel are using such sites for oﬃcial dues or in the conduct
of oﬃcial business, when organizaonal informaon is involved in social media and social
networking transacons, and when personnel access social media and networking sites from
organizaonal systems. Organizaons also address speciﬁc rules that prevent unauthorized
enes from obtaining non-public organizaonal informaon from social media and networking
sites either directly or through inference. Non-public informaon includes personally idenﬁable
informaon and system account informaon.
Related controls: AC-22, AU-13.
This document is produced from OSCAL source data
FAMILY: PL PAGE 185NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
References: [OMB A-130], [SP 800-18]
PL-5 Privacy Impact Assessment
[Withdrawn: Incorporated into RA-8.]
PL-6 Security-related Acvity Planning
[Withdrawn: Incorporated into PL-2.]
PL-7 CONCEPT OF OPERATIONS
Control:
a. Develop a Concept of Operaons (CONOPS) for the system describing how the organizaon
intends to operate the system from the perspecve of informaon security and privacy; and
b. Review and update the CONOPS [Assignment: organizaon-deﬁned frequency].
Discussion: The CONOPS may be included in the security or privacy plans for the system or in other
system development life cycle documents. The CONOPS is a living document that requires updang
throughout the system development life cycle. For example, during system design reviews, the
concept of operaons is checked to ensure that it remains consistent with the design for controls, the
system architecture, and the operaonal procedures. Changes to the CONOPS are reﬂected in ongoing
updates to the security and privacy plans, security and privacy architectures, and other organizaonal
documents, such as procurement speciﬁcaons, system development life cycle documents, and
systems engineering documents.
Related controls: PL-2, SA-2, SI-12.
Reference: [OMB A-130]
PL-8 SECURITY AND PRIVACY ARCHITECTURES
Control:
a. Develop security and privacy architectures for the system that:
1. Describe the requirements and approach to be taken for protecng the conﬁdenality,
integrity, and availability of organizaonal informaon;
2. Describe the requirements and approach to be taken for processing personally idenﬁable
informaon to minimize privacy risk to individuals;
3. Describe how the architectures are integrated into and support the enterprise architecture;
and
4. Describe any assumpons about, and dependencies on, external systems and services;
b. Review and update the architectures [Assignment: organizaon-deﬁned frequency] to reﬂect
changes in the enterprise architecture; and
c. Reﬂect planned architecture changes in security and privacy plans, Concept of Operaons
(CONOPS), cricality analysis, organizaonal procedures, and procurements and acquisions.
Discussion: The security and privacy architectures at the system level are consistent with the
organizaon-wide security and privacy architectures described in PM-7, which are integral to
and developed as part of the enterprise architecture. The architectures include an architectural
descripon, the allocaon of security and privacy funconality (including controls), security- and
privacy-related informaon for external interfaces, informaon being exchanged across the interfaces,
This document is produced from OSCAL source data
FAMILY: PL PAGE 186NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
and the protecon mechanisms associated with each interface. The architectures can also include
other informaon, such as user roles and the access privileges assigned to each role; security and
privacy requirements; types of informaon processed, stored, and transmied by the system; supply
chain risk management requirements; restoraon priories of informaon and system services; and
other protecon needs.
SP 800-160-1 provides guidance on the use of security architectures as part of the system
development life cycle process. OMB M-19-03 requires the use of the systems security engineering
concepts described in SP 800-160-1 for high value assets. Security and privacy architectures are
reviewed and updated throughout the system development life cycle, from analysis of alternaves
through review of the proposed architecture in the RFP responses to the design reviews before and
during implementaon (e.g., during preliminary design reviews and crical design reviews).
In today’s modern compung architectures, it is becoming less common for organizaons to control
all informaon resources. There may be key dependencies on external informaon services and
service providers. Describing such dependencies in the security and privacy architectures is necessary
for developing a comprehensive mission and business protecon strategy. Establishing, developing,
documenng, and maintaining under conﬁguraon control a baseline conﬁguraon for organizaonal
systems is crical to implemenng and maintaining eﬀecve architectures. The development of
the architectures is coordinated with the senior agency informaon security oﬃcer and the senior
agency oﬃcial for privacy to ensure that the controls needed to support security and privacy
requirements are idenﬁed and eﬀecvely implemented. In many circumstances, there may be
no disncon between the security and privacy architecture for a system. In other circumstances,
security objecves may be adequately sasﬁed, but privacy objecves may only be parally sasﬁed
by the security requirements. In these cases, consideraon of the privacy requirements needed to
achieve sasfacon will result in a disnct privacy architecture. The documentaon, however, may
simply reﬂect the combined architectures.
PL-8 is primarily directed at organizaons to ensure that architectures are developed for the system
and, moreover, that the architectures are integrated with or ghtly coupled to the enterprise
architecture. In contrast, SA-17 is primarily directed at the external informaon technology product
and system developers and integrators. SA-17, which is complementary to PL-8, is selected when
organizaons outsource the development of systems or components to external enes and when
there is a need to demonstrate consistency with the organizaon’s enterprise architecture and
security and privacy architectures.
Related controls: CM-2, CM-6, PL-2, PL-7, PL-9, PM-5, PM-7, RA-9, SA-3, SA-5, SA-8, SA-17, SC-7.
(1) SECURITY AND PRIVACY ARCHITECTURES | DEFENSE IN DEPTH
Design the security and privacy architectures for the system using a defense-in-depth
approach that:
(a) Allocates [Assignment: organizaon-deﬁned controls] to [Assignment: organizaon-
deﬁned locaons and architectural layers]; and
(b) Ensures that the allocated controls operate in a coordinated and mutually reinforcing
manner.
Discussion: Organizaons strategically allocate security and privacy controls in the security
and privacy architectures so that adversaries must overcome mulple controls to achieve
their objecve. Requiring adversaries to defeat mulple controls makes it more diﬃcult to
aack informaon resources by increasing the work factor of the adversary; it also increases
the likelihood of detecon. The coordinaon of allocated controls is essenal to ensure that
an aack that involves one control does not create adverse, unintended consequences by
This document is produced from OSCAL source data
FAMILY: PL PAGE 187NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
interfering with other controls. Unintended consequences can include system lockout and
cascading alarms. The placement of controls in systems and organizaons is an important
acvity that requires thoughul analysis. The value of organizaonal assets is an important
consideraon in providing addional layering. Defense-in-depth architectural approaches
include modularity and layering (see SA-8(3)), separaon of system and user funconality (see
SC-2), and security funcon isolaon (see SC-3).
Related controls: SC-2, SC-3, SC-29, SC-36.
(2) SECURITY AND PRIVACY ARCHITECTURES | SUPPLIER DIVERSITY
Require that [Assignment: organizaon-deﬁned controls] allocated to [Assignment:
organizaon-deﬁned locaons and architectural layers] are obtained from diﬀerent suppliers.
Discussion: Informaon technology products have diﬀerent strengths and weaknesses. Providing
a broad spectrum of products complements the individual oﬀerings. For example, vendors
oﬀering malicious code protecon typically update their products at diﬀerent mes, oen
developing soluons for known viruses, Trojans, or worms based on their priories and
development schedules. By deploying diﬀerent products at diﬀerent locaons, there is an
increased likelihood that at least one of the products will detect the malicious code. With
respect to privacy, vendors may oﬀer products that track personally idenﬁable informaon in
systems. Products may use diﬀerent tracking methods. Using mulple products may result in
more assurance that personally idenﬁable informaon is inventoried.
Related controls: SC-29, SR-3.
References: [OMB A-130], [SP 800-160-1], [SP 800-160-2]
PL-9 CENTRAL MANAGEMENT
Control: Centrally manage [Assignment: organizaon-deﬁned controls and related processes].
Discussion: Central management refers to organizaon-wide management and implementaon of
selected controls and processes. This includes planning, implemenng, assessing, authorizing, and
monitoring the organizaon-deﬁned, centrally managed controls and processes. As the central
management of controls is generally associated with the concept of common (inherited) controls,
such management promotes and facilitates standardizaon of control implementaons and
management and the judicious use of organizaonal resources. Centrally managed controls and
processes may also meet independence requirements for assessments in support of inial and
ongoing authorizaons to operate and as part of organizaonal connuous monitoring.
Automated tools (e.g., security informaon and event management tools or enterprise security
monitoring and management tools) can improve the accuracy, consistency, and availability of
informaon associated with centrally managed controls and processes. Automaon can also provide
data aggregaon and data correlaon capabilies; alerng mechanisms; and dashboards to support
risk-based decision-making within the organizaon.
As part of the control selecon processes, organizaons determine the controls that may be suitable
for central management based on resources and capabilies. It is not always possible to centrally
manage every aspect of a control. In such cases, the control can be treated as a hybrid control with
the control managed and implemented centrally or at the system level. The controls and control
enhancements that are candidates for full or paral central management include but are not limited
to: AC-2(1), AC-2(2), AC-2(3), AC-2(4), AC-4(all), AC-17(1), AC-17(2), AC-17(3), AC-17(9), AC-18(1),
AC-18(3), AC-18(4), AC-18(5), AC-19(4), AC-22, AC-23, AT-2(1), AT-2(2), AT-3(1), AT-3(2), AT-3(3), AT-4,
AU-3, AU-6(1), AU-6(3), AU-6(5), AU-6(6), AU-6(9), AU-7(1), AU-7(2), AU-11, AU-13, AU-16, CA-2(1),
CA-2(2), CA-2(3), CA-3(1), CA-3(2), CA-3(3), CA-7(1), CA-9, CM-2(2), CM-3(1), CM-3(4), CM-4, CM-6,
This document is produced from OSCAL source data
FAMILY: PL PAGE 188NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
CM-6(1), CM-7(2), CM-7(4), CM-7(5), CM-8(all), CM-9(1), CM-10, CM-11, CP-7(all), CP-8(all), SC-43,
SI-2, SI-3, SI-4(all), SI-7, SI-8.
Related controls: PL-8, PM-9.
References: [OMB A-130], [SP 800-37]
PL-10 BASELINE SELECTION
Control: Select a control baseline for the system.
Discussion: Control baselines are predeﬁned sets of controls speciﬁcally assembled to address
the protecon needs of a group, organizaon, or community of interest. Controls are chosen for
baselines to either sasfy mandates imposed by laws, execuve orders, direcves, regulaons,
policies, standards, and guidelines or address threats common to all users of the baseline under
the assumpons speciﬁc to the baseline. Baselines represent a starng point for the protecon
of individuals’ privacy, informaon, and informaon systems with subsequent tailoring acons to
manage risk in accordance with mission, business, or other constraints (see PL-11). Federal control
baselines are provided in SP 800-53B. The selecon of a control baseline is determined by the
needs of stakeholders. Stakeholder needs consider mission and business requirements as well as
mandates imposed by applicable laws, execuve orders, direcves, policies, regulaons, standards,
and guidelines. For example, the control baselines in SP 800-53B are based on the requirements from
FISMA and PRIVACT. The requirements, along with the NIST standards and guidelines implemenng
the legislaon, direct organizaons to select one of the control baselines aer the reviewing the
informaon types and the informaon that is processed, stored, and transmied on the system;
analyzing the potenal adverse impact of the loss or compromise of the informaon or system on the
organizaon’s operaons and assets, individuals, other organizaons, or the Naon; and considering
the results from system and organizaonal risk assessments. CNSSI 1253 provides guidance on control
baselines for naonal security systems.
Related controls: PL-2, PL-11, RA-2, RA-3, SA-8.
References: [CNSSI 1253], [FIPS 199], [FIPS 200], [SP 800-160-1], [SP 800-30], [SP 800-37], [SP 800-39],
[SP 800-53B], [SP 800-60-1], [SP 800-60-2]
PL-11 BASELINE TAILORING
Control: Tailor the selected control baseline by applying speciﬁed tailoring acons.
Discussion: The concept of tailoring allows organizaons to specialize or customize a set of baseline
controls by applying a deﬁned set of tailoring acons. Tailoring acons facilitate such specializaon
and customizaon by allowing organizaons to develop security and privacy plans that reﬂect
their speciﬁc mission and business funcons, the environments where their systems operate, the
threats and vulnerabilies that can aﬀect their systems, and any other condions or situaons
that can impact their mission or business success. Tailoring guidance is provided in SP 800-53B.
Tailoring a control baseline is accomplished by idenfying and designang common controls, applying
scoping consideraons, selecng compensang controls, assigning values to control parameters,
supplemenng the control baseline with addional controls as needed, and providing informaon
for control implementaon. The general tailoring acons in SP 800-53B can be supplemented with
addional acons based on the needs of organizaons. Tailoring acons can be applied to the
baselines in SP 800-53B in accordance with the security and privacy requirements from FISMA,
PRIVACT, and OMB A-130. Alternavely, other communies of interest adopng diﬀerent control
baselines can apply the tailoring acons in SP 800-53B to specialize or customize the controls that
represent the speciﬁc needs and concerns of those enes.
Related controls: PL-10, RA-2, RA-3, RA-9, SA-8.
This document is produced from OSCAL source data
FAMILY: PL PAGE 189NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
References: [CNSSI 1253], [FIPS 199], [FIPS 200], [SP 800-160-1], [SP 800-30], [SP 800-37], [SP 800-39],
[SP 800-53B], [SP 800-60-1], [SP 800-60-2]
This document is produced from OSCAL source data
FAMILY: PL PAGE 190NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
FAMILY: PROGRAM MANAGEMENT
PROGRAM MANAGEMENT CONTROLS
FISMA, PRIVACT, and OMB A-130 require federal agencies to develop, implement, and
provide oversight for organizaon-wide informaon security and privacy programs to
help ensure the conﬁdenality, integrity, and availability of federal informaon processed,
stored, and transmied by federal informaon systems and to protect individual privacy.
The program management (PM) controls described in this secon are implemented
at the organizaon level and not directed at individual informaon systems. The PM
controls have been designed to facilitate organizaonal compliance with applicable federal
laws, execuve orders, direcves, policies, regulaons, and standards. The controls are
independent of FIPS 200 impact levels and, therefore, are not associated with the control
baselines described in SP 800-53B.
Organizaons document program management controls in the informaon security and
privacy program plans. The organizaon-wide informaon security program plan (see
PM-1) and privacy program plan (see PM-18) supplement system security and privacy
plans (see PL-2) developed for organizaonal informaon systems. Together, the system
security and privacy plans for the individual informaon systems and the informaon
security and privacy program plans cover the totality of security and privacy controls
employed by the organizaon.
PM-1 INFORMATION SECURITY PROGRAM PLAN
Control:
a. Develop and disseminate an organizaon-wide informaon security program plan that:
1. Provides an overview of the requirements for the security program and a descripon of
the security program management controls and common controls in place or planned for
meeng those requirements;
2. Includes the idenﬁcaon and assignment of roles, responsibilies, management
commitment, coordinaon among organizaonal enes, and compliance;
3. Reﬂects the coordinaon among organizaonal enes responsible for informaon security;
and
4. Is approved by a senior oﬃcial with responsibility and accountability for the risk being
incurred to organizaonal operaons (including mission, funcons, image, and reputaon),
organizaonal assets, individuals, other organizaons, and the Naon;
b. Review and update the organizaon-wide informaon security program plan [Assignment:
organizaon-deﬁned frequency] and following [Assignment: organizaon-deﬁned events]; and
c. Protect the informaon security program plan from unauthorized disclosure and modiﬁcaon.
Discussion: An informaon security program plan is a formal document that provides an overview
of the security requirements for an organizaon-wide informaon security program and describes
the program management controls and common controls in place or planned for meeng those
requirements. An informaon security program plan can be represented in a single document or
This document is produced from OSCAL source data
FAMILY: PM PAGE 191NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
compilaons of documents. Privacy program plans and supply chain risk management plans are
addressed separately in PM-18 and SR-2, respecvely.
An informaon security program plan documents implementaon details about program
management and common controls. The plan provides suﬃcient informaon about the controls
(including speciﬁcaon of parameters for assignment and selecon operaons, explicitly or by
reference) to enable implementaons that are unambiguously compliant with the intent of the plan
and a determinaon of the risk to be incurred if the plan is implemented as intended. Updates to
informaon security program plans include organizaonal changes and problems idenﬁed during
plan implementaon or control assessments.
Program management controls may be implemented at the organizaon level or the mission or
business process level, and are essenal for managing the organizaon’s informaon security
program. Program management controls are disnct from common, system-speciﬁc, and hybrid
controls because program management controls are independent of any parcular system. Together,
the individual system security plans and the organizaon-wide informaon security program plan
provide complete coverage for the security controls employed within the organizaon.
Common controls available for inheritance by organizaonal systems are documented in an appendix
to the organizaon’s informaon security program plan unless the controls are included in a separate
security plan for a system. The organizaon-wide informaon security program plan indicates which
separate security plans contain descripons of common controls.
Events that may precipitate an update to the informaon security program plan include, but are not
limited to, organizaon-wide assessment or audit ﬁndings, security incidents or breaches, or changes
in laws, execuve orders, direcves, regulaons, policies, standards, and guidelines.
Related controls: PL-2, PM-18, PM-30, RA-9, SI-12, SR-2.
References: [FISMA], [OMB A-130], [SP 800-37], [SP 800-39]
PM-2 INFORMATION SECURITY PROGRAM LEADERSHIP ROLE
Control: Appoint a senior agency informaon security oﬃcer with the mission and resources to
coordinate, develop, implement, and maintain an organizaon-wide informaon security program.
Discussion: The senior agency informaon security oﬃcer is an organizaonal oﬃcial. For federal
agencies (as deﬁned by applicable laws, execuve orders, regulaons, direcves, policies, and
standards), this oﬃcial is the senior agency informaon security oﬃcer. Organizaons may also refer
to this oﬃcial as the senior informaon security oﬃcer or chief informaon security oﬃcer.
References: [OMB M-17-25], [SP 800-181], [SP 800-37], [SP 800-39]
PM-3 INFORMATION SECURITY AND PRIVACY RESOURCES
Control:
a. Include the resources needed to implement the informaon security and privacy programs in
capital planning and investment requests and document all excepons to this requirement;
b. Prepare documentaon required for addressing informaon security and privacy programs in
capital planning and investment requests in accordance with applicable laws, execuve orders,
direcves, policies, regulaons, standards; and
c. Make available for expenditure, the planned informaon security and privacy resources.
Discussion: Organizaons consider establishing champions for informaon security and privacy and,
as part of including the necessary resources, assign specialized experse and resources as needed.
This document is produced from OSCAL source data
FAMILY: PM PAGE 192NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
Organizaons may designate and empower an Investment Review Board or similar group to manage
and provide oversight for the informaon security and privacy aspects of the capital planning and
investment control process.
Related controls: PM-4, SA-2.
Reference: [OMB A-130]
PM-4 PLAN OF ACTION AND MILESTONES PROCESS
Control:
a. Implement a process to ensure that plans of acon and milestones for the informaon security,
privacy, and supply chain risk management programs and associated organizaonal systems:
1. Are developed and maintained;
2. Document the remedial informaon security, privacy, and supply chain risk management
acons to adequately respond to risk to organizaonal operaons and assets, individuals,
other organizaons, and the Naon; and
3. Are reported in accordance with established reporng requirements.
b. Review plans of acon and milestones for consistency with the organizaonal risk management
strategy and organizaon-wide priories for risk response acons.
Discussion: The plan of acon and milestones is a key organizaonal document and is subject to
reporng requirements established by the Oﬃce of Management and Budget. Organizaons develop
plans of acon and milestones with an organizaon-wide perspecve, priorizing risk response
acons and ensuring consistency with the goals and objecves of the organizaon. Plan of acon
and milestones updates are based on ﬁndings from control assessments and connuous monitoring
acvies. There can be mulple plans of acon and milestones corresponding to the informaon
system level, mission/business process level, and organizaonal/governance level. While plans of
acon and milestones are required for federal organizaons, other types of organizaons can help
reduce risk by documenng and tracking planned remediaons. Speciﬁc guidance on plans of acon
and milestones at the system level is provided in CA-5.
Related controls: CA-5, CA-7, PM-3, RA-7, SI-12.
References: [OMB A-130], [PRIVACT], [SP 800-37]
PM-5 SYSTEM INVENTORY
Control: Develop and update [Assignment: organizaon-deﬁned frequency] an inventory of
organizaonal systems.
Discussion: OMB A-130 provides guidance on developing systems inventories and associated reporng
requirements. System inventory refers to an organizaon-wide inventory of systems, not system
components as described in CM-8.
(1) SYSTEM INVENTORY | INVENTORY OF PERSONALLY IDENTIFIABLE INFORMATION
Establish, maintain, and update [Assignment: organizaon-deﬁned frequency] an inventory of
all systems, applicaons, and projects that process personally idenﬁable informaon.
Discussion: An inventory of systems, applicaons, and projects that process personally
idenﬁable informaon supports the mapping of data acons, providing individuals with
privacy noces, maintaining accurate personally idenﬁable informaon, and liming the
processing of personally idenﬁable informaon when such informaon is not needed for
This document is produced from OSCAL source data
FAMILY: PM PAGE 193NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
operaonal purposes. Organizaons may use this inventory to ensure that systems only process
the personally idenﬁable informaon for authorized purposes and that this processing is sll
relevant and necessary for the purpose speciﬁed therein.
Related controls: AC-3, CM-8, CM-12, CM-13, PL-8, PM-22, PT-3, PT-5, SI-12, SI-18.
References: [IR 8062], [OMB A-130]
PM-6 MEASURES OF PERFORMANCE
Control: Develop, monitor, and report on the results of informaon security and privacy measures of
performance.
Discussion: Measures of performance are outcome-based metrics used by an organizaon to measure
the eﬀecveness or eﬃciency of the informaon security and privacy programs and the controls
employed in support of the program. To facilitate security and privacy risk management, organizaons
consider aligning measures of performance with the organizaonal risk tolerance as deﬁned in the risk
management strategy.
Related controls: CA-7, PM-9.
References: [OMB A-130], [SP 800-137], [SP 800-37], [SP 800-39], [SP 800-55]
PM-7 ENTERPRISE ARCHITECTURE
Control: Develop and maintain an enterprise architecture with consideraon for informaon security,
privacy, and the resulng risk to organizaonal operaons and assets, individuals, other organizaons,
and the Naon.
Discussion: The integraon of security and privacy requirements and controls into the enterprise
architecture helps to ensure that security and privacy consideraons are addressed throughout the
system development life cycle and are explicitly related to the organizaon’s mission and business
processes. The process of security and privacy requirements integraon also embeds into the
enterprise architecture and the organizaon’s security and privacy architectures consistent with the
organizaonal risk management strategy. For PM-7, security and privacy architectures are developed
at a system-of-systems level, represenng all organizaonal systems. For PL-8, the security and
privacy architectures are developed at a level that represents an individual system. The system-level
architectures are consistent with the security and privacy architectures deﬁned for the organizaon.
Security and privacy requirements and control integraon are most eﬀecvely accomplished through
the rigorous applicaon of the Risk Management Framework SP 800-37 and supporng security
standards and guidelines.
Related controls: AU-6, PL-2, PL-8, PM-11, RA-2, SA-3, SA-8, SA-17.
(1) ENTERPRISE ARCHITECTURE | OFFLOADING
Oﬄoad [Assignment: organizaon-deﬁned non-essenal funcons or services] to other
systems, system components, or an external provider.
Discussion: Not every funcon or service that a system provides is essenal to organizaonal
mission or business funcons. Prinng or copying is an example of a non-essenal but
supporng service for an organizaon. Whenever feasible, such supporve but non-essenal
funcons or services are not co-located with the funcons or services that support essenal
mission or business funcons. Maintaining such funcons on the same system or system
component increases the aack surface of the organizaon’s mission-essenal funcons
or services. Moving supporve but non-essenal funcons to a non-crical system, system
component, or external provider can also increase eﬃciency by pung those funcons or
This document is produced from OSCAL source data
FAMILY: PM PAGE 194NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
services under the control of individuals or providers who are subject maer experts in the
funcons or services.
Related control: SA-8.
References: [OMB A-130], [SP 800-160-1], [SP 800-160-2], [SP 800-37], [SP 800-39]
PM-8 CRITICAL INFRASTRUCTURE PLAN
Control: Address informaon security and privacy issues in the development, documentaon, and
updang of a crical infrastructure and key resources protecon plan.
Discussion: Protecon strategies are based on the priorizaon of crical assets and resources. The
requirement and guidance for deﬁning crical infrastructure and key resources and for preparing
an associated crical infrastructure protecon plan are found in applicable laws, execuve orders,
direcves, policies, regulaons, standards, and guidelines.
Related controls: CP-2, CP-4, PE-18, PL-2, PM-9, PM-11, PM-18, RA-3, SI-12.
References: [DHS NIPP], [EO 13636], [HSPD 7], [OMB A-130]
PM-9 RISK MANAGEMENT STRATEGY
Control:
a. Develops a comprehensive strategy to manage:
1. Security risk to organizaonal operaons and assets, individuals, other organizaons, and
the Naon associated with the operaon and use of organizaonal systems; and
2. Privacy risk to individuals resulng from the authorized processing of personally idenﬁable
informaon;
b. Implement the risk management strategy consistently across the organizaon; and
c. Review and update the risk management strategy [Assignment: organizaon-deﬁned frequency]
or as required, to address organizaonal changes.
Discussion: An organizaon-wide risk management strategy includes an expression of the security
and privacy risk tolerance for the organizaon, security and privacy risk migaon strategies,
acceptable risk assessment methodologies, a process for evaluang security and privacy risk across
the organizaon with respect to the organizaon’s risk tolerance, and approaches for monitoring
risk over me. The senior accountable oﬃcial for risk management (agency head or designated
oﬃcial) aligns informaon security management processes with strategic, operaonal, and budgetary
planning processes. The risk execuve funcon, led by the senior accountable oﬃcial for risk
management, can facilitate consistent applicaon of the risk management strategy organizaon-wide.
The risk management strategy can be informed by security and privacy risk-related inputs from other
sources, both internal and external to the organizaon, to ensure that the strategy is broad-based
and comprehensive. The supply chain risk management strategy described in PM-30 can also provide
useful inputs to the organizaon-wide risk management strategy.
Related controls: AC-1, AT-1, AU-1, CA-1, CA-2, CA-5, CA-6, CA-7, CM-1, CP-1, IA-1, IR-1, MA-1, MP-1,
PE-1, PL-1, PL-2, PM-2, PM-8, PM-18, PM-28, PM-30, PS-1, PT-1, PT-2, PT-3, RA-1, RA-3, RA-9, SA-1,
SA-4, SC-1, SC-38, SI-1, SI-12, SR-1, SR-2.
References: [IR 8023], [OMB A-130], [SP 800-161], [SP 800-30], [SP 800-37], [SP 800-39]
This document is produced from OSCAL source data
FAMILY: PM PAGE 195NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
PM-10 AUTHORIZATION PROCESS
Control:
a. Manage the security and privacy state of organizaonal systems and the environments in which
those systems operate through authorizaon processes;
b. Designate individuals to fulﬁll speciﬁc roles and responsibilies within the organizaonal risk
management process; and
c. Integrate the authorizaon processes into an organizaon-wide risk management program.
Discussion: Authorizaon processes for organizaonal systems and environments of operaon require
the implementaon of an organizaon-wide risk management process and associated security
and privacy standards and guidelines. Speciﬁc roles for risk management processes include a risk
execuve (funcon) and designated authorizing oﬃcials for each organizaonal system and common
control provider. The authorizaon processes for the organizaon are integrated with connuous
monitoring processes to facilitate ongoing understanding and acceptance of security and privacy risks
to organizaonal operaons, organizaonal assets, individuals, other organizaons, and the Naon.
Related controls: CA-6, CA-7, PL-2.
References: [SP 800-181], [SP 800-37], [SP 800-39]
PM-11 MISSION AND BUSINESS PROCESS DEFINITION
Control:
a. Deﬁne organizaonal mission and business processes with consideraon for informaon security
and privacy and the resulng risk to organizaonal operaons, organizaonal assets, individuals,
other organizaons, and the Naon; and
b. Determine informaon protecon and personally idenﬁable informaon processing needs
arising from the deﬁned mission and business processes; and
c. Review and revise the mission and business processes [Assignment: organizaon-deﬁned
frequency].
Discussion: Protecon needs are technology-independent capabilies that are required to counter
threats to organizaons, individuals, systems, and the Naon through the compromise of informaon
(i.e., loss of conﬁdenality, integrity, availability, or privacy). Informaon protecon and personally
idenﬁable informaon processing needs are derived from the mission and business needs deﬁned
by organizaonal stakeholders, the mission and business processes designed to meet those needs,
and the organizaonal risk management strategy. Informaon protecon and personally idenﬁable
informaon processing needs determine the required controls for the organizaon and the systems.
Inherent to deﬁning protecon and personally idenﬁable informaon processing needs is an
understanding of the adverse impact that could result if a compromise or breach of informaon
occurs. The categorizaon process is used to make such potenal impact determinaons. Privacy
risks to individuals can arise from the compromise of personally idenﬁable informaon, but they
can also arise as unintended consequences or a byproduct of the processing of personally idenﬁable
informaon at any stage of the informaon life cycle. Privacy risk assessments are used to priorize
the risks that are created for individuals from system processing of personally idenﬁable informaon.
These risk assessments enable the selecon of the required privacy controls for the organizaon and
systems. Mission and business process deﬁnions and the associated protecon requirements are
documented in accordance with organizaonal policies and procedures.
Related controls: CP-2, PL-2, PM-7, PM-8, RA-2, RA-3, RA-9, SA-2.
References: [FIPS 199], [OMB A-130], [SP 800-160-1], [SP 800-39], [SP 800-60-1], [SP 800-60-2]
This document is produced from OSCAL source data
FAMILY: PM PAGE 196NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
PM-12 INSIDER THREAT PROGRAM
Control: Implement an insider threat program that includes a cross-discipline insider threat incident
handling team.
Discussion: Organizaons that handle classiﬁed informaon are required, under Execuve Order
13587 EO 13587 and the Naonal Insider Threat Policy ODNI NITP, to establish insider threat
programs. The same standards and guidelines that apply to insider threat programs in classiﬁed
environments can also be employed eﬀecvely to improve the security of controlled unclassiﬁed
and other informaon in non-naonal security systems. Insider threat programs include controls to
detect and prevent malicious insider acvity through the centralized integraon and analysis of both
technical and nontechnical informaon to idenfy potenal insider threat concerns. A senior oﬃcial
is designated by the department or agency head as the responsible individual to implement and
provide oversight for the program. In addion to the centralized integraon and analysis capability,
insider threat programs require organizaons to prepare department or agency insider threat policies
and implementaon plans, conduct host-based user monitoring of individual employee acvies on
government-owned classiﬁed computers, provide insider threat awareness training to employees,
receive access to informaon from oﬃces in the department or agency for insider threat analysis, and
conduct self-assessments of department or agency insider threat posture.
Insider threat programs can leverage the existence of incident handling teams that organizaons may
already have in place, such as computer security incident response teams. Human resources records
are especially important in this eﬀort, as there is compelling evidence to show that some types of
insider crimes are oen preceded by nontechnical behaviors in the workplace, including ongoing
paerns of disgruntled behavior and conﬂicts with coworkers and other colleagues. These precursors
can guide organizaonal oﬃcials in more focused, targeted monitoring eﬀorts. However, the use of
human resource records could raise signiﬁcant concerns for privacy. The parcipaon of a legal team,
including consultaon with the senior agency oﬃcial for privacy, ensures that monitoring acvies
are performed in accordance with applicable laws, execuve orders, direcves, regulaons, policies,
standards, and guidelines.
Related controls: AC-6, AT-2, AU-6, AU-7, AU-10, AU-12, AU-13, CA-7, IA-4, IR-4, MP-7, PE-2, PM-14,
PM-16, PS-3, PS-4, PS-5, PS-7, PS-8, SC-7, SC-38, SI-4.
References: [EO 13587], [NITP12], [ODNI NITP]
PM-13 SECURITY AND PRIVACY WORKFORCE
Control: Establish a security and privacy workforce development and improvement program.
Discussion: Security and privacy workforce development and improvement programs include
deﬁning the knowledge, skills, and abilies needed to perform security and privacy dues and
tasks; developing role-based training programs for individuals assigned security and privacy roles
and responsibilies; and providing standards and guidelines for measuring and building individual
qualiﬁcaons for incumbents and applicants for security- and privacy-related posions. Such
workforce development and improvement programs can also include security and privacy career
paths to encourage security and privacy professionals to advance in the ﬁeld and ﬁll posions with
greater responsibility. The programs encourage organizaons to ﬁll security- and privacy-related
posions with qualiﬁed personnel. Security and privacy workforce development and improvement
programs are complementary to organizaonal security awareness and training programs and focus
on developing and instuonalizing the core security and privacy capabilies of personnel needed to
protect organizaonal operaons, assets, and individuals.
Related controls: AT-2, AT-3.
References: [OMB A-130], [SP 800-181]
This document is produced from OSCAL source data
FAMILY: PM PAGE 197NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
PM-14 TESTING, TRAINING, AND MONITORING
Control:
a. Implement a process for ensuring that organizaonal plans for conducng security and privacy
tesng, training, and monitoring acvies associated with organizaonal systems:
1. Are developed and maintained; and
2. Connue to be executed; and
b. Review tesng, training, and monitoring plans for consistency with the organizaonal risk
management strategy and organizaon-wide priories for risk response acons.
Discussion: A process for organizaon-wide security and privacy tesng, training, and monitoring
helps ensure that organizaons provide oversight for tesng, training, and monitoring acvies
and that those acvies are coordinated. With the growing importance of connuous monitoring
programs, the implementaon of informaon security and privacy across the three levels of the risk
management hierarchy and the widespread use of common controls, organizaons coordinate and
consolidate the tesng and monitoring acvies that are rounely conducted as part of ongoing
assessments supporng a variety of controls. Security and privacy training acvies, while focused
on individual systems and speciﬁc roles, require coordinaon across all organizaonal elements.
Tesng, training, and monitoring plans and acvies are informed by current threat and vulnerability
assessments.
Related controls: AT-2, AT-3, CA-7, CP-4, IR-3, PM-12, SI-4.
References: [OMB A-130], [SP 800-115], [SP 800-137], [SP 800-37], [SP 800-39], [SP 800-53A]
PM-15 SECURITY AND PRIVACY GROUPS AND ASSOCIATIONS
Control: Establish and instuonalize contact with selected groups and associaons within the security
and privacy communies:
a. To facilitate ongoing security and privacy educaon and training for organizaonal personnel;
b. To maintain currency with recommended security and privacy pracces, techniques, and
technologies; and
c. To share current security and privacy informaon, including threats, vulnerabilies, and
incidents.
Discussion: Ongoing contact with security and privacy groups and associaons is important in an
environment of rapidly changing technologies and threats. Groups and associaons include special
interest groups, professional associaons, forums, news groups, users’ groups, and peer groups
of security and privacy professionals in similar organizaons. Organizaons select security and
privacy groups and associaons based on mission and business funcons. Organizaons share threat,
vulnerability, and incident informaon as well as contextual insights, compliance techniques, and
privacy problems consistent with applicable laws, execuve orders, direcves, policies, regulaons,
standards, and guidelines.
Related controls: SA-11, SI-5.
Reference: [OMB A-130]
PM-16 THREAT AWARENESS PROGRAM
Control: Implement a threat awareness program that includes a cross-organizaon informaon-sharing
capability for threat intelligence.
This document is produced from OSCAL source data
FAMILY: PM PAGE 198NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
Discussion: Because of the constantly changing and increasing sophiscaon of adversaries, especially
the advanced persistent threat (APT), it may be more likely that adversaries can successfully breach
or compromise organizaonal systems. One of the best techniques to address this concern is for
organizaons to share threat informaon, including threat events (i.e., taccs, techniques, and
procedures) that organizaons have experienced, migaons that organizaons have found are
eﬀecve against certain types of threats, and threat intelligence (i.e., indicaons and warnings about
threats). Threat informaon sharing may be bilateral or mullateral. Bilateral threat sharing includes
government-to-commercial and government-to-government cooperaves. Mullateral threat sharing
includes organizaons taking part in threat-sharing consora. Threat informaon may require special
agreements and protecon, or it may be freely shared.
Related controls: IR-4, PM-12.
(1) THREAT AWARENESS PROGRAM | AUTOMATED MEANS FOR SHARING THREAT
INTELLIGENCE
Employ automated mechanisms to maximize the eﬀecveness of sharing threat intelligence
informaon.
Discussion: To maximize the eﬀecveness of monitoring, it is important to know what threat
observables and indicators the sensors need to be searching for. By using well-established
frameworks, services, and automated tools, organizaons improve their ability to rapidly share
and feed the relevant threat detecon signatures into monitoring tools.
References: None
PM-17 PROTECTING CONTROLLED UNCLASSIFIED INFORMATION ON EXTERNAL SYSTEMS
Control:
a. Establish policy and procedures to ensure that requirements for the protecon of controlled
unclassiﬁed informaon that is processed, stored or transmied on external systems, are
implemented in accordance with applicable laws, execuve orders, direcves, policies,
regulaons, and standards; and
b. Review and update the policy and procedures [Assignment: organizaon-deﬁned frequency].
Discussion: Controlled unclassiﬁed informaon is deﬁned by the Naonal Archives and Records
Administraon along with the safeguarding and disseminaon requirements for such informaon and
is codiﬁed in 32 CFR 2002 and, speciﬁcally for systems external to the federal organizaon, 32 CFR
2002.14h. The policy prescribes the speciﬁc use and condions to be implemented in accordance with
organizaonal procedures, including via its contracng processes.
Related controls: CA-6, PM-10.
References: [32 CFR 2002], [NARA CUI], [SP 800-171], [SP 800-172]
This document is produced from OSCAL source data
FAMILY: PM PAGE 199NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
PM-18 PRIVACY PROGRAM PLAN
Control:
a. Develop and disseminate an organizaon-wide privacy program plan that provides an overview
of the agency’s privacy program, and:
1. Includes a descripon of the structure of the privacy program and the resources dedicated
to the privacy program;
2. Provides an overview of the requirements for the privacy program and a descripon of
the privacy program management controls and common controls in place or planned for
meeng those requirements;
3. Includes the role of the senior agency oﬃcial for privacy and the idenﬁcaon and
assignment of roles of other privacy oﬃcials and staﬀ and their responsibilies;
4. Describes management commitment, compliance, and the strategic goals and objecves of
the privacy program;
5. Reﬂects coordinaon among organizaonal enes responsible for the diﬀerent aspects of
privacy; and
6. Is approved by a senior oﬃcial with responsibility and accountability for the privacy risk
being incurred to organizaonal operaons (including mission, funcons, image, and
reputaon), organizaonal assets, individuals, other organizaons, and the Naon; and
b. Update the plan [Assignment: organizaon-deﬁned frequency] and to address changes in
federal privacy laws and policy and organizaonal changes and problems idenﬁed during plan
implementaon or privacy control assessments.
Discussion: A privacy program plan is a formal document that provides an overview of an organizaon’s
privacy program, including a descripon of the structure of the privacy program, the resources
dedicated to the privacy program, the role of the senior agency oﬃcial for privacy and other privacy
oﬃcials and staﬀ, the strategic goals and objecves of the privacy program, and the program
management controls and common controls in place or planned for meeng applicable privacy
requirements and managing privacy risks. Privacy program plans can be represented in single
documents or compilaons of documents.
The senior agency oﬃcial for privacy is responsible for designang which privacy controls the
organizaon will treat as program management, common, system-speciﬁc, and hybrid controls.
Privacy program plans provide suﬃcient informaon about the privacy program management and
common controls (including the speciﬁcaon of parameters and assignment and selecon operaons
explicitly or by reference) to enable control implementaons that are unambiguously compliant
with the intent of the plans and a determinaon of the risk incurred if the plans are implemented as
intended.
Program management controls are generally implemented at the organizaon level and are essenal
for managing the organizaon’s privacy program. Program management controls are disnct
from common, system-speciﬁc, and hybrid controls because program management controls are
independent of any parcular informaon system. Together, the privacy plans for individual systems
and the organizaon-wide privacy program plan provide complete coverage for the privacy controls
employed within the organizaon.
Common controls are documented in an appendix to the organizaon’s privacy program plan unless
the controls are included in a separate privacy plan for a system. The organizaon-wide privacy
program plan indicates which separate privacy plans contain descripons of privacy controls.
Related controls: PM-8, PM-9, PM-19.
This document is produced from OSCAL source data
FAMILY: PM PAGE 200NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
References: [OMB A-130], [PRIVACT]
PM-19 PRIVACY PROGRAM LEADERSHIP ROLE
Control: Appoint a senior agency oﬃcial for privacy with the authority, mission, accountability, and
resources to coordinate, develop, and implement, applicable privacy requirements and manage
privacy risks through the organizaon-wide privacy program.
Discussion: The privacy oﬃcer is an organizaonal oﬃcial. For federal agencies—as deﬁned by
applicable laws, execuve orders, direcves, regulaons, policies, standards, and guidelines—this
oﬃcial is designated as the senior agency oﬃcial for privacy. Organizaons may also refer to this
oﬃcial as the chief privacy oﬃcer. The senior agency oﬃcial for privacy also has roles on the data
management board (see PM-23) and the data integrity board (see PM-24).
Related controls: PM-18, PM-20, PM-23, PM-24, PM-27.
Reference: [OMB A-130]
PM-20 DISSEMINATION OF PRIVACY PROGRAM INFORMATION
Control: Maintain a central resource webpage on the organizaon’s principal public website that
serves as a central source of informaon about the organizaon’s privacy program and that:
a. Ensures that the public has access to informaon about organizaonal privacy acvies and can
communicate with its senior agency oﬃcial for privacy;
b. Ensures that organizaonal privacy pracces and reports are publicly available; and
c. Employs publicly facing email addresses and/or phone lines to enable the public to provide
feedback and/or direct quesons to privacy oﬃces regarding privacy pracces.
Discussion: For federal agencies, the webpage is located at www.[agency].gov/privacy. Federal agencies
include public privacy impact assessments, system of records noces, computer matching noces
and agreements, PRIVACT exempon and implementaon rules, privacy reports, privacy policies,
instrucons for individuals making an access or amendment request, email addresses for quesons/
complaints, blogs, and periodic publicaons.
Related controls: AC-3, PM-19, PT-5, PT-6, PT-7, RA-8.
(1) DISSEMINATION OF PRIVACY PROGRAM INFORMATION | PRIVACY POLICIES ON
WEBSITES, APPLICATIONS, AND DIGITAL SERVICES
Develop and post privacy policies on all external-facing websites, mobile applicaons, and
other digital services, that:
(a) Are wrien in plain language and organized in a way that is easy to understand and
navigate;
(b) Provide informaon needed by the public to make an informed decision about whether
and how to interact with the organizaon; and
(c) Are updated whenever the organizaon makes a substanve change to the pracces it
describes and includes a me/date stamp to inform the public of the date of the most
recent changes.
Discussion: Organizaons post privacy policies on all external-facing websites, mobile
applicaons, and other digital services. Organizaons post a link to the relevant privacy policy
on any known, major entry points to the website, applicaon, or digital service. In addion,
organizaons provide a link to the privacy policy on any webpage that collects personally
This document is produced from OSCAL source data
FAMILY: PM PAGE 201NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
idenﬁable informaon. Organizaons may be subject to applicable laws, execuve orders,
direcves, regulaons, or policies that require the provision of speciﬁc informaon to the public.
Organizaonal personnel consult with the senior agency oﬃcial for privacy and legal counsel
regarding such requirements.
References: [OMB A-130], [OMB M-17-06], [PRIVACT]
PM-21 ACCOUNTING OF DISCLOSURES
Control:
a. Develop and maintain an accurate accounng of disclosures of personally idenﬁable
informaon, including:
1. Date, nature, and purpose of each disclosure; and
2. Name and address, or other contact informaon of the individual or organizaon to which
the disclosure was made;
b. Retain the accounng of disclosures for the length of the me the personally idenﬁable
informaon is maintained or ﬁve years aer the disclosure is made, whichever is longer; and
c. Make the accounng of disclosures available to the individual to whom the personally
idenﬁable informaon relates upon request.
Discussion: The purpose of accounng of disclosures is to allow individuals to learn to whom their
personally idenﬁable informaon has been disclosed, to provide a basis for subsequently advising
recipients of any corrected or disputed personally idenﬁable informaon, and to provide an audit
trail for subsequent reviews of organizaonal compliance with condions for disclosures. For federal
agencies, keeping an accounng of disclosures is required by the PRIVACT; agencies should consult
with their senior agency oﬃcial for privacy and legal counsel on this requirement and be aware of the
statutory excepons and OMB guidance relang to the provision.
Organizaons can use any system for keeping notaons of disclosures, if it can construct from such
a system, a document lisng of all disclosures along with the required informaon. Automated
mechanisms can be used by organizaons to determine when personally idenﬁable informaon
is disclosed, including commercial services that provide noﬁcaons and alerts. Accounng of
disclosures may also be used to help organizaons verify compliance with applicable privacy statutes
and policies governing the disclosure or disseminaon of informaon and disseminaon restricons.
Related controls: AC-3, AU-2, PT-2.
References: [OMB A-130], [PRIVACT]
PM-22 PERSONALLY IDENTIFIABLE INFORMATION QUALITY MANAGEMENT
Control: Develop and document organizaon-wide policies and procedures for:
a. Reviewing for the accuracy, relevance, meliness, and completeness of personally idenﬁable
informaon across the informaon life cycle;
b. Correcng or deleng inaccurate or outdated personally idenﬁable informaon;
c. Disseminang noce of corrected or deleted personally idenﬁable informaon to individuals or
other appropriate enes; and
d. Appeals of adverse decisions on correcon or deleon requests.
Discussion: Personally idenﬁable informaon quality management includes steps that organizaons
take to conﬁrm the accuracy and relevance of personally idenﬁable informaon throughout the
This document is produced from OSCAL source data
FAMILY: PM PAGE 202NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
informaon life cycle. The informaon life cycle includes the creaon, collecon, use, processing,
storage, maintenance, disseminaon, disclosure, and disposion of personally idenﬁable
informaon. Organizaonal policies and procedures for personally idenﬁable informaon quality
management are important because inaccurate or outdated personally idenﬁable informaon
maintained by organizaons may cause problems for individuals. Organizaons consider the quality of
personally idenﬁable informaon involved in business funcons where inaccurate informaon may
result in adverse decisions or the denial of beneﬁts and services, or the disclosure of the informaon
may cause sgmazaon. Correct informaon, in certain circumstances, can cause problems for
individuals that outweigh the beneﬁts of organizaons maintaining the informaon. Organizaons
consider creang policies and procedures for the removal of such informaon.
The senior agency oﬃcial for privacy ensures that praccal means and mechanisms exist and are
accessible for individuals or their authorized representaves to seek the correcon or deleon of
personally idenﬁable informaon. Processes for correcng or deleng data are clearly deﬁned
and publicly available. Organizaons use discreon in determining whether data is to be deleted
or corrected based on the scope of requests, the changes sought, and the impact of the changes.
Addionally, processes include the provision of responses to individuals of decisions to deny requests
for correcon or deleon. The responses include the reasons for the decisions, a means to record
individual objecons to the decisions, and a means of requesng reviews of the inial determinaons.
Organizaons nofy individuals or their designated representaves when their personally idenﬁable
informaon is corrected or deleted to provide transparency and conﬁrm the completed acon. Due to
the complexity of data ﬂows and storage, other enes may need to be informed of the correcon or
deleon. Noce supports the consistent correcon and deleon of personally idenﬁable informaon
across the data ecosystem.
Related controls: PM-23, SI-18.
References: [OMB A-130], [OMB M-19-15], [SP 800-188]
PM-23 DATA GOVERNANCE BODY
Control: Establish a Data Governance Body consisng of [Assignment: organizaon-deﬁned roles] with
[Assignment: organizaon-deﬁned responsibilies].
Discussion: A Data Governance Body can help ensure that the organizaon has coherent policies and
the ability to balance the ulity of data with security and privacy requirements. The Data Governance
Body establishes policies, procedures, and standards that facilitate data governance so that data,
including personally idenﬁable informaon, is eﬀecvely managed and maintained in accordance
with applicable laws, execuve orders, direcves, regulaons, policies, standards, and guidance.
Responsibilies can include developing and implemenng guidelines that support data modeling,
quality, integrity, and the de-idenﬁcaon needs of personally idenﬁable informaon across the
informaon life cycle as well as reviewing and approving applicaons to release data outside of
the organizaon, archiving the applicaons and the released data, and performing post-release
monitoring to ensure that the assumpons made as part of the data release connue to be valid.
Members include the chief informaon oﬃcer, senior agency informaon security oﬃcer, and senior
agency oﬃcial for privacy. Federal agencies are required to establish a Data Governance Body with
speciﬁc roles and responsibilies in accordance with the EVIDACT and policies set forth under OMB
M-19-23.
Related controls: AT-2, AT-3, PM-19, PM-22, PM-24, PT-7, SI-4, SI-19.
References: [EVIDACT], [OMB A-130], [OMB M-19-23], [SP 800-188]
This document is produced from OSCAL source data
FAMILY: PM PAGE 203NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
PM-24 DATA INTEGRITY BOARD
Control: Establish a Data Integrity Board to:
a. Review proposals to conduct or parcipate in a matching program; and
b. Conduct an annual review of all matching programs in which the agency has parcipated.
Discussion: A Data Integrity Board is the board of senior oﬃcials designated by the head of a federal
agency and is responsible for, among other things, reviewing the agency’s proposals to conduct or
parcipate in a matching program and conducng an annual review of all matching programs in which
the agency has parcipated. As a general maer, a matching program is a computerized comparison
of records from two or more automated PRIVACT systems of records or an automated system of
records and automated records maintained by a non-federal agency (or agent thereof). A matching
program either pertains to Federal beneﬁt programs or Federal personnel or payroll records. At a
minimum, the Data Integrity Board includes the Inspector General of the agency, if any, and the senior
agency oﬃcial for privacy.
Related controls: AC-4, PM-19, PM-23, PT-2, PT-8.
References: [OMB A-108], [OMB A-130], [PRIVACT]
PM-25 MINIMIZATION OF PERSONALLY IDENTIFIABLE INFORMATION USED IN TESTING, TRAINING,
AND RESEARCH
Control:
a. Develop, document, and implement policies and procedures that address the use of personally
idenﬁable informaon for internal tesng, training, and research;
b. Limit or minimize the amount of personally idenﬁable informaon used for internal tesng,
training, and research purposes;
c. Authorize the use of personally idenﬁable informaon when such informaon is required for
internal tesng, training, and research; and
d. Review and update policies and procedures [Assignment: organizaon-deﬁned frequency].
Discussion: The use of personally idenﬁable informaon in tesng, research, and training increases
the risk of unauthorized disclosure or misuse of such informaon. Organizaons consult with the
senior agency oﬃcial for privacy and/or legal counsel to ensure that the use of personally idenﬁable
informaon in tesng, training, and research is compable with the original purpose for which it
was collected. When possible, organizaons use placeholder data to avoid exposure of personally
idenﬁable informaon when conducng tesng, training, and research.
Related controls: PM-23, PT-3, SA-3, SA-8, SI-12.
Reference: [OMB A-130]
PM-26 COMPLAINT MANAGEMENT
Control: Implement a process for receiving and responding to complaints, concerns, or quesons from
individuals about the organizaonal security and privacy pracces that includes:
a. Mechanisms that are easy to use and readily accessible by the public;
b. All informaon necessary for successfully ﬁling complaints;
c. Tracking mechanisms to ensure all complaints received are reviewed and addressed within
[Assignment: organizaon-deﬁned me period];
This document is produced from OSCAL source data
FAMILY: PM PAGE 204NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
d. Acknowledgement of receipt of complaints, concerns, or quesons from individuals within
[Assignment: organizaon-deﬁned me period]; and
e. Response to complaints, concerns, or quesons from individuals within [Assignment:
organizaon-deﬁned me period].
Discussion: Complaints, concerns, and quesons from individuals can serve as valuable sources of
input to organizaons and ulmately improve operaonal models, uses of technology, data collecon
pracces, and controls. Mechanisms that can be used by the public include telephone hotline,
email, or web-based forms. The informaon necessary for successfully ﬁling complaints includes
contact informaon for the senior agency oﬃcial for privacy or other oﬃcial designated to receive
complaints. Privacy complaints may also include personally idenﬁable informaon which is handled
in accordance with relevant policies and processes.
Related controls: IR-7, IR-9, PM-22, SI-18.
Reference: [OMB A-130]
PM-27 PRIVACY REPORTING
Control:
a. Develop [Assignment: organizaon-deﬁned privacy reports] and disseminate to:
1. [Assignment: organizaon-deﬁned oversight bodies] to demonstrate accountability with
statutory, regulatory, and policy privacy mandates; and
2. [Assignment: organizaon-deﬁned oﬃcials] and other personnel with responsibility for
monitoring privacy program compliance; and
b. Review and update privacy reports [Assignment: organizaon-deﬁned frequency].
Discussion: Through internal and external reporng, organizaons promote accountability and
transparency in organizaonal privacy operaons. Reporng can also help organizaons to determine
progress in meeng privacy compliance requirements and privacy controls, compare performance
across the federal government, discover vulnerabilies, idenfy gaps in policy and implementaon,
and idenfy models for success. For federal agencies, privacy reports include annual senior agency
oﬃcial for privacy reports to OMB, reports to Congress required by Implemenng Regulaons of
the 911 Commission Act, and other public reports required by law, regulaon, or policy, including
internal policies of organizaons. The senior agency oﬃcial for privacy consults with legal counsel,
where appropriate, to ensure that organizaons meet all applicable privacy reporng requirements.
Related controls: IR-9, PM-19.
References: [FISMA], [OMB A-108], [OMB A-130]
PM-28 RISK FRAMING
Control:
a. Idenfy and document:
1. Assumpons aﬀecng risk assessments, risk responses, and risk monitoring;
2. Constraints aﬀecng risk assessments, risk responses, and risk monitoring;
3. Priories and trade-oﬀs considered by the organizaon for managing risk; and
4. Organizaonal risk tolerance;
This document is produced from OSCAL source data
FAMILY: PM PAGE 205NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP .800-53r5
b. Distribute the results of risk framing acvies to [Assignment: organizaon-deﬁned personnel];
and
c. Review and update risk framing consideraons [Assignment: organizaon-deﬁned frequency].
Discussion: Risk framing is most eﬀecve when conducted at the organizaon level and in consultaon
with stakeholders throughout the organizaon including mission, business, and system owners. The
assumpons, constraints, risk tolerance, priories, and trade-oﬀs idenﬁed as part of the risk framing
process inform the risk management strategy, which in turn informs the conduct of risk assessment,
risk response, and risk monitoring acvies. Risk framing results are shared with organizaonal
personnel, including mission and business owners, informaon owners or stewards, system owners,
authorizing oﬃcials, senior agency informaon security oﬃcer, senior agency oﬃcial for privacy, and
senior accountable oﬃcial for risk management.
Related controls
: CA-7, PM-9, RA-3, RA-7.
References: [OMB A-130], [SP 800-39]
PM-29 RISK MANAGEMENT PROGRAM LEADERSHIP ROLES
Control:
a. Appoint a Senior Accountable Oﬃcial for Risk Management to align organizaonal informaon
security and privacy management processes with strategic, operaonal, and budgetary planning
processes; and
b. Establish a Risk Execuve (funcon) to view and analyze risk from an organizaon-wide
perspecve and ensure management of risk is consistent across the organizaon.
Discussion: The senior accountable oﬃcial for risk management leads the risk execuve (funcon) in
organizaon-wide risk management acvies.
Related controls: PM-2, PM-19.
References: [SP 800-181], [SP 800-37]
PM-30 SUPPLY CHAIN RISK MANAGEMENT STRATEGY
Control:
a. Develop an organizaon-wide strategy for managing supply chain risks associated with the 
development, acquision, maintenance, and disposal of systems, system components, and 
system services;
b. Implement the supply chain risk management strategy consistently across the organizaon; and
c. Review and update the supply chain risk management strategy on [Assignment: organizaon-
deﬁned frequency] or as required, to address organizaonal changes.
Discussion: An organizaon-wide supply chain risk management strategy includes an unambiguous
expression of the supply chain risk appete and tolerance for the organizaon, acceptable supply
chain risk migaon strategies or controls, a process for consistently evaluang and monitoring supply
chain risk, approaches for implemenng and communicang the supply chain risk management
strategy, and the associated roles and responsibilies. Supply chain risk management includes
consideraons of the security and privacy risks associated with the development, acquision,
maintenance, and disposal of systems, system components, and system services. The supply
chain risk management strategy can be incorporated into the organizaon’s overarching risk
management strategy and can guide and inform supply chain policies and system-level supply chain
This document is produced from OSCAL source data
FAMILY: 
PM PAGE 206NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
risk management plans. In addion, the use of a risk execuve funcon can facilitate a consistent,
organizaon-wide applicaon of the supply chain risk management strategy. The supply chain risk
management strategy is implemented at the organizaon and mission/business levels, whereas the
supply chain risk management plan (see SR-2) is implemented at the system level.
Related controls: CM-10, PM-9, SR-1, SR-2, SR-3, SR-4, SR-5, SR-6, SR-7, SR-8, SR-9, SR-11.
(1) SUPPLY CHAIN RISK MANAGEMENT STRATEGY | SUPPLIERS OF CRITICAL OR MISSION-
ESSENTIAL ITEMS
Idenfy, priorize, and assess suppliers of crical or mission-essenal technologies, products,
and services.
Discussion: The idenﬁcaon and priorizaon of suppliers of crical or mission-essenal
technologies, products, and services is paramount to the mission/business success of
organizaons. The assessment of suppliers is conducted using supplier reviews (see SR-6) and
supply chain risk assessment processes (see RA-3(1)). An analysis of supply chain risk can help an
organizaon idenfy systems or components for which addional supply chain risk migaons
are required.
Related controls: RA-3, SR-6.
References: [41 CFR 201], [CNSSD 505], [EO 13873], [FASC18], [IR 8272], [ISO 20243], [ISO 27036],
[OMB A-130], [OMB M-17-06], [PRIVACT], [SP 800-161]
PM-31 CONTINUOUS MONITORING STRATEGY
Control: Develop an organizaon-wide connuous monitoring strategy and implement connuous
monitoring programs that include:
a. Establishing the following organizaon-wide metrics to be monitored: [Assignment: organizaon-
deﬁned metrics];
b. Establishing [Assignment: organizaon-deﬁned frequencies] for monitoring and [Assignment:
organizaon-deﬁned frequencies] for assessment of control eﬀecveness;
c. Ongoing monitoring of organizaonally-deﬁned metrics in accordance with the connuous
monitoring strategy;
d. Correlaon and analysis of informaon generated by control assessments and monitoring;
e. Response acons to address results of the analysis of control assessment and monitoring
informaon; and
f. Reporng the security and privacy status of organizaonal systems to [Assignment: organizaon-
deﬁned personnel or roles] [Assignment: organizaon-deﬁned frequency].
Discussion: Connuous monitoring at the organizaon level facilitates ongoing awareness of the
security and privacy posture across the organizaon to support organizaonal risk management
decisions. The terms connuous and ongoing imply that organizaons assess and monitor their
controls and risks at a frequency suﬃcient to support risk-based decisions. Diﬀerent types of controls
may require diﬀerent monitoring frequencies. The results of connuous monitoring guide and inform
risk response acons by organizaons. Connuous monitoring programs allow organizaons to
maintain the authorizaons of systems and common controls in highly dynamic environments of
operaon with changing mission and business needs, threats, vulnerabilies, and technologies.
Having access to security- and privacy-related informaon on a connuing basis through reports
and dashboards gives organizaonal oﬃcials the capability to make eﬀecve, mely, and informed
risk management decisions, including ongoing authorizaon decisions. To further facilitate security
This document is produced from OSCAL source data
FAMILY: PM PAGE 207NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
and privacy risk management, organizaons consider aligning organizaon-deﬁned monitoring
metrics with organizaonal risk tolerance as deﬁned in the risk management strategy. Monitoring
requirements, including the need for monitoring, may be referenced in other controls and control
enhancements such as, AC-2g, AC-2(7), AC-2(12)(a), AC-2(7)(b), AC-2(7)(c), AC-17(1), AT-4a, AU-13,
AU-13(1), AU-13(2), CA-7, CM-3f, CM-6d, CM-11c, IR-5, MA-2b, MA-3a, MA-4a, PE-3d, PE-6, PE-14b,
PE-16, PE-20, PM-6, PM-23, PS-7e, SA-9c, SC-5(3)(b), SC-7a, SC-7(24)(b), SC-18b, SC-43b, SI-4.
Related controls: AC-2, AC-6, AC-17, AT-4, AU-6, AU-13, CA-2, CA-5, CA-6, CA-7, CM-3, CM-4, CM-6,
CM-11, IA-5, IR-5, MA-2, MA-3, MA-4, PE-3, PE-6, PE-14, PE-16, PE-20, PL-2, PM-4, PM-6, PM-9,
PM-10, PM-12, PM-14, PM-23, PM-28, PS-7, PT-7, RA-3, RA-5, RA-7, SA-9, SA-11, SC-5, SC-7, SC-18,
SC-38, SC-43, SI-3, SI-4, SI-12, SR-2, SR-4.
References: [SP 800-137], [SP 800-137A], [SP 800-37], [SP 800-39]
PM-32 PURPOSING
Control: Analyze [Assignment: organizaon-deﬁned systems or systems components] supporng
mission essenal services or funcons to ensure that the informaon resources are being used
consistent with their intended purpose.
Discussion: Systems are designed to support a speciﬁc mission or business funcon. However, over
me, systems and system components may be used to support services and funcons that are outside
of the scope of the intended mission or business funcons. This can result in exposing informaon
resources to unintended environments and uses that can signiﬁcantly increase threat exposure. In
doing so, the systems are more vulnerable to compromise, which can ulmately impact the services
and funcons for which they were intended. This is especially impacul for mission-essenal services
and funcons. By analyzing resource use, organizaons can idenfy such potenal exposures.
Related controls: CA-7, PL-2, RA-3, RA-9.
References: [SP 800-160-1], [SP 800-160-2]
This document is produced from OSCAL source data
FAMILY: PM PAGE 208NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
FAMILY: PERSONNEL SECURITY
PS-1 POLICY AND PROCEDURES
Control:
a. Develop, document, and disseminate to [Assignment: organizaon-deﬁned personnel or roles]:
1. [Selecon (one or more): Organizaon-level; Mission/business process-level; System-level]
personnel security policy that:
(a) Addresses purpose, scope, roles, responsibilies, management commitment,
coordinaon among organizaonal enes, and compliance; and
(b) Is consistent with applicable laws, execuve orders, direcves, regulaons, policies,
standards, and guidelines; and
2. Procedures to facilitate the implementaon of the personnel security policy and the
associated personnel security controls;
b. Designate an [Assignment: organizaon-deﬁned oﬃcial] to manage the development,
documentaon, and disseminaon of the personnel security policy and procedures; and
c. Review and update the current personnel security:
1. Policy [Assignment: organizaon-deﬁned frequency] and following [Assignment:
organizaon-deﬁned events]; and
2. Procedures [Assignment: organizaon-deﬁned frequency] and following [Assignment:
organizaon-deﬁned events].
Discussion: Personnel security policy and procedures for the controls in the PS family that are
implemented within systems and organizaons. The risk management strategy is an important
factor in establishing such policies and procedures. Policies and procedures contribute to security
and privacy assurance. Therefore, it is important that security and privacy programs collaborate on
their development. Security and privacy program policies and procedures at the organizaon level
are preferable, in general, and may obviate the need for mission level or system-speciﬁc policies
and procedures. The policy can be included as part of the general security and privacy policy or be
represented by mulple policies reﬂecng the complex nature of organizaons. Procedures can be
established for security and privacy programs, for mission/business processes, and for systems, if
needed. Procedures describe how the policies or controls are implemented and can be directed at
the individual or role that is the object of the procedure. Procedures can be documented in system
security and privacy plans or in one or more separate documents. Events that may precipitate an
update to personnel security policy and procedures include, but are not limited to, assessment
or audit ﬁndings, security incidents or breaches, or changes in applicable laws, execuve orders,
direcves, regulaons, policies, standards, and guidelines. Simply restang controls does not
constute an organizaonal policy or procedure.
Related controls: PM-9, PS-8, SI-12.
References: [SP 800-100], [SP 800-12], [SP 800-30], [SP 800-39]
PS-2 POSITION RISK DESIGNATION
Control:
a. Assign a risk designaon to all organizaonal posions;
b. Establish screening criteria for individuals ﬁlling those posions; and
c. Review and update posion risk designaons [Assignment: organizaon-deﬁned frequency].
This document is produced from OSCAL source data
FAMILY: PS PAGE 209NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
Discussion: Posion risk designaons reﬂect Oﬃce of Personnel Management (OPM) policy and
guidance. Proper posion designaon is the foundaon of an eﬀecve and consistent suitability
and personnel security program. The Posion Designaon System (PDS) assesses the dues and
responsibilies of a posion to determine the degree of potenal damage to the eﬃciency or integrity
of the service due to misconduct of an incumbent of a posion and establishes the risk level of
that posion. The PDS assessment also determines if the dues and responsibilies of the posion
present the potenal for posion incumbents to bring about a material adverse eﬀect on naonal
security and the degree of that potenal eﬀect, which establishes the sensivity level of a posion.
The results of the assessment determine what level of invesgaon is conducted for a posion. Risk
designaons can guide and inform the types of authorizaons that individuals receive when accessing
organizaonal informaon and informaon systems. Posion screening criteria include explicit
informaon security role appointment requirements. Parts 1400 and 731 of Title 5, Code of Federal
Regulaons, establish the requirements for organizaons to evaluate relevant covered posions for a
posion sensivity and posion risk designaon commensurate with the dues and responsibilies of
those posions.
Related controls: AC-5, AT-3, PE-2, PE-3, PL-2, PS-3, PS-6, SA-5, SA-21, SI-12.
References: [5 CFR 731], [SP 800-181]
PS-3 PERSONNEL SCREENING
Control:
a. Screen individuals prior to authorizing access to the system; and
b. Rescreen individuals in accordance with [Assignment: organizaon-deﬁned condions requiring
rescreening and, where rescreening is so indicated, the frequency of rescreening].
Discussion: Personnel screening and rescreening acvies reﬂect applicable laws, execuve orders,
direcves, regulaons, policies, standards, guidelines, and speciﬁc criteria established for the
risk designaons of assigned posions. Examples of personnel screening include background
invesgaons and agency checks. Organizaons may deﬁne diﬀerent rescreening condions and
frequencies for personnel accessing systems based on types of informaon processed, stored, or
transmied by the systems.
Related controls: AC-2, IA-4, MA-5, PE-2, PM-12, PS-2, PS-6, PS-7, SA-21.
(1) PERSONNEL SCREENING | CLASSIFIED INFORMATION
Verify that individuals accessing a system processing, storing, or transming classiﬁed
informaon are cleared and indoctrinated to the highest classiﬁcaon level of the informaon
to which they have access on the system.
Discussion: Classiﬁed informaon is the most sensive informaon that the Federal Government
processes, stores, or transmits. It is imperave that individuals have the requisite security
clearances and system access authorizaons prior to gaining access to such informaon. Access
authorizaons are enforced by system access controls (see AC-3) and ﬂow controls (see AC-4).
Related controls: AC-3, AC-4.
This document is produced from OSCAL source data
FAMILY: PS PAGE 210NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(2) PERSONNEL SCREENING | FORMAL INDOCTRINATION
Verify that individuals accessing a system processing, storing, or transming types of
classiﬁed informaon that require formal indoctrinaon, are formally indoctrinated for all the
relevant types of informaon to which they have access on the system.
Discussion: Types of classiﬁed informaon that require formal indoctrinaon include Special
Access Program (SAP), Restricted Data (RD), and Sensive Compartmented Informaon (SCI).
Related controls: AC-3, AC-4.
(3) PERSONNEL SCREENING | INFORMATION REQUIRING SPECIAL PROTECTIVE MEASURES
Verify that individuals accessing a system processing, storing, or transming informaon
requiring special protecon:
(a) Have valid access authorizaons that are demonstrated by assigned oﬃcial government
dues; and
(b) Sasfy [Assignment: organizaon-deﬁned addional personnel screening criteria].
Discussion: Organizaonal informaon that requires special protecon includes controlled
unclassiﬁed informaon. Personnel security criteria include posion sensivity background
screening requirements.
(4) PERSONNEL SCREENING | CITIZENSHIP REQUIREMENTS
Verify that individuals accessing a system processing, storing, or transming [Assignment:
organizaon-deﬁned informaon types] meet [Assignment: organizaon-deﬁned cizenship
requirements].
Discussion: None.
References: [EO 13526], [EO 13587], [FIPS 199], [FIPS 201-2], [SP 800-60-1], [SP 800-60-2], [SP
800-73-4], [SP 800-76-2], [SP 800-78-4]
PS-4 PERSONNEL TERMINATION
Control: Upon terminaon of individual employment:
a. Disable system access within [Assignment: organizaon-deﬁned me period];
b. Terminate or revoke any authencators and credenals associated with the individual;
c. Conduct exit interviews that include a discussion of [Assignment: organizaon-deﬁned
informaon security topics];
d. Retrieve all security-related organizaonal system-related property; and
e. Retain access to organizaonal informaon and systems formerly controlled by terminated
individual.
Discussion: System property includes hardware authencaon tokens, system administraon technical
manuals, keys, idenﬁcaon cards, and building passes. Exit interviews ensure that terminated
individuals understand the security constraints imposed by being former employees and that proper
accountability is achieved for system-related property. Security topics at exit interviews include
reminding individuals of nondisclosure agreements and potenal limitaons on future employment.
Exit interviews may not always be possible for some individuals, including in cases related to the
unavailability of supervisors, illnesses, or job abandonment. Exit interviews are important for
This document is produced from OSCAL source data
FAMILY: PS PAGE 211NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
individuals with security clearances. The mely execuon of terminaon acons is essenal for
individuals who have been terminated for cause. In certain situaons, organizaons consider disabling
the system accounts of individuals who are being terminated prior to the individuals being noﬁed.
Related controls: AC-2, IA-4, PE-2, PM-12, PS-6, PS-7.
(1) PERSONNEL TERMINATION | POST-EMPLOYMENT REQUIREMENTS
(a) Nofy terminated individuals of applicable, legally binding post-employment
requirements for the protecon of organizaonal informaon; and
(b) Require terminated individuals to sign an acknowledgment of post-employment
requirements as part of the organizaonal terminaon process.
Discussion: Organizaons consult with the Oﬃce of the General Counsel regarding maers of
post-employment requirements on terminated individuals.
(2) PERSONNEL TERMINATION | AUTOMATED ACTIONS
Use [Assignment: organizaon-deﬁned automated mechanisms] to [Selecon (one or more):
nofy [Assignment: organizaon-deﬁned personnel or roles] of individual terminaon acons;
disable access to system resources].
Discussion: In organizaons with many employees, not all personnel who need to know about
terminaon acons receive the appropriate noﬁcaons, or if such noﬁcaons are received,
they may not occur in a mely manner. Automated mechanisms can be used to send automac
alerts or noﬁcaons to organizaonal personnel or roles when individuals are terminated. Such
automac alerts or noﬁcaons can be conveyed in a variety of ways, including via telephone,
electronic mail, text message, or websites. Automated mechanisms can also be employed to
quickly and thoroughly disable access to system resources aer an employee is terminated.
References: None
PS-5 PERSONNEL TRANSFER
Control:
a. Review and conﬁrm ongoing operaonal need for current logical and physical access
authorizaons to systems and facilies when individuals are reassigned or transferred to other
posions within the organizaon;
b. Iniate [Assignment: organizaon-deﬁned transfer or reassignment acons] within [Assignment:
organizaon-deﬁned me period following the formal transfer acon];
c. Modify access authorizaon as needed to correspond with any changes in operaonal need due
to reassignment or transfer; and
d. Nofy [Assignment: organizaon-deﬁned personnel or roles] within [Assignment: organizaon-
deﬁned me period].
Discussion: Personnel transfer applies when reassignments or transfers of individuals are permanent or
of such extended duraon as to make the acons warranted. Organizaons deﬁne acons appropriate
for the types of reassignments or transfers, whether permanent or extended. Acons that may be
required for personnel transfers or reassignments to other posions within organizaons include
returning old and issuing new keys, idenﬁcaon cards, and building passes; closing system accounts
and establishing new accounts; changing system access authorizaons (i.e., privileges); and providing
This document is produced from OSCAL source data
FAMILY: PS PAGE 212NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
for access to oﬃcial records to which individuals had access at previous work locaons and in previous
system accounts.
Related controls: AC-2, IA-4, PE-2, PM-12, PS-4, PS-7.
References: None
PS-6 ACCESS AGREEMENTS
Control:
a. Develop and document access agreements for organizaonal systems;
b. Review and update the access agreements [Assignment: organizaon-deﬁned frequency]; and
c. Verify that individuals requiring access to organizaonal informaon and systems:
1. Sign appropriate access agreements prior to being granted access; and
2. Re-sign access agreements to maintain access to organizaonal systems when access
agreements have been updated or [Assignment: organizaon-deﬁned frequency].
Discussion: Access agreements include nondisclosure agreements, acceptable use agreements, rules of
behavior, and conﬂict-of-interest agreements. Signed access agreements include an acknowledgement
that individuals have read, understand, and agree to abide by the constraints associated with
organizaonal systems to which access is authorized. Organizaons can use electronic signatures to
acknowledge access agreements unless speciﬁcally prohibited by organizaonal policy.
Related controls: AC-17, PE-2, PL-4, PS-2, PS-3, PS-6, PS-7, PS-8, SA-21, SI-12.
(1) ACCESS AGREEMENTS | INFORMATION REQUIRING SPECIAL PROTECTION
[Withdrawn: Incorporated into PS-3.]
(2) ACCESS AGREEMENTS | CLASSIFIED INFORMATION REQUIRING SPECIAL PROTECTION
Verify that access to classiﬁed informaon requiring special protecon is granted only to
individuals who:
(a) Have a valid access authorizaon that is demonstrated by assigned oﬃcial government
dues;
(b) Sasfy associated personnel security criteria; and
(c) Have read, understood, and signed a nondisclosure agreement.
Discussion: Classiﬁed informaon that requires special protecon includes collateral informaon,
Special Access Program (SAP) informaon, and Sensive Compartmented Informaon (SCI).
Personnel security criteria reﬂect applicable laws, execuve orders, direcves, regulaons,
policies, standards, and guidelines.
(3) ACCESS AGREEMENTS | POST-EMPLOYMENT REQUIREMENTS
(a) Nofy individuals of applicable, legally binding post-employment requirements for
protecon of organizaonal informaon; and
(b) Require individuals to sign an acknowledgment of these requirements, if applicable, as
part of granng inial access to covered informaon.
Discussion: Organizaons consult with the Oﬃce of the General Counsel regarding maers of
post-employment requirements on terminated individuals.
This document is produced from OSCAL source data
FAMILY: PS PAGE 213NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
Related control: PS-4.
References: None
PS-7 EXTERNAL PERSONNEL SECURITY
Control:
a. Establish personnel security requirements, including security roles and responsibilies for
external providers;
b. Require external providers to comply with personnel security policies and procedures established
by the organizaon;
c. Document personnel security requirements;
d. Require external providers to nofy [Assignment: organizaon-deﬁned personnel or roles] of any
personnel transfers or terminaons of external personnel who possess organizaonal credenals
and/or badges, or who have system privileges within [Assignment: organizaon-deﬁned me
period]; and
e. Monitor provider compliance with personnel security requirements.
Discussion: External provider refers to organizaons other than the organizaon operang or acquiring
the system. External providers include service bureaus, contractors, and other organizaons that
provide system development, informaon technology services, tesng or assessment services,
outsourced applicaons, and network/security management. Organizaons explicitly include
personnel security requirements in acquision-related documents. External providers may have
personnel working at organizaonal facilies with credenals, badges, or system privileges issued
by organizaons. Noﬁcaons of external personnel changes ensure the appropriate terminaon of
privileges and credenals. Organizaons deﬁne the transfers and terminaons deemed reportable by
security-related characteriscs that include funcons, roles, and the nature of credenals or privileges
associated with transferred or terminated individuals.
Related controls: AT-2, AT-3, MA-5, PE-3, PS-2, PS-3, PS-4, PS-5, PS-6, SA-5, SA-9, SA-21.
References: [SP 800-35], [SP 800-63-3]
PS-8 PERSONNEL SANCTIONS
Control:
a. Employ a formal sancons process for individuals failing to comply with established informaon
security and privacy policies and procedures; and
b. Nofy [Assignment: organizaon-deﬁned personnel or roles] within [Assignment: organizaon-
deﬁned me period] when a formal employee sancons process is iniated, idenfying the
individual sanconed and the reason for the sancon.
Discussion: Organizaonal sancons reﬂect applicable laws, execuve orders, direcves, regulaons,
policies, standards, and guidelines. Sancons processes are described in access agreements and can
be included as part of general personnel policies for organizaons and/or speciﬁed in security and
privacy policies. Organizaons consult with the Oﬃce of the General Counsel regarding maers of
employee sancons.
Related controls: PL-4, PM-12, PS-6, PT-1.
References: None
This document is produced from OSCAL source data
FAMILY: PS PAGE 214NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
PS-9 POSITION DESCRIPTIONS
Control: Incorporate security and privacy roles and responsibilies into organizaonal posion
descripons.
Discussion: Speciﬁcaon of security and privacy roles in individual organizaonal posion descripons
facilitates clarity in understanding the security or privacy responsibilies associated with the roles and
the role-based security and privacy training requirements for the roles.
Reference: [SP 800-181]
This document is produced from OSCAL source data
FAMILY: PS PAGE 215NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
FAMILY: PERSONALLY IDENTIFIABLE INFORMATION PROCESSING AND TRANSPARENCY
PT-1 POLICY AND PROCEDURES
Control:
a. Develop, document, and disseminate to [Assignment: organizaon-deﬁned personnel or roles]:
1. [Selecon (one or more): Organizaon-level; Mission/business process-level; System-level]
personally idenﬁable informaon processing and transparency policy that:
(a) Addresses purpose, scope, roles, responsibilies, management commitment,
coordinaon among organizaonal enes, and compliance; and
(b) Is consistent with applicable laws, execuve orders, direcves, regulaons, policies,
standards, and guidelines; and
2. Procedures to facilitate the implementaon of the personally idenﬁable informaon
processing and transparency policy and the associated personally idenﬁable informaon
processing and transparency controls;
b. Designate an [Assignment: organizaon-deﬁned oﬃcial] to manage the development,
documentaon, and disseminaon of the personally idenﬁable informaon processing and
transparency policy and procedures; and
c. Review and update the current personally idenﬁable informaon processing and transparency:
1. Policy [Assignment: organizaon-deﬁned frequency] and following [Assignment:
organizaon-deﬁned events]; and
2. Procedures [Assignment: organizaon-deﬁned frequency] and following [Assignment:
organizaon-deﬁned events].
Discussion: Personally idenﬁable informaon processing and transparency policy and procedures
address the controls in the PT family that are implemented within systems and organizaons. The risk
management strategy is an important factor in establishing such policies and procedures. Policies and
procedures contribute to security and privacy assurance. Therefore, it is important that security and
privacy programs collaborate on the development of personally idenﬁable informaon processing
and transparency policy and procedures. Security and privacy program policies and procedures at
the organizaon level are preferable, in general, and may obviate the need for mission- or system-
speciﬁc policies and procedures. The policy can be included as part of the general security and
privacy policy or be represented by mulple policies that reﬂect the complex nature of organizaons.
Procedures can be established for security and privacy programs, for mission or business processes,
and for systems, if needed. Procedures describe how the policies or controls are implemented and
can be directed at the individual or role that is the object of the procedure. Procedures can be
documented in system security and privacy plans or in one or more separate documents. Events
that may precipitate an update to personally idenﬁable informaon processing and transparency
policy and procedures include assessment or audit ﬁndings, breaches, or changes in applicable laws,
execuve orders, direcves, regulaons, policies, standards, and guidelines. Simply restang controls
does not constute an organizaonal policy or procedure.
Reference: [OMB A-130]
This document is produced from OSCAL source data
FAMILY: PT PAGE 216NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
PT-2 AUTHORITY TO PROCESS PERSONALLY IDENTIFIABLE INFORMATION
Control:
a. Determine and document the [Assignment: organizaon-deﬁned authority] that permits the
[Assignment: organizaon-deﬁned processing] of personally idenﬁable informaon; and
b. Restrict the [Assignment: organizaon-deﬁned processing] of personally idenﬁable informaon
to only that which is authorized.
Discussion: The processing of personally idenﬁable informaon is an operaon or set of operaons
that the informaon system or organizaon performs with respect to personally idenﬁable
informaon across the informaon life cycle. Processing includes but is not limited to creaon,
collecon, use, processing, storage, maintenance, disseminaon, disclosure, and disposal. Processing
operaons also include logging, generaon, and transformaon, as well as analysis techniques, such
as data mining.
Organizaons may be subject to laws, execuve orders, direcves, regulaons, or policies that
establish the organizaon’s authority and thereby limit certain types of processing of personally
idenﬁable informaon or establish other requirements related to the processing. Organizaonal
personnel consult with the senior agency oﬃcial for privacy and legal counsel regarding such
authority, parcularly if the organizaon is subject to mulple jurisdicons or sources of authority. For
organizaons whose processing is not determined according to legal authories, the organizaon’s
policies and determinaons govern how they process personally idenﬁable informaon. While
processing of personally idenﬁable informaon may be legally permissible, privacy risks may sll
arise. Privacy risk assessments can idenfy the privacy risks associated with the authorized processing
of personally idenﬁable informaon and support soluons to manage such risks.
Organizaons consider applicable requirements and organizaonal policies to determine how
to document this authority. For federal agencies, the authority to process personally idenﬁable
informaon is documented in privacy policies and noces, system of records noces, privacy
impact assessments, PRIVACT statements, computer matching agreements and noces, contracts,
informaon sharing agreements, memoranda of understanding, and other documentaon.
Organizaons take steps to ensure that personally idenﬁable informaon is only processed for
authorized purposes, including training organizaonal personnel on the authorized processing of
personally idenﬁable informaon and monitoring and auding organizaonal use of personally
idenﬁable informaon.
Related controls: AC-2, AC-3, CM-13, IR-9, PM-9, PM-24, PT-1, PT-3, PT-5, PT-6, RA-3, RA-8, SI-12, SI-18.
(1) AUTHORITY TO PROCESS PERSONALLY IDENTIFIABLE INFORMATION | DATA TAGGING
Aach data tags containing [Assignment: organizaon-deﬁned authorized processing] to
[Assignment: organizaon-deﬁned elements of personally idenﬁable informaon].
Discussion: Data tags support the tracking and enforcement of authorized processing by
conveying the types of processing that are authorized along with the relevant elements of
personally idenﬁable informaon throughout the system. Data tags may also support the use of
automated tools.
Related controls: AC-16, CA-6, CM-12, PM-5, PM-22, PT-4, SC-16, SC-43, SI-10, SI-15, SI-19.
This document is produced from OSCAL source data
FAMILY: PT PAGE 217NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(2) AUTHORITY TO PROCESS PERSONALLY IDENTIFIABLE INFORMATION | AUTOMATION
Manage enforcement of the authorized processing of personally idenﬁable informaon using
[Assignment: organizaon-deﬁned automated mechanisms].
Discussion: Automated mechanisms augment veriﬁcaon that only authorized processing is
occurring.
Related controls: CA-6, CM-12, PM-5, PM-22, PT-4, SC-16, SC-43, SI-10, SI-15, SI-19.
References: [IR 8112], [OMB A-130], [PRIVACT]
PT-3 PERSONALLY IDENTIFIABLE INFORMATION PROCESSING PURPOSES
Control:
a. Idenfy and document the [Assignment: organizaon-deﬁned purpose(s)] for processing
personally idenﬁable informaon;
b. Describe the purpose(s) in the public privacy noces and policies of the organizaon;
c. Restrict the [Assignment: organizaon-deﬁned processing] of personally idenﬁable informaon
to only that which is compable with the idenﬁed purpose(s); and
d. Monitor changes in processing personally idenﬁable informaon and implement [Assignment:
organizaon-deﬁned mechanisms] to ensure that any changes are made in accordance with
[Assignment: organizaon-deﬁned requirements].
Discussion: Idenfying and documenng the purpose for processing provides organizaons with a
basis for understanding why personally idenﬁable informaon may be processed. The term process
includes every step of the informaon life cycle, including creaon, collecon, use, processing,
storage, maintenance, disseminaon, disclosure, and disposal. Idenfying and documenng
the purpose of processing is a prerequisite to enabling owners and operators of the system and
individuals whose informaon is processed by the system to understand how the informaon will
be processed. This enables individuals to make informed decisions about their engagement with
informaon systems and organizaons and to manage their privacy interests. Once the speciﬁc
processing purpose has been idenﬁed, the purpose is described in the organizaon’s privacy noces,
policies, and any related privacy compliance documentaon, including privacy impact assessments,
system of records noces, PRIVACT statements, computer matching noces, and other applicable
Federal Register noces.
Organizaons take steps to help ensure that personally idenﬁable informaon is processed only
for idenﬁed purposes, including training organizaonal personnel and monitoring and auding
organizaonal processing of personally idenﬁable informaon.
Organizaons monitor for changes in personally idenﬁable informaon processing. Organizaonal
personnel consult with the senior agency oﬃcial for privacy and legal counsel to ensure that any
new purposes that arise from changes in processing are compable with the purpose for which
the informaon was collected, or if the new purpose is not compable, implement mechanisms in
accordance with deﬁned requirements to allow for the new processing, if appropriate. Mechanisms
may include obtaining consent from individuals, revising privacy policies, or other measures to
manage privacy risks that arise from changes in personally idenﬁable informaon processing
purposes.
Related controls: AC-2, AC-3, AT-3, CM-13, IR-9, PM-9, PM-25, PT-2, PT-5, PT-6, PT-7, RA-8, SC-43, SI-12,
SI-18.
This document is produced from OSCAL source data
FAMILY: PT PAGE 218NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(1) PERSONALLY IDENTIFIABLE INFORMATION PROCESSING PURPOSES | DATA TAGGING
Aach data tags containing the following purposes to [Assignment: organizaon-deﬁned
elements of personally idenﬁable informaon]: [Assignment: organizaon-deﬁned
processing purposes].
Discussion: Data tags support the tracking of processing purposes by conveying the purposes
along with the relevant elements of personally idenﬁable informaon throughout the system.
By conveying the processing purposes in a data tag along with the personally idenﬁable
informaon as the informaon transits a system, a system owner or operator can idenfy
whether a change in processing would be compable with the idenﬁed and documented
purposes. Data tags may also support the use of automated tools.
Related controls: CA-6, CM-12, PM-5, PM-22, SC-16, SC-43, SI-10, SI-15, SI-19.
(2) PERSONALLY IDENTIFIABLE INFORMATION PROCESSING PURPOSES | AUTOMATION
Track processing purposes of personally idenﬁable informaon using [Assignment:
organizaon-deﬁned automated mechanisms].
Discussion: Automated mechanisms augment tracking of the processing purposes.
Related controls: CA-6, CM-12, PM-5, PM-22, SC-16, SC-43, SI-10, SI-15, SI-19.
References: [IR 8112], [OMB A-130], [PRIVACT]
PT-4 CONSENT
Control: Implement [Assignment: organizaon-deﬁned tools or mechanisms] for individuals to consent
to the processing of their personally idenﬁable informaon prior to its collecon that facilitate
individuals’ informed decision-making.
Discussion: Consent allows individuals to parcipate in making decisions about the processing of their
informaon and transfers some of the risk that arises from the processing of personally idenﬁable
informaon from the organizaon to an individual. Consent may be required by applicable laws,
execuve orders, direcves, regulaons, policies, standards, or guidelines. Otherwise, when selecng
consent as a control, organizaons consider whether individuals can be reasonably expected to
understand and accept the privacy risks that arise from their authorizaon. Organizaons consider
whether other controls may more eﬀecvely migate privacy risk either alone or in conjuncon with
consent. Organizaons also consider any demographic or contextual factors that may inﬂuence the
understanding or behavior of individuals with respect to the processing carried out by the system
or organizaon. When solicing consent from individuals, organizaons consider the appropriate
mechanism for obtaining consent, including the type of consent (e.g., opt-in, opt-out), how to
properly authencate and identy proof individuals and how to obtain consent through electronic
means. In addion, organizaons consider providing a mechanism for individuals to revoke consent
once it has been provided, as appropriate. Finally, organizaons consider usability factors to help
individuals understand the risks being accepted when providing consent, including the use of plain
language and avoiding technical jargon.
Related controls: AC-16, PT-2, PT-5.
This document is produced from OSCAL source data
FAMILY: PT PAGE 219NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(1) CONSENT | TAILORED CONSENT
Provide [Assignment: organizaon-deﬁned mechanisms] to allow individuals to tailor
processing permissions to selected elements of personally idenﬁable informaon.
Discussion: While some processing may be necessary for the basic funconality of the product
or service, other processing may not. In these circumstances, organizaons allow individuals
to select how speciﬁc personally idenﬁable informaon elements may be processed. More
tailored consent may help reduce privacy risk, increase individual sasfacon, and avoid adverse
behaviors, such as abandonment of the product or service.
Related control: PT-2.
(2) CONSENT | JUST-IN-TIME CONSENT
Present [Assignment: organizaon-deﬁned consent mechanisms] to individuals at
[Assignment: organizaon-deﬁned frequency] and in conjuncon with [Assignment:
organizaon-deﬁned personally idenﬁable informaon processing].
Discussion: Just-in-me consent enables individuals to parcipate in how their personally
idenﬁable informaon is being processed at the me or in conjuncon with speciﬁc types
of data processing when such parcipaon may be most useful to the individual. Individual
assumpons about how personally idenﬁable informaon is being processed might not be
accurate or reliable if me has passed since the individual last gave consent or the type of
processing creates signiﬁcant privacy risk. Organizaons use discreon to determine when to
use just-in-me consent and may use supporng informaon on demographics, focus groups, or
surveys to learn more about individuals’ privacy interests and concerns.
Related control: PT-2.
(3) CONSENT | REVOCATION
Implement [Assignment: organizaon-deﬁned tools or mechanisms] for individuals to revoke
consent to the processing of their personally idenﬁable informaon.
Discussion: Revocaon of consent enables individuals to exercise control over their inial consent
decision when circumstances change. Organizaons consider usability factors in enabling easy-
to-use revocaon capabilies.
Related control: PT-2.
References: [OMB A-130], [PRIVACT], [SP 800-63-3]
PT-5 PRIVACY NOTICE
Control: Provide noce to individuals about the processing of personally idenﬁable informaon that:
a. Is available to individuals upon ﬁrst interacng with an organizaon, and subsequently at
[Assignment: organizaon-deﬁned frequency];
b. Is clear and easy-to-understand, expressing informaon about personally idenﬁable informaon
processing in plain language;
c. Idenﬁes the authority that authorizes the processing of personally idenﬁable informaon;
d. Idenﬁes the purposes for which personally idenﬁable informaon is to be processed; and
e. Includes [Assignment: organizaon-deﬁned informaon].
This document is produced from OSCAL source data
FAMILY: PT PAGE 220NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
Discussion: Privacy noces help inform individuals about how their personally idenﬁable informaon
is being processed by the system or organizaon. Organizaons use privacy noces to inform
individuals about how, under what authority, and for what purpose their personally idenﬁable
informaon is processed, as well as other informaon such as choices individuals might have with
respect to that processing and other pares with whom informaon is shared. Laws, execuve orders,
direcves, regulaons, or policies may require that privacy noces include speciﬁc elements or be
provided in speciﬁc formats. Federal agency personnel consult with the senior agency oﬃcial for
privacy and legal counsel regarding when and where to provide privacy noces, as well as elements
to include in privacy noces and required formats. In circumstances where laws or government-wide
policies do not require privacy noces, organizaonal policies and determinaons may require privacy
noces and may serve as a source of the elements to include in privacy noces.
Privacy risk assessments idenfy the privacy risks associated with the processing of personally
idenﬁable informaon and may help organizaons determine appropriate elements to include in a
privacy noce to manage such risks. To help individuals understand how their informaon is being
processed, organizaons write materials in plain language and avoid technical jargon.
Related controls: PM-20, PM-22, PT-2, PT-3, PT-4, PT-7, RA-3, SC-42, SI-18.
(1) PRIVACY NOTICE | JUST-IN-TIME NOTICE
Present noce of personally idenﬁable informaon processing to individuals at a me and
locaon where the individual provides personally idenﬁable informaon or in conjuncon
with a data acon, or [Assignment: organizaon-deﬁned frequency].
Discussion: Just-in-me noces inform individuals of how organizaons process their personally
idenﬁable informaon at a me when such noces may be most useful to the individuals.
Individual assumpons about how personally idenﬁable informaon will be processed might
not be accurate or reliable if me has passed since the organizaon last presented noce or
the circumstances under which the individual was last provided noce have changed. A just-in-
me noce can explain data acons that organizaons have idenﬁed as potenally giving rise
to greater privacy risk for individuals. Organizaons can use a just-in-me noce to update or
remind individuals about speciﬁc data acons as they occur or highlight speciﬁc changes that
occurred since last presenng noce. A just-in-me noce can be used in conjuncon with just-
in-me consent to explain what will occur if consent is declined. Organizaons use discreon
to determine when to use a just-in-me noce and may use supporng informaon on user
demographics, focus groups, or surveys to learn about users’ privacy interests and concerns.
Related control: PM-21.
(2) PRIVACY NOTICE | PRIVACY ACT STATEMENTS
Include Privacy Act statements on forms that collect informaon that will be maintained in a
Privacy Act system of records, or provide Privacy Act statements on separate forms that can be
retained by individuals.
Discussion: If a federal agency asks individuals to supply informaon that will become part of a
system of records, the agency is required to provide a PRIVACT statement on the form used to
collect the informaon or on a separate form that can be retained by the individual. The agency
provides a PRIVACT statement in such circumstances regardless of whether the informaon
will be collected on a paper or electronic form, on a website, on a mobile applicaon, over the
telephone, or through some other medium. This requirement ensures that the individual is
provided with suﬃcient informaon about the request for informaon to make an informed
decision on whether or not to respond.
This document is produced from OSCAL source data
FAMILY: PT PAGE 221NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
PRIVACT statements provide formal noce to individuals of the authority that authorizes the
solicitaon of the informaon; whether providing the informaon is mandatory or voluntary;
the principal purpose(s) for which the informaon is to be used; the published roune uses to
which the informaon is subject; the eﬀects on the individual, if any, of not providing all or any
part of the informaon requested; and an appropriate citaon and link to the relevant system of
records noce. Federal agency personnel consult with the senior agency oﬃcial for privacy and
legal counsel regarding the noce provisions of the PRIVACT.
Related control: PT-6.
References: [OMB A-108], [OMB A-130], [PRIVACT]
PT-6 SYSTEM OF RECORDS NOTICE
Control: For systems that process informaon that will be maintained in a Privacy Act system of
records:
a. Dra system of records noces in accordance with OMB guidance and submit new and
signiﬁcantly modiﬁed system of records noces to the OMB and appropriate congressional
commiees for advance review;
b. Publish system of records noces in the Federal Register; and
c. Keep system of records noces accurate, up-to-date, and scoped in accordance with policy.
Discussion: The PRIVACT requires that federal agencies publish a system of records noce in the
Federal Register upon the establishment and/or modiﬁcaon of a PRIVACT system of records. As
a general maer, a system of records noce is required when an agency maintains a group of any
records under the control of the agency from which informaon is retrieved by the name of an
individual or by some idenfying number, symbol, or other idenﬁer. The noce describes the
existence and character of the system and idenﬁes the system of records, the purpose(s) of the
system, the authority for maintenance of the records, the categories of records maintained in the
system, the categories of individuals about whom records are maintained, the roune uses to which
the records are subject, and addional details about the system as described in OMB A-108.
Related controls: AC-3, PM-20, PT-2, PT-3, PT-5.
(1) SYSTEM OF RECORDS NOTICE | ROUTINE USES
Review all roune uses published in the system of records noce at [Assignment:
organizaon-deﬁned frequency] to ensure connued accuracy, and to ensure that roune uses
connue to be compable with the purpose for which the informaon was collected.
Discussion: A PRIVACT roune use is a parcular kind of disclosure of a record outside of the
federal agency maintaining the system of records. A roune use is an excepon to the PRIVACT
prohibion on the disclosure of a record in a system of records without the prior wrien consent
of the individual to whom the record pertains. To qualify as a roune use, the disclosure must
be for a purpose that is compable with the purpose for which the informaon was originally
collected. The PRIVACT requires agencies to describe each roune use of the records maintained
in the system of records, including the categories of users of the records and the purpose of
the use. Agencies may only establish roune uses by explicitly publishing them in the relevant
system of records noce.
This document is produced from OSCAL source data
FAMILY: PT PAGE 222NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(2) SYSTEM OF RECORDS NOTICE | EXEMPTION RULES
Review all Privacy Act exempons claimed for the system of records at [Assignment:
organizaon-deﬁned frequency] to ensure they remain appropriate and necessary in
accordance with law, that they have been promulgated as regulaons, and that they are
accurately described in the system of records noce.
Discussion: The PRIVACT includes two sets of provisions that allow federal agencies to claim
exempons from certain requirements in the statute. In certain circumstances, these provisions
allow agencies to promulgate regulaons to exempt a system of records from select provisions of
the PRIVACT. At a minimum, organizaons’ PRIVACT exempon regulaons include the speciﬁc
name(s) of any system(s) of records that will be exempt, the speciﬁc provisions of the PRIVACT
from which the system(s) of records is to be exempted, the reasons for the exempon, and an
explanaon for why the exempon is both necessary and appropriate.
References: [OMB A-108], [PRIVACT]
PT-7 SPECIFIC CATEGORIES OF PERSONALLY IDENTIFIABLE INFORMATION
Control: Apply [Assignment: organizaon-deﬁned processing condions] for speciﬁc categories of
personally idenﬁable informaon.
Discussion: Organizaons apply any condions or protecons that may be necessary for speciﬁc
categories of personally idenﬁable informaon. These condions may be required by laws, execuve
orders, direcves, regulaons, policies, standards, or guidelines. The requirements may also come
from the results of privacy risk assessments that factor in contextual changes that may result in
an organizaonal determinaon that a parcular category of personally idenﬁable informaon is
parcularly sensive or raises parcular privacy risks. Organizaons consult with the senior agency
oﬃcial for privacy and legal counsel regarding any protecons that may be necessary.
Related controls: IR-9, PT-2, PT-3, RA-3.
(1) SPECIFIC CATEGORIES OF PERSONALLY IDENTIFIABLE INFORMATION | SOCIAL SECURITY
NUMBERS
When a system processes Social Security numbers:
(a) Eliminate unnecessary collecon, maintenance, and use of Social Security numbers, and
explore alternaves to their use as a personal idenﬁer;
(b) Do not deny any individual any right, beneﬁt, or privilege provided by law because of
such individual’s refusal to disclose his or her Social Security number; and
(c) Inform any individual who is asked to disclose his or her Social Security number whether
that disclosure is mandatory or voluntary, by what statutory or other authority such
number is solicited, and what uses will be made of it.
Discussion: Federal law and policy establish speciﬁc requirements for organizaons’ processing
of Social Security numbers. Organizaons take steps to eliminate unnecessary uses of Social
Security numbers and other sensive informaon and observe any parcular requirements that
apply.
Related control: IA-4.
This document is produced from OSCAL source data
FAMILY: PT PAGE 223NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(2) SPECIFIC CATEGORIES OF PERSONALLY IDENTIFIABLE INFORMATION | FIRST
AMENDMENT INFORMATION
Prohibit the processing of informaon describing how any individual exercises rights
guaranteed by the First Amendment unless expressly authorized by statute or by the
individual or unless pernent to and within the scope of an authorized law enforcement
acvity.
Discussion: The PRIVACT limits agencies’ ability to process informaon that describes how
individuals exercise rights guaranteed by the First Amendment. Organizaons consult with the
senior agency oﬃcial for privacy and legal counsel regarding these requirements.
References: [NARA CUI], [OMB A-108], [OMB A-130], [PRIVACT]
PT-8 COMPUTER MATCHING REQUIREMENTS
Control: When a system or organizaon processes informaon for the purpose of conducng a
matching program:
a. Obtain approval from the Data Integrity Board to conduct the matching program;
b. Develop and enter into a computer matching agreement;
c. Publish a matching noce in the Federal Register;
d. Independently verify the informaon produced by the matching program before taking adverse
acon against an individual, if required; and
e. Provide individuals with noce and an opportunity to contest the ﬁndings before taking adverse
acon against an individual.
Discussion: The PRIVACT establishes requirements for federal and non-federal agencies if they engage
in a matching program. In general, a matching program is a computerized comparison of records
from two or more automated PRIVACT systems of records or an automated system of records and
automated records maintained by a non-federal agency (or agent thereof). A matching program either
pertains to federal beneﬁt programs or federal personnel or payroll records. A federal beneﬁt match is
performed to determine or verify eligibility for payments under federal beneﬁt programs or to recoup
payments or delinquent debts under federal beneﬁt programs. A matching program involves not just
the matching acvity itself but also the invesgave follow-up and ulmate acon, if any.
Related control: PM-24.
References: [CMPPA], [OMB A-108], [OMB A-130], [PRIVACT]
This document is produced from OSCAL source data
FAMILY: PT PAGE 224NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
FAMILY: RISK ASSESSMENT
RA-1 POLICY AND PROCEDURES
Control:
a. Develop, document, and disseminate to [Assignment: organizaon-deﬁned personnel or roles]:
1. [Selecon (one or more): Organizaon-level; Mission/business process-level; System-level]
risk assessment policy that:
(a) Addresses purpose, scope, roles, responsibilies, management commitment,
coordinaon among organizaonal enes, and compliance; and
(b) Is consistent with applicable laws, execuve orders, direcves, regulaons, policies,
standards, and guidelines; and
2. Procedures to facilitate the implementaon of the risk assessment policy and the associated
risk assessment controls;
b. Designate an [Assignment: organizaon-deﬁned oﬃcial] to manage the development,
documentaon, and disseminaon of the risk assessment policy and procedures; and
c. Review and update the current risk assessment:
1. Policy [Assignment: organizaon-deﬁned frequency] and following [Assignment:
organizaon-deﬁned events]; and
2. Procedures [Assignment: organizaon-deﬁned frequency] and following [Assignment:
organizaon-deﬁned events].
Discussion: Risk assessment policy and procedures address the controls in the RA family that are
implemented within systems and organizaons. The risk management strategy is an important
factor in establishing such policies and procedures. Policies and procedures contribute to security
and privacy assurance. Therefore, it is important that security and privacy programs collaborate on
the development of risk assessment policy and procedures. Security and privacy program policies
and procedures at the organizaon level are preferable, in general, and may obviate the need for
mission- or system-speciﬁc policies and procedures. The policy can be included as part of the general
security and privacy policy or be represented by mulple policies reﬂecng the complex nature
of organizaons. Procedures can be established for security and privacy programs, for mission or
business processes, and for systems, if needed. Procedures describe how the policies or controls
are implemented and can be directed at the individual or role that is the object of the procedure.
Procedures can be documented in system security and privacy plans or in one or more separate
documents. Events that may precipitate an update to risk assessment policy and procedures include
assessment or audit ﬁndings, security incidents or breaches, or changes in laws, execuve orders,
direcves, regulaons, policies, standards, and guidelines. Simply restang controls does not
constute an organizaonal policy or procedure.
Related controls: PM-9, PS-8, SI-12.
References: [OMB A-130], [SP 800-100], [SP 800-12], [SP 800-30], [SP 800-39]
RA-2 SECURITY CATEGORIZATION
Control:
a. Categorize the system and informaon it processes, stores, and transmits;
b. Document the security categorizaon results, including supporng raonale, in the security plan
for the system; and
This document is produced from OSCAL source data
FAMILY: RA PAGE 225NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
c. Verify that the authorizing oﬃcial or authorizing oﬃcial designated representave reviews and
approves the security categorizaon decision.
Discussion: Security categories describe the potenal adverse impacts or negave consequences
to organizaonal operaons, organizaonal assets, and individuals if organizaonal informaon
and systems are compromised through a loss of conﬁdenality, integrity, or availability. Security
categorizaon is also a type of asset loss characterizaon in systems security engineering processes
that is carried out throughout the system development life cycle. Organizaons can use privacy risk
assessments or privacy impact assessments to beer understand the potenal adverse eﬀects on
individuals. CNSSI 1253 provides addional guidance on categorizaon for naonal security systems.
Organizaons conduct the security categorizaon process as an organizaon-wide acvity with the
direct involvement of chief informaon oﬃcers, senior agency informaon security oﬃcers, senior
agency oﬃcials for privacy, system owners, mission and business owners, and informaon owners
or stewards. Organizaons consider the potenal adverse impacts to other organizaons and, in
accordance with USA PATRIOT and Homeland Security Presidenal Direcves, potenal naonal-level
adverse impacts.
Security categorizaon processes facilitate the development of inventories of informaon assets and,
along with CM-8, mappings to speciﬁc system components where informaon is processed, stored, or
transmied. The security categorizaon process is revisited throughout the system development life
cycle to ensure that the security categories remain accurate and relevant.
Related controls: CM-8, MP-4, PL-2, PL-10, PL-11, PM-7, RA-3, RA-5, RA-7, RA-8, SA-8, SC-7, SC-38, SI-12.
(1) SECURITY CATEGORIZATION | IMPACT-LEVEL PRIORITIZATION
Conduct an impact-level priorizaon of organizaonal systems to obtain addional
granularity on system impact levels.
Discussion: Organizaons apply the high-water mark concept to each system categorized in
accordance with FIPS 199, resulng in systems designated as low impact, moderate impact, or
high impact. Organizaons that desire addional granularity in the system impact designaons
for risk-based decision-making, can further paron the systems into sub-categories of the inial
system categorizaon. For example, an impact-level priorizaon on a moderate-impact system
can produce three new sub-categories: low-moderate systems, moderate-moderate systems,
and high-moderate systems. Impact-level priorizaon and the resulng sub-categories of the
system give organizaons an opportunity to focus their investments related to security control
selecon and the tailoring of control baselines in responding to idenﬁed risks. Impact-level
priorizaon can also be used to determine those systems that may be of heightened interest or
value to adversaries or represent a crical loss to the federal enterprise, somemes described as
high value assets. For such high value assets, organizaons may be more focused on complexity,
aggregaon, and informaon exchanges. Systems with high value assets can be priorized by
paroning high-impact systems into low-high systems, moderate-high systems, and high-high
systems. Alternavely, organizaons can apply the guidance in CNSSI 1253 for security objecve-
related categorizaon.
References: [CNSSI 1253], [FIPS 199], [FIPS 200], [NARA CUI], [SP 800-160-1], [SP 800-30], [SP 800-37],
[SP 800-39], [SP 800-60-1], [SP 800-60-2]
This document is produced from OSCAL source data
FAMILY: RA PAGE 226NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
RA-3 RISK ASSESSMENT
Control:
a. Conduct a risk assessment, including:
1. Idenfying threats to and vulnerabilies in the system;
2. Determining the likelihood and magnitude of harm from unauthorized access, use,
disclosure, disrupon, modiﬁcaon, or destrucon of the system, the informaon it
processes, stores, or transmits, and any related informaon; and
3. Determining the likelihood and impact of adverse eﬀects on individuals arising from the
processing of personally idenﬁable informaon;
b. Integrate risk assessment results and risk management decisions from the organizaon and
mission or business process perspecves with system-level risk assessments;
c. Document risk assessment results in [Selecon: security and privacy plans; risk assessment
report; [Assignment: organizaon-deﬁned document]];
d. Review risk assessment results [Assignment: organizaon-deﬁned frequency];
e. Disseminate risk assessment results to [Assignment: organizaon-deﬁned personnel or roles];
and
f. Update the risk assessment [Assignment: organizaon-deﬁned frequency] or when there are
signiﬁcant changes to the system, its environment of operaon, or other condions that may
impact the security or privacy state of the system.
Discussion: Risk assessments consider threats, vulnerabilies, likelihood, and impact to organizaonal
operaons and assets, individuals, other organizaons, and the Naon. Risk assessments also
consider risk from external pares, including contractors who operate systems on behalf of the
organizaon, individuals who access organizaonal systems, service providers, and outsourcing
enes.
Organizaons can conduct risk assessments at all three levels in the risk management hierarchy (i.e.,
organizaon level, mission/business process level, or informaon system level) and at any stage
in the system development life cycle. Risk assessments can also be conducted at various steps in
the Risk Management Framework, including preparaon, categorizaon, control selecon, control
implementaon, control assessment, authorizaon, and control monitoring. Risk assessment is an
ongoing acvity carried out throughout the system development life cycle.
Risk assessments can also address informaon related to the system, including system design,
the intended use of the system, tesng results, and supply chain-related informaon or arfacts.
Risk assessments can play an important role in control selecon processes, parcularly during the
applicaon of tailoring guidance and in the earliest phases of capability determinaon.
Related controls: CA-3, CA-6, CM-4, CM-13, CP-6, CP-7, IA-8, MA-5, PE-3, PE-8, PE-18, PL-2, PL-10, PL-11,
PM-8, PM-9, PM-28, PT-2, PT-7, RA-2, RA-5, RA-7, SA-8, SA-9, SC-38, SI-12.
(1) RISK ASSESSMENT | SUPPLY CHAIN RISK ASSESSMENT
(a) Assess supply chain risks associated with [Assignment: organizaon-deﬁned systems,
system components, and system services]; and
(b) Update the supply chain risk assessment [Assignment: organizaon-deﬁned frequency],
when there are signiﬁcant changes to the relevant supply chain, or when changes to the
This document is produced from OSCAL source data
FAMILY: RA PAGE 227NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
system, environments of operaon, or other condions may necessitate a change in the
supply chain.
Discussion: Supply chain-related events include disrupon, use of defecve components,
inseron of counterfeits, the, malicious development pracces, improper delivery
pracces, and inseron of malicious code. These events can have a signiﬁcant impact on the
conﬁdenality, integrity, or availability of a system and its informaon and, therefore, can also
adversely impact organizaonal operaons (including mission, funcons, image, or reputaon),
organizaonal assets, individuals, other organizaons, and the Naon. The supply chain-related
events may be unintenonal or malicious and can occur at any point during the system life cycle.
An analysis of supply chain risk can help an organizaon idenfy systems or components for
which addional supply chain risk migaons are required.
Related controls: PM-17, PM-30, RA-2, RA-9, SR-2.
(2) RISK ASSESSMENT | USE OF ALL-SOURCE INTELLIGENCE
Use all-source intelligence to assist in the analysis of risk.
Discussion: Organizaons employ all-source intelligence to inform engineering, acquision,
and risk management decisions. All-source intelligence consists of informaon derived from
all available sources, including publicly available or open-source informaon, measurement
and signature intelligence, human intelligence, signals intelligence, and imagery intelligence.
All-source intelligence is used to analyze the risk of vulnerabilies (both intenonal and
unintenonal) from development, manufacturing, and delivery processes, people, and the
environment. The risk analysis may be performed on suppliers at mulple ers in the supply
chain suﬃcient to manage risks. Organizaons may develop agreements to share all-source
intelligence informaon or resulng decisions with other organizaons, as appropriate.
(3) RISK ASSESSMENT | DYNAMIC THREAT AWARENESS
Determine the current cyber threat environment on an ongoing basis using [Assignment:
organizaon-deﬁned means].
Discussion: The threat awareness informaon that is gathered feeds into the organizaon’s
informaon security operaons to ensure that procedures are updated in response to the
changing threat environment. For example, at higher threat levels, organizaons may change the
privilege or authencaon thresholds required to perform certain operaons.
Related control: AT-2.
(4) RISK ASSESSMENT | PREDICTIVE CYBER ANALYTICS
Employ the following advanced automaon and analycs capabilies to predict and idenfy
risks to [Assignment: organizaon-deﬁned systems or system components]: [Assignment:
organizaon-deﬁned advanced automaon and analycs capabilies].
Discussion: A properly resourced Security Operaons Center (SOC) or Computer Incident
Response Team (CIRT) may be overwhelmed by the volume of informaon generated by the
proliferaon of security tools and appliances unless it employs advanced automaon and
analycs to analyze the data. Advanced automaon and analycs capabilies are typically
supported by arﬁcial intelligence concepts, including machine learning. Examples include
Automated Threat Discovery and Response (which includes broad-based collecon, context-
based analysis, and adapve response capabilies), automated workﬂow operaons, and
machine assisted decision tools. Note, however, that sophiscated adversaries may be able to
extract informaon related to analyc parameters and retrain the machine learning to classify
This document is produced from OSCAL source data
FAMILY: RA PAGE 228NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
malicious acvity as benign. Accordingly, machine learning is augmented by human monitoring
to ensure that sophiscated adversaries are not able to conceal their acvies.
References: [IR 8023], [IR 8062], [IR 8272], [OMB A-130], [SP 800-161], [SP 800-30], [SP 800-39]
RA-4 Risk Assessment Update
[Withdrawn: Incorporated into RA-3.]
RA-5 VULNERABILITY MONITORING AND SCANNING
Control:
a. Monitor and scan for vulnerabilies in the system and hosted applicaons [Assignment:
organizaon-deﬁned frequency and/or randomly in accordance with organizaon-deﬁned
process] and when new vulnerabilies potenally aﬀecng the system are idenﬁed and
reported;
b. Employ vulnerability monitoring tools and techniques that facilitate interoperability among tools
and automate parts of the vulnerability management process by using standards for:
1. Enumerang plaorms, soware ﬂaws, and improper conﬁguraons;
2. Formang checklists and test procedures; and
3. Measuring vulnerability impact;
c. Analyze vulnerability scan reports and results from vulnerability monitoring;
d. Remediate legimate vulnerabilies [Assignment: organizaon-deﬁned response mes] in
accordance with an organizaonal assessment of risk;
e. Share informaon obtained from the vulnerability monitoring process and control assessments
with [Assignment: organizaon-deﬁned personnel or roles] to help eliminate similar
vulnerabilies in other systems; and
f. Employ vulnerability monitoring tools that include the capability to readily update the
vulnerabilies to be scanned.
Discussion: Security categorizaon of informaon and systems guides the frequency and
comprehensiveness of vulnerability monitoring (including scans). Organizaons determine the
required vulnerability monitoring for system components, ensuring that the potenal sources
of vulnerabilies—such as infrastructure components (e.g., switches, routers, guards, sensors),
networked printers, scanners, and copiers—are not overlooked. The capability to readily update
vulnerability monitoring tools as new vulnerabilies are discovered and announced and as new
scanning methods are developed helps to ensure that new vulnerabilies are not missed by employed
vulnerability monitoring tools. The vulnerability monitoring tool update process helps to ensure that
potenal vulnerabilies in the system are idenﬁed and addressed as quickly as possible. Vulnerability
monitoring and analyses for custom soware may require addional approaches, such as stac
analysis, dynamic analysis, binary analysis, or a hybrid of the three approaches. Organizaons can
use these analysis approaches in source code reviews and in a variety of tools, including web-based
applicaon scanners, stac analysis tools, and binary analyzers.
Vulnerability monitoring includes scanning for patch levels; scanning for funcons, ports, protocols,
and services that should not be accessible to users or devices; and scanning for ﬂow control
mechanisms that are improperly conﬁgured or operang incorrectly. Vulnerability monitoring may
also include connuous vulnerability monitoring tools that use instrumentaon to connuously
analyze components. Instrumentaon-based tools may improve accuracy and may be run throughout
This document is produced from OSCAL source data
FAMILY: RA PAGE 229NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
an organizaon without scanning. Vulnerability monitoring tools that facilitate interoperability include
tools that are Security Content Automated Protocol (SCAP)-validated. Thus, organizaons consider
using scanning tools that express vulnerabilies in the Common Vulnerabilies and Exposures
(CVE) naming convenon and that employ the Open Vulnerability Assessment Language (OVAL)
to determine the presence of vulnerabilies. Sources for vulnerability informaon include the
Common Weakness Enumeraon (CWE) lisng and the Naonal Vulnerability Database (NVD). Control
assessments, such as red team exercises, provide addional sources of potenal vulnerabilies for
which to scan. Organizaons also consider using scanning tools that express vulnerability impact by
the Common Vulnerability Scoring System (CVSS).
Vulnerability monitoring includes a channel and process for receiving reports of security
vulnerabilies from the public at-large. Vulnerability disclosure programs can be as simple as
publishing a monitored email address or web form that can receive reports, including noﬁcaon
authorizing good-faith research and disclosure of security vulnerabilies. Organizaons generally
expect that such research is happening with or without their authorizaon and can use public
vulnerability disclosure channels to increase the likelihood that discovered vulnerabilies are reported
directly to the organizaon for remediaon.
Organizaons may also employ the use of ﬁnancial incenves (also known as bug bounes) to further
encourage external security researchers to report discovered vulnerabilies. Bug bounty programs can
be tailored to the organizaon’s needs. Bounes can be operated indeﬁnitely or over a deﬁned period
of me and can be oﬀered to the general public or to a curated group. Organizaons may run public
and private bounes simultaneously and could choose to oﬀer parally credenaled access to certain
parcipants in order to evaluate security vulnerabilies from privileged vantage points.
Related controls: CA-2, CA-7, CA-8, CM-2, CM-4, CM-6, CM-8, RA-2, RA-3, SA-11, SA-15, SC-38, SI-2, SI-3,
SI-4, SI-7, SR-11.
(1) VULNERABILITY MONITORING AND SCANNING | UPDATE TOOL CAPABILITY
[Withdrawn: Incorporated into RA-5.]
(2) VULNERABILITY MONITORING AND SCANNING | UPDATE VULNERABILITIES TO BE
SCANNED
Update the system vulnerabilies to be scanned [Selecon (one or more): [Assignment:
organizaon-deﬁned frequency]; prior to a new scan; when new vulnerabilies are idenﬁed
and reported].
Discussion: Due to the complexity of modern soware, systems, and other factors, new
vulnerabilies are discovered on a regular basis. It is important that newly discovered
vulnerabilies are added to the list of vulnerabilies to be scanned to ensure that the
organizaon can take steps to migate those vulnerabilies in a mely manner.
Related control: SI-5.
(3) VULNERABILITY MONITORING AND SCANNING | BREADTH AND DEPTH OF COVERAGE
Deﬁne the breadth and depth of vulnerability scanning coverage.
Discussion: The breadth of vulnerability scanning coverage can be expressed as a percentage
of components within the system, by the parcular types of systems, by the cricality of
systems, or by the number of vulnerabilies to be checked. Conversely, the depth of vulnerability
scanning coverage can be expressed as the level of the system design that the organizaon
intends to monitor (e.g., component, module, subsystem, element). Organizaons can
determine the suﬃciency of vulnerability scanning coverage with regard to its risk tolerance
This document is produced from OSCAL source data
FAMILY: RA PAGE 230NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
and other factors. Scanning tools and how the tools are conﬁgured may aﬀect the depth and
coverage. Mulple scanning tools may be needed to achieve the desired depth and coverage. SP
800-53A provides addional informaon on the breadth and depth of coverage.
(4) VULNERABILITY MONITORING AND SCANNING | DISCOVERABLE INFORMATION
Determine informaon about the system that is discoverable and take [Assignment:
organizaon-deﬁned correcve acons].
Discussion: Discoverable informaon includes informaon that adversaries could obtain without
compromising or breaching the system, such as by collecng informaon that the system
is exposing or by conducng extensive web searches. Correcve acons include nofying
appropriate organizaonal personnel, removing designated informaon, or changing the system
to make the designated informaon less relevant or aracve to adversaries. This enhancement
excludes intenonally discoverable informaon that may be part of a decoy capability (e.g.,
honeypots, honeynets, or decepon nets) deployed by the organizaon.
Related controls: AU-13, SC-26.
(5) VULNERABILITY MONITORING AND SCANNING | PRIVILEGED ACCESS
Implement privileged access authorizaon to [Assignment: organizaon-deﬁned system
components] for [Assignment: organizaon-deﬁned vulnerability scanning acvies].
Discussion: In certain situaons, the nature of the vulnerability scanning may be more intrusive,
or the system component that is the subject of the scanning may contain classiﬁed or controlled
unclassiﬁed informaon, such as personally idenﬁable informaon. Privileged access
authorizaon to selected system components facilitates more thorough vulnerability scanning
and protects the sensive nature of such scanning.
(6) VULNERABILITY MONITORING AND SCANNING | AUTOMATED TREND ANALYSES
Compare the results of mulple vulnerability scans using [Assignment: organizaon-deﬁned
automated mechanisms].
Discussion: Using automated mechanisms to analyze mulple vulnerability scans over me can
help determine trends in system vulnerabilies and idenfy paerns of aack.
(7) VULNERABILITY MONITORING AND SCANNING | AUTOMATED DETECTION AND
NOTIFICATION OF UNAUTHORIZED COMPONENTS
[Withdrawn: Incorporated into CM-8.]
(8) VULNERABILITY MONITORING AND SCANNING | REVIEW HISTORIC AUDIT LOGS
Review historic audit logs to determine if a vulnerability idenﬁed in a [Assignment:
organizaon-deﬁned system] has been previously exploited within an [Assignment:
organizaon-deﬁned me period].
Discussion: Reviewing historic audit logs to determine if a recently detected vulnerability in
a system has been previously exploited by an adversary can provide important informaon
for forensic analyses. Such analyses can help idenfy, for example, the extent of a previous
intrusion, the trade cra employed during the aack, organizaonal informaon exﬁltrated or
modiﬁed, mission or business capabilies aﬀected, and the duraon of the aack.
Related controls: AU-6, AU-11.
This document is produced from OSCAL source data
FAMILY: RA PAGE 231NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(9) VULNERABILITY MONITORING AND SCANNING | PENETRATION TESTING AND ANALYSES
[Withdrawn: Incorporated into CA-8.]
(10) VULNERABILITY MONITORING AND SCANNING | CORRELATE SCANNING INFORMATION
Correlate the output from vulnerability scanning tools to determine the presence of mul-
vulnerability and mul-hop aack vectors.
Discussion: An aack vector is a path or means by which an adversary can gain access to a
system in order to deliver malicious code or exﬁltrate informaon. Organizaons can use aack
trees to show how hosle acvies by adversaries interact and combine to produce adverse
impacts or negave consequences to systems and organizaons. Such informaon, together with
correlated data from vulnerability scanning tools, can provide greater clarity regarding mul-
vulnerability and mul-hop aack vectors. The correlaon of vulnerability scanning informaon
is especially important when organizaons are transioning from older technologies to newer
technologies (e.g., transioning from IPv4 to IPv6 network protocols). During such transions,
some system components may inadvertently be unmanaged and create opportunies for
adversary exploitaon.
(11) VULNERABILITY MONITORING AND SCANNING | PUBLIC DISCLOSURE PROGRAM
Establish a public reporng channel for receiving reports of vulnerabilies in organizaonal
systems and system components.
Discussion: The reporng channel is publicly discoverable and contains clear language authorizing
good-faith research and the disclosure of vulnerabilies to the organizaon. The organizaon
does not condion its authorizaon on an expectaon of indeﬁnite non-disclosure to the
public by the reporng enty but may request a speciﬁc me period to properly remediate the
vulnerability.
References: [IR 7788], [IR 8011-4], [IR 8023], [ISO 29147], [SP 800-115], [SP 800-126], [SP 800-40], [SP
800-53A], [SP 800-70]
RA-6 TECHNICAL SURVEILLANCE COUNTERMEASURES SURVEY
Control: Employ a technical surveillance countermeasures survey at [Assignment: organizaon-deﬁned
locaons] [Selecon (one or more): [Assignment: organizaon-deﬁned frequency]; when the following
events or indicators occur: [Assignment: organizaon-deﬁned events or indicators]].
Discussion: A technical surveillance countermeasures survey is a service provided by qualiﬁed
personnel to detect the presence of technical surveillance devices and hazards and to idenfy
technical security weaknesses that could be used in the conduct of a technical penetraon of the
surveyed facility. Technical surveillance countermeasures surveys also provide evaluaons of the
technical security posture of organizaons and facilies and include visual, electronic, and physical
examinaons of surveyed facilies, internally and externally. The surveys also provide useful input for
risk assessments and informaon regarding organizaonal exposure to potenal adversaries.
References: None
RA-7 RISK RESPONSE
Control: Respond to ﬁndings from security and privacy assessments, monitoring, and audits in
accordance with organizaonal risk tolerance.
This document is produced from OSCAL source data
FAMILY: RA PAGE 232NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
Discussion: Organizaons have many opons for responding to risk including migang risk by
implemenng new controls or strengthening exisng controls, accepng risk with appropriate
jusﬁcaon or raonale, sharing or transferring risk, or avoiding risk. The risk tolerance of the
organizaon inﬂuences risk response decisions and acons. Risk response addresses the need to
determine an appropriate response to risk before generang a plan of acon and milestones entry.
For example, the response may be to accept risk or reject risk, or it may be possible to migate the
risk immediately so that a plan of acon and milestones entry is not needed. However, if the risk
response is to migate the risk, and the migaon cannot be completed immediately, a plan of acon
and milestones entry is generated.
Related controls: CA-5, IR-9, PM-4, PM-28, RA-2, RA-3, SR-2.
References: [FIPS 199], [FIPS 200], [SP 800-160-1], [SP 800-30], [SP 800-37], [SP 800-39]
RA-8 PRIVACY IMPACT ASSESSMENTS
Control: Conduct privacy impact assessments for systems, programs, or other acvies before:
a. Developing or procuring informaon technology that processes personally idenﬁable
informaon; and
b. Iniang a new collecon of personally idenﬁable informaon that:
1. Will be processed using informaon technology; and
2. Includes personally idenﬁable informaon perming the physical or virtual (online)
contacng of a speciﬁc individual, if idencal quesons have been posed to, or idencal
reporng requirements imposed on, ten or more individuals, other than agencies,
instrumentalies, or employees of the federal government.
Discussion: A privacy impact assessment is an analysis of how personally idenﬁable informaon is
handled to ensure that handling conforms to applicable privacy requirements, determine the privacy
risks associated with an informaon system or acvity, and evaluate ways to migate privacy risks. A
privacy impact assessment is both an analysis and a formal document that details the process and the
outcome of the analysis.
Organizaons conduct and develop a privacy impact assessment with suﬃcient clarity and speciﬁcity
to demonstrate that the organizaon fully considered privacy and incorporated appropriate privacy
protecons from the earliest stages of the organizaon’s acvity and throughout the informaon life
cycle. In order to conduct a meaningful privacy impact assessment, the organizaon’s senior agency
oﬃcial for privacy works closely with program managers, system owners, informaon technology
experts, security oﬃcials, counsel, and other relevant organizaon personnel. Moreover, a privacy
impact assessment is not a me-restricted acvity that is limited to a parcular milestone or stage of
the informaon system or personally idenﬁable informaon life cycles. Rather, the privacy analysis
connues throughout the system and personally idenﬁable informaon life cycles. Accordingly, a
privacy impact assessment is a living document that organizaons update whenever changes to the
informaon technology, changes to the organizaon’s pracces, or other factors alter the privacy risks
associated with the use of such informaon technology.
To conduct the privacy impact assessment, organizaons can use security and privacy risk
assessments. Organizaons may also use other related processes that may have diﬀerent names,
including privacy threshold analyses. A privacy impact assessment can also serve as noce to the
public regarding the organizaon’s pracces with respect to privacy. Although conducng and
publishing privacy impact assessments may be required by law, organizaons may develop such
policies in the absence of applicable laws. For federal agencies, privacy impact assessments may
be required by EGOV; agencies should consult with their senior agency oﬃcial for privacy and legal
This document is produced from OSCAL source data
FAMILY: RA PAGE 233NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
counsel on this requirement and be aware of the statutory excepons and OMB guidance relang to
the provision.
Related controls: CM-4, CM-9, CM-13, PT-2, PT-3, PT-5, RA-1, RA-2, RA-3, RA-7.
References: [EGOV], [OMB A-130], [OMB M-03-22]
RA-9 CRITICALITY ANALYSIS
Control: Idenfy crical system components and funcons by performing a cricality analysis for
[Assignment: organizaon-deﬁned systems, system components, or system services] at [Assignment:
organizaon-deﬁned decision points in the system development life cycle].
Discussion: Not all system components, funcons, or services necessarily require signiﬁcant
protecons. For example, cricality analysis is a key tenet of supply chain risk management and
informs the priorizaon of protecon acvies. The idenﬁcaon of crical system components
and funcons considers applicable laws, execuve orders, regulaons, direcves, policies, standards,
system funconality requirements, system and component interfaces, and system and component
dependencies. Systems engineers conduct a funconal decomposion of a system to idenfy mission-
crical funcons and components. The funconal decomposion includes the idenﬁcaon of
organizaonal missions supported by the system, decomposion into the speciﬁc funcons to
perform those missions, and traceability to the hardware, soware, and ﬁrmware components that
implement those funcons, including when the funcons are shared by many components within and
external to the system.
The operaonal environment of a system or a system component may impact the cricality, including
the connecons to and dependencies on cyber-physical systems, devices, system-of-systems,
and outsourced IT services. System components that allow unmediated access to crical system
components or funcons are considered crical due to the inherent vulnerabilies that such
components create. Component and funcon cricality are assessed in terms of the impact of a
component or funcon failure on the organizaonal missions that are supported by the system that
contains the components and funcons.
Cricality analysis is performed when an architecture or design is being developed, modiﬁed, or
upgraded. If such analysis is performed early in the system development life cycle, organizaons may
be able to modify the system design to reduce the crical nature of these components and funcons,
such as by adding redundancy or alternate paths into the system design. Cricality analysis can also
inﬂuence the protecon measures required by development contractors. In addion to cricality
analysis for systems, system components, and system services, cricality analysis of informaon is an
important consideraon. Such analysis is conducted as part of security categorizaon in RA-2.
Related controls: CP-2, PL-2, PL-8, PL-11, PM-1, PM-11, RA-2, SA-8, SA-15, SA-20, SR-5.
Reference: [IR 8179]
RA-10 THREAT HUNTING
Control:
a. Establish and maintain a cyber threat hunng capability to:
1. Search for indicators of compromise in organizaonal systems; and
2. Detect, track, and disrupt threats that evade exisng controls; and
b. Employ the threat hunng capability [Assignment: organizaon-deﬁned frequency].
Discussion: Threat hunng is an acve means of cyber defense in contrast to tradional protecon
measures, such as ﬁrewalls, intrusion detecon and prevenon systems, quaranning malicious code
This document is produced from OSCAL source data
FAMILY: RA PAGE 234NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
in sandboxes, and Security Informaon and Event Management technologies and systems. Cyber
threat hunng involves proacvely searching organizaonal systems, networks, and infrastructure
for advanced threats. The objecve is to track and disrupt cyber adversaries as early as possible in
the aack sequence and to measurably improve the speed and accuracy of organizaonal responses.
Indicaons of compromise include unusual network traﬃc, unusual ﬁle changes, and the presence of
malicious code. Threat hunng teams leverage exisng threat intelligence and may create new threat
intelligence, which is shared with peer organizaons, Informaon Sharing and Analysis Organizaons
(ISAO), Informaon Sharing and Analysis Centers (ISAC), and relevant government departments and
agencies.
Related controls: CA-2, CA-7, CA-8, RA-3, RA-5, RA-6, SI-4.
Reference: [SP 800-30]
This document is produced from OSCAL source data
FAMILY: RA PAGE 235NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
FAMILY: SYSTEM AND SERVICES ACQUISITION
SA-1 POLICY AND PROCEDURES
Control:
a. Develop, document, and disseminate to [Assignment: organizaon-deﬁned personnel or roles]:
1. [Selecon (one or more): Organizaon-level; Mission/business process-level; System-level]
system and services acquision policy that:
(a) Addresses purpose, scope, roles, responsibilies, management commitment,
coordinaon among organizaonal enes, and compliance; and
(b) Is consistent with applicable laws, execuve orders, direcves, regulaons, policies,
standards, and guidelines; and
2. Procedures to facilitate the implementaon of the system and services acquision policy
and the associated system and services acquision controls;
b. Designate an [Assignment: organizaon-deﬁned oﬃcial] to manage the development,
documentaon, and disseminaon of the system and services acquision policy and procedures;
and
c. Review and update the current system and services acquision:
1. Policy [Assignment: organizaon-deﬁned frequency] and following [Assignment:
organizaon-deﬁned events]; and
2. Procedures [Assignment: organizaon-deﬁned frequency] and following [Assignment:
organizaon-deﬁned events].
Discussion: System and services acquision policy and procedures address the controls in the SA
family that are implemented within systems and organizaons. The risk management strategy is an
important factor in establishing such policies and procedures. Policies and procedures contribute
to security and privacy assurance. Therefore, it is important that security and privacy programs
collaborate on the development of system and services acquision policy and procedures. Security
and privacy program policies and procedures at the organizaon level are preferable, in general,
and may obviate the need for mission- or system-speciﬁc policies and procedures. The policy can be
included as part of the general security and privacy policy or be represented by mulple policies that
reﬂect the complex nature of organizaons. Procedures can be established for security and privacy
programs, for mission or business processes, and for systems, if needed. Procedures describe how the
policies or controls are implemented and can be directed at the individual or role that is the object
of the procedure. Procedures can be documented in system security and privacy plans or in one or
more separate documents. Events that may precipitate an update to system and services acquision
policy and procedures include assessment or audit ﬁndings, security incidents or breaches, or changes
in laws, execuve orders, direcves, regulaons, policies, standards, and guidelines. Simply restang
controls does not constute an organizaonal policy or procedure.
Related controls: PM-9, PS-8, SA-8, SI-12.
References: [OMB A-130], [SP 800-100], [SP 800-12], [SP 800-160-1], [SP 800-30], [SP 800-39]
SA-2 ALLOCATION OF RESOURCES
Control:
a. Determine the high-level informaon security and privacy requirements for the system or system
service in mission and business process planning;
This document is produced from OSCAL source data
FAMILY: SA PAGE 236NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
b. Determine, document, and allocate the resources required to protect the system or system
service as part of the organizaonal capital planning and investment control process; and
c. Establish a discrete line item for informaon security and privacy in organizaonal programming
and budgeng documentaon.
Discussion: Resource allocaon for informaon security and privacy includes funding for system and
services acquision, sustainment, and supply chain-related risks throughout the system development
life cycle.
Related controls: PL-7, PM-3, PM-11, SA-9, SR-3, SR-5.
References: [OMB A-130], [SP 800-160-1], [SP 800-37]
SA-3 SYSTEM DEVELOPMENT LIFE CYCLE
Control:
a. Acquire, develop, and manage the system using [Assignment: organizaon-deﬁned system
development life cycle] that incorporates informaon security and privacy consideraons;
b. Deﬁne and document informaon security and privacy roles and responsibilies throughout the
system development life cycle;
c. Idenfy individuals having informaon security and privacy roles and responsibilies; and
d. Integrate the organizaonal informaon security and privacy risk management process into
system development life cycle acvies.
Discussion: A system development life cycle process provides the foundaon for the successful
development, implementaon, and operaon of organizaonal systems. The integraon of security
and privacy consideraons early in the system development life cycle is a foundaonal principle
of systems security engineering and privacy engineering. To apply the required controls within the
system development life cycle requires a basic understanding of informaon security and privacy,
threats, vulnerabilies, adverse impacts, and risk to crical mission and business funcons. The
security engineering principles in SA-8 help individuals properly design, code, and test systems and
system components. Organizaons include qualiﬁed personnel (e.g., senior agency informaon
security oﬃcers, senior agency oﬃcials for privacy, security and privacy architects, and security and
privacy engineers) in system development life cycle processes to ensure that established security and
privacy requirements are incorporated into organizaonal systems. Role-based security and privacy
training programs can ensure that individuals with key security and privacy roles and responsibilies
have the experience, skills, and experse to conduct assigned system development life cycle acvies.
The eﬀecve integraon of security and privacy requirements into enterprise architecture also
helps to ensure that important security and privacy consideraons are addressed throughout the
system life cycle and that those consideraons are directly related to organizaonal mission and
business processes. This process also facilitates the integraon of the informaon security and privacy
architectures into the enterprise architecture, consistent with the risk management strategy of
the organizaon. Because the system development life cycle involves mulple organizaons, (e.g.,
external suppliers, developers, integrators, service providers), acquision and supply chain risk
management funcons and controls play signiﬁcant roles in the eﬀecve management of the system
during the life cycle.
Related controls: AT-3, PL-8, PM-7, SA-4, SA-5, SA-8, SA-11, SA-15, SA-17, SA-22, SR-3, SR-4, SR-5, SR-9.
This document is produced from OSCAL source data
FAMILY: SA PAGE 237NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(1) SYSTEM DEVELOPMENT LIFE CYCLE | MANAGE PREPRODUCTION ENVIRONMENT
Protect system preproducon environments commensurate with risk throughout the system
development life cycle for the system, system component, or system service.
Discussion: The preproducon environment includes development, test, and integraon
environments. The program protecon planning processes established by the Department of
Defense are examples of managing the preproducon environment for defense contractors.
Cricality analysis and the applicaon of controls on developers also contribute to a more secure
system development environment.
Related controls: CM-2, CM-4, RA-3, RA-9, SA-4.
(2) SYSTEM DEVELOPMENT LIFE CYCLE | USE OF LIVE OR OPERATIONAL DATA
(a) Approve, document, and control the use of live data in preproducon environments for
the system, system component, or system service; and
(b) Protect preproducon environments for the system, system component, or system
service at the same impact or classiﬁcaon level as any live data in use within the
preproducon environments.
Discussion: Live data is also referred to as operaonal data. The use of live or operaonal
data in preproducon (i.e., development, test, and integraon) environments can result in
signiﬁcant risks to organizaons. In addion, the use of personally idenﬁable informaon in
tesng, research, and training increases the risk of unauthorized disclosure or misuse of such
informaon. Therefore, it is important for the organizaon to manage any addional risks that
may result from the use of live or operaonal data. Organizaons can minimize such risks by
using test or dummy data during the design, development, and tesng of systems, system
components, and system services. Risk assessment techniques may be used to determine if the
risk of using live or operaonal data is acceptable.
Related controls: PM-25, RA-3.
(3) SYSTEM DEVELOPMENT LIFE CYCLE | TECHNOLOGY REFRESH
Plan for and implement a technology refresh schedule for the system throughout the system
development life cycle.
Discussion: Technology refresh planning may encompass hardware, soware, ﬁrmware,
processes, personnel skill sets, suppliers, service providers, and facilies. The use of obsolete
or nearing obsolete technology may increase the security and privacy risks associated with
unsupported components, counterfeit or repurposed components, components unable to
implement security or privacy requirements, slow or inoperable components, components from
untrusted sources, inadvertent personnel error, or increased complexity. Technology refreshes
typically occur during the operaons and maintenance stage of the system development life
cycle.
Related control: MA-6.
References: [OMB A-130], [SP 800-160-1], [SP 800-171], [SP 800-172], [SP 800-30], [SP 800-37]
This document is produced from OSCAL source data
FAMILY: SA PAGE 238NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
SA-4 ACQUISITION PROCESS
Control: Include the following requirements, descripons, and criteria, explicitly or by reference, using
[Selecon (one or more): standardized contract language; [Assignment: organizaon-deﬁned contract
language]] in the acquision contract for the system, system component, or system service:
a. Security and privacy funconal requirements;
b. Strength of mechanism requirements;
c. Security and privacy assurance requirements;
d. Controls needed to sasfy the security and privacy requirements.
e. Security and privacy documentaon requirements;
f. Requirements for protecng security and privacy documentaon;
g. Descripon of the system development environment and environment in which the system is
intended to operate;
h. Allocaon of responsibility or idenﬁcaon of pares responsible for informaon security,
privacy, and supply chain risk management; and
i. Acceptance criteria.
Discussion: Security and privacy funconal requirements are typically derived from the high-level
security and privacy requirements described in SA-2. The derived requirements include security
and privacy capabilies, funcons, and mechanisms. Strength requirements associated with such
capabilies, funcons, and mechanisms include degree of correctness, completeness, resistance to
tampering or bypass, and resistance to direct aack. Assurance requirements include development
processes, procedures, and methodologies as well as the evidence from development and assessment
acvies that provide grounds for conﬁdence that the required funconality is implemented and
possesses the required strength of mechanism. SP 800-160-1 describes the process of requirements
engineering as part of the system development life cycle.
Controls can be viewed as descripons of the safeguards and protecon capabilies appropriate
for achieving the parcular security and privacy objecves of the organizaon and for reﬂecng
the security and privacy requirements of stakeholders. Controls are selected and implemented in
order to sasfy system requirements and include developer and organizaonal responsibilies.
Controls can include technical, administrave, and physical aspects. In some cases, the selecon and
implementaon of a control may necessitate addional speciﬁcaon by the organizaon in the form
of derived requirements or instanated control parameter values. The derived requirements and
control parameter values may be necessary to provide the appropriate level of implementaon detail
for controls within the system development life cycle.
Security and privacy documentaon requirements address all stages of the system development
life cycle. Documentaon provides user and administrator guidance for the implementaon and
operaon of controls. The level of detail required in such documentaon is based on the security
categorizaon or classiﬁcaon level of the system and the degree to which organizaons depend on
the capabilies, funcons, or mechanisms to meet risk response expectaons. Requirements can
include mandated conﬁguraon sengs that specify allowed funcons, ports, protocols, and services.
Acceptance criteria for systems, system components, and system services are deﬁned in the same
manner as the criteria for any organizaonal acquision or procurement.
Related controls: CM-6, CM-8, PS-7, SA-3, SA-5, SA-8, SA-11, SA-15, SA-16, SA-17, SA-21, SR-3, SR-5.
This document is produced from OSCAL source data
FAMILY: SA PAGE 239NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(1) ACQUISITION PROCESS | FUNCTIONAL PROPERTIES OF CONTROLS
Require the developer of the system, system component, or system service to provide a
descripon of the funconal properes of the controls to be implemented.
Discussion: Funconal properes of security and privacy controls describe the funconality
(i.e., security or privacy capability, funcons, or mechanisms) visible at the interfaces of the
controls and speciﬁcally exclude funconality and data structures internal to the operaon of
the controls.
(2) ACQUISITION PROCESS | DESIGN AND IMPLEMENTATION INFORMATION FOR
CONTROLS
Require the developer of the system, system component, or system service to provide design
and implementaon informaon for the controls that includes: [Selecon (one or more):
security-relevant external system interfaces; high-level design; low-level design; source code
or hardware schemacs; [Assignment: organizaon-deﬁned design and implementaon
informaon]] at [Assignment: organizaon-deﬁned level of detail].
Discussion: Organizaons may require diﬀerent levels of detail in the documentaon for the
design and implementaon of controls in organizaonal systems, system components, or
system services based on mission and business requirements, requirements for resiliency and
trustworthiness, and requirements for analysis and tesng. Systems can be paroned into
mulple subsystems. Each subsystem within the system can contain one or more modules.
The high-level design for the system is expressed in terms of subsystems and the interfaces
between subsystems providing security-relevant funconality. The low-level design for the
system is expressed in terms of modules and the interfaces between modules providing security-
relevant funconality. Design and implementaon documentaon can include manufacturer,
version, serial number, veriﬁcaon hash signature, soware libraries used, date of purchase
or download, and the vendor or download source. Source code and hardware schemacs are
referred to as the implementaon representaon of the system.
(3) ACQUISITION PROCESS | DEVELOPMENT METHODS, TECHNIQUES, AND PRACTICES
Require the developer of the system, system component, or system service to demonstrate
the use of a system development life cycle process that includes:
(a) [Assignment: organizaon-deﬁned systems engineering methods];
(b) [Assignment: organizaon-deﬁned [Selecon (one or more): systems security; privacy]
engineering methods]; and
(c) [Assignment: organizaon-deﬁned soware development methods; tesng, evaluaon,
assessment, veriﬁcaon, and validaon methods; and quality control processes].
Discussion: Following a system development life cycle that includes state-of-the-pracce soware
development methods, systems engineering methods, systems security and privacy engineering
methods, and quality control processes helps to reduce the number and severity of latent errors
within systems, system components, and system services. Reducing the number and severity of
such errors reduces the number of vulnerabilies in those systems, components, and services.
Transparency in the methods and techniques that developers select and implement for systems
engineering, systems security and privacy engineering, soware development, component and
system assessments, and quality control processes provides an increased level of assurance in
the trustworthiness of the system, system component, or system service being acquired.
This document is produced from OSCAL source data
FAMILY: SA PAGE 240NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(4) ACQUISITION PROCESS | ASSIGNMENT OF COMPONENTS TO SYSTEMS
[Withdrawn: Incorporated into CM-8(9).]
(5) ACQUISITION PROCESS | SYSTEM, COMPONENT, AND SERVICE CONFIGURATIONS
Require the developer of the system, system component, or system service to:
(a) Deliver the system, component, or service with [Assignment: organizaon-deﬁned
security conﬁguraons] implemented; and
(b) Use the conﬁguraons as the default for any subsequent system, component, or service
reinstallaon or upgrade.
Discussion: Examples of security conﬁguraons include the U.S. Government Conﬁguraon
Baseline (USGCB), Security Technical Implementaon Guides (STIGs), and any limitaons on
funcons, ports, protocols, and services. Security characteriscs can include requiring that
default passwords have been changed.
(6) ACQUISITION PROCESS | USE OF INFORMATION ASSURANCE PRODUCTS
(a) Employ only government oﬀ-the-shelf or commercial oﬀ-the-shelf informaon assurance
and informaon assurance-enabled informaon technology products that compose an
NSA-approved soluon to protect classiﬁed informaon when the networks used to
transmit the informaon are at a lower classiﬁcaon level than the informaon being
transmied; and
(b) Ensure that these products have been evaluated and/or validated by NSA or in
accordance with NSA-approved procedures.
Discussion: Commercial oﬀ-the-shelf IA or IA-enabled informaon technology products used to
protect classiﬁed informaon by cryptographic means may be required to use NSA-approved key
management. See NSA CSFC.
Related controls: SC-8, SC-12, SC-13.
(7) ACQUISITION PROCESS | NIAP-APPROVED PROTECTION PROFILES
(a) Limit the use of commercially provided informaon assurance and informaon assurance-
enabled informaon technology products to those products that have been successfully
evaluated against a Naonal Informaon Assurance partnership (NIAP)-approved
Protecon Proﬁle for a speciﬁc technology type, if such a proﬁle exists; and
(b) Require, if no NIAP-approved Protecon Proﬁle exists for a speciﬁc technology type
but a commercially provided informaon technology product relies on cryptographic
funconality to enforce its security policy, that the cryptographic module is FIPS-validated
or NSA-approved.
Discussion: See NIAP CCEVS for addional informaon on NIAP. See NIST CMVP for addional
informaon on FIPS-validated cryptographic modules.
Related controls: IA-7, SC-12, SC-13.
This document is produced from OSCAL source data
FAMILY: SA PAGE 241NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(8) ACQUISITION PROCESS | CONTINUOUS MONITORING PLAN FOR CONTROLS
Require the developer of the system, system component, or system service to produce a plan
for connuous monitoring of control eﬀecveness that is consistent with the connuous
monitoring program of the organizaon.
Discussion: The objecve of connuous monitoring plans is to determine if the planned, required,
and deployed controls within the system, system component, or system service connue to be
eﬀecve over me based on the inevitable changes that occur. Developer connuous monitoring
plans include a suﬃcient level of detail such that the informaon can be incorporated into
connuous monitoring programs implemented by organizaons. Connuous monitoring plans
can include the types of control assessment and monitoring acvies planned, frequency of
control monitoring, and acons to be taken when controls fail or become ineﬀecve.
Related control: CA-7.
(9) ACQUISITION PROCESS | FUNCTIONS, PORTS, PROTOCOLS, AND SERVICES IN USE
Require the developer of the system, system component, or system service to idenfy the
funcons, ports, protocols, and services intended for organizaonal use.
Discussion: The idenﬁcaon of funcons, ports, protocols, and services early in the system
development life cycle (e.g., during the inial requirements deﬁnion and design stages) allows
organizaons to inﬂuence the design of the system, system component, or system service. This
early involvement in the system development life cycle helps organizaons avoid or minimize the
use of funcons, ports, protocols, or services that pose unnecessarily high risks and understand
the trade-oﬀs involved in blocking speciﬁc ports, protocols, or services or requiring system
service providers to do so. Early idenﬁcaon of funcons, ports, protocols, and services
avoids costly retroﬁng of controls aer the system, component, or system service has been
implemented. SA-9 describes the requirements for external system services. Organizaons
idenfy which funcons, ports, protocols, and services are provided from external sources.
Related controls: CM-7, SA-9.
(10) ACQUISITION PROCESS | USE OF APPROVED PIV PRODUCTS
Employ only informaon technology products on the FIPS 201-approved products list for
Personal Identy Veriﬁcaon (PIV) capability implemented within organizaonal systems.
Discussion: Products on the FIPS 201-approved products list meet NIST requirements for Personal
Identy Veriﬁcaon (PIV) of Federal Employees and Contractors. PIV cards are used for mul-
factor authencaon in systems and organizaons.
Related controls: IA-2, IA-8, PM-9.
(11) ACQUISITION PROCESS | SYSTEM OF RECORDS
Include [Assignment: organizaon-deﬁned Privacy Act requirements] in the acquision
contract for the operaon of a system of records on behalf of an organizaon to accomplish an
organizaonal mission or funcon.
Discussion: When, by contract, an organizaon provides for the operaon of a system of records
to accomplish an organizaonal mission or funcon, the organizaon, consistent with its
authority, causes the requirements of the PRIVACT to be applied to the system of records.
Related control: PT-6.
This document is produced from OSCAL source data
FAMILY: SA PAGE 242NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(12) ACQUISITION PROCESS | DATA OWNERSHIP
(a) Include organizaonal data ownership requirements in the acquision contract; and
(b) Require all data to be removed from the contractor’s system and returned to the
organizaon within [Assignment: organizaon-deﬁned me frame].
Discussion: Contractors who operate a system that contains data owned by an organizaon
iniang the contract have policies and procedures in place to remove the data from their
systems and/or return the data in a me frame deﬁned by the contract.
References: [FIPS 140-3], [FIPS 201-2], [IR 7539], [IR 7622], [IR 7676], [IR 7870], [IR 8062], [ISO
15408-1], [ISO 15408-2], [ISO 15408-3], [ISO 29148], [NIAP CCEVS], [NSA CSFC], [OMB A-130],
[PRIVACT], [SP 800-137], [SP 800-160-1], [SP 800-161], [SP 800-35], [SP 800-37], [SP 800-70], [SP
800-73-4]
SA-5 SYSTEM DOCUMENTATION
Control:
a. Obtain or develop administrator documentaon for the system, system component, or system
service that describes:
1. Secure conﬁguraon, installaon, and operaon of the system, component, or service;
2. Eﬀecve use and maintenance of security and privacy funcons and mechanisms; and
3. Known vulnerabilies regarding conﬁguraon and use of administrave or privileged
funcons;
b. Obtain or develop user documentaon for the system, system component, or system service that
describes:
1. User-accessible security and privacy funcons and mechanisms and how to eﬀecvely use
those funcons and mechanisms;
2. Methods for user interacon, which enables individuals to use the system, component, or
service in a more secure manner and protect individual privacy; and
3. User responsibilies in maintaining the security of the system, component, or service and
privacy of individuals;
c. Document aempts to obtain system, system component, or system service documentaon
when such documentaon is either unavailable or nonexistent and take [Assignment:
organizaon-deﬁned acons] in response; and
d. Distribute documentaon to [Assignment: organizaon-deﬁned personnel or roles].
Discussion: System documentaon helps personnel understand the implementaon and operaon
of controls. Organizaons consider establishing speciﬁc measures to determine the quality and
completeness of the content provided. System documentaon may be used to support the
management of supply chain risk, incident response, and other funcons. Personnel or roles that
require documentaon include system owners, system security oﬃcers, and system administrators.
Aempts to obtain documentaon include contacng manufacturers or suppliers and conducng
web-based searches. The inability to obtain documentaon may occur due to the age of the system
or component or the lack of support from developers and contractors. When documentaon
cannot be obtained, organizaons may need to recreate the documentaon if it is essenal to
the implementaon or operaon of the controls. The protecon provided for the documentaon
This document is produced from OSCAL source data
FAMILY: SA PAGE 243NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
is commensurate with the security category or classiﬁcaon of the system. Documentaon that
addresses system vulnerabilies may require an increased level of protecon. Secure operaon of
the system includes inially starng the system and resuming secure system operaon aer a lapse in
system operaon.
Related controls: CM-4, CM-6, CM-7, CM-8, PL-2, PL-4, PL-8, PS-2, SA-3, SA-4, SA-8, SA-9, SA-10, SA-11,
SA-15, SA-16, SA-17, SI-12, SR-3.
(1) SYSTEM DOCUMENTATION | FUNCTIONAL PROPERTIES OF SECURITY CONTROLS
[Withdrawn: Incorporated into SA-4(1).]
(2) SYSTEM DOCUMENTATION | SECURITY-RELEVANT EXTERNAL SYSTEM INTERFACES
[Withdrawn: Incorporated into SA-4(2).]
(3) SYSTEM DOCUMENTATION | HIGH-LEVEL DESIGN
[Withdrawn: Incorporated into SA-4(2).]
(4) SYSTEM DOCUMENTATION | LOW-LEVEL DESIGN
[Withdrawn: Incorporated into SA-4(2).]
(5) SYSTEM DOCUMENTATION | SOURCE CODE
[Withdrawn: Incorporated into SA-4(2).]
Reference: [SP 800-160-1]
SA-6 Soware Usage Restricons
[Withdrawn: Incorporated into CM-10, SI-7.]
SA-7 User-installed Soware
[Withdrawn: Incorporated into CM-11, SI-7.]
SA-8 SECURITY AND PRIVACY ENGINEERING PRINCIPLES
Control: Apply the following systems security and privacy engineering principles in the speciﬁcaon,
design, development, implementaon, and modiﬁcaon of the system and system components:
[Assignment: organizaon-deﬁned systems security and privacy engineering principles].
Discussion: Systems security and privacy engineering principles are closely related to and implemented
throughout the system development life cycle (see SA-3). Organizaons can apply systems security
and privacy engineering principles to new systems under development or to systems undergoing
upgrades. For exisng systems, organizaons apply systems security and privacy engineering
principles to system upgrades and modiﬁcaons to the extent feasible, given the current state of
hardware, soware, and ﬁrmware components within those systems.
The applicaon of systems security and privacy engineering principles helps organizaons develop
trustworthy, secure, and resilient systems and reduces the suscepbility to disrupons, hazards,
threats, and the creaon of privacy problems for individuals. Examples of system security engineering
principles include: developing layered protecons; establishing security and privacy policies,
architecture, and controls as the foundaon for design and development; incorporang security and
This document is produced from OSCAL source data
FAMILY: SA PAGE 244NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
privacy requirements into the system development life cycle; delineang physical and logical security
boundaries; ensuring that developers are trained on how to build secure soware; tailoring controls
to meet organizaonal needs; and performing threat modeling to idenfy use cases, threat agents,
aack vectors and paerns, design paerns, and compensang controls needed to migate risk.
Organizaons that apply systems security and privacy engineering concepts and principles can
facilitate the development of trustworthy, secure systems, system components, and system services;
reduce risk to acceptable levels; and make informed risk management decisions. System security
engineering principles can also be used to protect against certain supply chain risks, including
incorporang tamper-resistant hardware into a design.
Related controls: PL-8, PM-7, RA-2, RA-3, RA-9, SA-3, SA-4, SA-15, SA-17, SA-20, SC-2, SC-3, SC-32,
SC-39, SR-2, SR-3, SR-4, SR-5.
(1) SECURITY AND PRIVACY ENGINEERING PRINCIPLES | CLEAR ABSTRACTIONS
Implement the security design principle of clear abstracons.
Discussion: The principle of clear abstracons states that a system has simple, well-deﬁned
interfaces and funcons that provide a consistent and intuive view of the data and how the
data is managed. The clarity, simplicity, necessity, and suﬃciency of the system interfaces—
combined with a precise deﬁnion of their funconal behavior—promotes ease of analysis,
inspecon, and tesng as well as the correct and secure use of the system. The clarity of
an abstracon is subjecve. Examples that reﬂect the applicaon of this principle include
avoidance of redundant, unused interfaces; informaon hiding; and avoidance of semanc
overloading of interfaces or their parameters. Informaon hiding (i.e., representaon-
independent programming), is a design discipline used to ensure that the internal representaon
of informaon in one system component is not visible to another system component invoking
or calling the ﬁrst component, such that the published abstracon is not inﬂuenced by how the
data may be managed internally.
(2) SECURITY AND PRIVACY ENGINEERING PRINCIPLES | LEAST COMMON MECHANISM
Implement the security design principle of least common mechanism in [Assignment:
organizaon-deﬁned systems or system components].
Discussion: The principle of least common mechanism states that the amount of mechanism
common to more than one user and depended on by all users is minimized POPEK74.
Mechanism minimizaon implies that diﬀerent components of a system refrain from using
the same mechanism to access a system resource. Every shared mechanism (especially a
mechanism involving shared variables) represents a potenal informaon path between users
and is designed with care to ensure that it does not unintenonally compromise security
SALTZER75. Implemenng the principle of least common mechanism helps to reduce the adverse
consequences of sharing the system state among diﬀerent programs. A single program that
corrupts a shared state (including shared variables) has the potenal to corrupt other programs
that are dependent on the state. The principle of least common mechanism also supports the
principle of simplicity of design and addresses the issue of covert storage channels LAMPSON73.
(3) SECURITY AND PRIVACY ENGINEERING PRINCIPLES | MODULARITY AND LAYERING
Implement the security design principles of modularity and layering in [Assignment:
organizaon-deﬁned systems or system components].
Discussion: The principles of modularity and layering are fundamental across system engineering
disciplines. Modularity and layering derived from funconal decomposion are eﬀecve in
This document is produced from OSCAL source data
FAMILY: SA PAGE 245NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
managing system complexity by making it possible to comprehend the structure of the system.
Modular decomposion, or reﬁnement in system design, is challenging and resists general
statements of principle. Modularity serves to isolate funcons and related data structures
into well-deﬁned logical units. Layering allows the relaonships of these units to be beer
understood so that dependencies are clear and undesired complexity can be avoided. The
security design principle of modularity extends funconal modularity to include consideraons
based on trust, trustworthiness, privilege, and security policy. Security-informed modular
decomposion includes the allocaon of policies to systems in a network, separaon of system
applicaons into processes with disnct address spaces, allocaon of system policies to layers,
and separaon of processes into subjects with disnct privileges based on hardware-supported
privilege domains.
Related controls: SC-2, SC-3.
(4) SECURITY AND PRIVACY ENGINEERING PRINCIPLES | PARTIALLY ORDERED
DEPENDENCIES
Implement the security design principle of parally ordered dependencies in [Assignment:
organizaon-deﬁned systems or system components].
Discussion: The principle of parally ordered dependencies states that the synchronizaon,
calling, and other dependencies in the system are parally ordered. A fundamental concept
in system design is layering, whereby the system is organized into well-deﬁned, funconally
related modules or components. The layers are linearly ordered with respect to inter-layer
dependencies, such that higher layers are dependent on lower layers. While providing
funconality to higher layers, some layers can be self-contained and not dependent on
lower layers. While a paral ordering of all funcons in a given system may not be possible,
if circular dependencies are constrained to occur within layers, the inherent problems of
circularity can be more easily managed. Parally ordered dependencies and system layering
contribute signiﬁcantly to the simplicity and coherency of the system design. Parally ordered
dependencies also facilitate system tesng and analysis.
(5) SECURITY AND PRIVACY ENGINEERING PRINCIPLES | EFFICIENTLY MEDIATED ACCESS
Implement the security design principle of eﬃciently mediated access in [Assignment:
organizaon-deﬁned systems or system components].
Discussion: The principle of eﬃciently mediated access states that policy enforcement
mechanisms ulize the least common mechanism available while sasfying stakeholder
requirements within expressed constraints. The mediaon of access to system resources (i.e.,
CPU, memory, devices, communicaon ports, services, infrastructure, data, and informaon)
is oen the predominant security funcon of secure systems. It also enables the realizaon of
protecons for the capability provided to stakeholders by the system. Mediaon of resource
access can result in performance bolenecks if the system is not designed correctly. For
example, by using hardware mechanisms, eﬃciently mediated access can be achieved. Once
access to a low-level resource such as memory has been obtained, hardware protecon
mechanisms can ensure that out-of-bounds access does not occur.
Related control: AC-25.
This document is produced from OSCAL source data
FAMILY: SA PAGE 246NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(6) SECURITY AND PRIVACY ENGINEERING PRINCIPLES | MINIMIZED SHARING
Implement the security design principle of minimized sharing in [Assignment: organizaon-
deﬁned systems or system components].
Discussion: The principle of minimized sharing states that no computer resource is shared
between system components (e.g., subjects, processes, funcons) unless it is absolutely
necessary to do so. Minimized sharing helps to simplify system design and implementaon.
In order to protect user-domain resources from arbitrary acve enes, no resource is shared
unless that sharing has been explicitly requested and granted. The need for resource sharing can
be movated by the design principle of least common mechanism in the case of internal enes
or driven by stakeholder requirements. However, internal sharing is carefully designed to avoid
performance and covert storage and ming channel problems. Sharing via common mechanism
can increase the suscepbility of data and informaon to unauthorized access, disclosure,
use, or modiﬁcaon and can adversely aﬀect the inherent capability provided by the system.
To minimize sharing induced by common mechanisms, such mechanisms can be designed to
be reentrant or virtualized to preserve separaon. Moreover, the use of global data to share
informaon is carefully scrunized. The lack of encapsulaon may obfuscate relaonships
among the sharing enes.
Related control: SC-31.
(7) SECURITY AND PRIVACY ENGINEERING PRINCIPLES | REDUCED COMPLEXITY
Implement the security design principle of reduced complexity in [Assignment: organizaon-
deﬁned systems or system components].
Discussion: The principle of reduced complexity states that the system design is as simple and
small as possible. A small and simple design is more understandable, more analyzable, and less
prone to error. The reduced complexity principle applies to any aspect of a system, but it has
parcular importance for security due to the various analyses performed to obtain evidence
about the emergent security property of the system. For such analyses to be successful, a small
and simple design is essenal. Applicaon of the principle of reduced complexity contributes
to the ability of system developers to understand the correctness and completeness of system
security funcons. It also facilitates the idenﬁcaon of potenal vulnerabilies. The corollary
of reduced complexity states that the simplicity of the system is directly related to the number
of vulnerabilies it will contain; that is, simpler systems contain fewer vulnerabilies. An beneﬁt
of reduced complexity is that it is easier to understand whether the intended security policy has
been captured in the system design and that fewer vulnerabilies are likely to be introduced
during engineering development. An addional beneﬁt is that any such conclusion about
correctness, completeness, and the existence of vulnerabilies can be reached with a higher
degree of assurance in contrast to conclusions reached in situaons where the system design
is inherently more complex. Transioning from older technologies to newer technologies (e.g.,
transioning from IPv4 to IPv6) may require implemenng the older and newer technologies
simultaneously during the transion period. This may result in a temporary increase in system
complexity during the transion.
This document is produced from OSCAL source data
FAMILY: SA PAGE 247NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(8) SECURITY AND PRIVACY ENGINEERING PRINCIPLES | SECURE EVOLVABILITY
Implement the security design principle of secure evolvability in [Assignment: organizaon-
deﬁned systems or system components].
Discussion: The principle of secure evolvability states that a system is developed to facilitate
the maintenance of its security properes when there are changes to the system’s structure,
interfaces, interconnecons (i.e., system architecture), funconality, or conﬁguraon (i.e.,
security policy enforcement). Changes include a new, enhanced, or upgraded system capability;
maintenance and sustainment acvies; and reconﬁguraon. Although it is not possible to
plan for every aspect of system evoluon, system upgrades and changes can be ancipated
by analyses of mission or business strategic direcon, ancipated changes in the threat
environment, and ancipated maintenance and sustainment needs. It is unrealisc to expect
that complex systems remain secure in contexts not envisioned during development, whether
such contexts are related to the operaonal environment or to usage. A system may be secure
in some new contexts, but there is no guarantee that its emergent behavior will always be
secure. It is easier to build trustworthiness into a system from the outset, and it follows that the
sustainment of system trustworthiness requires planning for change as opposed to adapng in
an ad hoc or non-methodical manner. The beneﬁts of this principle include reduced vendor life
cycle costs, reduced cost of ownership, improved system security, more eﬀecve management of
security risk, and less risk uncertainty.
Related control: CM-3.
(9) SECURITY AND PRIVACY ENGINEERING PRINCIPLES | TRUSTED COMPONENTS
Implement the security design principle of trusted components in [Assignment: organizaon-
deﬁned systems or system components].
Discussion: The principle of trusted components states that a component is trustworthy to at
least a level commensurate with the security dependencies it supports (i.e., how much it is
trusted to perform its security funcons by other components). This principle enables the
composion of components such that trustworthiness is not inadvertently diminished and
the trust is not consequently misplaced. Ulmately, this principle demands some metric by
which the trust in a component and the trustworthiness of a component can be measured
on the same abstract scale. The principle of trusted components is parcularly relevant when
considering systems and components in which there are complex chains of trust dependencies.
A trust dependency is also referred to as a trust relaonship and there may be chains of trust
relaonships.
The principle of trusted components also applies to a compound component that consists of
subcomponents (e.g., a subsystem), which may have varying levels of trustworthiness. The
conservave assumpon is that the trustworthiness of a compound component is that of its
least trustworthy subcomponent. It may be possible to provide a security engineering raonale
that the trustworthiness of a parcular compound component is greater than the conservave
assumpon. However, any such raonale reﬂects logical reasoning based on a clear statement of
the trustworthiness objecves as well as relevant and credible evidence. The trustworthiness of
a compound component is not the same as increased applicaon of defense-in-depth layering
within the component or a replicaon of components. Defense-in-depth techniques do not
increase the trustworthiness of the whole above that of the least trustworthy component.
This document is produced from OSCAL source data
FAMILY: SA PAGE 248NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(10) SECURITY AND PRIVACY ENGINEERING PRINCIPLES | HIERARCHICAL TRUST
Implement the security design principle of hierarchical trust in [Assignment: organizaon-
deﬁned systems or system components].
Discussion: The principle of hierarchical trust for components builds on the principle of trusted
components and states that the security dependencies in a system will form a paral ordering
if they preserve the principle of trusted components. The paral ordering provides the basis
for trustworthiness reasoning or an assurance case (assurance argument) when composing a
secure system from heterogeneously trustworthy components. To analyze a system composed
of heterogeneously trustworthy components for its trustworthiness, it is essenal to eliminate
circular dependencies with regard to the trustworthiness. If a more trustworthy component
located in a lower layer of the system were to depend on a less trustworthy component in a
higher layer, this would, in eﬀect, put the components in the same less trustworthy equivalence
class per the principle of trusted components. Trust relaonships, or chains of trust, can have
various manifestaons. For example, the root cerﬁcate of a cerﬁcate hierarchy is the most
trusted node in the hierarchy, whereas the leaves in the hierarchy may be the least trustworthy
nodes. Another example occurs in a layered high-assurance system where the security kernel
(including the hardware base), which is located at the lowest layer of the system, is the most
trustworthy component. The principle of hierarchical trust, however, does not prohibit the use of
overly trustworthy components. There may be cases in a system of low trustworthiness where it
is reasonable to employ a highly trustworthy component rather than one that is less trustworthy
(e.g., due to availability or other cost-beneﬁt driver). For such a case, any dependency of the
highly trustworthy component upon a less trustworthy component does not degrade the
trustworthiness of the resulng low-trust system.
(11) SECURITY AND PRIVACY ENGINEERING PRINCIPLES | INVERSE MODIFICATION
THRESHOLD
Implement the security design principle of inverse modiﬁcaon threshold in [Assignment:
organizaon-deﬁned systems or system components].
Discussion: The principle of inverse modiﬁcaon threshold builds on the principle of trusted
components and the principle of hierarchical trust and states that the degree of protecon
provided to a component is commensurate with its trustworthiness. As the trust placed in a
component increases, the protecon against unauthorized modiﬁcaon of the component
also increases to the same degree. Protecon from unauthorized modiﬁcaon can come in the
form of the component’s own self-protecon and innate trustworthiness, or it can come from
the protecons aﬀorded to the component from other elements or aributes of the security
architecture (to include protecons in the environment of operaon).
(12) SECURITY AND PRIVACY ENGINEERING PRINCIPLES | HIERARCHICAL PROTECTION
Implement the security design principle of hierarchical protecon in [Assignment:
organizaon-deﬁned systems or system components].
Discussion: The principle of hierarchical protecon states that a component need not be
protected from more trustworthy components. In the degenerate case of the most trusted
component, it protects itself from all other components. For example, if an operang system
kernel is deemed the most trustworthy component in a system, then it protects itself from all
untrusted applicaons it supports, but the applicaons, conversely, do not need to protect
themselves from the kernel. The trustworthiness of users is a consideraon for applying the
This document is produced from OSCAL source data
FAMILY: SA PAGE 249NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
principle of hierarchical protecon. A trusted system need not protect itself from an equally
trustworthy user, reﬂecng use of untrusted systems in system high environments where users
are highly trustworthy and where other protecons are put in place to bound and protect the
system high execuon environment.
(13) SECURITY AND PRIVACY ENGINEERING PRINCIPLES | MINIMIZED SECURITY ELEMENTS
Implement the security design principle of minimized security elements in [Assignment:
organizaon-deﬁned systems or system components].
Discussion: The principle of minimized security elements states that the system does not
have extraneous trusted components. The principle of minimized security elements has two
aspects: the overall cost of security analysis and the complexity of security analysis. Trusted
components are generally costlier to construct and implement, owing to the increased rigor
of development processes. Trusted components require greater security analysis to qualify
their trustworthiness. Thus, to reduce the cost and decrease the complexity of the security
analysis, a system contains as few trustworthy components as possible. The analysis of the
interacon of trusted components with other components of the system is one of the most
important aspects of system security veriﬁcaon. If the interacons between components are
unnecessarily complex, the security of the system will also be more diﬃcult to ascertain than
one whose internal trust relaonships are simple and elegantly constructed. In general, fewer
trusted components result in fewer internal trust relaonships and a simpler system.
(14) SECURITY AND PRIVACY ENGINEERING PRINCIPLES | LEAST PRIVILEGE
Implement the security design principle of least privilege in [Assignment: organizaon-deﬁned
systems or system components].
Discussion: The principle of least privilege states that each system component is allocated
suﬃcient privileges to accomplish its speciﬁed funcons but no more. Applying the principle
of least privilege limits the scope of the component’s acons, which has two desirable eﬀects:
the security impact of a failure, corrupon, or misuse of the component will have a minimized
security impact, and the security analysis of the component will be simpliﬁed. Least privilege
is a pervasive principle that is reﬂected in all aspects of the secure system design. Interfaces
used to invoke component capability are available to only certain subsets of the user populaon,
and component design supports a suﬃciently ﬁne granularity of privilege decomposion. For
example, in the case of an audit mechanism, there may be an interface for the audit manager,
who conﬁgures the audit sengs; an interface for the audit operator, who ensures that audit
data is safely collected and stored; and, ﬁnally, yet another interface for the audit reviewer, who
only has need to view the audit data that has been collected but no need to perform operaons
on that data.
In addion to its manifestaons at the system interface, least privilege can be used as a guiding
principle for the internal structure of the system itself. One aspect of internal least privilege is to
construct modules so that only the elements encapsulated by the module are directly operated
on by the funcons within the module. Elements external to a module that may be aﬀected by
the module’s operaon are indirectly accessed through interacon (e.g., via a funcon call) with
the module that contains those elements. Another aspect of internal least privilege is that the
scope of a given module or component includes only those system elements that are necessary
for its funconality and that the access modes for the elements (e.g., read, write) are minimal.
Related controls: AC-6, CM-7.
This document is produced from OSCAL source data
FAMILY: SA PAGE 250NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(15) SECURITY AND PRIVACY ENGINEERING PRINCIPLES | PREDICATE PERMISSION
Implement the security design principle of predicate permission in [Assignment: organizaon-
deﬁned systems or system components].
Discussion: The principle of predicate permission states that system designers consider requiring
mulple authorized enes to provide consent before a highly crical operaon or access to
highly sensive data, informaon, or resources is allowed to proceed. SALTZER75 originally
named predicate permission the separaon of privilege. It is also equivalent to separaon of
duty. The division of privilege among mulple pares decreases the likelihood of abuse and
provides the safeguard that no single accident, decepon, or breach of trust is suﬃcient to
enable an unrecoverable acon that can lead to signiﬁcantly damaging eﬀects. The design
opons for such a mechanism may require simultaneous acon (e.g., the ﬁring of a nuclear
weapon requires two diﬀerent authorized individuals to give the correct command within a small
me window) or a sequence of operaons where each successive acon is enabled by some
prior acon, but no single individual is able to enable more than one acon.
Related control: AC-5.
(16) SECURITY AND PRIVACY ENGINEERING PRINCIPLES | SELF-RELIANT TRUSTWORTHINESS
Implement the security design principle of self-reliant trustworthiness in [Assignment:
organizaon-deﬁned systems or system components].
Discussion: The principle of self-reliant trustworthiness states that systems minimize their reliance
on other systems for their own trustworthiness. A system is trustworthy by default, and any
connecon to an external enty is used to supplement its funcon. If a system were required to
maintain a connecon with another external enty in order to maintain its trustworthiness, then
that system would be vulnerable to malicious and non-malicious threats that could result in the
loss or degradaon of that connecon. The beneﬁt of the principle of self-reliant trustworthiness
is that the isolaon of a system will make it less vulnerable to aack. A corollary to this principle
relates to the ability of the system (or system component) to operate in isolaon and then
resynchronize with other components when it is rejoined with them.
(17) SECURITY AND PRIVACY ENGINEERING PRINCIPLES | SECURE DISTRIBUTED
COMPOSITION
Implement the security design principle of secure distributed composion in [Assignment:
organizaon-deﬁned systems or system components].
Discussion: The principle of secure distributed composion states that the composion of
distributed components that enforce the same system security policy result in a system that
enforces that policy at least as well as the individual components do. Many of the design
principles for secure systems deal with how components can or should interact. The need to
create or enable a capability from the composion of distributed components can magnify
the relevancy of these principles. In parcular, the translaon of security policy from a stand-
alone to a distributed system or a system-of-systems can have unexpected or emergent
results. Communicaon protocols and distributed data consistency mechanisms help to ensure
consistent policy enforcement across a distributed system. To ensure a system-wide level of
assurance of correct policy enforcement, the security architecture of a distributed composite
system is thoroughly analyzed.
This document is produced from OSCAL source data
FAMILY: SA PAGE 251NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(18) SECURITY AND PRIVACY ENGINEERING PRINCIPLES | TRUSTED COMMUNICATIONS
CHANNELS
Implement the security design principle of trusted communicaons channels in [Assignment:
organizaon-deﬁned systems or system components].
Discussion: The principle of trusted communicaon channels states that when composing a
system where there is a potenal threat to communicaons between components (i.e., the
interconnecons between components), each communicaon channel is trustworthy to a level
commensurate with the security dependencies it supports (i.e., how much it is trusted by other
components to perform its security funcons). Trusted communicaon channels are achieved
by a combinaon of restricng access to the communicaon channel (to ensure an acceptable
match in the trustworthiness of the endpoints involved in the communicaon) and employing
end-to-end protecons for the data transmied over the communicaon channel (to protect
against intercepon and modiﬁcaon and to further increase the assurance of proper end-to-
end communicaon).
Related controls: SC-8, SC-12, SC-13.
(19) SECURITY AND PRIVACY ENGINEERING PRINCIPLES | CONTINUOUS PROTECTION
Implement the security design principle of connuous protecon in [Assignment:
organizaon-deﬁned systems or system components].
Discussion: The principle of connuous protecon states that components and data used to
enforce the security policy have uninterrupted protecon that is consistent with the security
policy and the security architecture assumpons. No assurances that the system can provide
the conﬁdenality, integrity, availability, and privacy protecons for its design capability can
be made if there are gaps in the protecon. Any assurances about the ability to secure a
delivered capability require that data and informaon are connuously protected. That is, there
are no periods during which data and informaon are le unprotected while under control
of the system (i.e., during the creaon, storage, processing, or communicaon of the data
and informaon, as well as during system inializaon, execuon, failure, interrupon, and
shutdown). Connuous protecon requires adherence to the precepts of the reference monitor
concept (i.e., every request is validated by the reference monitor; the reference monitor is able
to protect itself from tampering; and suﬃcient assurance of the correctness and completeness
of the mechanism can be ascertained from analysis and tesng) and the principle of secure
failure and recovery (i.e., preservaon of a secure state during error, fault, failure, and successful
aack; preservaon of a secure state during recovery to normal, degraded, or alternave
operaonal modes).
Connuous protecon also applies to systems designed to operate in varying conﬁguraons,
including those that deliver full operaonal capability and degraded-mode conﬁguraons that
deliver paral operaonal capability. The connuous protecon principle requires that changes
to the system security policies be traceable to the operaonal need that drives the conﬁguraon
and be veriﬁable (i.e., it is possible to verify that the proposed changes will not put the system
into an insecure state). Insuﬃcient traceability and veriﬁcaon may lead to inconsistent states
or protecon disconnuies due to the complex or undecidable nature of the problem. The use
of pre-veriﬁed conﬁguraon deﬁnions that reﬂect the new security policy enables analysis to
determine that a transion from old to new policies is essenally atomic and that any residual
eﬀects from the old policy are guaranteed to not conﬂict with the new policy. The ability to
demonstrate connuous protecon is rooted in the clear arculaon of life cycle protecon
needs as stakeholder security requirements.
This document is produced from OSCAL source data
FAMILY: SA PAGE 252NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
Related control: AC-25.
(20) SECURITY AND PRIVACY ENGINEERING PRINCIPLES | SECURE METADATA MANAGEMENT
Implement the security design principle of secure metadata management in [Assignment:
organizaon-deﬁned systems or system components].
Discussion: The principle of secure metadata management states that metadata are ﬁrst class
objects with respect to security policy when the policy requires either complete protecon of
informaon or that the security subsystem be self-protecng. The principle of secure metadata
management is driven by the recognion that a system, subsystem, or component cannot
achieve self-protecon unless it protects the data it relies on for correct execuon. Data is
generally not interpreted by the system that stores it. It may have semanc value (i.e., it
comprises informaon) to users and programs that process the data. In contrast, metadata is
informaon about data, such as a ﬁle name or the date when the ﬁle was created. Metadata is
bound to the target data that it describes in a way that the system can interpret, but it need not
be stored inside of or proximate to its target data. There may be metadata whose target is itself
metadata (e.g., the classiﬁcaon level or impact level of a ﬁle name), including self-referenal
metadata.
The apparent secondary nature of metadata can lead to neglect of its legimate need for
protecon, resulng in a violaon of the security policy that includes the exﬁltraon of
informaon. A parcular concern associated with insuﬃcient protecons for metadata is
associated with mullevel secure (MLS) systems. MLS systems mediate access by a subject to
an object based on relave sensivity levels. It follows that all subjects and objects in the scope
of control of the MLS system are either directly labeled or indirectly aributed with sensivity
levels. The corollary of labeled metadata for MLS systems states that objects containing
metadata are labeled. As with protecon needs assessments for data, aenon is given to
ensure that the conﬁdenality and integrity protecons are individually assessed, speciﬁed, and
allocated to metadata, as would be done for mission, business, and system data.
(21) SECURITY AND PRIVACY ENGINEERING PRINCIPLES | SELF-ANALYSIS
Implement the security design principle of self-analysis in [Assignment: organizaon-deﬁned
systems or system components].
Discussion: The principle of self-analysis states that a system component is able to assess its
internal state and funconality to a limited extent at various stages of execuon, and that
this self-analysis capability is commensurate with the level of trustworthiness invested in the
system. At the system level, self-analysis can be achieved through hierarchical assessments
of trustworthiness established in a boom-up fashion. In this approach, the lower-level
components check for data integrity and correct funconality (to a limited extent) of higher-
level components. For example, trusted boot sequences involve a trusted lower-level component
that aests to the trustworthiness of the next higher-level components so that a transive
chain of trust can be established. At the root, a component aests to itself, which usually
involves an axiomac or environmentally enforced assumpon about its integrity. Results of the
self-analyses can be used to guard against externally induced errors, internal malfuncon, or
transient errors. By following this principle, some simple malfuncons or errors can be detected
without allowing the eﬀects of the error or malfuncon to propagate outside of the component.
Further, the self-test can be used to aest to the conﬁguraon of the component, detecng any
potenal conﬂicts in conﬁguraon with respect to the expected conﬁguraon.
Related control: CA-7.
This document is produced from OSCAL source data
FAMILY: SA PAGE 253NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(22) SECURITY AND PRIVACY ENGINEERING PRINCIPLES | ACCOUNTABILITY AND
TRACEABILITY
Implement the security design principle of accountability and traceability in [Assignment:
organizaon-deﬁned systems or system components].
Discussion: The principle of accountability and traceability states that it is possible to trace
security-relevant acons (i.e., subject-object interacons) to the enty on whose behalf the
acon is being taken. The principle of accountability and traceability requires a trustworthy
infrastructure that can record details about acons that aﬀect system security (e.g., an audit
subsystem). To record the details about acons, the system is able to uniquely idenfy the enty
on whose behalf the acon is being carried out and also record the relevant sequence of acons
that are carried out. The accountability policy also requires that audit trail itself be protected
from unauthorized access and modiﬁcaon. The principle of least privilege assists in tracing
the acons to parcular enes, as it increases the granularity of accountability. Associang
speciﬁc acons with system enes, and ulmately with users, and making the audit trail
secure against unauthorized access and modiﬁcaons provide non-repudiaon because once an
acon is recorded, it is not possible to change the audit trail. Another important funcon that
accountability and traceability serves is in the roune and forensic analysis of events associated
with the violaon of security policy. Analysis of audit logs may provide addional informaon
that may be helpful in determining the path or component that allowed the violaon of the
security policy and the acons of individuals associated with the violaon of the security policy.
Related controls: AC-6, AU-2, AU-3, AU-6, AU-9, AU-10, AU-12, IA-2, IR-4.
(23) SECURITY AND PRIVACY ENGINEERING PRINCIPLES | SECURE DEFAULTS
Implement the security design principle of secure defaults in [Assignment: organizaon-
deﬁned systems or system components].
Discussion: The principle of secure defaults states that the default conﬁguraon of a system
(including its constuent subsystems, components, and mechanisms) reﬂects a restricve
and conservave enforcement of security policy. The principle of secure defaults applies
to the inial (i.e., default) conﬁguraon of a system as well as to the security engineering
and design of access control and other security funcons that follow a deny unless explicitly
authorized strategy. The inial conﬁguraon aspect of this principle requires that any as shipped
conﬁguraon of a system, subsystem, or system component does not aid in the violaon of the
security policy and can prevent the system from operang in the default conﬁguraon for those
cases where the security policy itself requires conﬁguraon by the operaonal user.
Restricve defaults mean that the system will operate as-shipped with adequate self-protecon
and be able to prevent security breaches before the intended security policy and system
conﬁguraon is established. In cases where the protecon provided by the as-shipped product
is inadequate, stakeholders assess the risk of using it prior to establishing a secure inial state.
Adherence to the principle of secure defaults guarantees that a system is established in a secure
state upon successfully compleng inializaon. In situaons where the system fails to complete
inializaon, either it will perform a requested operaon using secure defaults or it will not
perform the operaon. Refer to the principles of connuous protecon and secure failure and
recovery that parallel this principle to provide the ability to detect and recover from failure.
The security engineering approach to this principle states that security mechanisms deny
requests unless the request is found to be well-formed and consistent with the security policy.
The insecure alternave is to allow a request unless it is shown to be inconsistent with the
policy. In a large system, the condions that are sasﬁed to grant a request that is denied by
This document is produced from OSCAL source data
FAMILY: SA PAGE 254NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
default are oen far more compact and complete than those that would need to be checked in
order to deny a request that is granted by default.
Related controls: CM-2, CM-6, SA-4.
(24) SECURITY AND PRIVACY ENGINEERING PRINCIPLES | SECURE FAILURE AND RECOVERY
Implement the security design principle of secure failure and recovery in [Assignment:
organizaon-deﬁned systems or system components].
Discussion: The principle of secure failure and recovery states that neither a failure in a system
funcon or mechanism nor any recovery acon in response to failure leads to a violaon of
security policy. The principle of secure failure and recovery parallels the principle of connuous
protecon to ensure that a system is capable of detecng (within limits) actual and impending
failure at any stage of its operaon (i.e., inializaon, normal operaon, shutdown, and
maintenance) and to take appropriate steps to ensure that security policies are not violated. In
addion, when speciﬁed, the system is capable of recovering from impending or actual failure to
resume normal, degraded, or alternave secure operaons while ensuring that a secure state is
maintained such that security policies are not violated.
Failure is a condion in which the behavior of a component deviates from its speciﬁed
or expected behavior for an explicitly documented input. Once a failed security funcon
is detected, the system may reconﬁgure itself to circumvent the failed component while
maintaining security and provide all or part of the funconality of the original system, or it may
completely shut itself down to prevent any further violaon of security policies. For this to occur,
the reconﬁguraon funcons of the system are designed to ensure connuous enforcement of
security policy during the various phases of reconﬁguraon.
Another technique that can be used to recover from failures is to perform a rollback to a
secure state (which may be the inial state) and then either shutdown or replace the service or
component that failed such that secure operaons may resume. Failure of a component may
or may not be detectable to the components using it. The principle of secure failure indicates
that components fail in a state that denies rather than grants access. For example, a nominally
atomic operaon interrupted before compleon does not violate security policy and is designed
to handle interrupon events by employing higher-level atomicity and rollback mechanisms
(e.g., transacons). If a service is being used, its atomicity properes are well-documented
and characterized so that the component availing itself of that service can detect and handle
interrupon events appropriately. For example, a system is designed to gracefully respond to
disconnecon and support resynchronizaon and data consistency aer disconnecon.
Failure protecon strategies that employ replicaon of policy enforcement mechanisms,
somemes called defense in depth, can allow the system to connue in a secure state even
when one mechanism has failed to protect the system. If the mechanisms are similar, however,
the addional protecon may be illusory, as the adversary can simply aack in series. Similarly,
in a networked system, breaking the security on one system or service may enable an aacker to
do the same on other similar replicated systems and services. By employing mulple protecon
mechanisms whose features are signiﬁcantly diﬀerent, the possibility of aack replicaon or
repeon can be reduced. Analyses are conducted to weigh the costs and beneﬁts of such
redundancy techniques against increased resource usage and adverse eﬀects on the overall
system performance. Addional analyses are conducted as the complexity of these mechanisms
increases, as could be the case for dynamic behaviors. Increased complexity generally reduces
trustworthiness. When a resource cannot be connuously protected, it is crical to detect and
repair any security breaches before the resource is once again used in a secure context.
Related controls: CP-10, CP-12, SC-7, SC-8, SC-24, SI-13.
This document is produced from OSCAL source data
FAMILY: SA PAGE 255NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(25) SECURITY AND PRIVACY ENGINEERING PRINCIPLES | ECONOMIC SECURITY
Implement the security design principle of economic security in [Assignment: organizaon-
deﬁned systems or system components].
Discussion: The principle of economic security states that security mechanisms are not costlier
than the potenal damage that could occur from a security breach. This is the security-relevant
form of the cost-beneﬁt analyses used in risk management. The cost assumpons of cost-
beneﬁt analysis prevent the system designer from incorporang security mechanisms of greater
strength than necessary, where strength of mechanism is proporonal to cost. The principle of
economic security also requires analysis of the beneﬁts of assurance relave to the cost of that
assurance in terms of the eﬀort expended to obtain relevant and credible evidence as well as the
necessary analyses to assess and draw trustworthiness and risk conclusions from the evidence.
Related control: RA-3.
(26) SECURITY AND PRIVACY ENGINEERING PRINCIPLES | PERFORMANCE SECURITY
Implement the security design principle of performance security in [Assignment: organizaon-
deﬁned systems or system components].
Discussion: The principle of performance security states that security mechanisms are
constructed so that they do not degrade system performance unnecessarily. Stakeholder
and system design requirements for performance and security are precisely arculated and
priorized. For the system implementaon to meet its design requirements and be found
acceptable to stakeholders (i.e., validaon against stakeholder requirements), the designers
adhere to the speciﬁed constraints that capability performance needs place on protecon
needs. The overall impact of computaonally intensive security services (e.g., cryptography)
are assessed and demonstrated to pose no signiﬁcant impact to higher-priority performance
consideraons or are deemed to provide an acceptable trade-oﬀ of performance for trustworthy
protecon. The trade-oﬀ consideraons include less computaonally intensive security services
unless they are unavailable or insuﬃcient. The insuﬃciency of a security service is determined
by funconal capability and strength of mechanism. The strength of mechanism is selected with
respect to security requirements, performance-crical overhead issues (e.g., cryptographic key
management), and an assessment of the capability of the threat.
The principle of performance security leads to the incorporaon of features that help in the
enforcement of security policy but incur minimum overhead, such as low-level hardware
mechanisms upon which higher-level services can be built. Such low-level mechanisms are
usually very speciﬁc, have very limited funconality, and are opmized for performance. For
example, once access rights to a poron of memory is granted, many systems use hardware
mechanisms to ensure that all further accesses involve the correct memory address and access
mode. Applicaon of this principle reinforces the need to design security into the system from
the ground up and to incorporate simple mechanisms at the lower layers that can be used as
building blocks for higher-level mechanisms.
Related controls: SC-12, SC-13, SI-2, SI-7.
(27) SECURITY AND PRIVACY ENGINEERING PRINCIPLES | HUMAN FACTORED SECURITY
Implement the security design principle of human factored security in [Assignment:
organizaon-deﬁned systems or system components].
Discussion: The principle of human factored security states that the user interface for security
funcons and supporng services is intuive, user-friendly, and provides feedback for user
This document is produced from OSCAL source data
FAMILY: SA PAGE 256NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
acons that aﬀect such policy and its enforcement. The mechanisms that enforce security policy
are not intrusive to the user and are designed not to degrade user eﬃciency. Security policy
enforcement mechanisms also provide the user with meaningful, clear, and relevant feedback
and warnings when insecure choices are being made. Parcular aenon is given to interfaces
through which personnel responsible for system administraon and operaon conﬁgure and
set up the security policies. Ideally, these personnel are able to understand the impact of
their choices. Personnel with system administrave and operaonal responsibilies are able
to conﬁgure systems before start-up and administer them during runme with conﬁdence
that their intent is correctly mapped to the system’s mechanisms. Security services, funcons,
and mechanisms do not impede or unnecessarily complicate the intended use of the system.
There is a trade-oﬀ between system usability and the strictness necessary for security policy
enforcement. If security mechanisms are frustrang or diﬃcult to use, then users may disable
them, avoid them, or use them in ways inconsistent with the security requirements and
protecon needs that the mechanisms were designed to sasfy.
(28) SECURITY AND PRIVACY ENGINEERING PRINCIPLES | ACCEPTABLE SECURITY
Implement the security design principle of acceptable security in [Assignment: organizaon-
deﬁned systems or system components].
Discussion: The principle of acceptable security requires that the level of privacy and performance
that the system provides is consistent with the users’ expectaons. The percepon of personal
privacy may aﬀect user behavior, morale, and eﬀecveness. Based on the organizaonal privacy
policy and the system design, users should be able to restrict their acons to protect their
privacy. When systems fail to provide intuive interfaces or meet privacy and performance
expectaons, users may either choose to completely avoid the system or use it in ways that may
be ineﬃcient or even insecure.
(29) SECURITY AND PRIVACY ENGINEERING PRINCIPLES | REPEATABLE AND DOCUMENTED
PROCEDURES
Implement the security design principle of repeatable and documented procedures in
[Assignment: organizaon-deﬁned systems or system components].
Discussion: The principle of repeatable and documented procedures states that the techniques
and methods employed to construct a system component permit the same component to be
completely and correctly reconstructed at a later me. Repeatable and documented procedures
support the development of a component that is idencal to the component created earlier,
which may be in widespread use. In the case of other system arfacts (e.g., documentaon
and tesng results), repeatability supports consistency and the ability to inspect the arfacts.
Repeatable and documented procedures can be introduced at various stages within the system
development life cycle and contribute to the ability to evaluate assurance claims for the system.
Examples include systemac procedures for code development and review, procedures for
the conﬁguraon management of development tools and system arfacts, and procedures for
system delivery.
Related controls: CM-1, SA-1, SA-10, SA-11, SA-15, SA-17, SC-1, SI-1.
This document is produced from OSCAL source data
FAMILY: SA PAGE 257NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(30) SECURITY AND PRIVACY ENGINEERING PRINCIPLES | PROCEDURAL RIGOR
Implement the security design principle of procedural rigor in [Assignment: organizaon-
deﬁned systems or system components].
Discussion: The principle of procedural rigor states that the rigor of a system life cycle process is
commensurate with its intended trustworthiness. Procedural rigor deﬁnes the scope, depth, and
detail of the system life cycle procedures. Rigorous system life cycle procedures contribute to the
assurance that the system is correct and free of unintended funconality in several ways. First,
the procedures impose checks and balances on the life cycle process such that the introducon
of unspeciﬁed funconality is prevented.
Second, rigorous procedures applied to systems security engineering acvies that produce
speciﬁcaons and other system design documents contribute to the ability to understand the
system as it has been built rather than trusng that the component, as implemented, is the
authoritave (and potenally misleading) speciﬁcaon.
Finally, modiﬁcaons to an exisng system component are easier when there are detailed
speciﬁcaons that describe its current design instead of studying source code or schemacs
to try to understand how it works. Procedural rigor helps ensure that security funconal and
assurance requirements have been sasﬁed, and it contributes to a beer-informed basis for the
determinaon of trustworthiness and risk posture. Procedural rigor is commensurate with the
degree of assurance desired for the system. If the required trustworthiness of the system is low,
a high level of procedural rigor may add unnecessary cost, whereas when high trustworthiness is
crical, the cost of high procedural rigor is merited.
(31) SECURITY AND PRIVACY ENGINEERING PRINCIPLES | SECURE SYSTEM MODIFICATION
Implement the security design principle of secure system modiﬁcaon in [Assignment:
organizaon-deﬁned systems or system components].
Discussion: The principle of secure system modiﬁcaon states that system modiﬁcaon maintains
system security with respect to the security requirements and risk tolerance of stakeholders.
Upgrades or modiﬁcaons to systems can transform secure systems into systems that are not
secure. The procedures for system modiﬁcaon ensure that if the system is to maintain its
trustworthiness, the same rigor that was applied to its inial development is applied to any
system changes. Because modiﬁcaons can aﬀect the ability of the system to maintain its secure
state, a careful security analysis of the modiﬁcaon is needed prior to its implementaon and
deployment. This principle parallels the principle of secure evolvability.
Related controls: CM-3, CM-4.
(32) SECURITY AND PRIVACY ENGINEERING PRINCIPLES | SUFFICIENT DOCUMENTATION
Implement the security design principle of suﬃcient documentaon in [Assignment:
organizaon-deﬁned systems or system components].
Discussion: The principle of suﬃcient documentaon states that organizaonal personnel with
responsibilies to interact with the system are provided with adequate documentaon and
other informaon such that the personnel contribute to rather than detract from system
security. Despite aempts to comply with principles such as human factored security and
acceptable security, systems are inherently complex, and the design intent for the use of security
mechanisms and the ramiﬁcaons of the misuse or misconﬁguraon of security mechanisms
are not always intuively obvious. Uninformed and insuﬃciently trained users can introduce
vulnerabilies due to errors of omission and commission. The availability of documentaon and
This document is produced from OSCAL source data
FAMILY: SA PAGE 258NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
training can help to ensure a knowledgeable cadre of personnel, all of whom have a crical role
in the achievement of principles such as connuous protecon. Documentaon is wrien clearly
and supported by training that provides security awareness and understanding of security-
relevant responsibilies.
Related controls: AT-2, AT-3, SA-5.
(33) SECURITY AND PRIVACY ENGINEERING PRINCIPLES | MINIMIZATION
Implement the privacy principle of minimizaon using [Assignment: organizaon-deﬁned
processes].
Discussion: The principle of minimizaon states that organizaons should only process personally
idenﬁable informaon that is directly relevant and necessary to accomplish an authorized
purpose and should only maintain personally idenﬁable informaon for as long as is necessary
to accomplish the purpose. Organizaons have processes in place, consistent with applicable
laws and policies, to implement the principle of minimizaon.
Related controls: PE-8, PM-25, SC-42, SI-12.
References: [FIPS 199], [FIPS 200], [IR 8062], [OMB A-130], [PRIVACT], [SP 800-160-1], [SP 800-37], [SP
800-53A], [SP 800-60-1], [SP 800-60-2]
SA-9 EXTERNAL SYSTEM SERVICES
Control:
a. Require that providers of external system services comply with organizaonal security and
privacy requirements and employ the following controls: [Assignment: organizaon-deﬁned
controls];
b. Deﬁne and document organizaonal oversight and user roles and responsibilies with regard to
external system services; and
c. Employ the following processes, methods, and techniques to monitor control compliance by
external service providers on an ongoing basis: [Assignment: organizaon-deﬁned processes,
methods, and techniques].
Discussion: External system services are provided by an external provider, and the organizaon has
no direct control over the implementaon of the required controls or the assessment of control
eﬀecveness. Organizaons establish relaonships with external service providers in a variety of
ways, including through business partnerships, contracts, interagency agreements, lines of business
arrangements, licensing agreements, joint ventures, and supply chain exchanges. The responsibility
for managing risks from the use of external system services remains with authorizing oﬃcials. For
services external to organizaons, a chain of trust requires that organizaons establish and retain
a certain level of conﬁdence that each provider in the consumer-provider relaonship provides
adequate protecon for the services rendered. The extent and nature of this chain of trust vary based
on relaonships between organizaons and the external providers. Organizaons document the
basis for the trust relaonships so that the relaonships can be monitored. External system services
documentaon includes government, service providers, end user security roles and responsibilies,
and service-level agreements. Service-level agreements deﬁne the expectaons of performance
for implemented controls, describe measurable outcomes, and idenfy remedies and response
requirements for idenﬁed instances of noncompliance.
Related controls: AC-20, CA-3, CP-2, IR-4, IR-7, PL-10, PL-11, PS-7, SA-2, SA-4, SR-3, SR-5.
This document is produced from OSCAL source data
FAMILY: SA PAGE 259NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(1) EXTERNAL SYSTEM SERVICES | RISK ASSESSMENTS AND ORGANIZATIONAL APPROVALS
(a) Conduct an organizaonal assessment of risk prior to the acquision or outsourcing of
informaon security services; and
(b) Verify that the acquision or outsourcing of dedicated informaon security services is
approved by [Assignment: organizaon-deﬁned personnel or roles].
Discussion: Informaon security services include the operaon of security devices, such as
ﬁrewalls or key management services as well as incident monitoring, analysis, and response.
Risks assessed can include system, mission or business, security, privacy, or supply chain risks.
Related controls: CA-6, RA-3, RA-8.
(2) EXTERNAL SYSTEM SERVICES | IDENTIFICATION OF FUNCTIONS, PORTS, PROTOCOLS,
AND SERVICES
Require providers of the following external system services to idenfy the funcons, ports,
protocols, and other services required for the use of such services: [Assignment: organizaon-
deﬁned external system services].
Discussion: Informaon from external service providers regarding the speciﬁc funcons, ports,
protocols, and services used in the provision of such services can be useful when the need arises
to understand the trade-oﬀs involved in restricng certain funcons and services or blocking
certain ports and protocols.
Related controls: CM-6, CM-7.
(3) EXTERNAL SYSTEM SERVICES | ESTABLISH AND MAINTAIN TRUST RELATIONSHIP WITH
PROVIDERS
Establish, document, and maintain trust relaonships with external service providers based
on the following requirements, properes, factors, or condions: [Assignment: organizaon-
deﬁned security and privacy requirements, properes, factors, or condions deﬁning
acceptable trust relaonships].
Discussion: Trust relaonships between organizaons and external service providers reﬂect
the degree of conﬁdence that the risk from using external services is at an acceptable level.
Trust relaonships can help organizaons gain increased levels of conﬁdence that service
providers are providing adequate protecon for the services rendered and can also be useful
when conducng incident response or when planning for upgrades or obsolescence. Trust
relaonships can be complicated due to the potenally large number of enes parcipang
in the consumer-provider interacons, subordinate relaonships and levels of trust, and types
of interacons between the pares. In some cases, the degree of trust is based on the level
of control that organizaons can exert on external service providers regarding the controls
necessary for the protecon of the service, informaon, or individual privacy and the evidence
brought forth as to the eﬀecveness of the implemented controls. The level of control is
established by the terms and condions of the contracts or service-level agreements.
Related control: SR-2.
This document is produced from OSCAL source data
FAMILY: SA PAGE 260NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(4) EXTERNAL SYSTEM SERVICES | CONSISTENT INTERESTS OF CONSUMERS AND
PROVIDERS
Take the following acons to verify that the interests of [Assignment: organizaon-
deﬁned external service providers] are consistent with and reﬂect organizaonal interests:
[Assignment: organizaon-deﬁned acons].
Discussion: As organizaons increasingly use external service providers, it is possible that the
interests of the service providers may diverge from organizaonal interests. In such situaons,
simply having the required technical, management, or operaonal controls in place may not
be suﬃcient if the providers that implement and manage those controls are not operang in a
manner consistent with the interests of the consuming organizaons. Acons that organizaons
take to address such concerns include requiring background checks for selected service provider
personnel; examining ownership records; employing only trustworthy service providers, such
as providers with which organizaons have had successful trust relaonships; and conducng
roune, periodic, unscheduled visits to service provider facilies.
(5) EXTERNAL SYSTEM SERVICES | PROCESSING, STORAGE, AND SERVICE LOCATION
Restrict the locaon of [Selecon (one or more): informaon processing; informaon or data;
system services] to [Assignment: organizaon-deﬁned locaons] based on [Assignment:
organizaon-deﬁned requirements or condions].
Discussion: The locaon of informaon processing, informaon and data storage, or system
services can have a direct impact on the ability of organizaons to successfully execute their
mission and business funcons. The impact occurs when external providers control the locaon
of processing, storage, or services. The criteria that external providers use for the selecon of
processing, storage, or service locaons may be diﬀerent from the criteria that organizaons
use. For example, organizaons may desire that data or informaon storage locaons be
restricted to certain locaons to help facilitate incident response acvies in case of informaon
security incidents or breaches. Incident response acvies, including forensic analyses and aer-
the-fact invesgaons, may be adversely aﬀected by the governing laws, policies, or protocols
in the locaons where processing and storage occur and/or the locaons from which system
services emanate.
Related controls: SA-5, SR-4.
(6) EXTERNAL SYSTEM SERVICES | ORGANIZATION-CONTROLLED CRYPTOGRAPHIC KEYS
Maintain exclusive control of cryptographic keys for encrypted material stored or transmied
through an external system.
Discussion: Maintaining exclusive control of cryptographic keys in an external system
prevents decrypon of organizaonal data by external system staﬀ. Organizaonal control
of cryptographic keys can be implemented by encrypng and decrypng data inside the
organizaon as data is sent to and received from the external system or by employing a
component that permits encrypon and decrypon funcons to be local to the external system
but allows exclusive organizaonal access to the encrypon keys.
Related controls: SC-12, SC-13, SI-4.
This document is produced from OSCAL source data
FAMILY: SA PAGE 261NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(7) EXTERNAL SYSTEM SERVICES | ORGANIZATION-CONTROLLED INTEGRITY CHECKING
Provide the capability to check the integrity of informaon while it resides in the external
system.
Discussion: Storage of organizaonal informaon in an external system could limit visibility into
the security status of its data. The ability of the organizaon to verify and validate the integrity
of its stored data without transferring it out of the external system provides such visibility.
Related control: SI-7.
(8) EXTERNAL SYSTEM SERVICES | PROCESSING AND STORAGE LOCATION — U.S.
JURISDICTION
Restrict the geographic locaon of informaon processing and data storage to facilies located
within in the legal jurisdiconal boundary of the United States.
Discussion: The geographic locaon of informaon processing and data storage can have a
direct impact on the ability of organizaons to successfully execute their mission and business
funcons. A compromise or breach of high impact informaon and systems can have severe
or catastrophic adverse impacts on organizaonal assets and operaons, individuals, other
organizaons, and the Naon. Restricng the processing and storage of high-impact informaon
to facilies within the legal jurisdiconal boundary of the United States provides greater control
over such processing and storage.
Related controls: SA-5, SR-4.
References: [OMB A-130], [SP 800-160-1], [SP 800-161], [SP 800-171], [SP 800-35]
SA-10 DEVELOPER CONFIGURATION MANAGEMENT
Control: Require the developer of the system, system component, or system service to:
a. Perform conﬁguraon management during system, component, or service [Selecon (one or
more): design; development; implementaon; operaon; disposal];
b. Document, manage, and control the integrity of changes to [Assignment: organizaon-deﬁned
conﬁguraon items under conﬁguraon management];
c. Implement only organizaon-approved changes to the system, component, or service;
d. Document approved changes to the system, component, or service and the potenal security
and privacy impacts of such changes; and
e. Track security ﬂaws and ﬂaw resoluon within the system, component, or service and report
ﬁndings to [Assignment: organizaon-deﬁned personnel].
Discussion: Organizaons consider the quality and completeness of conﬁguraon management
acvies conducted by developers as direct evidence of applying eﬀecve security controls. Controls
include protecng the master copies of material used to generate security-relevant porons of
the system hardware, soware, and ﬁrmware from unauthorized modiﬁcaon or destrucon.
Maintaining the integrity of changes to the system, system component, or system service requires
strict conﬁguraon control throughout the system development life cycle to track authorized changes
and prevent unauthorized changes.
The conﬁguraon items that are placed under conﬁguraon management include the formal model;
the funconal, high-level, and low-level design speciﬁcaons; other design data; implementaon
documentaon; source code and hardware schemacs; the current running version of the object
This document is produced from OSCAL source data
FAMILY: SA PAGE 262NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
code; tools for comparing new versions of security-relevant hardware descripons and source code
with previous versions; and test ﬁxtures and documentaon. Depending on the mission and business
needs of organizaons and the nature of the contractual relaonships in place, developers may
provide conﬁguraon management support during the operaons and maintenance stage of the
system development life cycle.
Related controls: CM-2, CM-3, CM-4, CM-7, CM-9, SA-4, SA-5, SA-8, SA-15, SI-2, SR-3, SR-4, SR-5, SR-6.
(1) DEVELOPER CONFIGURATION MANAGEMENT | SOFTWARE AND FIRMWARE INTEGRITY
VERIFICATION
Require the developer of the system, system component, or system service to enable integrity
veriﬁcaon of soware and ﬁrmware components.
Discussion: Soware and ﬁrmware integrity veriﬁcaon allows organizaons to detect
unauthorized changes to soware and ﬁrmware components using developer-provided tools,
techniques, and mechanisms. The integrity checking mechanisms can also address counterfeing
of soware and ﬁrmware components. Organizaons verify the integrity of soware and
ﬁrmware components, for example, through secure one-way hashes provided by developers.
Delivered soware and ﬁrmware components also include any updates to such components.
Related controls: SI-7, SR-11.
(2) DEVELOPER CONFIGURATION MANAGEMENT | ALTERNATIVE CONFIGURATION
MANAGEMENT PROCESSES
Provide an alternate conﬁguraon management process using organizaonal personnel in the
absence of a dedicated developer conﬁguraon management team.
Discussion: Alternate conﬁguraon management processes may be required when organizaons
use commercial oﬀ-the-shelf informaon technology products. Alternate conﬁguraon
management processes include organizaonal personnel who review and approve proposed
changes to systems, system components, and system services and conduct security and privacy
impact analyses prior to the implementaon of changes to systems, components, or services.
(3) DEVELOPER CONFIGURATION MANAGEMENT | HARDWARE INTEGRITY VERIFICATION
Require the developer of the system, system component, or system service to enable integrity
veriﬁcaon of hardware components.
Discussion: Hardware integrity veriﬁcaon allows organizaons to detect unauthorized changes to
hardware components using developer-provided tools, techniques, methods, and mechanisms.
Organizaons may verify the integrity of hardware components with hard-to-copy labels,
veriﬁable serial numbers provided by developers, and by requiring the use of an-tamper
technologies. Delivered hardware components also include hardware and ﬁrmware updates to
such components.
Related control: SI-7.
(4) DEVELOPER CONFIGURATION MANAGEMENT | TRUSTED GENERATION
Require the developer of the system, system component, or system service to employ tools for
comparing newly generated versions of security-relevant hardware descripons, source code,
and object code with previous versions.
Discussion: The trusted generaon of descripons, source code, and object code addresses
authorized changes to hardware, soware, and ﬁrmware components between versions during
This document is produced from OSCAL source data
FAMILY: SA PAGE 263NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
development. The focus is on the eﬃcacy of the conﬁguraon management process by the
developer to ensure that newly generated versions of security-relevant hardware descripons,
source code, and object code connue to enforce the security policy for the system, system
component, or system service. In contrast, SA-10(1) and SA-10(3) allow organizaons to detect
unauthorized changes to hardware, soware, and ﬁrmware components using tools, techniques,
or mechanisms provided by developers.
(5) DEVELOPER CONFIGURATION MANAGEMENT | MAPPING INTEGRITY FOR VERSION
CONTROL
Require the developer of the system, system component, or system service to maintain the
integrity of the mapping between the master build data describing the current version of
security-relevant hardware, soware, and ﬁrmware and the on-site master copy of the data
for the current version.
Discussion: Mapping integrity for version control addresses changes to hardware, soware,
and ﬁrmware components during both inial development and system development life cycle
updates. Maintaining the integrity between the master copies of security-relevant hardware,
soware, and ﬁrmware (including designs, hardware drawings, source code) and the equivalent
data in master copies in operaonal environments is essenal to ensuring the availability of
organizaonal systems that support crical mission and business funcons.
(6) DEVELOPER CONFIGURATION MANAGEMENT | TRUSTED DISTRIBUTION
Require the developer of the system, system component, or system service to execute
procedures for ensuring that security-relevant hardware, soware, and ﬁrmware updates
distributed to the organizaon are exactly as speciﬁed by the master copies.
Discussion: The trusted distribuon of security-relevant hardware, soware, and ﬁrmware
updates help to ensure that the updates are correct representaons of the master copies
maintained by the developer and have not been tampered with during distribuon.
(7) DEVELOPER CONFIGURATION MANAGEMENT | SECURITY AND PRIVACY
REPRESENTATIVES
Require [Assignment: organizaon-deﬁned security and privacy representaves] to be
included in the [Assignment: organizaon-deﬁned conﬁguraon change management and
control process].
Discussion: Informaon security and privacy representaves can include system security oﬃcers,
senior agency informaon security oﬃcers, senior agency oﬃcials for privacy, and system
privacy oﬃcers. Representaon by personnel with informaon security and privacy experse is
important because changes to system conﬁguraons can have unintended side eﬀects, some of
which may be security- or privacy-relevant. Detecng such changes early in the process can help
avoid unintended, negave consequences that could ulmately aﬀect the security and privacy
posture of systems. The conﬁguraon change management and control process in this control
enhancement refers to the change management and control process deﬁned by organizaons in
SA-10b.
References: [FIPS 140-3], [FIPS 180-4], [FIPS 202], [SP 800-128], [SP 800-160-1]
This document is produced from OSCAL source data
FAMILY: SA PAGE 264NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
SA-11 DEVELOPER TESTING AND EVALUATION
Control: Require the developer of the system, system component, or system service, at all post-design
stages of the system development life cycle, to:
a. Develop and implement a plan for ongoing security and privacy control assessments;
b. Perform [Selecon (one or more): unit; integraon; system; regression] tesng/evaluaon
[Assignment: organizaon-deﬁned frequency] at [Assignment: organizaon-deﬁned depth and
coverage];
c. Produce evidence of the execuon of the assessment plan and the results of the tesng and
evaluaon;
d. Implement a veriﬁable ﬂaw remediaon process; and
e. Correct ﬂaws idenﬁed during tesng and evaluaon.
Discussion: Developmental tesng and evaluaon conﬁrms that the required controls are implemented
correctly, operang as intended, enforcing the desired security and privacy policies, and meeng
established security and privacy requirements. Security properes of systems and the privacy of
individuals may be aﬀected by the interconnecon of system components or changes to those
components. The interconnecons or changes—including upgrading or replacing applicaons,
operang systems, and ﬁrmware—may adversely aﬀect previously implemented controls. Ongoing
assessment during development allows for addional types of tesng and evaluaon that developers
can conduct to reduce or eliminate potenal ﬂaws. Tesng custom soware applicaons may require
approaches such as manual code review, security architecture review, and penetraon tesng, as well
as and stac analysis, dynamic analysis, binary analysis, or a hybrid of the three analysis approaches.
Developers can use the analysis approaches, along with security instrumentaon and fuzzing, in
a variety of tools and in source code reviews. The security and privacy assessment plans include
the speciﬁc acvies that developers plan to carry out, including the types of analyses, tesng,
evaluaon, and reviews of soware and ﬁrmware components; the degree of rigor to be applied; the
frequency of the ongoing tesng and evaluaon; and the types of arfacts produced during those
processes. The depth of tesng and evaluaon refers to the rigor and level of detail associated with
the assessment process. The coverage of tesng and evaluaon refers to the scope (i.e., number and
type) of the arfacts included in the assessment process. Contracts specify the acceptance criteria for
security and privacy assessment plans, ﬂaw remediaon processes, and the evidence that the plans
and processes have been diligently applied. Methods for reviewing and protecng assessment plans,
evidence, and documentaon are commensurate with the security category or classiﬁcaon level of
the system. Contracts may specify protecon requirements for documentaon.
Related controls: CA-2, CA-7, CM-4, SA-3, SA-4, SA-5, SA-8, SA-15, SA-17, SI-2, SR-5, SR-6, SR-7.
(1) DEVELOPER TESTING AND EVALUATION | STATIC CODE ANALYSIS
Require the developer of the system, system component, or system service to employ stac
code analysis tools to idenfy common ﬂaws and document the results of the analysis.
Discussion: Stac code analysis provides a technology and methodology for security reviews
and includes checking for weaknesses in the code as well as for the incorporaon of libraries
or other included code with known vulnerabilies or that are out-of-date and not supported.
Stac code analysis can be used to idenfy vulnerabilies and enforce secure coding pracces.
It is most eﬀecve when used early in the development process, when each code change
can automacally be scanned for potenal weaknesses. Stac code analysis can provide
clear remediaon guidance and idenfy defects for developers to ﬁx. Evidence of the correct
implementaon of stac analysis can include aggregate defect density for crical defect types,
This document is produced from OSCAL source data
FAMILY: SA PAGE 265NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
evidence that defects were inspected by developers or security professionals, and evidence
that defects were remediated. A high density of ignored ﬁndings, commonly referred to as false
posives, indicates a potenal problem with the analysis process or the analysis tool. In such
cases, organizaons weigh the validity of the evidence against evidence from other sources.
(2) DEVELOPER TESTING AND EVALUATION | THREAT MODELING AND VULNERABILITY
ANALYSES
Require the developer of the system, system component, or system service to perform threat
modeling and vulnerability analyses during development and the subsequent tesng and
evaluaon of the system, component, or service that:
(a) Uses the following contextual informaon: [Assignment: organizaon-deﬁned
informaon concerning impact, environment of operaons, known or assumed threats,
and acceptable risk levels];
(b) Employs the following tools and methods: [Assignment: organizaon-deﬁned tools and
methods];
(c) Conducts the modeling and analyses at the following level of rigor: [Assignment:
organizaon-deﬁned breadth and depth of modeling and analyses]; and
(d) Produces evidence that meets the following acceptance criteria: [Assignment:
organizaon-deﬁned acceptance criteria].
Discussion: Systems, system components, and system services may deviate signiﬁcantly from
the funconal and design speciﬁcaons created during the requirements and design stages
of the system development life cycle. Therefore, updates to threat modeling and vulnerability
analyses of those systems, system components, and system services during development and
prior to delivery are crical to the eﬀecve operaon of those systems, components, and
services. Threat modeling and vulnerability analyses at this stage of the system development
life cycle ensure that design and implementaon changes have been accounted for and that
vulnerabilies created because of those changes have been reviewed and migated.
Related controls: PM-15, RA-3, RA-5.
(3) DEVELOPER TESTING AND EVALUATION | INDEPENDENT VERIFICATION OF ASSESSMENT
PLANS AND EVIDENCE
(a) Require an independent agent sasfying [Assignment: organizaon-deﬁned
independence criteria] to verify the correct implementaon of the developer security and
privacy assessment plans and the evidence produced during tesng and evaluaon; and
(b) Verify that the independent agent is provided with suﬃcient informaon to complete the
veriﬁcaon process or granted the authority to obtain such informaon.
Discussion: Independent agents have the qualiﬁcaons—including the experse, skills, training,
cerﬁcaons, and experience—to verify the correct implementaon of developer security and
privacy assessment plans.
Related controls: AT-3, RA-5.
(4) DEVELOPER TESTING AND EVALUATION | MANUAL CODE REVIEWS
Require the developer of the system, system component, or system service to perform a
manual code review of [Assignment: organizaon-deﬁned speciﬁc code] using the following
This document is produced from OSCAL source data
FAMILY: SA PAGE 266NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
processes, procedures, and/or techniques: [Assignment: organizaon-deﬁned processes,
procedures, and/or techniques].
Discussion: Manual code reviews are usually reserved for the crical soware and ﬁrmware
components of systems. Manual code reviews are eﬀecve at idenfying weaknesses
that require knowledge of the applicaon’s requirements or context that, in most cases, is
unavailable to automated analyc tools and techniques, such as stac and dynamic analysis.
The beneﬁts of manual code review include the ability to verify access control matrices against
applicaon controls and review detailed aspects of cryptographic implementaons and controls.
(5) DEVELOPER TESTING AND EVALUATION | PENETRATION TESTING
Require the developer of the system, system component, or system service to perform
penetraon tesng:
(a) At the following level of rigor: [Assignment: organizaon-deﬁned breadth and depth of
tesng]; and
(b) Under the following constraints: [Assignment: organizaon-deﬁned constraints].
Discussion: Penetraon tesng is an assessment methodology in which assessors, using all
available informaon technology product or system documentaon and working under speciﬁc
constraints, aempt to circumvent the implemented security and privacy features of informaon
technology products and systems. Useful informaon for assessors who conduct penetraon
tesng includes product and system design speciﬁcaons, source code, and administrator and
operator manuals. Penetraon tesng can include white-box, gray-box, or black-box tesng with
analyses performed by skilled professionals who simulate adversary acons. The objecve of
penetraon tesng is to discover vulnerabilies in systems, system components, and services
that result from implementaon errors, conﬁguraon faults, or other operaonal weaknesses
or deﬁciencies. Penetraon tests can be performed in conjuncon with automated and manual
code reviews to provide a greater level of analysis than would ordinarily be possible. When user
session informaon and other personally idenﬁable informaon is captured or recorded during
penetraon tesng, such informaon is handled appropriately to protect privacy.
Related controls: CA-8, PM-14, PM-25, PT-2, SA-3, SI-2, SI-6.
(6) DEVELOPER TESTING AND EVALUATION | ATTACK SURFACE REVIEWS
Require the developer of the system, system component, or system service to perform aack
surface reviews.
Discussion: Aack surfaces of systems and system components are exposed areas that make
those systems more vulnerable to aacks. Aack surfaces include any accessible areas where
weaknesses or deﬁciencies in the hardware, soware, and ﬁrmware components provide
opportunies for adversaries to exploit vulnerabilies. Aack surface reviews ensure that
developers analyze the design and implementaon changes to systems and migate aack
vectors generated as a result of the changes. The correcon of idenﬁed ﬂaws includes
deprecaon of unsafe funcons.
Related control: SA-15.
(7) DEVELOPER TESTING AND EVALUATION | VERIFY SCOPE OF TESTING AND EVALUATION
Require the developer of the system, system component, or system service to verify that the
scope of tesng and evaluaon provides complete coverage of the required controls at the
This document is produced from OSCAL source data
FAMILY: SA PAGE 267NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
following level of rigor: [Assignment: organizaon-deﬁned breadth and depth of tesng and
evaluaon].
Discussion: Verifying that tesng and evaluaon provides complete coverage of required controls
can be accomplished by a variety of analyc techniques ranging from informal to formal. Each
of these techniques provides an increasing level of assurance that corresponds to the degree
of formality of the analysis. Rigorously demonstrang control coverage at the highest levels of
assurance can be achieved using formal modeling and analysis techniques, including correlaon
between control implementaon and corresponding test cases.
Related control: SA-15.
(8) DEVELOPER TESTING AND EVALUATION | DYNAMIC CODE ANALYSIS
Require the developer of the system, system component, or system service to employ dynamic
code analysis tools to idenfy common ﬂaws and document the results of the analysis.
Discussion: Dynamic code analysis provides runme veriﬁcaon of soware programs using
tools capable of monitoring programs for memory corrupon, user privilege issues, and other
potenal security problems. Dynamic code analysis employs runme tools to ensure that
security funconality performs in the way it was designed. A type of dynamic analysis, known as
fuzz tesng, induces program failures by deliberately introducing malformed or random data into
soware programs. Fuzz tesng strategies are derived from the intended use of applicaons and
the funconal and design speciﬁcaons for the applicaons. To understand the scope of dynamic
code analysis and the assurance provided, organizaons may also consider conducng code
coverage analysis (i.e., checking the degree to which the code has been tested using metrics
such as percent of subrounes tested or percent of program statements called during execuon
of the test suite) and/or concordance analysis (i.e., checking for words that are out of place in
soware code, such as non-English language words or derogatory terms).
(9) DEVELOPER TESTING AND EVALUATION | INTERACTIVE APPLICATION SECURITY TESTING
Require the developer of the system, system component, or system service to employ
interacve applicaon security tesng tools to idenfy ﬂaws and document the results.
Discussion: Interacve (also known as instrumentaon-based) applicaon security tesng is
a method of detecng vulnerabilies by observing applicaons as they run during tesng.
The use of instrumentaon relies on direct measurements of the actual running applicaons
and uses access to the code, user interacon, libraries, frameworks, backend connecons,
and conﬁguraons to directly measure control eﬀecveness. When combined with analysis
techniques, interacve applicaon security tesng can idenfy a broad range of potenal
vulnerabilies and conﬁrm control eﬀecveness. Instrumentaon-based tesng works in real
me and can be used connuously throughout the system development life cycle.
References: [ISO 15408-3], [SP 800-154], [SP 800-160-1], [SP 800-30], [SP 800-53A]
SA-12 Supply Chain Protecon
[Withdrawn: Incorporated into Supply Chain Risk Management.]
(1) SUPPLY CHAIN PROTECTION | ACQUISITION STRATEGIES  TOOLS  METHODS
[Withdrawn: Incorporated into SR-5.]
This document is produced from OSCAL source data
FAMILY: SA PAGE 268NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(2) SUPPLY CHAIN PROTECTION | SUPPLIER REVIEWS
[Withdrawn: Incorporated into SR-6.]
(3) SUPPLY CHAIN PROTECTION | TRUSTED SHIPPING AND WAREHOUSING
[Withdrawn: Incorporated into SR-3.]
(4) SUPPLY CHAIN PROTECTION | DIVERSITY OF SUPPLIERS
[Withdrawn: Incorporated into SR-3(1).]
(5) SUPPLY CHAIN PROTECTION | LIMITATION OF HARM
[Withdrawn: Incorporated into SR-3(2).]
(6) SUPPLY CHAIN PROTECTION | MINIMIZING PROCUREMENT TIME
[Withdrawn: Incorporated into SR-5(1).]
(7) SUPPLY CHAIN PROTECTION | ASSESSMENTS PRIOR TO SELECTION  ACCEPTANCE 
UPDATE
[Withdrawn: Incorporated into SR-5(2).]
(8) SUPPLY CHAIN PROTECTION | USE OF ALL-SOURCE INTELLIGENCE
[Withdrawn: Incorporated into RA-3(2).]
(9) SUPPLY CHAIN PROTECTION | OPERATIONS SECURITY
[Withdrawn: Incorporated into SR-7.]
(10) SUPPLY CHAIN PROTECTION | VALIDATE AS GENUINE AND NOT ALTERED
[Withdrawn: Incorporated into SR-4(3).]
(11) SUPPLY CHAIN PROTECTION | PENETRATION TESTING  ANALYSIS OF ELEMENTS,
PROCESSES, AND ACTORS
[Withdrawn: Incorporated into SR-6(1).]
(12) SUPPLY CHAIN PROTECTION | INTER-ORGANIZATIONAL AGREEMENTS
[Withdrawn: Incorporated into SR-8.]
(13) SUPPLY CHAIN PROTECTION | CRITICAL INFORMATION SYSTEM COMPONENTS
[Withdrawn: Incorporated into MA-6, RA-9.]
(14) SUPPLY CHAIN PROTECTION | IDENTITY AND TRACEABILITY
[Withdrawn: Incorporated into SR-4(1), SR-4(2).]
This document is produced from OSCAL source data
FAMILY: SA PAGE 269NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(15) SUPPLY CHAIN PROTECTION | PROCESSES TO ADDRESS WEAKNESSES OR DEFICIENCIES
[Withdrawn: Incorporated into SR-3.]
SA-13 Trustworthiness
[Withdrawn: Incorporated into SA-8.]
SA-14 Cricality Analysis
[Withdrawn: Incorporated into RA-9.]
(1) CRITICALITY ANALYSIS | CRITICAL COMPONENTS WITH NO VIABLE ALTERNATIVE
SOURCING
[Withdrawn: Incorporated into SA-20.]
SA-15 DEVELOPMENT PROCESS, STANDARDS, AND TOOLS
Control:
a. Require the developer of the system, system component, or system service to follow a
documented development process that:
1. Explicitly addresses security and privacy requirements;
2. Idenﬁes the standards and tools used in the development process;
3. Documents the speciﬁc tool opons and tool conﬁguraons used in the development
process; and
4. Documents, manages, and ensures the integrity of changes to the process and/or tools used
in development; and
b. Review the development process, standards, tools, tool opons, and tool conﬁguraons
[Assignment: organizaon-deﬁned frequency] to determine if the process, standards, tools, tool
opons and tool conﬁguraons selected and employed can sasfy the following security and
privacy requirements: [Assignment: organizaon-deﬁned security and privacy requirements].
Discussion: Development tools include programming languages and computer-aided design systems.
Reviews of development processes include the use of maturity models to determine the potenal
eﬀecveness of such processes. Maintaining the integrity of changes to tools and processes facilitates
eﬀecve supply chain risk assessment and migaon. Such integrity requires conﬁguraon control
throughout the system development life cycle to track authorized changes and prevent unauthorized
changes.
Related controls: MA-6, SA-3, SA-4, SA-8, SA-10, SA-11, SR-3, SR-4, SR-5, SR-6, SR-9.
This document is produced from OSCAL source data
FAMILY: SA PAGE 270NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(1) DEVELOPMENT PROCESS, STANDARDS, AND TOOLS | QUALITY METRICS
Require the developer of the system, system component, or system service to:
(a) Deﬁne quality metrics at the beginning of the development process; and
(b) Provide evidence of meeng the quality metrics [Selecon (one or more): [Assignment:
organizaon-deﬁned frequency]; [Assignment: organizaon-deﬁned program review
milestones]; upon delivery].
Discussion: Organizaons use quality metrics to establish acceptable levels of system
quality. Metrics can include quality gates, which are collecons of compleon criteria or
suﬃciency standards that represent the sasfactory execuon of speciﬁc phases of the system
development project. For example, a quality gate may require the eliminaon of all compiler
warnings or a determinaon that such warnings have no impact on the eﬀecveness of required
security or privacy capabilies. During the execuon phases of development projects, quality
gates provide clear, unambiguous indicaons of progress. Other metrics apply to the enre
development project. Metrics can include deﬁning the severity thresholds of vulnerabilies in
accordance with organizaonal risk tolerance, such as requiring no known vulnerabilies in the
delivered system with a Common Vulnerability Scoring System (CVSS) severity of medium or
high.
(2) DEVELOPMENT PROCESS, STANDARDS, AND TOOLS | SECURITY AND PRIVACY TRACKING
TOOLS
Require the developer of the system, system component, or system service to select and
employ security and privacy tracking tools for use during the development process.
Discussion: System development teams select and deploy security and privacy tracking tools,
including vulnerability or work item tracking systems that facilitate assignment, sorng, ﬁltering,
and tracking of completed work items or tasks associated with development processes.
Related control: SA-11.
(3) DEVELOPMENT PROCESS, STANDARDS, AND TOOLS | CRITICALITY ANALYSIS
Require the developer of the system, system component, or system service to perform a
cricality analysis:
(a) At the following decision points in the system development life cycle: [Assignment:
organizaon-deﬁned decision points in the system development life cycle]; and
(b) At the following level of rigor: [Assignment: organizaon-deﬁned breadth and depth of
cricality analysis].
Discussion: Cricality analysis performed by the developer provides input to the cricality
analysis performed by organizaons. Developer input is essenal to organizaonal cricality
analysis because organizaons may not have access to detailed design documentaon for
system components that are developed as commercial oﬀ-the-shelf products. Such design
documentaon includes funconal speciﬁcaons, high-level designs, low-level designs, source
code, and hardware schemacs. Cricality analysis is important for organizaonal systems that
are designated as high value assets. High value assets can be moderate- or high-impact systems
due to heightened adversarial interest or potenal adverse eﬀects on the federal enterprise.
Developer input is especially important when organizaons conduct supply chain cricality
analyses.
This document is produced from OSCAL source data
FAMILY: SA PAGE 271NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
Related control: RA-9.
(4) DEVELOPMENT PROCESS, STANDARDS, AND TOOLS | THREAT MODELING AND
VULNERABILITY ANALYSIS
[Withdrawn: Incorporated into SA-11(2).]
(5) DEVELOPMENT PROCESS, STANDARDS, AND TOOLS | ATTACK SURFACE REDUCTION
Require the developer of the system, system component, or system service to reduce aack
surfaces to [Assignment: organizaon-deﬁned thresholds].
Discussion: Aack surface reducon is closely aligned with threat and vulnerability analyses
and system architecture and design. Aack surface reducon is a means of reducing risk to
organizaons by giving aackers less opportunity to exploit weaknesses or deﬁciencies (i.e.,
potenal vulnerabilies) within systems, system components, and system services. Aack
surface reducon includes implemenng the concept of layered defenses, applying the
principles of least privilege and least funconality, applying secure soware development
pracces, deprecang unsafe funcons, reducing entry points available to unauthorized users,
reducing the amount of code that executes, and eliminang applicaon programming interfaces
(APIs) that are vulnerable to aacks.
Related controls: AC-6, CM-7, RA-3, SA-11.
(6) DEVELOPMENT PROCESS, STANDARDS, AND TOOLS | CONTINUOUS IMPROVEMENT
Require the developer of the system, system component, or system service to implement an
explicit process to connuously improve the development process.
Discussion: Developers of systems, system components, and system services consider the
eﬀecveness and eﬃciency of their development processes for meeng quality objecves and
addressing the security and privacy capabilies in current threat environments.
(7) DEVELOPMENT PROCESS, STANDARDS, AND TOOLS | AUTOMATED VULNERABILITY
ANALYSIS
Require the developer of the system, system component, or system service [Assignment:
organizaon-deﬁned frequency] to:
(a) Perform an automated vulnerability analysis using [Assignment: organizaon-deﬁned
tools];
(b) Determine the exploitaon potenal for discovered vulnerabilies;
(c) Determine potenal risk migaons for delivered vulnerabilies; and
(d) Deliver the outputs of the tools and results of the analysis to [Assignment: organizaon-
deﬁned personnel or roles].
Discussion: Automated tools can be more eﬀecve at analyzing exploitable weaknesses or
deﬁciencies in large and complex systems, priorizing vulnerabilies by severity, and providing
recommendaons for risk migaons.
Related controls: RA-5, SA-11.
This document is produced from OSCAL source data
FAMILY: SA PAGE 272NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(8) DEVELOPMENT PROCESS, STANDARDS, AND TOOLS | REUSE OF THREAT AND
VULNERABILITY INFORMATION
Require the developer of the system, system component, or system service to use threat
modeling and vulnerability analyses from similar systems, components, or services to inform
the current development process.
Discussion: Analysis of vulnerabilies found in similar soware applicaons can inform potenal
design and implementaon issues for systems under development. Similar systems or system
components may exist within developer organizaons. Vulnerability informaon is available from
a variety of public and private sector sources, including the NIST Naonal Vulnerability Database.
(9) DEVELOPMENT PROCESS, STANDARDS, AND TOOLS | USE OF LIVE DATA
[Withdrawn: Incorporated into SA-3(2).]
(10) DEVELOPMENT PROCESS, STANDARDS, AND TOOLS | INCIDENT RESPONSE PLAN
Require the developer of the system, system component, or system service to provide,
implement, and test an incident response plan.
Discussion: The incident response plan provided by developers may provide informaon not
readily available to organizaons and be incorporated into organizaonal incident response
plans. Developer informaon may also be extremely helpful, such as when organizaons
respond to vulnerabilies in commercial oﬀ-the-shelf products.
Related control: IR-8.
(11) DEVELOPMENT PROCESS, STANDARDS, AND TOOLS | ARCHIVE SYSTEM OR
COMPONENT
Require the developer of the system or system component to archive the system or
component to be released or delivered together with the corresponding evidence supporng
the ﬁnal security and privacy review.
Discussion: Archiving system or system components requires the developer to retain key
development arfacts, including hardware speciﬁcaons, source code, object code, and relevant
documentaon from the development process that can provide a readily available conﬁguraon
baseline for system and component upgrades or modiﬁcaons.
Related control: CM-2.
(12) DEVELOPMENT PROCESS, STANDARDS, AND TOOLS | MINIMIZE PERSONALLY
IDENTIFIABLE INFORMATION
Require the developer of the system or system component to minimize the use of personally
idenﬁable informaon in development and test environments.
Discussion: Organizaons can minimize the risk to an individual’s privacy by using techniques such
as de-idenﬁcaon or synthec data. Liming the use of personally idenﬁable informaon in
development and test environments helps reduce the level of privacy risk created by a system.
Related controls: PM-25, SA-3, SA-8.
References: [IR 8179], [SP 800-160-1]
This document is produced from OSCAL source data
FAMILY: SA PAGE 273NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
SA-16 DEVELOPER-PROVIDED TRAINING
Control: Require the developer of the system, system component, or system service to provide
the following training on the correct use and operaon of the implemented security and privacy
funcons, controls, and/or mechanisms: [Assignment: organizaon-deﬁned training].
Discussion: Developer-provided training applies to external and internal (in-house) developers. Training
personnel is essenal to ensuring the eﬀecveness of the controls implemented within organizaonal
systems. Types of training include web-based and computer-based training, classroom-style training,
and hands-on training (including micro-training). Organizaons can also request training materials
from developers to conduct in-house training or oﬀer self-training to organizaonal personnel.
Organizaons determine the type of training necessary and may require diﬀerent types of training for
diﬀerent security and privacy funcons, controls, and mechanisms.
Related controls: AT-2, AT-3, PE-3, SA-4, SA-5.
References: None
SA-17 DEVELOPER SECURITY AND PRIVACY ARCHITECTURE AND DESIGN
Control: Require the developer of the system, system component, or system service to produce a
design speciﬁcaon and security and privacy architecture that:
a. Is consistent with the organizaon’s security and privacy architecture that is an integral part the
organizaon’s enterprise architecture;
b. Accurately and completely describes the required security and privacy funconality, and the
allocaon of controls among physical and logical components; and
c. Expresses how individual security and privacy funcons, mechanisms, and services work together
to provide required security and privacy capabilies and a uniﬁed approach to protecon.
Discussion: Developer security and privacy architecture and design are directed at external developers,
although they could also be applied to internal (in-house) development. In contrast, PL-8 is directed
at internal developers to ensure that organizaons develop a security and privacy architecture that
is integrated with the enterprise architecture. The disncon between SA-17 and PL-8 is especially
important when organizaons outsource the development of systems, system components, or
system services and when there is a requirement to demonstrate consistency with the enterprise
architecture and security and privacy architecture of the organizaon. ISO 15408-2, ISO 15408-3, and
SP 800-160-1 provide informaon on security architecture and design, including formal policy models,
security-relevant components, formal and informal correspondence, conceptually simple design, and
structuring for least privilege and tesng.
Related controls: PL-2, PL-8, PM-7, SA-3, SA-4, SA-8, SC-7.
(1) DEVELOPER SECURITY AND PRIVACY ARCHITECTURE AND DESIGN | FORMAL POLICY
MODEL
Require the developer of the system, system component, or system service to:
(a) Produce, as an integral part of the development process, a formal policy model describing
the [Assignment: organizaon-deﬁned elements of organizaonal security and privacy
policy] to be enforced; and
(b) Prove that the formal policy model is internally consistent and suﬃcient to enforce the
deﬁned elements of the organizaonal security and privacy policy when implemented.
Discussion: Formal models describe speciﬁc behaviors or security and privacy policies using
formal languages, thus enabling the correctness of those behaviors and policies to be formally
This document is produced from OSCAL source data
FAMILY: SA PAGE 274NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
proven. Not all components of systems can be modeled. Generally, formal speciﬁcaons are
scoped to the behaviors or policies of interest, such as nondiscreonary access control policies.
Organizaons choose the formal modeling language and approach based on the nature of the
behaviors and policies to be described and the available tools.
Related controls: AC-3, AC-4, AC-25.
(2) DEVELOPER SECURITY AND PRIVACY ARCHITECTURE AND DESIGN | SECURITY-RELEVANT
COMPONENTS
Require the developer of the system, system component, or system service to:
(a) Deﬁne security-relevant hardware, soware, and ﬁrmware; and
(b) Provide a raonale that the deﬁnion for security-relevant hardware, soware, and
ﬁrmware is complete.
Discussion: The security-relevant hardware, soware, and ﬁrmware represent the poron of the
system, component, or service that is trusted to perform correctly to maintain required security
properes.
Related controls: AC-25, SA-5.
(3) DEVELOPER SECURITY AND PRIVACY ARCHITECTURE AND DESIGN | FORMAL
CORRESPONDENCE
Require the developer of the system, system component, or system service to:
(a) Produce, as an integral part of the development process, a formal top-level speciﬁcaon
that speciﬁes the interfaces to security-relevant hardware, soware, and ﬁrmware in
terms of excepons, error messages, and eﬀects;
(b) Show via proof to the extent feasible with addional informal demonstraon as
necessary, that the formal top-level speciﬁcaon is consistent with the formal policy
model;
(c) Show via informal demonstraon, that the formal top-level speciﬁcaon completely
covers the interfaces to security-relevant hardware, soware, and ﬁrmware;
(d) Show that the formal top-level speciﬁcaon is an accurate descripon of the
implemented security-relevant hardware, soware, and ﬁrmware; and
(e) Describe the security-relevant hardware, soware, and ﬁrmware mechanisms not
addressed in the formal top-level speciﬁcaon but strictly internal to the security-relevant
hardware, soware, and ﬁrmware.
Discussion: Correspondence is an important part of the assurance gained through modeling.
It demonstrates that the implementaon is an accurate transformaon of the model, and
that any addional code or implementaon details that are present have no impact on the
behaviors or policies being modeled. Formal methods can be used to show that the high-level
security properes are sasﬁed by the formal system descripon, and that the formal system
descripon is correctly implemented by a descripon of some lower level, including a hardware
descripon. Consistency between the formal top-level speciﬁcaon and the formal policy
models is generally not amenable to being fully proven. Therefore, a combinaon of formal
and informal methods may be needed to demonstrate such consistency. Consistency between
the formal top-level speciﬁcaon and the actual implementaon may require the use of an
informal demonstraon due to limitaons on the applicability of formal methods to prove that
the speciﬁcaon accurately reﬂects the implementaon. Hardware, soware, and ﬁrmware
This document is produced from OSCAL source data
FAMILY: SA PAGE 275NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
mechanisms internal to security-relevant components include mapping registers and direct
memory input and output.
Related controls: AC-3, AC-4, AC-25, SA-4, SA-5.
(4) DEVELOPER SECURITY AND PRIVACY ARCHITECTURE AND DESIGN | INFORMAL
CORRESPONDENCE
Require the developer of the system, system component, or system service to:
(a) Produce, as an integral part of the development process, an informal descripve top-level
speciﬁcaon that speciﬁes the interfaces to security-relevant hardware, soware, and
ﬁrmware in terms of excepons, error messages, and eﬀects;
(b) Show via [Selecon: informal demonstraon; convincing argument with formal methods
as feasible] that the descripve top-level speciﬁcaon is consistent with the formal policy
model;
(c) Show via informal demonstraon, that the descripve top-level speciﬁcaon completely
covers the interfaces to security-relevant hardware, soware, and ﬁrmware;
(d) Show that the descripve top-level speciﬁcaon is an accurate descripon of the
interfaces to security-relevant hardware, soware, and ﬁrmware; and
(e) Describe the security-relevant hardware, soware, and ﬁrmware mechanisms not
addressed in the descripve top-level speciﬁcaon but strictly internal to the security-
relevant hardware, soware, and ﬁrmware.
Discussion: Correspondence is an important part of the assurance gained through modeling. It
demonstrates that the implementaon is an accurate transformaon of the model, and that
addional code or implementaon detail has no impact on the behaviors or policies being
modeled. Consistency between the descripve top-level speciﬁcaon (i.e., high-level/low-level
design) and the formal policy model is generally not amenable to being fully proven. Therefore,
a combinaon of formal and informal methods may be needed to show such consistency.
Hardware, soware, and ﬁrmware mechanisms strictly internal to security-relevant hardware,
soware, and ﬁrmware include mapping registers and direct memory input and output.
Related controls: AC-3, AC-4, AC-25, SA-4, SA-5.
(5) DEVELOPER SECURITY AND PRIVACY ARCHITECTURE AND DESIGN | CONCEPTUALLY
SIMPLE DESIGN
Require the developer of the system, system component, or system service to:
(a) Design and structure the security-relevant hardware, soware, and ﬁrmware to use a
complete, conceptually simple protecon mechanism with precisely deﬁned semancs;
and
(b) Internally structure the security-relevant hardware, soware, and ﬁrmware with speciﬁc
regard for this mechanism.
Discussion: The principle of reduced complexity states that the system design is as simple and
small as possible (see SA-8(7)). A small and simple design is easier to understand and analyze
and is also less prone to error (see AC-25, SA-8(13)). The principle of reduced complexity applies
to any aspect of a system, but it has parcular importance for security due to the various
analyses performed to obtain evidence about the emergent security property of the system.
For such analyses to be successful, a small and simple design is essenal. Applicaon of the
principle of reduced complexity contributes to the ability of system developers to understand
This document is produced from OSCAL source data
FAMILY: SA PAGE 276NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
the correctness and completeness of system security funcons and facilitates the idenﬁcaon
of potenal vulnerabilies. The corollary of reduced complexity states that the simplicity of the
system is directly related to the number of vulnerabilies it will contain. That is, simpler systems
contain fewer vulnerabilies. An important beneﬁt of reduced complexity is that it is easier to
understand whether the security policy has been captured in the system design and that fewer
vulnerabilies are likely to be introduced during engineering development. An addional beneﬁt
is that any such conclusion about correctness, completeness, and existence of vulnerabilies can
be reached with a higher degree of assurance in contrast to conclusions reached in situaons
where the system design is inherently more complex.
Related controls: AC-25, SA-8, SC-3.
(6) DEVELOPER SECURITY AND PRIVACY ARCHITECTURE AND DESIGN | STRUCTURE FOR
TESTING
Require the developer of the system, system component, or system service to structure
security-relevant hardware, soware, and ﬁrmware to facilitate tesng.
Discussion: Applying the security design principles in SP 800-160-1 promotes complete,
consistent, and comprehensive tesng and evaluaon of systems, system components, and
services. The thoroughness of such tesng contributes to the evidence produced to generate
an eﬀecve assurance case or argument as to the trustworthiness of the system, system
component, or service.
Related controls: SA-5, SA-11.
(7) DEVELOPER SECURITY AND PRIVACY ARCHITECTURE AND DESIGN | STRUCTURE FOR
LEAST PRIVILEGE
Require the developer of the system, system component, or system service to structure
security-relevant hardware, soware, and ﬁrmware to facilitate controlling access with least
privilege.
Discussion: The principle of least privilege states that each component is allocated suﬃcient
privileges to accomplish its speciﬁed funcons but no more (see SA-8(14)). Applying the principle
of least privilege limits the scope of the component’s acons, which has two desirable eﬀects.
First, the security impact of a failure, corrupon, or misuse of the system component results
in a minimized security impact. Second, the security analysis of the component is simpliﬁed.
Least privilege is a pervasive principle that is reﬂected in all aspects of the secure system design.
Interfaces used to invoke component capability are available to only certain subsets of the
user populaon, and component design supports a suﬃciently ﬁne granularity of privilege
decomposion. For example, in the case of an audit mechanism, there may be an interface for
the audit manager, who conﬁgures the audit sengs; an interface for the audit operator, who
ensures that audit data is safely collected and stored; and, ﬁnally, yet another interface for the
audit reviewer, who only has a need to view the audit data that has been collected but no need
to perform operaons on that data.
In addion to its manifestaons at the system interface, least privilege can be used as a guiding
principle for the internal structure of the system itself. One aspect of internal least privilege
is to construct modules so that only the elements encapsulated by the module are directly
operated upon by the funcons within the module. Elements external to a module that may
be aﬀected by the module’s operaon are indirectly accessed through interacon (e.g., via a
funcon call) with the module that contains those elements. Another aspect of internal least
privilege is that the scope of a given module or component includes only those system elements
This document is produced from OSCAL source data
FAMILY: SA PAGE 277NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
that are necessary for its funconality, and the access modes to the elements (e.g., read, write)
are minimal.
Related controls: AC-5, AC-6, SA-8.
(8) DEVELOPER SECURITY AND PRIVACY ARCHITECTURE AND DESIGN | ORCHESTRATION
Design [Assignment: organizaon-deﬁned crical systems or system components] with
coordinated behavior to implement the following capabilies: [Assignment: organizaon-
deﬁned capabilies, by system or component].
Discussion: Security resources that are distributed, located at diﬀerent layers or in diﬀerent
system elements, or are implemented to support diﬀerent aspects of trustworthiness can
interact in unforeseen or incorrect ways. Adverse consequences can include cascading failures,
interference, or coverage gaps. Coordinaon of the behavior of security resources (e.g., by
ensuring that one patch is installed across all resources before making a conﬁguraon change
that assumes that the patch is propagated) can avert such negave interacons.
(9) DEVELOPER SECURITY AND PRIVACY ARCHITECTURE AND DESIGN | DESIGN DIVERSITY
Use diﬀerent designs for [Assignment: organizaon-deﬁned crical systems or system
components] to sasfy a common set of requirements or to provide equivalent funconality.
Discussion: Design diversity is achieved by supplying the same requirements speciﬁcaon to
mulple developers, each of whom is responsible for developing a variant of the system or
system component that meets the requirements. Variants can be in soware design, in hardware
design, or in both hardware and a soware design. Diﬀerences in the designs of the variants can
result from developer experience (e.g., prior use of a design paern), design style (e.g., when
decomposing a required funcon into smaller tasks, determining what constutes a separate
task and how far to decompose tasks into sub-tasks), selecon of libraries to incorporate into
the variant, and the development environment (e.g., diﬀerent design tools make some design
paerns easier to visualize). Hardware design diversity includes making diﬀerent decisions
about what informaon to keep in analog form and what informaon to convert to digital
form, transming the same informaon at diﬀerent mes, and introducing delays in sampling
(temporal diversity). Design diversity is commonly used to support fault tolerance.
References: [ISO 15408-2], [ISO 15408-3], [SP 800-160-1]
SA-18 Tamper Resistance and Detecon
[Withdrawn: Moved to SR-9.]
(1) TAMPER RESISTANCE AND DETECTION | MULTIPLE PHASES OF SYSTEM DEVELOPMENT
LIFE CYCLE
[Withdrawn: Incorporated into SR-9(1).]
(2) TAMPER RESISTANCE AND DETECTION | INSPECTION OF SYSTEMS OR COMPONENTS
[Withdrawn: Incorporated into SR-10.]
SA-19 Component Authencity
[Withdrawn: Moved to SR-11.]
This document is produced from OSCAL source data
FAMILY: SA PAGE 278NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(1) COMPONENT AUTHENTICITY | ANTI-COUNTERFEIT TRAINING
[Withdrawn: Incorporated into SR-11(1).]
(2) COMPONENT AUTHENTICITY | CONFIGURATION CONTROL FOR COMPONENT SERVICE
AND REPAIR
[Withdrawn: Incorporated into SR-11(2).]
(3) COMPONENT AUTHENTICITY | COMPONENT DISPOSAL
[Withdrawn: Incorporated into SR-12.]
(4) COMPONENT AUTHENTICITY | ANTI-COUNTERFEIT SCANNING
[Withdrawn: Incorporated into SR-11(3).]
SA-20 CUSTOMIZED DEVELOPMENT OF CRITICAL COMPONENTS
Control: Reimplement or custom develop the following crical system components: [Assignment:
organizaon-deﬁned crical system components].
Discussion: Organizaons determine that certain system components likely cannot be trusted
due to speciﬁc threats to and vulnerabilies in those components for which there are no viable
security controls to adequately migate risk. Reimplementaon or custom development of such
components may sasfy requirements for higher assurance and is carried out by iniang changes
to system components (including hardware, soware, and ﬁrmware) such that the standard aacks
by adversaries are less likely to succeed. In situaons where no alternave sourcing is available and
organizaons choose not to reimplement or custom develop crical system components, addional
controls can be employed. Controls include enhanced auding, restricons on source code and
system ulity access, and protecon from deleon of system and applicaon ﬁles.
Related controls: CP-2, RA-9, SA-8.
Reference: [SP 800-160-1]
SA-21 DEVELOPER SCREENING
Control: Require that the developer of [Assignment: organizaon-deﬁned system, system component,
or system service]:
a. Has appropriate access authorizaons as determined by assigned [Assignment: organizaon-
deﬁned oﬃcial government dues]; and
b. Sasﬁes the following addional personnel screening criteria: [Assignment: organizaon-deﬁned
addional personnel screening criteria].
Discussion: Developer screening is directed at external developers. Internal developer screening is
addressed by PS-3. Because the system, system component, or system service may be used in crical
acvies essenal to the naonal or economic security interests of the United States, organizaons
have a strong interest in ensuring that developers are trustworthy. The degree of trust required of
developers may need to be consistent with that of the individuals who access the systems, system
components, or system services once deployed. Authorizaon and personnel screening criteria
include clearances, background checks, cizenship, and naonality. Developer trustworthiness may
also include a review and analysis of company ownership and relaonships that the company has with
This document is produced from OSCAL source data
FAMILY: SA PAGE 279NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
enes that may potenally aﬀect the quality and reliability of the systems, components, or services
being developed. Sasfying the required access authorizaons and personnel screening criteria
includes providing a list of all individuals who are authorized to perform development acvies on
the selected system, system component, or system service so that organizaons can validate that the
developer has sasﬁed the authorizaon and screening requirements.
Related controls: PS-2, PS-3, PS-6, PS-7, SA-4, SR-6.
(1) DEVELOPER SCREENING | VALIDATION OF SCREENING
[Withdrawn: Incorporated into SA-21.]
References: None
SA-22 UNSUPPORTED SYSTEM COMPONENTS
Control:
a. Replace system components when support for the components is no longer available from the
developer, vendor, or manufacturer; or
b. Provide the following opons for alternave sources for connued support for unsupported
components [Selecon (one or more): in-house support; [Assignment: organizaon-deﬁned
support from external providers]].
Discussion: Support for system components includes soware patches, ﬁrmware updates, replacement
parts, and maintenance contracts. An example of unsupported components includes when vendors
no longer provide crical soware patches or product updates, which can result in an opportunity for
adversaries to exploit weaknesses in the installed components. Excepons to replacing unsupported
system components include systems that provide crical mission or business capabilies where
newer technologies are not available or where the systems are so isolated that installing replacement
components is not an opon.
Alternave sources for support address the need to provide connued support for system
components that are no longer supported by the original manufacturers, developers, or vendors
when such components remain essenal to organizaonal mission and business funcons. If
necessary, organizaons can establish in-house support by developing customized patches for
crical soware components or, alternavely, obtain the services of external providers who provide
ongoing support for the designated unsupported components through contractual relaonships.
Such contractual relaonships can include open-source soware value-added vendors. The increased
risk of using unsupported system components can be migated, for example, by prohibing the
connecon of such components to public or uncontrolled networks, or implemenng other forms of
isolaon.
Related controls: PL-2, SA-3.
(1) UNSUPPORTED SYSTEM COMPONENTS | ALTERNATIVE SOURCES FOR CONTINUED
SUPPORT
[Withdrawn: Incorporated into SA-22.]
References: None
This document is produced from OSCAL source data
FAMILY: SA PAGE 280NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
SA-23 SPECIALIZATION
Control: Employ [Selecon (one or more): design; modiﬁcaon; augmentaon; reconﬁguraon] on
[Assignment: organizaon-deﬁned systems or system components] supporng mission essenal
services or funcons to increase the trustworthiness in those systems or components.
Discussion: It is oen necessary for a system or system component that supports mission-essenal
services or funcons to be enhanced to maximize the trustworthiness of the resource. Somemes
this enhancement is done at the design level. In other instances, it is done post-design, either through
modiﬁcaons of the system in queson or by augmenng the system with addional components. For
example, supplemental authencaon or non-repudiaon funcons may be added to the system to
enhance the identy of crical resources to other resources that depend on the organizaon-deﬁned
resources.
Related controls: RA-9, SA-8.
References: [SP 800-160-1], [SP 800-160-2]
This document is produced from OSCAL source data
FAMILY: SA PAGE 281NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
FAMILY: SYSTEM AND COMMUNICATIONS PROTECTION
SC-1 POLICY AND PROCEDURES
Control:
a. Develop, document, and disseminate to [Assignment: organizaon-deﬁned personnel or roles]:
1. [Selecon (one or more): Organizaon-level; Mission/business process-level; System-level]
system and communicaons protecon policy that:
(a) Addresses purpose, scope, roles, responsibilies, management commitment,
coordinaon among organizaonal enes, and compliance; and
(b) Is consistent with applicable laws, execuve orders, direcves, regulaons, policies,
standards, and guidelines; and
2. Procedures to facilitate the implementaon of the system and communicaons protecon
policy and the associated system and communicaons protecon controls;
b. Designate an [Assignment: organizaon-deﬁned oﬃcial] to manage the development,
documentaon, and disseminaon of the system and communicaons protecon policy and
procedures; and
c. Review and update the current system and communicaons protecon:
1. Policy [Assignment: organizaon-deﬁned frequency] and following [Assignment:
organizaon-deﬁned events]; and
2. Procedures [Assignment: organizaon-deﬁned frequency] and following [Assignment:
organizaon-deﬁned events].
Discussion: System and communicaons protecon policy and procedures address the controls in the
SC family that are implemented within systems and organizaons. The risk management strategy is
an important factor in establishing such policies and procedures. Policies and procedures contribute
to security and privacy assurance. Therefore, it is important that security and privacy programs
collaborate on the development of system and communicaons protecon policy and procedures.
Security and privacy program policies and procedures at the organizaon level are preferable, in
general, and may obviate the need for mission- or system-speciﬁc policies and procedures. The policy
can be included as part of the general security and privacy policy or be represented by mulple
policies that reﬂect the complex nature of organizaons. Procedures can be established for security
and privacy programs, for mission or business processes, and for systems, if needed. Procedures
describe how the policies or controls are implemented and can be directed at the individual or role
that is the object of the procedure. Procedures can be documented in system security and privacy
plans or in one or more separate documents. Events that may precipitate an update to system and
communicaons protecon policy and procedures include assessment or audit ﬁndings, security
incidents or breaches, or changes in applicable laws, execuve orders, direcves, regulaons, policies,
standards, and guidelines. Simply restang controls does not constute an organizaonal policy or
procedure.
Related controls: PM-9, PS-8, SA-8, SI-12.
References: [OMB A-130], [SP 800-100], [SP 800-12]
SC-2 SEPARATION OF SYSTEM AND USER FUNCTIONALITY
Control: Separate user funconality, including user interface services, from system management
funconality.
This document is produced from OSCAL source data
FAMILY: SC PAGE 282NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
Discussion: System management funconality includes funcons that are necessary to administer
databases, network components, workstaons, or servers. These funcons typically require privileged
user access. The separaon of user funcons from system management funcons is physical or
logical. Organizaons may separate system management funcons from user funcons by using
diﬀerent computers, instances of operang systems, central processing units, or network addresses;
by employing virtualizaon techniques; or some combinaon of these or other methods. Separaon
of system management funcons from user funcons includes web administrave interfaces that
employ separate authencaon methods for users of any other system resources. Separaon of
system and user funcons may include isolang administrave interfaces on diﬀerent domains and
with addional access controls. The separaon of system and user funconality can be achieved by
applying the systems security engineering design principles in SA-8, including SA-8(1), SA-8(3), SA-8(4),
SA-8(10), SA-8(12), SA-8(13), SA-8(14), and SA-8(18).
Related controls: AC-6, SA-4, SA-8, SC-3, SC-7, SC-22, SC-32, SC-39.
(1) SEPARATION OF SYSTEM AND USER FUNCTIONALITY | INTERFACES FOR NON-
PRIVILEGED USERS
Prevent the presentaon of system management funconality at interfaces to non-privileged
users.
Discussion: Prevenng the presentaon of system management funconality at interfaces to non-
privileged users ensures that system administraon opons, including administrator privileges,
are not available to the general user populaon. Restricng user access also prohibits the use
of the grey-out opon commonly used to eliminate accessibility to such informaon. One
potenal soluon is to withhold system administraon opons unl users establish sessions with
administrator privileges.
Related control: AC-3.
(2) SEPARATION OF SYSTEM AND USER FUNCTIONALITY | DISASSOCIABILITY
Store state informaon from applicaons and soware separately.
Discussion: If a system is compromised, storing applicaons and soware separately from state
informaon about users’ interacons with an applicaon may beer protect individuals’ privacy.
References: None
SC-3 SECURITY FUNCTION ISOLATION
Control: Isolate security funcons from nonsecurity funcons.
Discussion: Security funcons are isolated from nonsecurity funcons by means of an isolaon
boundary implemented within a system via parons and domains. The isolaon boundary controls
access to and protects the integrity of the hardware, soware, and ﬁrmware that perform system
security funcons. Systems implement code separaon in many ways, such as through the provision
of security kernels via processor rings or processor modes. For non-kernel code, security funcon
isolaon is oen achieved through ﬁle system protecons that protect the code on disk and address
space protecons that protect execung code. Systems can restrict access to security funcons using
access control mechanisms and by implemenng least privilege capabilies. While the ideal is for all
code within the deﬁned security funcon isolaon boundary to only contain security-relevant code,
it is somemes necessary to include nonsecurity funcons as an excepon. The isolaon of security
funcons from nonsecurity funcons can be achieved by applying the systems security engineering
This document is produced from OSCAL source data
FAMILY: SC PAGE 283NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
design principles in SA-8, including SA-8(1), SA-8(3), SA-8(4), SA-8(10), SA-8(12), SA-8(13), SA-8(14),
and SA-8(18).
Related controls: AC-3, AC-6, AC-25, CM-2, CM-4, SA-4, SA-5, SA-8, SA-15, SA-17, SC-2, SC-7, SC-32,
SC-39, SI-16.
(1) SECURITY FUNCTION ISOLATION | HARDWARE SEPARATION
Employ hardware separaon mechanisms to implement security funcon isolaon.
Discussion: Hardware separaon mechanisms include hardware ring architectures that are
implemented within microprocessors and hardware-enforced address segmentaon used to
support logically disnct storage objects with separate aributes (i.e., readable, writeable).
(2) SECURITY FUNCTION ISOLATION | ACCESS AND FLOW CONTROL FUNCTIONS
Isolate security funcons enforcing access and informaon ﬂow control from nonsecurity
funcons and from other security funcons.
Discussion: Security funcon isolaon occurs because of implementaon. The funcons can sll
be scanned and monitored. Security funcons that are potenally isolated from access and
ﬂow control enforcement funcons include auding, intrusion detecon, and malicious code
protecon funcons.
(3) SECURITY FUNCTION ISOLATION | MINIMIZE NONSECURITY FUNCTIONALITY
Minimize the number of nonsecurity funcons included within the isolaon boundary
containing security funcons.
Discussion: Where it is not feasible to achieve strict isolaon of nonsecurity funcons from
security funcons, it is necessary to take acons to minimize nonsecurity-relevant funcons
within the security funcon boundary. Nonsecurity funcons contained within the isolaon
boundary are considered security-relevant because errors or malicious code in the soware can
directly impact the security funcons of systems. The fundamental design objecve is that the
speciﬁc porons of systems that provide informaon security are of minimal size and complexity.
Minimizing the number of nonsecurity funcons in the security-relevant system components
allows designers and implementers to focus only on those funcons which are necessary
to provide the desired security capability (typically access enforcement). By minimizing the
nonsecurity funcons within the isolaon boundaries, the amount of code that is trusted to
enforce security policies is signiﬁcantly reduced, thus contribung to understandability.
(4) SECURITY FUNCTION ISOLATION | MODULE COUPLING AND COHESIVENESS
Implement security funcons as largely independent modules that maximize internal
cohesiveness within modules and minimize coupling between modules.
Discussion: The reducon of inter-module interacons helps to constrain security funcons
and manage complexity. The concepts of coupling and cohesion are important with respect
to modularity in soware design. Coupling refers to the dependencies that one module has
on other modules. Cohesion refers to the relaonship between funcons within a module.
Best pracces in soware engineering and systems security engineering rely on layering,
minimizaon, and modular decomposion to reduce and manage complexity. This produces
soware modules that are highly cohesive and loosely coupled.
This document is produced from OSCAL source data
FAMILY: SC PAGE 284NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(5) SECURITY FUNCTION ISOLATION | LAYERED STRUCTURES
Implement security funcons as a layered structure minimizing interacons between layers of
the design and avoiding any dependence by lower layers on the funconality or correctness of
higher layers.
Discussion: The implementaon of layered structures with minimized interacons among security
funcons and non-looping layers (i.e., lower-layer funcons do not depend on higher-layer
funcons) enables the isolaon of security funcons and the management of complexity.
References: None
SC-4 INFORMATION IN SHARED SYSTEM RESOURCES
Control: Prevent unauthorized and unintended informaon transfer via shared system resources.
Discussion: Prevenng unauthorized and unintended informaon transfer via shared system resources
stops informaon produced by the acons of prior users or roles (or the acons of processes acng
on behalf of prior users or roles) from being available to current users or roles (or current processes
acng on behalf of current users or roles) that obtain access to shared system resources aer those
resources have been released back to the system. Informaon in shared system resources also applies
to encrypted representaons of informaon. In other contexts, control of informaon in shared
system resources is referred to as object reuse and residual informaon protecon. Informaon
in shared system resources does not address informaon remanence, which refers to the residual
representaon of data that has been nominally deleted; covert channels (including storage and ming
channels), where shared system resources are manipulated to violate informaon ﬂow restricons; or
components within systems for which there are only single users or roles.
Related controls: AC-3, AC-4, SA-8.
(1) INFORMATION IN SHARED SYSTEM RESOURCES | SECURITY LEVELS
[Withdrawn: Incorporated into SC-4.]
(2) INFORMATION IN SHARED SYSTEM RESOURCES | MULTILEVEL OR PERIODS PROCESSING
Prevent unauthorized informaon transfer via shared resources in accordance with
[Assignment: organizaon-deﬁned procedures] when system processing explicitly switches
between diﬀerent informaon classiﬁcaon levels or security categories.
Discussion: Changes in processing levels can occur during mullevel or periods processing with
informaon at diﬀerent classiﬁcaon levels or security categories. It can also occur during serial
reuse of hardware components at diﬀerent classiﬁcaon levels. Organizaon-deﬁned procedures
can include approved sanizaon processes for electronically stored informaon.
References: None
SC-5 DENIAL-OF-SERVICE PROTECTION
Control:
a. [Selecon: Protect against; Limit] the eﬀects of the following types of denial-of-service events:
[Assignment: organizaon-deﬁned types of denial-of-service events]; and
b. Employ the following controls to achieve the denial-of-service objecve: [Assignment:
organizaon-deﬁned controls by type of denial-of-service event].
This document is produced from OSCAL source data
FAMILY: SC PAGE 285NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
Discussion: Denial-of-service events may occur due to a variety of internal and external causes, such
as an aack by an adversary or a lack of planning to support organizaonal needs with respect to
capacity and bandwidth. Such aacks can occur across a wide range of network protocols (e.g.,
IPv4, IPv6). A variety of technologies are available to limit or eliminate the originaon and eﬀects of
denial-of-service events. For example, boundary protecon devices can ﬁlter certain types of packets
to protect system components on internal networks from being directly aﬀected by or the source
of denial-of-service aacks. Employing increased network capacity and bandwidth combined with
service redundancy also reduces the suscepbility to denial-of-service events.
Related controls: CP-2, IR-4, SC-6, SC-7, SC-40.
(1) DENIAL-OF-SERVICE PROTECTION | RESTRICT ABILITY TO ATTACK OTHER SYSTEMS
Restrict the ability of individuals to launch the following denial-of-service aacks against other
systems: [Assignment: organizaon-deﬁned denial-of-service aacks].
Discussion: Restricng the ability of individuals to launch denial-of-service aacks requires the
mechanisms commonly used for such aacks to be unavailable. Individuals of concern include
hosle insiders or external adversaries who have breached or compromised the system and are
using it to launch a denial-of-service aack. Organizaons can restrict the ability of individuals
to connect and transmit arbitrary informaon on the transport medium (i.e., wired networks,
wireless networks, spoofed Internet protocol packets). Organizaons can also limit the ability of
individuals to use excessive system resources. Protecon against individuals having the ability to
launch denial-of-service aacks may be implemented on speciﬁc systems or boundary devices
that prohibit egress to potenal target systems.
(2) DENIAL-OF-SERVICE PROTECTION | CAPACITY, BANDWIDTH, AND REDUNDANCY
Manage capacity, bandwidth, or other redundancy to limit the eﬀects of informaon ﬂooding
denial-of-service aacks.
Discussion: Managing capacity ensures that suﬃcient capacity is available to counter ﬂooding
aacks. Managing capacity includes establishing selected usage priories, quotas, paroning,
or load balancing.
(3) DENIAL-OF-SERVICE PROTECTION | DETECTION AND MONITORING
(a) Employ the following monitoring tools to detect indicators of denial-of-service aacks
against, or launched from, the system: [Assignment: organizaon-deﬁned monitoring
tools]; and
(b) Monitor the following system resources to determine if suﬃcient resources exist to
prevent eﬀecve denial-of-service aacks: [Assignment: organizaon-deﬁned system
resources].
Discussion: Organizaons consider the ulizaon and capacity of system resources when
managing risk associated with a denial of service due to malicious aacks. Denial-of-service
aacks can originate from external or internal sources. System resources that are sensive to
denial of service include physical disk storage, memory, and CPU cycles. Techniques used to
prevent denial-of-service aacks related to storage ulizaon and capacity include instung
disk quotas, conﬁguring systems to automacally alert administrators when speciﬁc storage
capacity thresholds are reached, using ﬁle compression technologies to maximize available
storage space, and imposing separate parons for system and user data.
This document is produced from OSCAL source data
FAMILY: SC PAGE 286NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
Related controls: CA-7, SI-4.
Reference: [SP 800-189]
SC-6 RESOURCE AVAILABILITY
Control: Protect the availability of resources by allocang [Assignment: organizaon-deﬁned resources]
by [Selecon (one or more): priority; quota; [Assignment: organizaon-deﬁned controls]].
Discussion: Priority protecon prevents lower-priority processes from delaying or interfering with the
system that services higher-priority processes. Quotas prevent users or processes from obtaining
more than predetermined amounts of resources.
Related control: SC-5.
References: [DHS TIC], [OMB M-08-05]
SC-7 BOUNDARY PROTECTION
Control:
a. Monitor and control communicaons at the external managed interfaces to the system and at
key internal managed interfaces within the system;
b. Implement subnetworks for publicly accessible system components that are [Selecon:
physically; logically] separated from internal organizaonal networks; and
c. Connect to external networks or systems only through managed interfaces consisng of
boundary protecon devices arranged in accordance with an organizaonal security and privacy
architecture.
Discussion: Managed interfaces include gateways, routers, ﬁrewalls, guards, network-based
malicious code analysis, virtualizaon systems, or encrypted tunnels implemented within a security
architecture. Subnetworks that are physically or logically separated from internal networks are
referred to as demilitarized zones or DMZs. Restricng or prohibing interfaces within organizaonal
systems includes restricng external web traﬃc to designated web servers within managed interfaces,
prohibing external traﬃc that appears to be spooﬁng internal addresses, and prohibing internal
traﬃc that appears to be spooﬁng external addresses. SP 800-189 provides addional informaon on
source address validaon techniques to prevent ingress and egress of traﬃc with spoofed addresses.
Commercial telecommunicaons services are provided by network components and consolidated
management systems shared by customers. These services may also include third party-provided
access lines and other service elements. Such services may represent sources of increased risk despite
contract security provisions. Boundary protecon may be implemented as a common control for all
or part of an organizaonal network such that the boundary to be protected is greater than a system-
speciﬁc boundary (i.e., an authorizaon boundary).
Related controls: AC-4, AC-17, AC-18, AC-19, AC-20, AU-13, CA-3, CM-2, CM-4, CM-7, CM-10, CP-8,
CP-10, IR-4, MA-4, PE-3, PL-8, PM-12, SA-8, SA-17, SC-5, SC-26, SC-32, SC-35, SC-43.
(1) BOUNDARY PROTECTION | PHYSICALLY SEPARATED SUBNETWORKS
[Withdrawn: Incorporated into SC-7.]
(2) BOUNDARY PROTECTION | PUBLIC ACCESS
[Withdrawn: Incorporated into SC-7.]
This document is produced from OSCAL source data
FAMILY: SC PAGE 287NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(3) BOUNDARY PROTECTION | ACCESS POINTS
Limit the number of external network connecons to the system.
Discussion: Liming the number of external network connecons facilitates monitoring of
inbound and outbound communicaons traﬃc. The Trusted Internet Connecon DHS TIC
iniave is an example of a federal guideline that requires limits on the number of external
network connecons. Liming the number of external network connecons to the system is
important during transion periods from older to newer technologies (e.g., transioning from
IPv4 to IPv6 network protocols). Such transions may require implemenng the older and newer
technologies simultaneously during the transion period and thus increase the number of access
points to the system.
(4) BOUNDARY PROTECTION | EXTERNAL TELECOMMUNICATIONS SERVICES
(a) Implement a managed interface for each external telecommunicaon service;
(b) Establish a traﬃc ﬂow policy for each managed interface;
(c) Protect the conﬁdenality and integrity of the informaon being transmied across each
interface;
(d) Document each excepon to the traﬃc ﬂow policy with a supporng mission or business
need and duraon of that need;
(e) Review excepons to the traﬃc ﬂow policy [Assignment: organizaon-deﬁned frequency]
and remove excepons that are no longer supported by an explicit mission or business
need;
(f) Prevent unauthorized exchange of control plane traﬃc with external networks;
(g) Publish informaon to enable remote networks to detect unauthorized control plane
traﬃc from internal networks; and
(h) Filter unauthorized control plane traﬃc from external networks.
Discussion: External telecommunicaons services can provide data and/or voice communicaons
services. Examples of control plane traﬃc include Border Gateway Protocol (BGP) roung,
Domain Name System (DNS), and management protocols. See SP 800-189 for addional
informaon on the use of the resource public key infrastructure (RPKI) to protect BGP routes and
detect unauthorized BGP announcements.
Related controls: AC-3, SC-8, SC-20, SC-21, SC-22.
(5) BOUNDARY PROTECTION | DENY BY DEFAULT — ALLOW BY EXCEPTION
Deny network communicaons traﬃc by default and allow network communicaons traﬃc
by excepon [Selecon (one or more): at managed interfaces; for [Assignment: organizaon-
deﬁned systems]].
Discussion: Denying by default and allowing by excepon applies to inbound and outbound
network communicaons traﬃc. A deny-all, permit-by-excepon network communicaons traﬃc
policy ensures that only those system connecons that are essenal and approved are allowed.
Deny by default, allow by excepon also applies to a system that is connected to an external
system.
This document is produced from OSCAL source data
FAMILY: SC PAGE 288NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(6) BOUNDARY PROTECTION | RESPONSE TO RECOGNIZED FAILURES
[Withdrawn: Incorporated into SC-7(18).]
(7) BOUNDARY PROTECTION | SPLIT TUNNELING FOR REMOTE DEVICES
Prevent split tunneling for remote devices connecng to organizaonal systems unless the
split tunnel is securely provisioned using [Assignment: organizaon-deﬁned safeguards].
Discussion: Split tunneling is the process of allowing a remote user or device to establish a non-
remote connecon with a system and simultaneously communicate via some other connecon
to a resource in an external network. This method of network access enables a user to access
remote devices and simultaneously, access uncontrolled networks. Split tunneling might be
desirable by remote users to communicate with local system resources, such as printers or ﬁle
servers. However, split tunneling can facilitate unauthorized external connecons, making the
system vulnerable to aack and to exﬁltraon of organizaonal informaon. Split tunneling can
be prevented by disabling conﬁguraon sengs that allow such capability in remote devices
and by prevenng those conﬁguraon sengs from being conﬁgurable by users. Prevenon can
also be achieved by the detecon of split tunneling (or of conﬁguraon sengs that allow split
tunneling) in the remote device, and by prohibing the connecon if the remote device is using
split tunneling. A virtual private network (VPN) can be used to securely provision a split tunnel.
A securely provisioned VPN includes locking connecvity to exclusive, managed, and named
environments, or to a speciﬁc set of pre-approved addresses, without user control.
(8) BOUNDARY PROTECTION | ROUTE TRAFFIC TO AUTHENTICATED PROXY SERVERS
Route [Assignment: organizaon-deﬁned internal communicaons traﬃc] to [Assignment:
organizaon-deﬁned external networks] through authencated proxy servers at managed
interfaces.
Discussion: External networks are networks outside of organizaonal control. A proxy server is
a server (i.e., system or applicaon) that acts as an intermediary for clients requesng system
resources from non-organizaonal or other organizaonal servers. System resources that may be
requested include ﬁles, connecons, web pages, or services. Client requests established through
a connecon to a proxy server are assessed to manage complexity and provide addional
protecon by liming direct connecvity. Web content ﬁltering devices are one of the most
common proxy servers that provide access to the Internet. Proxy servers can support the
logging of Transmission Control Protocol sessions and the blocking of speciﬁc Uniform Resource
Locators, Internet Protocol addresses, and domain names. Web proxies can be conﬁgured with
organizaon-deﬁned lists of authorized and unauthorized websites. Note that proxy servers may
inhibit the use of virtual private networks (VPNs) and create the potenal for man-in-the-middle
aacks (depending on the implementaon).
Related control: AC-3.
(9) BOUNDARY PROTECTION | RESTRICT THREATENING OUTGOING COMMUNICATIONS
TRAFFIC
(a) Detect and deny outgoing communicaons traﬃc posing a threat to external systems; and
(b) Audit the identy of internal users associated with denied communicaons.
Discussion: Detecng outgoing communicaons traﬃc from internal acons that may pose
threats to external systems is known as extrusion detecon. Extrusion detecon is carried out
This document is produced from OSCAL source data
FAMILY: SC PAGE 289NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
within the system at managed interfaces. Extrusion detecon includes the analysis of incoming
and outgoing communicaons traﬃc while searching for indicaons of internal threats to
the security of external systems. Internal threats to external systems include traﬃc indicave
of denial-of-service aacks, traﬃc with spoofed source addresses, and traﬃc that contains
malicious code. Organizaons have criteria to determine, update, and manage idenﬁed threats
related to extrusion detecon.
Related controls: AU-2, AU-6, SC-5, SC-38, SC-44, SI-3, SI-4.
(10) BOUNDARY PROTECTION | PREVENT EXFILTRATION
(a) Prevent the exﬁltraon of informaon; and
(b) Conduct exﬁltraon tests [Assignment: organizaon-deﬁned frequency].
Discussion: Prevenon of exﬁltraon applies to both the intenonal and unintenonal exﬁltraon
of informaon. Techniques used to prevent the exﬁltraon of informaon from systems may
be implemented at internal endpoints, external boundaries, and across managed interfaces
and include adherence to protocol formats, monitoring for beaconing acvity from systems,
disconnecng external network interfaces except when explicitly needed, employing traﬃc
proﬁle analysis to detect deviaons from the volume and types of traﬃc expected, call
backs to command and control centers, conducng penetraon tesng, monitoring for
steganography, disassembling and reassembling packet headers, and using data loss and
data leakage prevenon tools. Devices that enforce strict adherence to protocol formats
include deep packet inspecon ﬁrewalls and Extensible Markup Language (XML) gateways.
The devices verify adherence to protocol formats and speciﬁcaons at the applicaon layer
and idenfy vulnerabilies that cannot be detected by devices that operate at the network or
transport layers. The prevenon of exﬁltraon is similar to data loss prevenon or data leakage
prevenon and is closely associated with cross-domain soluons and system guards that enforce
informaon ﬂow requirements.
Related controls: AC-2, CA-8, SI-3.
(11) BOUNDARY PROTECTION | RESTRICT INCOMING COMMUNICATIONS TRAFFIC
Only allow incoming communicaons from [Assignment: organizaon-deﬁned authorized
sources] to be routed to [Assignment: organizaon-deﬁned authorized desnaons].
Discussion: General source address validaon techniques are applied to restrict the use of
illegal and unallocated source addresses as well as source addresses that should only be used
within the system. The restricon of incoming communicaons traﬃc provides determinaons
that source and desnaon address pairs represent authorized or allowed communicaons.
Determinaons can be based on several factors, including the presence of such address pairs
in the lists of authorized or allowed communicaons, the absence of such address pairs in lists
of unauthorized or disallowed pairs, or meeng more general rules for authorized or allowed
source and desnaon pairs. Strong authencaon of network addresses is not possible without
the use of explicit security protocols, and thus, addresses can oen be spoofed. Further, identy-
based incoming traﬃc restricon methods can be employed, including router access control lists
and ﬁrewall rules.
Related control: AC-3.
This document is produced from OSCAL source data
FAMILY: SC PAGE 290NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(12) BOUNDARY PROTECTION | HOST-BASED PROTECTION
Implement [Assignment: organizaon-deﬁned host-based boundary protecon mechanisms]
at [Assignment: organizaon-deﬁned system components].
Discussion: Host-based boundary protecon mechanisms include host-based ﬁrewalls. System
components that employ host-based boundary protecon mechanisms include servers,
workstaons, notebook computers, and mobile devices.
(13) BOUNDARY PROTECTION | ISOLATION OF SECURITY TOOLS, MECHANISMS, AND
SUPPORT COMPONENTS
Isolate [Assignment: organizaon-deﬁned informaon security tools, mechanisms, and
support components] from other internal system components by implemenng physically
separate subnetworks with managed interfaces to other components of the system.
Discussion: Physically separate subnetworks with managed interfaces are useful in isolang
computer network defenses from crical operaonal processing networks to prevent adversaries
from discovering the analysis and forensics techniques employed by organizaons.
Related controls: SC-2, SC-3.
(14) BOUNDARY PROTECTION | PROTECT AGAINST UNAUTHORIZED PHYSICAL
CONNECTIONS
Protect against unauthorized physical connecons at [Assignment: organizaon-deﬁned
managed interfaces].
Discussion: Systems that operate at diﬀerent security categories or classiﬁcaon levels may
share common physical and environmental controls, since the systems may share space within
the same facilies. In pracce, it is possible that these separate systems may share common
equipment rooms, wiring closets, and cable distribuon paths. Protecon against unauthorized
physical connecons can be achieved by using clearly idenﬁed and physically separated cable
trays, connecon frames, and patch panels for each side of managed interfaces with physical
access controls that enforce limited authorized access to these items.
Related controls: PE-4, PE-19.
(15) BOUNDARY PROTECTION | NETWORKED PRIVILEGED ACCESSES
Route networked, privileged accesses through a dedicated, managed interface for purposes of
access control and auding.
Discussion: Privileged access provides greater accessibility to system funcons, including security
funcons. Adversaries aempt to gain privileged access to systems through remote access to
cause adverse mission or business impacts, such as by exﬁltrang informaon or bringing down
a crical system capability. Roung networked, privileged access requests through a dedicated,
managed interface further restricts privileged access for increased access control and auding.
Related controls: AC-2, AC-3, AU-2, SI-4.
(16) BOUNDARY PROTECTION | PREVENT DISCOVERY OF SYSTEM COMPONENTS
Prevent the discovery of speciﬁc system components that represent a managed interface.
Discussion: Prevenng the discovery of system components represenng a managed interface
helps protect network addresses of those components from discovery through common tools
This document is produced from OSCAL source data
FAMILY: SC PAGE 291NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
and techniques used to idenfy devices on networks. Network addresses are not available for
discovery and require prior knowledge for access. Prevenng the discovery of components
and devices can be accomplished by not publishing network addresses, using network address
translaon, or not entering the addresses in domain name systems. Another prevenon
technique is to periodically change network addresses.
(17) BOUNDARY PROTECTION | AUTOMATED ENFORCEMENT OF PROTOCOL FORMATS
Enforce adherence to protocol formats.
Discussion: System components that enforce protocol formats include deep packet inspecon
ﬁrewalls and XML gateways. The components verify adherence to protocol formats and
speciﬁcaons at the applicaon layer and idenfy vulnerabilies that cannot be detected by
devices operang at the network or transport layers.
Related control: SC-4.
(18) BOUNDARY PROTECTION | FAIL SECURE
Prevent systems from entering unsecure states in the event of an operaonal failure of a
boundary protecon device.
Discussion: Fail secure is a condion achieved by employing mechanisms to ensure that in
the event of operaonal failures of boundary protecon devices at managed interfaces,
systems do not enter into unsecure states where intended security properes no longer hold.
Managed interfaces include routers, ﬁrewalls, and applicaon gateways that reside on protected
subnetworks (commonly referred to as demilitarized zones). Failures of boundary protecon
devices cannot lead to or cause informaon external to the devices to enter the devices nor can
failures permit unauthorized informaon releases.
Related controls: CP-2, CP-12, SC-24.
(19) BOUNDARY PROTECTION | BLOCK COMMUNICATION FROM NON-ORGANIZATIONALLY
CONFIGURED HOSTS
Block inbound and outbound communicaons traﬃc between [Assignment: organizaon-
deﬁned communicaon clients] that are independently conﬁgured by end users and external
service providers.
Discussion: Communicaon clients independently conﬁgured by end users and external service
providers include instant messaging clients and video conferencing soware and applicaons.
Traﬃc blocking does not apply to communicaon clients that are conﬁgured by organizaons to
perform authorized funcons.
(20) BOUNDARY PROTECTION | DYNAMIC ISOLATION AND SEGREGATION
Provide the capability to dynamically isolate [Assignment: organizaon-deﬁned system
components] from other system components.
Discussion: The capability to dynamically isolate certain internal system components is useful
when it is necessary to paron or separate system components of quesonable origin from
components that possess greater trustworthiness. Component isolaon reduces the aack
surface of organizaonal systems. Isolang selected system components can also limit the
damage from successful aacks when such aacks occur.
This document is produced from OSCAL source data
FAMILY: SC PAGE 292NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(21) BOUNDARY PROTECTION | ISOLATION OF SYSTEM COMPONENTS
Employ boundary protecon mechanisms to isolate [Assignment: organizaon-deﬁned
system components] supporng [Assignment: organizaon-deﬁned missions and/or business
funcons].
Discussion: Organizaons can isolate system components that perform diﬀerent mission
or business funcons. Such isolaon limits unauthorized informaon ﬂows among system
components and provides the opportunity to deploy greater levels of protecon for selected
system components. Isolang system components with boundary protecon mechanisms
provides the capability for increased protecon of individual system components and to
more eﬀecvely control informaon ﬂows between those components. Isolang system
components provides enhanced protecon that limits the potenal harm from hosle cyber-
aacks and errors. The degree of isolaon varies depending upon the mechanisms chosen.
Boundary protecon mechanisms include routers, gateways, and ﬁrewalls that separate system
components into physically separate networks or subnetworks; cross-domain devices that
separate subnetworks; virtualizaon techniques; and the encrypon of informaon ﬂows among
system components using disnct encrypon keys.
Related control: CA-9.
(22) BOUNDARY PROTECTION | SEPARATE SUBNETS FOR CONNECTING TO DIFFERENT
SECURITY DOMAINS
Implement separate network addresses to connect to systems in diﬀerent security domains.
Discussion: The decomposion of systems into subnetworks (i.e., subnets) helps to provide the
appropriate level of protecon for network connecons to diﬀerent security domains that
contain informaon with diﬀerent security categories or classiﬁcaon levels.
(23) BOUNDARY PROTECTION | DISABLE SENDER FEEDBACK ON PROTOCOL VALIDATION
FAILURE
Disable feedback to senders on protocol format validaon failure.
Discussion: Disabling feedback to senders when there is a failure in protocol validaon format
prevents adversaries from obtaining informaon that would otherwise be unavailable.
(24) BOUNDARY PROTECTION | PERSONALLY IDENTIFIABLE INFORMATION
For systems that process personally idenﬁable informaon:
(a) Apply the following processing rules to data elements of personally idenﬁable
informaon: [Assignment: organizaon-deﬁned processing rules];
(b) Monitor for permied processing at the external interfaces to the system and at key
internal boundaries within the system;
(c) Document each processing excepon; and
(d) Review and remove excepons that are no longer supported.
Discussion: Managing the processing of personally idenﬁable informaon is an important aspect
of protecng an individual’s privacy. Applying, monitoring for, and documenng excepons to
processing rules ensure that personally idenﬁable informaon is processed only in accordance
with established privacy requirements.
This document is produced from OSCAL source data
FAMILY: SC PAGE 293NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
Related controls: PT-2, SI-15.
(25) BOUNDARY PROTECTION | UNCLASSIFIED NATIONAL SECURITY SYSTEM CONNECTIONS
Prohibit the direct connecon of [Assignment: organizaon-deﬁned unclassiﬁed naonal
security system] to an external network without the use of [Assignment: organizaon-deﬁned
boundary protecon device].
Discussion: A direct connecon is a dedicated physical or virtual connecon between two or
more systems. Organizaons typically do not have complete control over external networks,
including the Internet. Boundary protecon devices (e.g., ﬁrewalls, gateways, and routers)
mediate communicaons and informaon ﬂows between unclassiﬁed naonal security systems
and external networks.
(26) BOUNDARY PROTECTION | CLASSIFIED NATIONAL SECURITY SYSTEM CONNECTIONS
Prohibit the direct connecon of a classiﬁed naonal security system to an external network
without the use of [Assignment: organizaon-deﬁned boundary protecon device].
Discussion: A direct connecon is a dedicated physical or virtual connecon between two or
more systems. Organizaons typically do not have complete control over external networks,
including the Internet. Boundary protecon devices (e.g., ﬁrewalls, gateways, and routers)
mediate communicaons and informaon ﬂows between classiﬁed naonal security systems
and external networks. In addion, approved boundary protecon devices (typically managed
interface or cross-domain systems) provide informaon ﬂow enforcement from systems to
external networks.
(27) BOUNDARY PROTECTION | UNCLASSIFIED NON-NATIONAL SECURITY SYSTEM
CONNECTIONS
Prohibit the direct connecon of [Assignment: organizaon-deﬁned unclassiﬁed non-naonal
security system] to an external network without the use of [Assignment: organizaon-deﬁned
boundary protecon device].
Discussion: A direct connecon is a dedicated physical or virtual connecon between two or
more systems. Organizaons typically do not have complete control over external networks,
including the Internet. Boundary protecon devices (e.g., ﬁrewalls, gateways, and routers)
mediate communicaons and informaon ﬂows between unclassiﬁed non-naonal security
systems and external networks.
(28) BOUNDARY PROTECTION | CONNECTIONS TO PUBLIC NETWORKS
Prohibit the direct connecon of [Assignment: organizaon-deﬁned system] to a public
network.
Discussion: A direct connecon is a dedicated physical or virtual connecon between two or
more systems. A public network is a network accessible to the public, including the Internet and
organizaonal extranets with public access.
This document is produced from OSCAL source data
FAMILY: SC PAGE 294NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(29) BOUNDARY PROTECTION | SEPARATE SUBNETS TO ISOLATE FUNCTIONS
Implement [Selecon: physically; logically] separate subnetworks to isolate the following
crical system components and funcons: [Assignment: organizaon-deﬁned crical system
components and funcons].
Discussion: Separang crical system components and funcons from other noncrical system
components and funcons through separate subnetworks may be necessary to reduce
suscepbility to a catastrophic or debilitang breach or compromise that results in system
failure. For example, physically separang the command and control funcon from the in-ﬂight
entertainment funcon through separate subnetworks in a commercial aircra provides an
increased level of assurance in the trustworthiness of crical system funcons.
References: [FIPS 199], [OMB A-130], [SP 800-189], [SP 800-37], [SP 800-41], [SP 800-77]
SC-8 TRANSMISSION CONFIDENTIALITY AND INTEGRITY
Control: Protect the [Selecon (one or more): conﬁdenality; integrity] of transmied informaon.
Discussion: Protecng the conﬁdenality and integrity of transmied informaon applies to internal
and external networks as well as any system components that can transmit informaon, including
servers, notebook computers, desktop computers, mobile devices, printers, copiers, scanners,
facsimile machines, and radios. Unprotected communicaon paths are exposed to the possibility
of intercepon and modiﬁcaon. Protecng the conﬁdenality and integrity of informaon can be
accomplished by physical or logical means. Physical protecon can be achieved by using protected
distribuon systems. A protected distribuon system is a wireline or ﬁber-opcs telecommunicaons
system that includes terminals and adequate electromagnec, acouscal, electrical, and physical
controls to permit its use for the unencrypted transmission of classiﬁed informaon. Logical
protecon can be achieved by employing encrypon techniques.
Organizaons that rely on commercial providers who oﬀer transmission services as commodity
services rather than as fully dedicated services may ﬁnd it diﬃcult to obtain the necessary assurances
regarding the implementaon of needed controls for transmission conﬁdenality and integrity.
In such situaons, organizaons determine what types of conﬁdenality or integrity services are
available in standard, commercial telecommunicaons service packages. If it is not feasible to obtain
the necessary controls and assurances of control eﬀecveness through appropriate contracng
vehicles, organizaons can implement appropriate compensang controls.
Related controls: AC-17, AC-18, AU-10, IA-3, IA-8, IA-9, MA-4, PE-4, SA-4, SA-8, SC-7, SC-16, SC-20,
SC-23, SC-28.
(1) TRANSMISSION CONFIDENTIALITY AND INTEGRITY | CRYPTOGRAPHIC PROTECTION
Implement cryptographic mechanisms to [Selecon (one or more): prevent unauthorized
disclosure of informaon; detect changes to informaon] during transmission.
Discussion: Encrypon protects informaon from unauthorized disclosure and modiﬁcaon
during transmission. Cryptographic mechanisms that protect the conﬁdenality and integrity
of informaon during transmission include TLS and IPSec. Cryptographic mechanisms used to
protect informaon integrity include cryptographic hash funcons that have applicaons in
digital signatures, checksums, and message authencaon codes.
Related controls: SC-12, SC-13.
This document is produced from OSCAL source data
FAMILY: SC PAGE 295NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(2) TRANSMISSION CONFIDENTIALITY AND INTEGRITY | PRE- AND POST-TRANSMISSION
HANDLING
Maintain the [Selecon (one or more): conﬁdenality; integrity] of informaon during
preparaon for transmission and during recepon.
Discussion: Informaon can be unintenonally or maliciously disclosed or modiﬁed during
preparaon for transmission or during recepon, including during aggregaon, at protocol
transformaon points, and during packing and unpacking. Such unauthorized disclosures or
modiﬁcaons compromise the conﬁdenality or integrity of the informaon.
(3) TRANSMISSION CONFIDENTIALITY AND INTEGRITY | CRYPTOGRAPHIC PROTECTION FOR
MESSAGE EXTERNALS
Implement cryptographic mechanisms to protect message externals unless otherwise
protected by [Assignment: organizaon-deﬁned alternave physical controls].
Discussion: Cryptographic protecon for message externals addresses protecon from the
unauthorized disclosure of informaon. Message externals include message headers and roung
informaon. Cryptographic protecon prevents the exploitaon of message externals and
applies to internal and external networks or links that may be visible to individuals who are not
authorized users. Header and roung informaon is somemes transmied in clear text (i.e.,
unencrypted) because the informaon is not idenﬁed by organizaons as having signiﬁcant
value or because encrypng the informaon can result in lower network performance or higher
costs. Alternave physical controls include protected distribuon systems.
Related controls: SC-12, SC-13.
(4) TRANSMISSION CONFIDENTIALITY AND INTEGRITY | CONCEAL OR RANDOMIZE
COMMUNICATIONS
Implement cryptographic mechanisms to conceal or randomize communicaon paerns
unless otherwise protected by [Assignment: organizaon-deﬁned alternave physical
controls].
Discussion: Concealing or randomizing communicaon paerns addresses protecon from
unauthorized disclosure of informaon. Communicaon paerns include frequency, periods,
predictability, and amount. Changes to communicaons paerns can reveal informaon with
intelligence value, especially when combined with other available informaon related to the
mission and business funcons of the organizaon. Concealing or randomizing communicaons
prevents the derivaon of intelligence based on communicaons paerns and applies to both
internal and external networks or links that may be visible to individuals who are not authorized
users. Encrypng the links and transming in connuous, ﬁxed, or random paerns prevents
the derivaon of intelligence from the system communicaons paerns. Alternave physical
controls include protected distribuon systems.
Related controls: SC-12, SC-13.
This document is produced from OSCAL source data
FAMILY: SC PAGE 296NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(5) TRANSMISSION CONFIDENTIALITY AND INTEGRITY | PROTECTED DISTRIBUTION SYSTEM
Implement [Assignment: organizaon-deﬁned protected distribuon system] to [Selecon
(one or more): prevent unauthorized disclosure of informaon; detect changes to informaon]
during transmission.
Discussion: The purpose of a protected distribuon system is to deter, detect, and/or make
diﬃcult physical access to the communicaon lines that carry naonal security informaon.
References: [FIPS 140-3], [FIPS 197], [IR 8023], [SP 800-113], [SP 800-177], [SP 800-52], [SP 800-77], [SP
800-81-2]
SC-9 Transmission Conﬁdenality
[Withdrawn: Incorporated into SC-8.]
SC-10 NETWORK DISCONNECT
Control: Terminate the network connecon associated with a communicaons session at the end of
the session or aer [Assignment: organizaon-deﬁned me period] of inacvity.
Discussion: Network disconnect applies to internal and external networks. Terminang network
connecons associated with speciﬁc communicaons sessions includes de-allocang TCP/IP address
or port pairs at the operang system level and de-allocang the networking assignments at the
applicaon level if mulple applicaon sessions are using a single operang system-level network
connecon. Periods of inacvity may be established by organizaons and include me periods by type
of network access or for speciﬁc network accesses.
Related controls: AC-17, SC-23.
References: None
SC-11 TRUSTED PATH
Control:
a. Provide a [Selecon: physically; logically] isolated trusted communicaons path for
communicaons between the user and the trusted components of the system; and
b. Permit users to invoke the trusted communicaons path for communicaons between the user
and the following security funcons of the system, including at a minimum, authencaon and
re-authencaon: [Assignment: organizaon-deﬁned security funcons].
Discussion: Trusted paths are mechanisms by which users can communicate (using input devices such
as keyboards) directly with the security funcons of systems with the requisite assurance to support
security policies. Trusted path mechanisms can only be acvated by users or the security funcons of
organizaonal systems. User responses that occur via trusted paths are protected from modiﬁcaon
by and disclosure to untrusted applicaons. Organizaons employ trusted paths for trustworthy, high-
assurance connecons between security funcons of systems and users, including during system
logons. The original implementaons of trusted paths employed an out-of-band signal to iniate the
path, such as using the <BREAK> key, which does not transmit characters that can be spoofed. In later
implementaons, a key combinaon that could not be hijacked was used (e.g., the <CTRL> + <ALT>
+ <DEL> keys). Such key combinaons, however, are plaorm-speciﬁc and may not provide a trusted
path implementaon in every case. The enforcement of trusted communicaons paths is provided by
a speciﬁc implementaon that meets the reference monitor concept.
Related controls: AC-16, AC-25, SC-12, SC-23.
This document is produced from OSCAL source data
FAMILY: SC PAGE 297NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(1) TRUSTED PATH | IRREFUTABLE COMMUNICATIONS PATH
(a) Provide a trusted communicaons path that is irrefutably disnguishable from other
communicaons paths; and
(b) Iniate the trusted communicaons path for communicaons between the [Assignment:
organizaon-deﬁned security funcons] of the system and the user.
Discussion: An irrefutable communicaons path permits the system to iniate a trusted path,
which necessitates that the user can unmistakably recognize the source of the communicaon as
a trusted system component. For example, the trusted path may appear in an area of the display
that other applicaons cannot access or be based on the presence of an idenﬁer that cannot be
spoofed.
Reference: [OMB A-130]
SC-12 CRYPTOGRAPHIC KEY ESTABLISHMENT AND MANAGEMENT
Control: Establish and manage cryptographic keys when cryptography is employed within the system
in accordance with the following key management requirements: [Assignment: organizaon-deﬁned
requirements for key generaon, distribuon, storage, access, and destrucon].
Discussion: Cryptographic key management and establishment can be performed using manual
procedures or automated mechanisms with supporng manual procedures. Organizaons deﬁne
key management requirements in accordance with applicable laws, execuve orders, direcves,
regulaons, policies, standards, and guidelines and specify appropriate opons, parameters, and
levels. Organizaons manage trust stores to ensure that only approved trust anchors are part
of such trust stores. This includes cerﬁcates with visibility external to organizaonal systems
and cerﬁcates related to the internal operaons of systems. NIST CMVP and NIST CAVP provide
addional informaon on validated cryptographic modules and algorithms that can be used in
cryptographic key management and establishment.
Related controls: AC-17, AU-9, AU-10, CM-3, IA-3, IA-7, SA-4, SA-8, SA-9, SC-8, SC-11, SC-12, SC-13,
SC-17, SC-20, SC-37, SC-40, SI-3, SI-7.
(1) CRYPTOGRAPHIC KEY ESTABLISHMENT AND MANAGEMENT | AVAILABILITY
Maintain availability of informaon in the event of the loss of cryptographic keys by users.
Discussion: Escrowing of encrypon keys is a common pracce for ensuring availability in the
event of key loss. A forgoen passphrase is an example of losing a cryptographic key.
(2) CRYPTOGRAPHIC KEY ESTABLISHMENT AND MANAGEMENT | SYMMETRIC KEYS
Produce, control, and distribute symmetric cryptographic keys using [Selecon: NIST FIPS-
validated; NSA-approved] key management technology and processes.
Discussion: SP 800-56A, SP 800-56B, and SP 800-56C provide guidance on cryptographic key
establishment schemes and key derivaon methods. SP 800-57-1, SP 800-57-2, and SP 800-57-3
provide guidance on cryptographic key management.
(3) CRYPTOGRAPHIC KEY ESTABLISHMENT AND MANAGEMENT | ASYMMETRIC KEYS
Produce, control, and distribute asymmetric cryptographic keys using [Selecon: NSA-
approved key management technology and processes; preposioned keying material; DoD-
This document is produced from OSCAL source data
FAMILY: SC PAGE 298NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
approved or DoD-issued Medium Assurance PKI cerﬁcates; DoD-approved or DoD-issued
Medium Hardware Assurance PKI cerﬁcates and hardware security tokens that protect the
user’s private key; cerﬁcates issued in accordance with organizaon-deﬁned requirements].
Discussion: SP 800-56A, SP 800-56B, and SP 800-56C provide guidance on cryptographic key
establishment schemes and key derivaon methods. SP 800-57-1, SP 800-57-2, and SP 800-57-3
provide guidance on cryptographic key management.
(4) CRYPTOGRAPHIC KEY ESTABLISHMENT AND MANAGEMENT | PKI CERTIFICATES
[Withdrawn: Incorporated into SC-12(3).]
(5) CRYPTOGRAPHIC KEY ESTABLISHMENT AND MANAGEMENT | PKI CERTIFICATES 
HARDWARE TOKENS
[Withdrawn: Incorporated into SC-12(3).]
(6) CRYPTOGRAPHIC KEY ESTABLISHMENT AND MANAGEMENT | PHYSICAL CONTROL OF
KEYS
Maintain physical control of cryptographic keys when stored informaon is encrypted by
external service providers.
Discussion: For organizaons that use external service providers (e.g., cloud service or data center
providers), physical control of cryptographic keys provides addional assurance that informaon
stored by such external providers is not subject to unauthorized disclosure or modiﬁcaon.
References: [FIPS 140-3], [IR 7956], [IR 7966], [SP 800-56A], [SP 800-56B], [SP 800-56C], [SP 800-57-1],
[SP 800-57-2], [SP 800-57-3], [SP 800-63-3]
SC-13 CRYPTOGRAPHIC PROTECTION
Control:
a. Determine the [Assignment: organizaon-deﬁned cryptographic uses]; and
b. Implement the following types of cryptography required for each speciﬁed cryptographic use:
[Assignment: organizaon-deﬁned types of cryptography for each speciﬁed cryptographic use].
Discussion: Cryptography can be employed to support a variety of security soluons, including
the protecon of classiﬁed informaon and controlled unclassiﬁed informaon, the provision
and implementaon of digital signatures, and the enforcement of informaon separaon when
authorized individuals have the necessary clearances but lack the necessary formal access approvals.
Cryptography can also be used to support random number and hash generaon. Generally applicable
cryptographic standards include FIPS-validated cryptography and NSA-approved cryptography. For
example, organizaons that need to protect classiﬁed informaon may specify the use of NSA-
approved cryptography. Organizaons that need to provision and implement digital signatures may
specify the use of FIPS-validated cryptography. Cryptography is implemented in accordance with
applicable laws, execuve orders, direcves, regulaons, policies, standards, and guidelines.
Related controls: AC-2, AC-3, AC-7, AC-17, AC-18, AC-19, AU-9, AU-10, CM-11, CP-9, IA-3, IA-5, IA-7,
MA-4, MP-2, MP-4, MP-5, SA-4, SA-8, SA-9, SC-8, SC-12, SC-20, SC-23, SC-28, SC-40, SI-3, SI-7.
(1) CRYPTOGRAPHIC PROTECTION | FIPS-VALIDATED CRYPTOGRAPHY
[Withdrawn: Incorporated into SC-13.]
This document is produced from OSCAL source data
FAMILY: SC PAGE 299NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(2) CRYPTOGRAPHIC PROTECTION | NSA-APPROVED CRYPTOGRAPHY
[Withdrawn: Incorporated into SC-13.]
(3) CRYPTOGRAPHIC PROTECTION | INDIVIDUALS WITHOUT FORMAL ACCESS APPROVALS
[Withdrawn: Incorporated into SC-13.]
(4) CRYPTOGRAPHIC PROTECTION | DIGITAL SIGNATURES
[Withdrawn: Incorporated into SC-13.]
Reference: [FIPS 140-3]
SC-14 Public Access Protecons
[Withdrawn: Incorporated into AC-2, AC-3, AC-5, AC-6, SI-10, SI-3, SI-4, SI-5, SI-7.]
SC-15 COLLABORATIVE COMPUTING DEVICES AND APPLICATIONS
Control:
a. Prohibit remote acvaon of collaborave compung devices and applicaons with the following
excepons: [Assignment: organizaon-deﬁned excepons where remote acvaon is to be
allowed]; and
b. Provide an explicit indicaon of use to users physically present at the devices.
Discussion: Collaborave compung devices and applicaons include remote meeng devices and
applicaons, networked white boards, cameras, and microphones. The explicit indicaon of use
includes signals to users when collaborave compung devices and applicaons are acvated.
Related controls: AC-21, SC-42.
(1) COLLABORATIVE COMPUTING DEVICES AND APPLICATIONS | PHYSICAL OR LOGICAL
DISCONNECT
Provide [Selecon (one or more): physical; logical] disconnect of collaborave compung
devices in a manner that supports ease of use.
Discussion: Failing to disconnect from collaborave compung devices can result in subsequent
compromises of organizaonal informaon. Providing easy methods to disconnect from
such devices aer a collaborave compung session ensures that parcipants carry out the
disconnect acvity without having to go through complex and tedious procedures. Disconnect
from collaborave compung devices can be manual or automac.
(2) COLLABORATIVE COMPUTING DEVICES AND APPLICATIONS | BLOCKING INBOUND AND
OUTBOUND COMMUNICATIONS TRAFFIC
[Withdrawn: Incorporated into SC-7.]
This document is produced from OSCAL source data
FAMILY: SC PAGE 300NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(3) COLLABORATIVE COMPUTING DEVICES AND APPLICATIONS | DISABLING AND REMOVAL
IN SECURE WORK AREAS
Disable or remove collaborave compung devices and applicaons from [Assignment:
organizaon-deﬁned systems or system components] in [Assignment: organizaon-deﬁned
secure work areas].
Discussion: Failing to disable or remove collaborave compung devices and applicaons
from systems or system components can result in compromises of informaon, including
eavesdropping on conversaons. A Sensive Compartmented Informaon Facility (SCIF) is an
example of a secure work area.
(4) COLLABORATIVE COMPUTING DEVICES AND APPLICATIONS | EXPLICITLY INDICATE
CURRENT PARTICIPANTS
Provide an explicit indicaon of current parcipants in [Assignment: organizaon-deﬁned
online meengs and teleconferences].
Discussion: Explicitly indicang current parcipants prevents unauthorized individuals from
parcipang in collaborave compung sessions without the explicit knowledge of other
parcipants.
References: None
SC-16 TRANSMISSION OF SECURITY AND PRIVACY ATTRIBUTES
Control: Associate [Assignment: organizaon-deﬁned security and privacy aributes] with informaon
exchanged between systems and between system components.
Discussion: Security and privacy aributes can be explicitly or implicitly associated with the
informaon contained in organizaonal systems or system components. Aributes are abstracons
that represent the basic properes or characteriscs of an enty with respect to protecng
informaon or the management of personally idenﬁable informaon. Aributes are typically
associated with internal data structures, including records, buﬀers, and ﬁles within the system.
Security and privacy aributes are used to implement access control and informaon ﬂow control
policies; reﬂect special disseminaon, management, or distribuon instrucons, including permied
uses of personally idenﬁable informaon; or support other aspects of the informaon security
and privacy policies. Privacy aributes may be used independently or in conjuncon with security
aributes.
Related controls: AC-3, AC-4, AC-16.
(1) TRANSMISSION OF SECURITY AND PRIVACY ATTRIBUTES | INTEGRITY VERIFICATION
Verify the integrity of transmied security and privacy aributes.
Discussion: Part of verifying the integrity of transmied informaon is ensuring that security
and privacy aributes that are associated with such informaon have not been modiﬁed in an
unauthorized manner. Unauthorized modiﬁcaon of security or privacy aributes can result in a
loss of integrity for transmied informaon.
Related controls: AU-10, SC-8.
This document is produced from OSCAL source data
FAMILY: SC PAGE 301NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(2) TRANSMISSION OF SECURITY AND PRIVACY ATTRIBUTES | ANTI-SPOOFING
MECHANISMS
Implement an-spooﬁng mechanisms to prevent adversaries from falsifying the security
aributes indicang the successful applicaon of the security process.
Discussion: Some aack vectors operate by altering the security aributes of an informaon
system to intenonally and maliciously implement an insuﬃcient level of security within the
system. The alteraon of aributes leads organizaons to believe that a greater number of
security funcons are in place and operaonal than have actually been implemented.
Related controls: SI-3, SI-4, SI-7.
(3) TRANSMISSION OF SECURITY AND PRIVACY ATTRIBUTES | CRYPTOGRAPHIC BINDING
Implement [Assignment: organizaon-deﬁned mechanisms or techniques] to bind security and
privacy aributes to transmied informaon.
Discussion: Cryptographic mechanisms and techniques can provide strong security and privacy
aribute binding to transmied informaon to help ensure the integrity of such informaon.
Related controls: AC-16, SC-12, SC-13.
Reference: [OMB A-130]
SC-17 PUBLIC KEY INFRASTRUCTURE CERTIFICATES
Control:
a. Issue public key cerﬁcates under an [Assignment: organizaon-deﬁned cerﬁcate policy] or
obtain public key cerﬁcates from an approved service provider; and
b. Include only approved trust anchors in trust stores or cerﬁcate stores managed by the
organizaon.
Discussion: Public key infrastructure (PKI) cerﬁcates are cerﬁcates with visibility external to
organizaonal systems and cerﬁcates related to the internal operaons of systems, such as
applicaon-speciﬁc me services. In cryptographic systems with a hierarchical structure, a trust
anchor is an authoritave source (i.e., a cerﬁcate authority) for which trust is assumed and not
derived. A root cerﬁcate for a PKI system is an example of a trust anchor. A trust store or cerﬁcate
store maintains a list of trusted root cerﬁcates.
Related controls: AU-10, IA-5, SC-12.
References: [SP 800-32], [SP 800-57-1], [SP 800-57-2], [SP 800-57-3], [SP 800-63-3]
SC-18 MOBILE CODE
Control:
a. Deﬁne acceptable and unacceptable mobile code and mobile code technologies; and
b. Authorize, monitor, and control the use of mobile code within the system.
Discussion: Mobile code includes any program, applicaon, or content that can be transmied across
a network (e.g., embedded in an email, document, or website) and executed on a remote system.
Decisions regarding the use of mobile code within organizaonal systems are based on the potenal
for the code to cause damage to the systems if used maliciously. Mobile code technologies include
Java applets, JavaScript, HTML5, WebGL, and VBScript. Usage restricons and implementaon
guidelines apply to both the selecon and use of mobile code installed on servers and mobile code
This document is produced from OSCAL source data
FAMILY: SC PAGE 302NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
downloaded and executed on individual workstaons and devices, including notebook computers
and smart phones. Mobile code policy and procedures address speciﬁc acons taken to prevent
the development, acquision, and introducon of unacceptable mobile code within organizaonal
systems, including requiring mobile code to be digitally signed by a trusted source.
Related controls: AU-2, AU-12, CM-2, CM-6, SI-3.
(1) MOBILE CODE | IDENTIFY UNACCEPTABLE CODE AND TAKE CORRECTIVE ACTIONS
Idenfy [Assignment: organizaon-deﬁned unacceptable mobile code] and take [Assignment:
organizaon-deﬁned correcve acons].
Discussion: Correcve acons when unacceptable mobile code is detected include blocking,
quaranne, or alerng administrators. Blocking includes prevenng the transmission of word
processing ﬁles with embedded macros when such macros have been determined to be
unacceptable mobile code.
(2) MOBILE CODE | ACQUISITION, DEVELOPMENT, AND USE
Verify that the acquision, development, and use of mobile code to be deployed in the system
meets [Assignment: organizaon-deﬁned mobile code requirements].
Discussion: None.
(3) MOBILE CODE | PREVENT DOWNLOADING AND EXECUTION
Prevent the download and execuon of [Assignment: organizaon-deﬁned unacceptable
mobile code].
Discussion: None.
(4) MOBILE CODE | PREVENT AUTOMATIC EXECUTION
Prevent the automac execuon of mobile code in [Assignment: organizaon-deﬁned
soware applicaons] and enforce [Assignment: organizaon-deﬁned acons] prior to
execung the code.
Discussion: Acons enforced before execung mobile code include prompng users prior to
opening email aachments or clicking on web links. Prevenng the automac execuon of
mobile code includes disabling auto-execute features on system components that employ
portable storage devices, such as compact discs, digital versale discs, and universal serial bus
devices.
(5) MOBILE CODE | ALLOW EXECUTION ONLY IN CONFINED ENVIRONMENTS
Allow execuon of permied mobile code only in conﬁned virtual machine environments.
Discussion: Perming the execuon of mobile code only in conﬁned virtual machine
environments helps prevent the introducon of malicious code into other systems and system
components.
Related controls: SC-44, SI-7.
Reference: [SP 800-28]
SC-19 Voice Over Internet Protocol
[Withdrawn. Technology-speciﬁc; addressed as any other technology or protocol.]
This document is produced from OSCAL source data
FAMILY: SC PAGE 303NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
SC-20 SECURE NAME/ADDRESS RESOLUTION SERVICE (AUTHORITATIVE SOURCE)
Control:
a. Provide addional data origin authencaon and integrity veriﬁcaon arfacts along with the
authoritave name resoluon data the system returns in response to external name/address
resoluon queries; and
b. Provide the means to indicate the security status of child zones and (if the child supports secure
resoluon services) to enable veriﬁcaon of a chain of trust among parent and child domains,
when operang as part of a distributed, hierarchical namespace.
Discussion: Providing authoritave source informaon enables external clients, including remote
Internet clients, to obtain origin authencaon and integrity veriﬁcaon assurances for the host/
service name to network address resoluon informaon obtained through the service. Systems
that provide name and address resoluon services include domain name system (DNS) servers.
Addional arfacts include DNS Security Extensions (DNSSEC) digital signatures and cryptographic
keys. Authoritave data includes DNS resource records. The means for indicang the security status
of child zones include the use of delegaon signer resource records in the DNS. Systems that use
technologies other than the DNS to map between host and service names and network addresses
provide other means to assure the authencity and integrity of response data.
Related controls: AU-10, SC-8, SC-12, SC-13, SC-21, SC-22.
(1) SECURE NAME/ADDRESS RESOLUTION SERVICE (AUTHORITATIVE SOURCE) | CHILD
SUBSPACES
[Withdrawn: Incorporated into SC-20.]
(2) SECURE NAME/ADDRESS RESOLUTION SERVICE (AUTHORITATIVE SOURCE) | DATA
ORIGIN AND INTEGRITY
Provide data origin and integrity protecon arfacts for internal name/address resoluon
queries.
Discussion: None.
References: [FIPS 140-3], [FIPS 186-4], [SP 800-81-2]
SC-21 SECURE NAME/ADDRESS RESOLUTION SERVICE (RECURSIVE OR CACHING RESOLVER)
Control: Request and perform data origin authencaon and data integrity veriﬁcaon on the name/
address resoluon responses the system receives from authoritave sources.
Discussion: Each client of name resoluon services either performs this validaon on its own or has
authencated channels to trusted validaon providers. Systems that provide name and address
resoluon services for local clients include recursive resolving or caching domain name system
(DNS) servers. DNS client resolvers either perform validaon of DNSSEC signatures, or clients use
authencated channels to recursive resolvers that perform such validaons. Systems that use
technologies other than the DNS to map between host and service names and network addresses
provide some other means to enable clients to verify the authencity and integrity of response data.
Related controls: SC-20, SC-22.
This document is produced from OSCAL source data
FAMILY: SC PAGE 304NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(1) SECURE NAME/ADDRESS RESOLUTION SERVICE (RECURSIVE OR CACHING RESOLVER) |
DATA ORIGIN AND INTEGRITY
[Withdrawn: Incorporated into SC-21.]
Reference: [SP 800-81-2]
SC-22 ARCHITECTURE AND PROVISIONING FOR NAME/ADDRESS RESOLUTION SERVICE
Control: Ensure the systems that collecvely provide name/address resoluon service for an
organizaon are fault-tolerant and implement internal and external role separaon.
Discussion: Systems that provide name and address resoluon services include domain name system
(DNS) servers. To eliminate single points of failure in systems and enhance redundancy, organizaons
employ at least two authoritave domain name system servers—one conﬁgured as the primary server
and the other conﬁgured as the secondary server. Addionally, organizaons typically deploy the
servers in two geographically separated network subnetworks (i.e., not located in the same physical
facility). For role separaon, DNS servers with internal roles only process name and address resoluon
requests from within organizaons (i.e., from internal clients). DNS servers with external roles only
process name and address resoluon informaon requests from clients external to organizaons
(i.e., on external networks, including the Internet). Organizaons specify clients that can access
authoritave DNS servers in certain roles (e.g., by address ranges and explicit lists).
Related controls: SC-2, SC-20, SC-21, SC-24.
Reference: [SP 800-81-2]
SC-23 SESSION AUTHENTICITY
Control: Protect the authencity of communicaons sessions.
Discussion: Protecng session authencity addresses communicaons protecon at the session
level, not at the packet level. Such protecon establishes grounds for conﬁdence at both ends of
communicaons sessions in the ongoing idenes of other pares and the validity of transmied
informaon. Authencity protecon includes protecng against man-in-the-middle aacks, session
hijacking, and the inseron of false informaon into sessions.
Related controls: AU-10, SC-8, SC-10, SC-11.
(1) SESSION AUTHENTICITY | INVALIDATE SESSION IDENTIFIERS AT LOGOUT
Invalidate session idenﬁers upon user logout or other session terminaon.
Discussion: Invalidang session idenﬁers at logout curtails the ability of adversaries to capture
and connue to employ previously valid session IDs.
(2) SESSION AUTHENTICITY | USER-INITIATED LOGOUTS AND MESSAGE DISPLAYS
[Withdrawn: Incorporated into AC-12(1).]
This document is produced from OSCAL source data
FAMILY: SC PAGE 305NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(3) SESSION AUTHENTICITY | UNIQUE SYSTEM-GENERATED SESSION IDENTIFIERS
Generate a unique session idenﬁer for each session with [Assignment: organizaon-deﬁned
randomness requirements] and recognize only session idenﬁers that are system-generated.
Discussion: Generang unique session idenﬁers curtails the ability of adversaries to reuse
previously valid session IDs. Employing the concept of randomness in the generaon of unique
session idenﬁers protects against brute-force aacks to determine future session idenﬁers.
Related controls: AC-10, SC-12, SC-13.
(4) SESSION AUTHENTICITY | UNIQUE SESSION IDENTIFIERS WITH RANDOMIZATION
[Withdrawn: Incorporated into SC-23(3).]
(5) SESSION AUTHENTICITY | ALLOWED CERTIFICATE AUTHORITIES
Only allow the use of [Assignment: organizaon-deﬁned cerﬁcate authories] for veriﬁcaon
of the establishment of protected sessions.
Discussion: Reliance on cerﬁcate authories for the establishment of secure sessions includes
the use of Transport Layer Security (TLS) cerﬁcates. These cerﬁcates, aer veriﬁcaon by their
respecve cerﬁcate authories, facilitate the establishment of protected sessions between web
clients and web servers.
Related controls: SC-12, SC-13.
References: [SP 800-113], [SP 800-52], [SP 800-77], [SP 800-95]
SC-24 FAIL IN KNOWN STATE
Control: Fail to a [Assignment: organizaon-deﬁned known system state] for the following failures
on the indicated components while preserving [Assignment: organizaon-deﬁned system state
informaon] in failure: [Assignment: list of organizaon-deﬁned types of system failures on
organizaon-deﬁned system components].
Discussion: Failure in a known state addresses security concerns in accordance with the mission and
business needs of organizaons. Failure in a known state prevents the loss of conﬁdenality, integrity,
or availability of informaon in the event of failures of organizaonal systems or system components.
Failure in a known safe state helps to prevent systems from failing to a state that may cause injury to
individuals or destrucon to property. Preserving system state informaon facilitates system restart
and return to the operaonal mode with less disrupon of mission and business processes.
Related controls: CP-2, CP-4, CP-10, CP-12, SA-8, SC-7, SC-22, SI-13.
References: None
SC-25 THIN NODES
Control: Employ minimal funconality and informaon storage on the following system components:
[Assignment: organizaon-deﬁned system components].
Discussion: The deployment of system components with minimal funconality reduces the need to
secure every endpoint and may reduce the exposure of informaon, systems, and services to aacks.
Reduced or minimal funconality includes diskless nodes and thin client technologies.
Related controls: SC-30, SC-44.
References: None
This document is produced from OSCAL source data
FAMILY: SC PAGE 306NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
SC-26 DECOYS
Control: Include components within organizaonal systems speciﬁcally designed to be the target of
malicious aacks for detecng, deﬂecng, and analyzing such aacks.
Discussion: Decoys (i.e., honeypots, honeynets, or decepon nets) are established to aract
adversaries and deﬂect aacks away from the operaonal systems that support organizaonal mission
and business funcons. Use of decoys requires some supporng isolaon measures to ensure that any
deﬂected malicious code does not infect organizaonal systems. Depending on the speciﬁc usage of
the decoy, consultaon with the Oﬃce of the General Counsel before deployment may be needed.
Related controls: RA-5, SC-7, SC-30, SC-35, SC-44, SI-3, SI-4.
(1) DECOYS | DETECTION OF MALICIOUS CODE
[Withdrawn: Incorporated into SC-35.]
References: None
SC-27 PLATFORM-INDEPENDENT APPLICATIONS
Control: Include within organizaonal systems the following plaorm independent applicaons:
[Assignment: organizaon-deﬁned plaorm-independent applicaons].
Discussion: Plaorms are combinaons of hardware, ﬁrmware, and soware components used
to execute soware applicaons. Plaorms include operang systems, the underlying computer
architectures, or both. Plaorm-independent applicaons are applicaons with the capability to
execute on mulple plaorms. Such applicaons promote portability and reconstuon on diﬀerent
plaorms. Applicaon portability and the ability to reconstute on diﬀerent plaorms increase the
availability of mission-essenal funcons within organizaons in situaons where systems with
speciﬁc operang systems are under aack.
Related control: SC-29.
References: None
SC-28 PROTECTION OF INFORMATION AT REST
Control: Protect the [Selecon (one or more): conﬁdenality; integrity] of the following informaon at
rest: [Assignment: organizaon-deﬁned informaon at rest].
Discussion: Informaon at rest refers to the state of informaon when it is not in process or in transit
and is located on system components. Such components include internal or external hard disk
drives, storage area network devices, or databases. However, the focus of protecng informaon
at rest is not on the type of storage device or frequency of access but rather on the state of the
informaon. Informaon at rest addresses the conﬁdenality and integrity of informaon and covers
user informaon and system informaon. System-related informaon that requires protecon
includes conﬁguraons or rule sets for ﬁrewalls, intrusion detecon and prevenon systems, ﬁltering
routers, and authencaon informaon. Organizaons may employ diﬀerent mechanisms to achieve
conﬁdenality and integrity protecons, including the use of cryptographic mechanisms and ﬁle
share scanning. Integrity protecon can be achieved, for example, by implemenng write-once-read-
many (WORM) technologies. When adequate protecon of informaon at rest cannot otherwise be
achieved, organizaons may employ other controls, including frequent scanning to idenfy malicious
code at rest and secure oﬄine storage in lieu of online storage.
Related controls: AC-3, AC-4, AC-6, AC-19, CA-7, CM-3, CM-5, CM-6, CP-9, MP-4, MP-5, PE-3, SC-8,
SC-12, SC-13, SC-34, SI-3, SI-7, SI-16.
This document is produced from OSCAL source data
FAMILY: SC PAGE 307NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(1) PROTECTION OF INFORMATION AT REST | CRYPTOGRAPHIC PROTECTION
Implement cryptographic mechanisms to prevent unauthorized disclosure and modiﬁcaon of
the following informaon at rest on [Assignment: organizaon-deﬁned system components or
media]: [Assignment: organizaon-deﬁned informaon].
Discussion: The selecon of cryptographic mechanisms is based on the need to protect the
conﬁdenality and integrity of organizaonal informaon. The strength of mechanism is
commensurate with the security category or classiﬁcaon of the informaon. Organizaons have
the ﬂexibility to encrypt informaon on system components or media or encrypt data structures,
including ﬁles, records, or ﬁelds.
Related controls: AC-19, SC-12, SC-13.
(2) PROTECTION OF INFORMATION AT REST | OFFLINE STORAGE
Remove the following informaon from online storage and store oﬄine in a secure locaon:
[Assignment: organizaon-deﬁned informaon].
Discussion: Removing organizaonal informaon from online storage to oﬄine storage eliminates
the possibility of individuals gaining unauthorized access to the informaon through a network.
Therefore, organizaons may choose to move informaon to oﬄine storage in lieu of protecng
such informaon in online storage.
(3) PROTECTION OF INFORMATION AT REST | CRYPTOGRAPHIC KEYS
Provide protected storage for cryptographic keys [Selecon: [Assignment: organizaon-deﬁned
safeguards]; hardware-protected key store].
Discussion: A Trusted Plaorm Module (TPM) is an example of a hardware-protected data store
that can be used to protect cryptographic keys.
Related controls: SC-12, SC-13.
References: [OMB A-130], [SP 800-111], [SP 800-124], [SP 800-56A], [SP 800-56B], [SP 800-56C], [SP
800-57-1], [SP 800-57-2], [SP 800-57-3]
SC-29 HETEROGENEITY
Control: Employ a diverse set of informaon technologies for the following system components in the
implementaon of the system: [Assignment: organizaon-deﬁned system components].
Discussion: Increasing the diversity of informaon technologies within organizaonal systems reduces
the impact of potenal exploitaons or compromises of speciﬁc technologies. Such diversity protects
against common mode failures, including those failures induced by supply chain aacks. Diversity in
informaon technologies also reduces the likelihood that the means adversaries use to compromise
one system component will be eﬀecve against other system components, thus further increasing
the adversary work factor to successfully complete planned aacks. An increase in diversity may
add complexity and management overhead that could ulmately lead to mistakes and unauthorized
conﬁguraons.
Related controls: AU-9, PL-8, SC-27, SC-30, SR-3.
This document is produced from OSCAL source data
FAMILY: SC PAGE 308NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(1) HETEROGENEITY | VIRTUALIZATION TECHNIQUES
Employ virtualizaon techniques to support the deployment of a diversity of operang
systems and applicaons that are changed [Assignment: organizaon-deﬁned frequency].
Discussion: While frequent changes to operang systems and applicaons can pose signiﬁcant
conﬁguraon management challenges, the changes can result in an increased work factor for
adversaries to conduct successful aacks. Changing virtual operang systems or applicaons,
as opposed to changing actual operang systems or applicaons, provides virtual changes
that impede aacker success while reducing conﬁguraon management eﬀorts. Virtualizaon
techniques can assist in isolang untrustworthy soware or soware of dubious provenance into
conﬁned execuon environments.
References: None
SC-30 CONCEALMENT AND MISDIRECTION
Control: Employ the following concealment and misdirecon techniques for [Assignment:
organizaon-deﬁned systems] at [Assignment: organizaon-deﬁned me periods] to confuse and
mislead adversaries: [Assignment: organizaon-deﬁned concealment and misdirecon techniques].
Discussion: Concealment and misdirecon techniques can signiﬁcantly reduce the targeng capabilies
of adversaries (i.e., window of opportunity and available aack surface) to iniate and complete
aacks. For example, virtualizaon techniques provide organizaons with the ability to disguise
systems, potenally reducing the likelihood of successful aacks without the cost of having mulple
plaorms. The increased use of concealment and misdirecon techniques and methods—including
randomness, uncertainty, and virtualizaon—may suﬃciently confuse and mislead adversaries
and subsequently increase the risk of discovery and/or exposing tradecra. Concealment and
misdirecon techniques may provide addional me to perform core mission and business funcons.
The implementaon of concealment and misdirecon techniques may add to the complexity and
management overhead required for the system.
Related controls: AC-6, SC-25, SC-26, SC-29, SC-44, SI-14.
(1) CONCEALMENT AND MISDIRECTION | VIRTUALIZATION TECHNIQUES
[Withdrawn: Incorporated into SC-29(1).]
(2) CONCEALMENT AND MISDIRECTION | RANDOMNESS
Employ [Assignment: organizaon-deﬁned techniques] to introduce randomness into
organizaonal operaons and assets.
Discussion: Randomness introduces increased levels of uncertainty for adversaries regarding the
acons that organizaons take to defend their systems against aacks. Such acons may impede
the ability of adversaries to correctly target informaon resources of organizaons that support
crical missions or business funcons. Uncertainty may also cause adversaries to hesitate
before iniang or connuing aacks. Misdirecon techniques that involve randomness include
performing certain roune acons at diﬀerent mes of day, employing diﬀerent informaon
technologies, using diﬀerent suppliers, and rotang roles and responsibilies of organizaonal
personnel.
This document is produced from OSCAL source data
FAMILY: SC PAGE 309NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(3) CONCEALMENT AND MISDIRECTION | CHANGE PROCESSING AND STORAGE LOCATIONS
Change the locaon of [Assignment: organizaon-deﬁned processing and/or storage]
[Selecon: [Assignment: organizaon-deﬁned me frequency]; at random me intervals].
Discussion: Adversaries target crical mission and business funcons and the systems that
support those mission and business funcons while also trying to minimize the exposure of their
existence and tradecra. The stac, homogeneous, and determinisc nature of organizaonal
systems targeted by adversaries make such systems more suscepble to aacks with less
adversary cost and eﬀort to be successful. Changing processing and storage locaons (also
referred to as moving target defense) addresses the advanced persistent threat using techniques
such as virtualizaon, distributed processing, and replicaon. This enables organizaons
to relocate the system components (i.e., processing, storage) that support crical mission
and business funcons. Changing the locaons of processing acvies and/or storage sites
introduces a degree of uncertainty into the targeng acvies of adversaries. The targeng
uncertainty increases the work factor of adversaries and makes compromises or breaches of
the organizaonal systems more diﬃcult and me-consuming. It also increases the chances that
adversaries may inadvertently disclose certain aspects of their tradecra while aempng to
locate crical organizaonal resources.
(4) CONCEALMENT AND MISDIRECTION | MISLEADING INFORMATION
Employ realisc, but misleading informaon in [Assignment: organizaon-deﬁned system
components] about its security state or posture.
Discussion: Employing misleading informaon is intended to confuse potenal adversaries
regarding the nature and extent of controls deployed by organizaons. Thus, adversaries may
employ incorrect and ineﬀecve aack techniques. One technique for misleading adversaries
is for organizaons to place misleading informaon regarding the speciﬁc controls deployed in
external systems that are known to be targeted by adversaries. Another technique is the use of
decepon nets that mimic actual aspects of organizaonal systems but use, for example, out-of-
date soware conﬁguraons.
(5) CONCEALMENT AND MISDIRECTION | CONCEALMENT OF SYSTEM COMPONENTS
Employ the following techniques to hide or conceal [Assignment: organizaon-deﬁned system
components]: [Assignment: organizaon-deﬁned techniques].
Discussion: By hiding, disguising, or concealing crical system components, organizaons may
be able to decrease the probability that adversaries target and successfully compromise
those assets. Potenal means to hide, disguise, or conceal system components include the
conﬁguraon of routers or the use of encrypon or virtualizaon techniques.
References: None
SC-31 COVERT CHANNEL ANALYSIS
Control:
a. Perform a covert channel analysis to idenfy those aspects of communicaons within the system
that are potenal avenues for covert [Selecon (one or more): storage; ming] channels; and
b. Esmate the maximum bandwidth of those channels.
This document is produced from OSCAL source data
FAMILY: SC PAGE 310NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
Discussion: Developers are in the best posion to idenfy potenal areas within systems that might
lead to covert channels. Covert channel analysis is a meaningful acvity when there is the potenal
for unauthorized informaon ﬂows across security domains, such as in the case of systems that
contain export-controlled informaon and have connecons to external networks (i.e., networks
that are not controlled by organizaons). Covert channel analysis is also useful for mullevel secure
systems, mulple security level systems, and cross-domain systems.
Related controls: AC-3, AC-4, SA-8, SI-11.
(1) COVERT CHANNEL ANALYSIS | TEST COVERT CHANNELS FOR EXPLOITABILITY
Test a subset of the idenﬁed covert channels to determine the channels that are exploitable.
Discussion: None.
(2) COVERT CHANNEL ANALYSIS | MAXIMUM BANDWIDTH
Reduce the maximum bandwidth for idenﬁed covert [Selecon (one or more): storage;
ming] channels to [Assignment: organizaon-deﬁned values].
Discussion: The complete eliminaon of covert channels, especially covert ming channels, is
usually not possible without signiﬁcant performance impacts.
(3) COVERT CHANNEL ANALYSIS | MEASURE BANDWIDTH IN OPERATIONAL
ENVIRONMENTS
Measure the bandwidth of [Assignment: organizaon-deﬁned subset of idenﬁed covert
channels] in the operaonal environment of the system.
Discussion: Measuring covert channel bandwidth in speciﬁed operaonal environments helps
organizaons determine how much informaon can be covertly leaked before such leakage
adversely aﬀects mission or business funcons. Covert channel bandwidth may be signiﬁcantly
diﬀerent when measured in sengs that are independent of the speciﬁc environments of
operaon, including laboratories or system development environments.
References: None
SC-32 SYSTEM PARTITIONING
Control: Paron the system into [Assignment: organizaon-deﬁned system components] residing in
separate [Selecon: physical; logical] domains or environments based on [Assignment: organizaon-
deﬁned circumstances for physical or logical separaon of components].
Discussion: System paroning is part of a defense-in-depth protecon strategy. Organizaons
determine the degree of physical separaon of system components. Physical separaon opons
include physically disnct components in separate racks in the same room, crical components in
separate rooms, and geographical separaon of crical components. Security categorizaon can guide
the selecon of candidates for domain paroning. Managed interfaces restrict or prohibit network
access and informaon ﬂow among paroned system components.
Related controls: AC-4, AC-6, SA-8, SC-2, SC-3, SC-7, SC-36.
This document is produced from OSCAL source data
FAMILY: SC PAGE 311NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(1) SYSTEM PARTITIONING | SEPARATE PHYSICAL DOMAINS FOR PRIVILEGED FUNCTIONS
Paron privileged funcons into separate physical domains.
Discussion: Privileged funcons that operate in a single physical domain may represent a single
point of failure if that domain becomes compromised or experiences a denial of service.
References: [FIPS 199], [IR 8179]
SC-33 Transmission Preparaon Integrity
[Withdrawn: Incorporated into SC-8.]
SC-34 NON-MODIFIABLE EXECUTABLE PROGRAMS
Control: For [Assignment: organizaon-deﬁned system components], load and execute:
a. The operang environment from hardware-enforced, read-only media; and
b. The following applicaons from hardware-enforced, read-only media: [Assignment: organizaon-
deﬁned applicaons].
Discussion: The operang environment for a system contains the code that hosts applicaons,
including operang systems, execuves, or virtual machine monitors (i.e., hypervisors). It can also
include certain applicaons that run directly on hardware plaorms. Hardware-enforced, read-
only media include Compact Disc-Recordable (CD-R) and Digital Versale Disc-Recordable (DVD-
R) disk drives as well as one-me, programmable, read-only memory. The use of non-modiﬁable
storage ensures the integrity of soware from the point of creaon of the read-only image. The use
of reprogrammable, read-only memory can be accepted as read-only media provided that integrity
can be adequately protected from the point of inial wring to the inseron of the memory into
the system, and there are reliable hardware protecons against reprogramming the memory while
installed in organizaonal systems.
Related controls: AC-3, SI-7, SI-14.
(1) NON-MODIFIABLE EXECUTABLE PROGRAMS | NO WRITABLE STORAGE
Employ [Assignment: organizaon-deﬁned system components] with no writeable storage that
is persistent across component restart or power on/oﬀ.
Discussion: Disallowing writeable storage eliminates the possibility of malicious code inseron via
persistent, writeable storage within the designated system components. The restricon applies
to ﬁxed and removable storage, with the laer being addressed either directly or as speciﬁc
restricons imposed through access controls for mobile devices.
Related controls: AC-19, MP-7.
(2) NON-MODIFIABLE EXECUTABLE PROGRAMS | INTEGRITY PROTECTION ON READ-ONLY
MEDIA
Protect the integrity of informaon prior to storage on read-only media and control the media
aer such informaon has been recorded onto the media.
Discussion: Controls prevent the substuon of media into systems or the reprogramming of
programmable read-only media prior to installaon into the systems. Integrity protecon
controls include a combinaon of prevenon, detecon, and response.
Related controls: CM-3, CM-5, CM-9, MP-2, MP-4, MP-5, SC-28, SI-3.
This document is produced from OSCAL source data
FAMILY: SC PAGE 312NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(3) NON-MODIFIABLE EXECUTABLE PROGRAMS | HARDWARE-BASED PROTECTION
[Withdrawn: Incorporated into SC-51.]
References: None
SC-35 EXTERNAL MALICIOUS CODE IDENTIFICATION
Control: Include system components that proacvely seek to idenfy network-based malicious code or
malicious websites.
Discussion: External malicious code idenﬁcaon diﬀers from decoys in SC-26 in that the components
acvely probe networks, including the Internet, in search of malicious code contained on external
websites. Like decoys, the use of external malicious code idenﬁcaon techniques requires some
supporng isolaon measures to ensure that any malicious code discovered during the search and
subsequently executed does not infect organizaonal systems. Virtualizaon is a common technique
for achieving such isolaon.
Related controls: SC-7, SC-26, SC-44, SI-3, SI-4.
References: None
SC-36 DISTRIBUTED PROCESSING AND STORAGE
Control: Distribute the following processing and storage components across mulple [Selecon:
physical locaons; logical domains]: [Assignment: organizaon-deﬁned processing and storage
components].
Discussion: Distribung processing and storage across mulple physical locaons or logical domains
provides a degree of redundancy or overlap for organizaons. The redundancy and overlap increase
the work factor of adversaries to adversely impact organizaonal operaons, assets, and individuals.
The use of distributed processing and storage does not assume a single primary processing or storage
locaon. Therefore, it allows for parallel processing and storage.
Related controls: CP-6, CP-7, PL-8, SC-32.
(1) DISTRIBUTED PROCESSING AND STORAGE | POLLING TECHNIQUES
(a) Employ polling techniques to idenfy potenal faults, errors, or compromises to the
following processing and storage components: [Assignment: organizaon-deﬁned
distributed processing and storage components]; and
(b) Take the following acons in response to idenﬁed faults, errors, or compromises:
[Assignment: organizaon-deﬁned acons].
Discussion: Distributed processing and/or storage may be used to reduce opportunies for
adversaries to compromise the conﬁdenality, integrity, or availability of organizaonal
informaon and systems. However, the distribuon of processing and storage components
does not prevent adversaries from compromising one or more of the components. Polling
compares the processing results and/or storage content from the distributed components and
subsequently votes on the outcomes. Polling idenﬁes potenal faults, compromises, or errors
in the distributed processing and storage components.
Related control: SI-4.
This document is produced from OSCAL source data
FAMILY: SC PAGE 313NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(2) DISTRIBUTED PROCESSING AND STORAGE | SYNCHRONIZATION
Synchronize the following duplicate systems or system components: [Assignment:
organizaon-deﬁned duplicate systems or system components].
Discussion: SC-36 and CP-9(6) require the duplicaon of systems or system components in
distributed locaons. The synchronizaon of duplicated and redundant services and data helps
to ensure that informaon contained in the distributed locaons can be used in the mission or
business funcons of organizaons, as needed.
Related control: CP-9.
Reference: [SP 800-160-2]
SC-37 OUT-OF-BAND CHANNELS
Control: Employ the following out-of-band channels for the physical delivery or electronic transmission
of [Assignment: organizaon-deﬁned informaon, system components, or devices] to [Assignment:
organizaon-deﬁned individuals or systems]: [Assignment: organizaon-deﬁned out-of-band
channels].
Discussion: Out-of-band channels include local, non-network accesses to systems; network paths
physically separate from network paths used for operaonal traﬃc; or non-electronic paths, such
as the U.S. Postal Service. The use of out-of-band channels is contrasted with the use of in-band
channels (i.e., the same channels) that carry roune operaonal traﬃc. Out-of-band channels do not
have the same vulnerability or exposure as in-band channels. Therefore, the conﬁdenality, integrity,
or availability compromises of in-band channels will not compromise or adversely aﬀect the out-
of-band channels. Organizaons may employ out-of-band channels in the delivery or transmission
of organizaonal items, including authencators and credenals; cryptographic key management
informaon; system and data backups; conﬁguraon management changes for hardware, ﬁrmware,
or soware; security updates; maintenance informaon; and malicious code protecon updates.
Related controls: AC-2, CM-3, CM-5, CM-7, IA-2, IA-4, IA-5, MA-4, SC-12, SI-3, SI-4, SI-7.
(1) OUT-OF-BAND CHANNELS | ENSURE DELIVERY AND TRANSMISSION
Employ [Assignment: organizaon-deﬁned controls] to ensure that only [Assignment:
organizaon-deﬁned individuals or systems] receive the following informaon, system
components, or devices: [Assignment: organizaon-deﬁned informaon, system components,
or devices].
Discussion: Techniques employed by organizaons to ensure that only designated systems
or individuals receive certain informaon, system components, or devices include sending
authencators via an approved courier service but requiring recipients to show some form of
government-issued photographic idenﬁcaon as a condion of receipt.
References: [SP 800-57-1], [SP 800-57-2], [SP 800-57-3]
SC-38 OPERATIONS SECURITY
Control: Employ the following operaons security controls to protect key organizaonal informaon
throughout the system development life cycle: [Assignment: organizaon-deﬁned operaons security
controls].
Discussion: Operaons security (OPSEC) is a systemac process by which potenal adversaries can be
denied informaon about the capabilies and intenons of organizaons by idenfying, controlling,
This document is produced from OSCAL source data
FAMILY: SC PAGE 314NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
and protecng generally unclassiﬁed informaon that speciﬁcally relates to the planning and
execuon of sensive organizaonal acvies. The OPSEC process involves ﬁve steps: idenﬁcaon
of crical informaon, analysis of threats, analysis of vulnerabilies, assessment of risks, and the
applicaon of appropriate countermeasures. OPSEC controls are applied to organizaonal systems
and the environments in which those systems operate. OPSEC controls protect the conﬁdenality
of informaon, including liming the sharing of informaon with suppliers, potenal suppliers, and
other non-organizaonal elements and individuals. Informaon crical to organizaonal mission and
business funcons includes user idenes, element uses, suppliers, supply chain processes, funconal
requirements, security requirements, system design speciﬁcaons, tesng and evaluaon protocols,
and security control implementaon details.
Related controls: CA-2, CA-7, PL-1, PM-9, PM-12, RA-2, RA-3, RA-5, SC-7, SR-3, SR-7.
References: None
SC-39 PROCESS ISOLATION
Control: Maintain a separate execuon domain for each execung system process.
Discussion: Systems can maintain separate execuon domains for each execung process by assigning
each process a separate address space. Each system process has a disnct address space so that
communicaon between processes is performed in a manner controlled through the security
funcons, and one process cannot modify the execung code of another process. Maintaining
separate execuon domains for execung processes can be achieved, for example, by implemenng
separate address spaces. Process isolaon technologies, including sandboxing or virtualizaon,
logically separate soware and ﬁrmware from other soware, ﬁrmware, and data. Process isolaon
helps limit the access of potenally untrusted soware to other system resources. The capability to
maintain separate execuon domains is available in commercial operang systems that employ mul-
state processor technologies.
Related controls: AC-3, AC-4, AC-6, AC-25, SA-8, SC-2, SC-3, SI-16.
(1) PROCESS ISOLATION | HARDWARE SEPARATION
Implement hardware separaon mechanisms to facilitate process isolaon.
Discussion: Hardware-based separaon of system processes is generally less suscepble to
compromise than soware-based separaon, thus providing greater assurance that the
separaon will be enforced. Hardware separaon mechanisms include hardware memory
management.
(2) PROCESS ISOLATION | SEPARATE EXECUTION DOMAIN PER THREAD
Maintain a separate execuon domain for each thread in [Assignment: organizaon-deﬁned
mul-threaded processing].
Discussion: None.
Reference: [SP 800-160-1]
SC-40 WIRELESS LINK PROTECTION
Control: Protect external and internal [Assignment: organizaon-deﬁned wireless links] from the
following signal parameter aacks: [Assignment: organizaon-deﬁned types of signal parameter
aacks or references to sources for such aacks].
This document is produced from OSCAL source data
FAMILY: SC PAGE 315NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
Discussion: Wireless link protecon applies to internal and external wireless communicaon links
that may be visible to individuals who are not authorized system users. Adversaries can exploit the
signal parameters of wireless links if such links are not adequately protected. There are many ways
to exploit the signal parameters of wireless links to gain intelligence, deny service, or spoof system
users. Protecon of wireless links reduces the impact of aacks that are unique to wireless systems.
If organizaons rely on commercial service providers for transmission services as commodity items
rather than as fully dedicated services, it may not be possible to implement wireless link protecons
to the extent necessary to meet organizaonal security requirements.
Related controls: AC-18, SC-5.
(1) WIRELESS LINK PROTECTION | ELECTROMAGNETIC INTERFERENCE
Implement cryptographic mechanisms that achieve [Assignment: organizaon-deﬁned level of
protecon] against the eﬀects of intenonal electromagnec interference.
Discussion: The implementaon of cryptographic mechanisms for electromagnec interference
protects systems against intenonal jamming that might deny or impair communicaons by
ensuring that wireless spread spectrum waveforms used to provide an-jam protecon are not
predictable by unauthorized individuals. The implementaon of cryptographic mechanisms
may also coincidentally migate the eﬀects of unintenonal jamming due to interference from
legimate transmiers that share the same spectrum. Mission requirements, projected threats,
concept of operaons, and laws, execuve orders, direcves, regulaons, policies, and standards
determine levels of wireless link availability, cryptography needed, and performance.
Related controls: PE-21, SC-12, SC-13.
(2) WIRELESS LINK PROTECTION | REDUCE DETECTION POTENTIAL
Implement cryptographic mechanisms to reduce the detecon potenal of wireless links to
[Assignment: organizaon-deﬁned level of reducon].
Discussion: The implementaon of cryptographic mechanisms to reduce detecon potenal is
used for covert communicaons and to protect wireless transmiers from geo-locaon. It also
ensures that the spread spectrum waveforms used to achieve a low probability of detecon are
not predictable by unauthorized individuals. Mission requirements, projected threats, concept of
operaons, and applicable laws, execuve orders, direcves, regulaons, policies, and standards
determine the levels to which wireless links are undetectable.
Related controls: SC-12, SC-13.
(3) WIRELESS LINK PROTECTION | IMITATIVE OR MANIPULATIVE COMMUNICATIONS
DECEPTION
Implement cryptographic mechanisms to idenfy and reject wireless transmissions that are
deliberate aempts to achieve imitave or manipulave communicaons decepon based on
signal parameters.
Discussion: The implementaon of cryptographic mechanisms to idenfy and reject imitave or
manipulave communicaons ensures that the signal parameters of wireless transmissions are
not predictable by unauthorized individuals. Such unpredictability reduces the probability of
imitave or manipulave communicaons decepon based on signal parameters alone.
Related controls: SC-12, SC-13, SI-4.
This document is produced from OSCAL source data
FAMILY: SC PAGE 316NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(4) WIRELESS LINK PROTECTION | SIGNAL PARAMETER IDENTIFICATION
Implement cryptographic mechanisms to prevent the idenﬁcaon of [Assignment:
organizaon-deﬁned wireless transmiers] by using the transmier signal parameters.
Discussion: The implementaon of cryptographic mechanisms to prevent the idenﬁcaon of
wireless transmiers protects against the unique idenﬁcaon of wireless transmiers for the
purposes of intelligence exploitaon by ensuring that an-ﬁngerprinng alteraons to signal
parameters are not predictable by unauthorized individuals. It also provides anonymity when
required. Radio ﬁngerprinng techniques idenfy the unique signal parameters of transmiers
to ﬁngerprint such transmiers for purposes of tracking and mission or user idenﬁcaon.
Related controls: SC-12, SC-13.
References: None
SC-41 PORT AND I/O DEVICE ACCESS
Control: [Selecon: Physically; Logically] disable or remove [Assignment: organizaon-deﬁned
connecon ports or input/output devices] on the following systems or system components:
[Assignment: organizaon-deﬁned systems or system components].
Discussion: Connecon ports include Universal Serial Bus (USB), Thunderbolt, and Firewire (IEEE 1394).
Input/output (I/O) devices include compact disc and digital versale disc drives. Disabling or removing
such connecon ports and I/O devices helps prevent the exﬁltraon of informaon from systems and
the introducon of malicious code from those ports or devices. Physically disabling or removing ports
and/or devices is the stronger acon.
Related controls: AC-20, MP-7.
References: None
SC-42 SENSOR CAPABILITY AND DATA
Control:
a. Prohibit [Selecon (one or more): the use of devices possessing [Assignment: organizaon-
deﬁned environmental sensing capabilies] in [Assignment: organizaon-deﬁned facilies,
areas, or systems]; the remote acvaon of environmental sensing capabilies on organizaonal
systems or system components with the following excepons: [Assignment: organizaon-deﬁned
excepons where remote acvaon of sensors is allowed]]; and
b. Provide an explicit indicaon of sensor use to [Assignment: organizaon-deﬁned group of users].
Discussion: Sensor capability and data applies to types of systems or system components characterized
as mobile devices, such as cellular telephones, smart phones, and tablets. Mobile devices oen
include sensors that can collect and record data regarding the environment where the system is
in use. Sensors that are embedded within mobile devices include microphones, cameras, Global
Posioning System (GPS) mechanisms, and accelerometers. While the sensors on mobiles devices
provide an important funcon, if acvated covertly, such devices can potenally provide a means for
adversaries to learn valuable informaon about individuals and organizaons. For example, remotely
acvang the GPS funcon on a mobile device could provide an adversary with the ability to track the
movements of an individual. Organizaons may prohibit individuals from bringing cellular telephones
or digital cameras into certain designated facilies or controlled areas within facilies where classiﬁed
informaon is stored or sensive conversaons are taking place.
Related control: SC-15.
This document is produced from OSCAL source data
FAMILY: SC PAGE 317NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(1) SENSOR CAPABILITY AND DATA | REPORTING TO AUTHORIZED INDIVIDUALS OR ROLES
Verify that the system is conﬁgured so that data or informaon collected by the [Assignment:
organizaon-deﬁned sensors] is only reported to authorized individuals or roles.
Discussion: In situaons where sensors are acvated by authorized individuals, it is sll possible
that the data or informaon collected by the sensors will be sent to unauthorized enes.
(2) SENSOR CAPABILITY AND DATA | AUTHORIZED USE
Employ the following measures so that data or informaon collected by [Assignment:
organizaon-deﬁned sensors] is only used for authorized purposes: [Assignment:
organizaon-deﬁned measures].
Discussion: Informaon collected by sensors for a speciﬁc authorized purpose could be misused
for some unauthorized purpose. For example, GPS sensors that are used to support traﬃc
navigaon could be misused to track the movements of individuals. Measures to migate such
acvies include addional training to help ensure that authorized individuals do not abuse
their authority and, in the case where sensor data is maintained by external pares, contractual
restricons on the use of such data.
Related control: PT-2.
(3) SENSOR CAPABILITY AND DATA | PROHIBIT USE OF DEVICES
[Withdrawn: Incorporated into SC-42.]
(4) SENSOR CAPABILITY AND DATA | NOTICE OF COLLECTION
Employ the following measures to facilitate an individual’s awareness that personally
idenﬁable informaon is being collected by [Assignment: organizaon-deﬁned sensors]:
[Assignment: organizaon-deﬁned measures].
Discussion: Awareness that organizaonal sensors are collecng data enables individuals to
more eﬀecvely engage in managing their privacy. Measures can include convenonal wrien
noces and sensor conﬁguraons that make individuals directly or indirectly aware through
other devices that the sensor is collecng informaon. The usability and eﬃcacy of the noce
are important consideraons.
Related controls: PT-1, PT-4, PT-5.
(5) SENSOR CAPABILITY AND DATA | COLLECTION MINIMIZATION
Employ [Assignment: organizaon-deﬁned sensors] that are conﬁgured to minimize the
collecon of informaon about individuals that is not needed.
Discussion: Although policies to control for authorized use can be applied to informaon once it
is collected, minimizing the collecon of informaon that is not needed migates privacy risk
at the system entry point and migates the risk of policy control failures. Sensor conﬁguraons
include the obscuring of human features, such as blurring or pixelang ﬂesh tones.
Related controls: SA-8, SI-12.
References: [OMB A-130], [SP 800-124]
This document is produced from OSCAL source data
FAMILY: SC PAGE 318NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
SC-43 USAGE RESTRICTIONS
Control:
a. Establish usage restricons and implementaon guidelines for the following system components:
[Assignment: organizaon-deﬁned system components]; and
b. Authorize, monitor, and control the use of such components within the system.
Discussion: Usage restricons apply to all system components including but not limited to mobile code,
mobile devices, wireless access, and wired and wireless peripheral components (e.g., copiers, printers,
scanners, opcal devices, and other similar technologies). The usage restricons and implementaon
guidelines are based on the potenal for system components to cause damage to the system and help
to ensure that only authorized system use occurs.
Related controls: AC-18, AC-19, CM-6, SC-7, SC-18.
References: [OMB A-130], [SP 800-124]
SC-44 DETONATION CHAMBERS
Control: Employ a detonaon chamber capability within [Assignment: organizaon-deﬁned system,
system component, or locaon].
Discussion: Detonaon chambers, also known as dynamic execuon environments, allow organizaons
to open email aachments, execute untrusted or suspicious applicaons, and execute Universal
Resource Locator requests in the safety of an isolated environment or a virtualized sandbox. Protected
and isolated execuon environments provide a means of determining whether the associated
aachments or applicaons contain malicious code. While related to the concept of decepon nets,
the employment of detonaon chambers is not intended to maintain a long-term environment in
which adversaries can operate and their acons can be observed. Rather, detonaon chambers
are intended to quickly idenfy malicious code and either reduce the likelihood that the code is
propagated to user environments of operaon or prevent such propagaon completely.
Related controls: SC-7, SC-18, SC-25, SC-26, SC-30, SC-35, SC-39, SI-3, SI-7.
Reference: [SP 800-177]
SC-45 SYSTEM TIME SYNCHRONIZATION
Control: Synchronize system clocks within and between systems and system components.
Discussion: Time synchronizaon of system clocks is essenal for the correct execuon of many system
services, including idenﬁcaon and authencaon processes that involve cerﬁcates and me-of-
day restricons as part of access control. Denial of service or failure to deny expired credenals may
result without properly synchronized clocks within and between systems and system components.
Time is commonly expressed in Coordinated Universal Time (UTC), a modern connuaon of
Greenwich Mean Time (GMT), or local me with an oﬀset from UTC. The granularity of me
measurements refers to the degree of synchronizaon between system clocks and reference clocks,
such as clocks synchronizing within hundreds of milliseconds or tens of milliseconds. Organizaons
may deﬁne diﬀerent me granularies for system components. Time service can be crical to other
security capabilies—such as access control and idenﬁcaon and authencaon—depending on the
nature of the mechanisms used to support the capabilies.
Related controls: AC-3, AU-8, IA-2, IA-8.
This document is produced from OSCAL source data
FAMILY: SC PAGE 319NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(1) SYSTEM TIME SYNCHRONIZATION | SYNCHRONIZATION WITH AUTHORITATIVE TIME
SOURCE
(a) Compare the internal system clocks [Assignment: organizaon-deﬁned frequency] with
[Assignment: organizaon-deﬁned authoritave me source]; and
(b) Synchronize the internal system clocks to the authoritave me source when the me
diﬀerence is greater than [Assignment: organizaon-deﬁned me period].
Discussion: Synchronizaon of internal system clocks with an authoritave source provides
uniformity of me stamps for systems with mulple system clocks and systems connected over a
network.
(2) SYSTEM TIME SYNCHRONIZATION | SECONDARY AUTHORITATIVE TIME SOURCE
(a) Idenfy a secondary authoritave me source that is in a diﬀerent geographic region
than the primary authoritave me source; and
(b) Synchronize the internal system clocks to the secondary authoritave me source if the
primary authoritave me source is unavailable.
Discussion: It may be necessary to employ geolocaon informaon to determine that the
secondary authoritave me source is in a diﬀerent geographic region.
Reference: [IETF 5905]
SC-46 CROSS DOMAIN POLICY ENFORCEMENT
Control: Implement a policy enforcement mechanism [Selecon: physically; logically] between the
physical and/or network interfaces for the connecng security domains.
Discussion: For logical policy enforcement mechanisms, organizaons avoid creang a logical path
between interfaces to prevent the ability to bypass the policy enforcement mechanism. For physical
policy enforcement mechanisms, the robustness of physical isolaon aﬀorded by the physical
implementaon of policy enforcement to preclude the presence of logical covert channels penetrang
the security domain may be needed. Contact ncdsmo@nsa.gov for more informaon.
Related controls: AC-4, SC-7.
Reference: [SP 800-160-1]
SC-47 ALTERNATE COMMUNICATIONS PATHS
Control: Establish [Assignment: organizaon-deﬁned alternate communicaons paths] for system
operaons organizaonal command and control.
Discussion: An incident, whether adversarial- or nonadversarial-based, can disrupt established
communicaons paths used for system operaons and organizaonal command and control.
Alternate communicaons paths reduce the risk of all communicaons paths being aﬀected by
the same incident. To compound the problem, the inability of organizaonal oﬃcials to obtain
mely informaon about disrupons or to provide mely direcon to operaonal elements aer a
communicaons path incident, can impact the ability of the organizaon to respond to such incidents
in a mely manner. Establishing alternate communicaons paths for command and control purposes,
including designang alternave decision makers if primary decision makers are unavailable and
establishing the extent and limitaons of their acons, can greatly facilitate the organizaon’s ability
to connue to operate and take appropriate acons during an incident.
This document is produced from OSCAL source data
FAMILY: SC PAGE 320NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
Related controls: CP-2, CP-8.
References: [SP 800-160-2], [SP 800-34], [SP 800-61]
SC-48 SENSOR RELOCATION
Control: Relocate [Assignment: organizaon-deﬁned sensors and monitoring capabilies] to
[Assignment: organizaon-deﬁned locaons] under the following condions or circumstances:
[Assignment: organizaon-deﬁned condions or circumstances].
Discussion: Adversaries may take various paths and use diﬀerent approaches as they move laterally
through an organizaon (including its systems) to reach their target or as they aempt to exﬁltrate
informaon from the organizaon. The organizaon oen only has a limited set of monitoring and
detecon capabilies, and they may be focused on the crical or likely inﬁltraon or exﬁltraon paths.
By using communicaons paths that the organizaon typically does not monitor, the adversary can
increase its chances of achieving its desired goals. By relocang its sensors or monitoring capabilies
to new locaons, the organizaon can impede the adversary’s ability to achieve its goals. The
relocaon of the sensors or monitoring capabilies might be done based on threat informaon that
the organizaon has acquired or randomly to confuse the adversary and make its lateral transion
through the system or organizaon more challenging.
Related controls: AU-2, SC-7, SI-4.
(1) SENSOR RELOCATION | DYNAMIC RELOCATION OF SENSORS OR MONITORING
CAPABILITIES
Dynamically relocate [Assignment: organizaon-deﬁned sensors and monitoring capabilies]
to [Assignment: organizaon-deﬁned locaons] under the following condions or
circumstances: [Assignment: organizaon-deﬁned condions or circumstances].
Discussion: None.
Reference: [SP 800-160-2]
SC-49 HARDWARE-ENFORCED SEPARATION AND POLICY ENFORCEMENT
Control: Implement hardware-enforced separaon and policy enforcement mechanisms between
[Assignment: organizaon-deﬁned security domains].
Discussion: System owners may require addional strength of mechanism and robustness to ensure
domain separaon and policy enforcement for speciﬁc types of threats and environments of
operaon. Hardware-enforced separaon and policy enforcement provide greater strength of
mechanism than soware-enforced separaon and policy enforcement.
Related controls: AC-4, SA-8, SC-50.
Reference: [SP 800-160-1]
SC-50 SOFTWARE-ENFORCED SEPARATION AND POLICY ENFORCEMENT
Control: Implement soware-enforced separaon and policy enforcement mechanisms between
[Assignment: organizaon-deﬁned security domains].
Discussion: System owners may require addional strength of mechanism to ensure domain separaon
and policy enforcement for speciﬁc types of threats and environments of operaon.
Related controls: AC-3, AC-4, SA-8, SC-2, SC-3, SC-49.
Reference: [SP 800-160-1]
This document is produced from OSCAL source data
FAMILY: SC PAGE 321NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
SC-51 HARDWARE-BASED PROTECTION
Control:
a. Employ hardware-based, write-protect for [Assignment: organizaon-deﬁned system ﬁrmware
components]; and
b. Implement speciﬁc procedures for [Assignment: organizaon-deﬁned authorized individuals] to
manually disable hardware write-protect for ﬁrmware modiﬁcaons and re-enable the write-
protect prior to returning to operaonal mode.
Discussion: None.
References: None
This document is produced from OSCAL source data
FAMILY: SC PAGE 322NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
FAMILY: SYSTEM AND INFORMATION INTEGRITY
SI-1 POLICY AND PROCEDURES
Control:
a. Develop, document, and disseminate to [Assignment: organizaon-deﬁned personnel or roles]:
1. [Selecon (one or more): Organizaon-level; Mission/business process-level; System-level]
system and informaon integrity policy that:
(a) Addresses purpose, scope, roles, responsibilies, management commitment,
coordinaon among organizaonal enes, and compliance; and
(b) Is consistent with applicable laws, execuve orders, direcves, regulaons, policies,
standards, and guidelines; and
2. Procedures to facilitate the implementaon of the system and informaon integrity policy
and the associated system and informaon integrity controls;
b. Designate an [Assignment: organizaon-deﬁned oﬃcial] to manage the development,
documentaon, and disseminaon of the system and informaon integrity policy and
procedures; and
c. Review and update the current system and informaon integrity:
1. Policy [Assignment: organizaon-deﬁned frequency] and following [Assignment:
organizaon-deﬁned events]; and
2. Procedures [Assignment: organizaon-deﬁned frequency] and following [Assignment:
organizaon-deﬁned events].
Discussion: System and informaon integrity policy and procedures address the controls in the SI
family that are implemented within systems and organizaons. The risk management strategy is an
important factor in establishing such policies and procedures. Policies and procedures contribute
to security and privacy assurance. Therefore, it is important that security and privacy programs
collaborate on the development of system and informaon integrity policy and procedures. Security
and privacy program policies and procedures at the organizaon level are preferable, in general,
and may obviate the need for mission- or system-speciﬁc policies and procedures. The policy can be
included as part of the general security and privacy policy or be represented by mulple policies that
reﬂect the complex nature of organizaons. Procedures can be established for security and privacy
programs, for mission or business processes, and for systems, if needed. Procedures describe how the
policies or controls are implemented and can be directed at the individual or role that is the object of
the procedure. Procedures can be documented in system security and privacy plans or in one or more
separate documents. Events that may precipitate an update to system and informaon integrity policy
and procedures include assessment or audit ﬁndings, security incidents or breaches, or changes in
applicable laws, execuve orders, direcves, regulaons, policies, standards, and guidelines. Simply
restang controls does not constute an organizaonal policy or procedure.
Related controls: PM-9, PS-8, SA-8, SI-12.
References: [OMB A-130], [SP 800-100], [SP 800-12]
SI-2 FLAW REMEDIATION
Control:
a. Idenfy, report, and correct system ﬂaws;
This document is produced from OSCAL source data
FAMILY: SI PAGE 323NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
b. Test soware and ﬁrmware updates related to ﬂaw remediaon for eﬀecveness and potenal
side eﬀects before installaon;
c. Install security-relevant soware and ﬁrmware updates within [Assignment: organizaon-deﬁned
me period] of the release of the updates; and
d. Incorporate ﬂaw remediaon into the organizaonal conﬁguraon management process.
Discussion: The need to remediate system ﬂaws applies to all types of soware and ﬁrmware.
Organizaons idenfy systems aﬀected by soware ﬂaws, including potenal vulnerabilies resulng
from those ﬂaws, and report this informaon to designated organizaonal personnel with informaon
security and privacy responsibilies. Security-relevant updates include patches, service packs,
and malicious code signatures. Organizaons also address ﬂaws discovered during assessments,
connuous monitoring, incident response acvies, and system error handling. By incorporang ﬂaw
remediaon into conﬁguraon management processes, required remediaon acons can be tracked
and veriﬁed.
Organizaon-deﬁned me periods for updang security-relevant soware and ﬁrmware may vary
based on a variety of risk factors, including the security category of the system, the cricality of
the update (i.e., severity of the vulnerability related to the discovered ﬂaw), the organizaonal
risk tolerance, the mission supported by the system, or the threat environment. Some types of
ﬂaw remediaon may require more tesng than other types. Organizaons determine the type
of tesng needed for the speciﬁc type of ﬂaw remediaon acvity under consideraon and the
types of changes that are to be conﬁguraon-managed. In some situaons, organizaons may
determine that the tesng of soware or ﬁrmware updates is not necessary or praccal, such as when
implemenng simple malicious code signature updates. In tesng decisions, organizaons consider
whether security-relevant soware or ﬁrmware updates are obtained from authorized sources with
appropriate digital signatures.
Related controls: CA-5, CM-3, CM-4, CM-5, CM-6, CM-8, MA-2, RA-5, SA-8, SA-10, SA-11, SI-3, SI-5, SI-7,
SI-11.
(1) FLAW REMEDIATION | CENTRAL MANAGEMENT
[Withdrawn: Incorporated into PL-9.]
(2) FLAW REMEDIATION | AUTOMATED FLAW REMEDIATION STATUS
Determine if system components have applicable security-relevant soware and ﬁrmware
updates installed using [Assignment: organizaon-deﬁned automated mechanisms]
[Assignment: organizaon-deﬁned frequency].
Discussion: Automated mechanisms can track and determine the status of known ﬂaws for
system components.
Related controls: CA-7, SI-4.
This document is produced from OSCAL source data
FAMILY: SI PAGE 324NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(3) FLAW REMEDIATION | TIME TO REMEDIATE FLAWS AND BENCHMARKS FOR
CORRECTIVE ACTIONS
(a) Measure the me between ﬂaw idenﬁcaon and ﬂaw remediaon; and
(b) Establish the following benchmarks for taking correcve acons: [Assignment:
organizaon-deﬁned benchmarks].
Discussion: Organizaons determine the me it takes on average to correct system ﬂaws aer
such ﬂaws have been idenﬁed and subsequently establish organizaonal benchmarks (i.e., me
frames) for taking correcve acons. Benchmarks can be established by the type of ﬂaw or the
severity of the potenal vulnerability if the ﬂaw can be exploited.
(4) FLAW REMEDIATION | AUTOMATED PATCH MANAGEMENT TOOLS
Employ automated patch management tools to facilitate ﬂaw remediaon to the following
system components: [Assignment: organizaon-deﬁned system components].
Discussion: Using automated tools to support patch management helps to ensure the meliness
and completeness of system patching operaons.
(5) FLAW REMEDIATION | AUTOMATIC SOFTWARE AND FIRMWARE UPDATES
Install [Assignment: organizaon-deﬁned security-relevant soware and ﬁrmware updates]
automacally to [Assignment: organizaon-deﬁned system components].
Discussion: Due to system integrity and availability concerns, organizaons consider the
methodology used to carry out automac updates. Organizaons balance the need to ensure
that the updates are installed as soon as possible with the need to maintain conﬁguraon
management and control with any mission or operaonal impacts that automac updates might
impose.
(6) FLAW REMEDIATION | REMOVAL OF PREVIOUS VERSIONS OF SOFTWARE AND
FIRMWARE
Remove previous versions of [Assignment: organizaon-deﬁned soware and ﬁrmware
components] aer updated versions have been installed.
Discussion: Previous versions of soware or ﬁrmware components that are not removed from the
system aer updates have been installed may be exploited by adversaries. Some products may
automacally remove previous versions of soware and ﬁrmware from the system.
References: [FIPS 140-3], [FIPS 186-4], [IR 7788], [OMB A-130], [SP 800-128], [SP 800-39], [SP 800-40]
SI-3 MALICIOUS CODE PROTECTION
Control:
a. Implement [Selecon (one or more): signature based; non-signature based] malicious code
protecon mechanisms at system entry and exit points to detect and eradicate malicious code;
b. Automacally update malicious code protecon mechanisms as new releases are available in
accordance with organizaonal conﬁguraon management policy and procedures;
This document is produced from OSCAL source data
FAMILY: SI PAGE 325NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
c. Conﬁgure malicious code protecon mechanisms to:
1. Perform periodic scans of the system [Assignment: organizaon-deﬁned frequency] and
real-me scans of ﬁles from external sources at [Selecon (one or more): endpoint; network
entry and exit points] as the ﬁles are downloaded, opened, or executed in accordance with
organizaonal policy; and
2. [Selecon (one or more): block malicious code; quaranne malicious code; take [Assignment:
organizaon-deﬁned acon]]; and send alert to [Assignment: organizaon-deﬁned
personnel or roles] in response to malicious code detecon; and
d. Address the receipt of false posives during malicious code detecon and eradicaon and the
resulng potenal impact on the availability of the system.
Discussion: System entry and exit points include ﬁrewalls, remote access servers, workstaons,
electronic mail servers, web servers, proxy servers, notebook computers, and mobile devices.
Malicious code includes viruses, worms, Trojan horses, and spyware. Malicious code can also be
encoded in various formats contained within compressed or hidden ﬁles or hidden in ﬁles using
techniques such as steganography. Malicious code can be inserted into systems in a variety of ways,
including by electronic mail, the world-wide web, and portable storage devices. Malicious code
inserons occur through the exploitaon of system vulnerabilies. A variety of technologies and
methods exist to limit or eliminate the eﬀects of malicious code.
Malicious code protecon mechanisms include both signature- and nonsignature-based technologies.
Nonsignature-based detecon mechanisms include arﬁcial intelligence techniques that use
heuriscs to detect, analyze, and describe the characteriscs or behavior of malicious code and
to provide controls against such code for which signatures do not yet exist or for which exisng
signatures may not be eﬀecve. Malicious code for which acve signatures do not yet exist or may be
ineﬀecve includes polymorphic malicious code (i.e., code that changes signatures when it replicates).
Nonsignature-based mechanisms also include reputaon-based technologies. In addion to the
above technologies, pervasive conﬁguraon management, comprehensive soware integrity controls,
and an-exploitaon soware may be eﬀecve in prevenng the execuon of unauthorized code.
Malicious code may be present in commercial oﬀ-the-shelf soware as well as custom-built soware
and could include logic bombs, backdoors, and other types of aacks that could aﬀect organizaonal
mission and business funcons.
In situaons where malicious code cannot be detected by detecon methods or technologies,
organizaons rely on other types of controls, including secure coding pracces, conﬁguraon
management and control, trusted procurement processes, and monitoring pracces to ensure that
soware does not perform funcons other than the funcons intended. Organizaons may determine
that, in response to the detecon of malicious code, diﬀerent acons may be warranted. For example,
organizaons can deﬁne acons in response to malicious code detecon during periodic scans, the
detecon of malicious downloads, or the detecon of maliciousness when aempng to open or
execute ﬁles.
Related controls: AC-4, AC-19, CM-3, CM-8, IR-4, MA-3, MA-4, PL-9, RA-5, SC-7, SC-23, SC-26, SC-28,
SC-44, SI-2, SI-4, SI-7, SI-8, SI-15.
(1) MALICIOUS CODE PROTECTION | CENTRAL MANAGEMENT
[Withdrawn: Incorporated into PL-9.]
(2) MALICIOUS CODE PROTECTION | AUTOMATIC UPDATES
[Withdrawn: Incorporated into SI-3.]
This document is produced from OSCAL source data
FAMILY: SI PAGE 326NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(3) MALICIOUS CODE PROTECTION | NON-PRIVILEGED USERS
[Withdrawn: Incorporated into AC-6(10).]
(4) MALICIOUS CODE PROTECTION | UPDATES ONLY BY PRIVILEGED USERS
Update malicious code protecon mechanisms only when directed by a privileged user.
Discussion: Protecon mechanisms for malicious code are typically categorized as security-related
soware and, as such, are only updated by organizaonal personnel with appropriate access
privileges.
Related control: CM-5.
(5) MALICIOUS CODE PROTECTION | PORTABLE STORAGE DEVICES
[Withdrawn: Incorporated into MP-7.]
(6) MALICIOUS CODE PROTECTION | TESTING AND VERIFICATION
(a) Test malicious code protecon mechanisms [Assignment: organizaon-deﬁned frequency]
by introducing known benign code into the system; and
(b) Verify that the detecon of the code and the associated incident reporng occur.
Discussion: None.
Related controls: CA-2, CA-7, RA-5.
(7) MALICIOUS CODE PROTECTION | NONSIGNATURE-BASED DETECTION
[Withdrawn: Incorporated into SI-3.]
(8) MALICIOUS CODE PROTECTION | DETECT UNAUTHORIZED COMMANDS
(a) Detect the following unauthorized operang system commands through the kernel
applicaon programming interface on [Assignment: organizaon-deﬁned system
hardware components]: [Assignment: organizaon-deﬁned unauthorized operang
system commands]; and
(b) [Selecon (one or more): issue a warning; audit the command execuon; prevent the
execuon of the command].
Discussion: Detecng unauthorized commands can be applied to crical interfaces other than
kernel-based interfaces, including interfaces with virtual machines and privileged applicaons.
Unauthorized operang system commands include commands for kernel funcons from system
processes that are not trusted to iniate such commands as well as commands for kernel
funcons that are suspicious even though commands of that type are reasonable for processes
to iniate. Organizaons can deﬁne the malicious commands to be detected by a combinaon
of command types, command classes, or speciﬁc instances of commands. Organizaons can
also deﬁne hardware components by component type, component, component locaon in the
network, or a combinaon thereof. Organizaons may select diﬀerent acons for diﬀerent types,
classes, or instances of malicious commands.
Related controls: AU-2, AU-6, AU-12.
This document is produced from OSCAL source data
FAMILY: SI PAGE 327NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(9) MALICIOUS CODE PROTECTION | AUTHENTICATE REMOTE COMMANDS
[Withdrawn: Incorporated into AC-17(10).]
(10) MALICIOUS CODE PROTECTION | MALICIOUS CODE ANALYSIS
(a) Employ the following tools and techniques to analyze the characteriscs and behavior of
malicious code: [Assignment: organizaon-deﬁned tools and techniques]; and
(b) Incorporate the results from malicious code analysis into organizaonal incident response
and ﬂaw remediaon processes.
Discussion: The use of malicious code analysis tools provides organizaons with a more in-
depth understanding of adversary tradecra (i.e., taccs, techniques, and procedures) and
the funconality and purpose of speciﬁc instances of malicious code. Understanding the
characteriscs of malicious code facilitates eﬀecve organizaonal responses to current and
future threats. Organizaons can conduct malicious code analyses by employing reverse
engineering techniques or by monitoring the behavior of execung code.
References: [SP 800-125B], [SP 800-177], [SP 800-83]
SI-4 SYSTEM MONITORING
Control:
a. Monitor the system to detect:
1. Aacks and indicators of potenal aacks in accordance with the following monitoring
objecves: [Assignment: organizaon-deﬁned monitoring objecves]; and
2. Unauthorized local, network, and remote connecons;
b. Idenfy unauthorized use of the system through the following techniques and methods:
[Assignment: organizaon-deﬁned techniques and methods];
c. Invoke internal monitoring capabilies or deploy monitoring devices:
1. Strategically within the system to collect organizaon-determined essenal informaon; and
2. At ad hoc locaons within the system to track speciﬁc types of transacons of interest to the
organizaon;
d. Analyze detected events and anomalies;
e. Adjust the level of system monitoring acvity when there is a change in risk to organizaonal
operaons and assets, individuals, other organizaons, or the Naon;
f. Obtain legal opinion regarding system monitoring acvies; and
g. Provide [Assignment: organizaon-deﬁned system monitoring informaon] to [Assignment:
organizaon-deﬁned personnel or roles] [Selecon (one or more): as needed; [Assignment:
organizaon-deﬁned frequency]].
Discussion: System monitoring includes external and internal monitoring. External monitoring
includes the observaon of events occurring at external interfaces to the system. Internal monitoring
includes the observaon of events occurring within the system. Organizaons monitor systems
by observing audit acvies in real me or by observing other system aspects such as access
paerns, characteriscs of access, and other acons. The monitoring objecves guide and inform
the determinaon of the events. System monitoring capabilies are achieved through a variety of
This document is produced from OSCAL source data
FAMILY: SI PAGE 328NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
tools and techniques, including intrusion detecon and prevenon systems, malicious code protecon
soware, scanning tools, audit record monitoring soware, and network monitoring soware.
Depending on the security architecture, the distribuon and conﬁguraon of monitoring devices
may impact throughput at key internal and external boundaries as well as at other locaons across
a network due to the introducon of network throughput latency. If throughput management is
needed, such devices are strategically located and deployed as part of an established organizaon-
wide security architecture. Strategic locaons for monitoring devices include selected perimeter
locaons and near key servers and server farms that support crical applicaons. Monitoring devices
are typically employed at the managed interfaces associated with controls SC-7 and AC-17. The
informaon collected is a funcon of the organizaonal monitoring objecves and the capability
of systems to support such objecves. Speciﬁc types of transacons of interest include Hypertext
Transfer Protocol (HTTP) traﬃc that bypasses HTTP proxies. System monitoring is an integral part
of organizaonal connuous monitoring and incident response programs, and output from system
monitoring serves as input to those programs. System monitoring requirements, including the
need for speciﬁc types of system monitoring, may be referenced in other controls (e.g., AC-2g,
AC-2(7), AC-2(12)(a), AC-17(1), AU-13, AU-13(1), AU-13(2), CM-3f, CM-6d, MA-3a, MA-4a, SC-5(3)
(b), SC-7a, SC-7(24)(b), SC-18b, SC-43b). Adjustments to levels of system monitoring are based on
law enforcement informaon, intelligence informaon, or other sources of informaon. The legality
of system monitoring acvies is based on applicable laws, execuve orders, direcves, regulaons,
policies, standards, and guidelines.
Related controls: AC-2, AC-3, AC-4, AC-8, AC-17, AU-2, AU-6, AU-7, AU-9, AU-12, AU-13, AU-14, CA-7,
CM-3, CM-6, CM-8, CM-11, IA-10, IR-4, MA-3, MA-4, PL-9, PM-12, RA-5, RA-10, SC-5, SC-7, SC-18,
SC-26, SC-31, SC-35, SC-36, SC-37, SC-43, SI-3, SI-6, SI-7, SR-9, SR-10.
(1) SYSTEM MONITORING | SYSTEM-WIDE INTRUSION DETECTION SYSTEM
Connect and conﬁgure individual intrusion detecon tools into a system-wide intrusion
detecon system.
Discussion: Linking individual intrusion detecon tools into a system-wide intrusion detecon
system provides addional coverage and eﬀecve detecon capabilies. The informaon
contained in one intrusion detecon tool can be shared widely across the organizaon, making
the system-wide detecon capability more robust and powerful.
(2) SYSTEM MONITORING | AUTOMATED TOOLS AND MECHANISMS FOR REAL-TIME
ANALYSIS
Employ automated tools and mechanisms to support near real-me analysis of events.
Discussion: Automated tools and mechanisms include host-based, network-based, transport-
based, or storage-based event monitoring tools and mechanisms or security informaon
and event management (SIEM) technologies that provide real-me analysis of alerts and
noﬁcaons generated by organizaonal systems. Automated monitoring techniques can create
unintended privacy risks because automated controls may connect to external or otherwise
unrelated systems. The matching of records between these systems may create linkages with
unintended consequences. Organizaons assess and document these risks in their privacy
impact assessment and make determinaons that are in alignment with their privacy program
plan.
Related controls: PM-23, PM-25.
This document is produced from OSCAL source data
FAMILY: SI PAGE 329NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(3) SYSTEM MONITORING | AUTOMATED TOOL AND MECHANISM INTEGRATION
Employ automated tools and mechanisms to integrate intrusion detecon tools and
mechanisms into access control and ﬂow control mechanisms.
Discussion: Using automated tools and mechanisms to integrate intrusion detecon tools and
mechanisms into access and ﬂow control mechanisms facilitates a rapid response to aacks by
enabling the reconﬁguraon of mechanisms in support of aack isolaon and eliminaon.
Related controls: PM-23, PM-25.
(4) SYSTEM MONITORING | INBOUND AND OUTBOUND COMMUNICATIONS TRAFFIC
(a) Determine criteria for unusual or unauthorized acvies or condions for inbound and
outbound communicaons traﬃc;
(b) Monitor inbound and outbound communicaons traﬃc [Assignment: organizaon-
deﬁned frequency] for [Assignment: organizaon-deﬁned unusual or unauthorized
acvies or condions].
Discussion: Unusual or unauthorized acvies or condions related to system inbound and
outbound communicaons traﬃc includes internal traﬃc that indicates the presence of
malicious code or unauthorized use of legimate code or credenals within organizaonal
systems or propagang among system components, signaling to external systems, and the
unauthorized exporng of informaon. Evidence of malicious code or unauthorized use of
legimate code or credenals is used to idenfy potenally compromised systems or system
components.
(5) SYSTEM MONITORING | SYSTEM-GENERATED ALERTS
Alert [Assignment: organizaon-deﬁned personnel or roles] when the following system-
generated indicaons of compromise or potenal compromise occur: [Assignment:
organizaon-deﬁned compromise indicators].
Discussion: Alerts may be generated from a variety of sources, including audit records or inputs
from malicious code protecon mechanisms, intrusion detecon or prevenon mechanisms, or
boundary protecon devices such as ﬁrewalls, gateways, and routers. Alerts can be automated
and may be transmied telephonically, by electronic mail messages, or by text messaging.
Organizaonal personnel on the alert noﬁcaon list can include system administrators, mission
or business owners, system owners, informaon owners/stewards, senior agency informaon
security oﬃcers, senior agency oﬃcials for privacy, system security oﬃcers, or privacy oﬃcers.
In contrast to alerts generated by the system, alerts generated by organizaons in SI-4(12) focus
on informaon sources external to the system, such as suspicious acvity reports and reports on
potenal insider threats.
Related controls: AU-4, AU-5, PE-6.
(6) SYSTEM MONITORING | RESTRICT NON-PRIVILEGED USERS
[Withdrawn: Incorporated into AC-6(10).]
This document is produced from OSCAL source data
FAMILY: SI PAGE 330NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(7) SYSTEM MONITORING | AUTOMATED RESPONSE TO SUSPICIOUS EVENTS
(a) Nofy [Assignment: organizaon-deﬁned incident response personnel (idenﬁed by name
and/or by role)] of detected suspicious events; and
(b) Take the following acons upon detecon: [Assignment: organizaon-deﬁned least-
disrupve acons to terminate suspicious events].
Discussion: Least-disrupve acons include iniang requests for human responses.
(8) SYSTEM MONITORING | PROTECTION OF MONITORING INFORMATION
[Withdrawn: Incorporated into SI-4.]
(9) SYSTEM MONITORING | TESTING OF MONITORING TOOLS AND MECHANISMS
Test intrusion-monitoring tools and mechanisms [Assignment: organizaon-deﬁned
frequency].
Discussion: Tesng intrusion-monitoring tools and mechanisms is necessary to ensure that
the tools and mechanisms are operang correctly and connue to sasfy the monitoring
objecves of organizaons. The frequency and depth of tesng depends on the types of tools
and mechanisms used by organizaons and the methods of deployment.
(10) SYSTEM MONITORING | VISIBILITY OF ENCRYPTED COMMUNICATIONS
Make provisions so that [Assignment: organizaon-deﬁned encrypted communicaons traﬃc]
is visible to [Assignment: organizaon-deﬁned system monitoring tools and mechanisms].
Discussion: Organizaons balance the need to encrypt communicaons traﬃc to protect
data conﬁdenality with the need to maintain visibility into such traﬃc from a monitoring
perspecve. Organizaons determine whether the visibility requirement applies to internal
encrypted traﬃc, encrypted traﬃc intended for external desnaons, or a subset of the traﬃc
types.
(11) SYSTEM MONITORING | ANALYZE COMMUNICATIONS TRAFFIC ANOMALIES
Analyze outbound communicaons traﬃc at the external interfaces to the system and selected
[Assignment: organizaon-deﬁned interior points within the system] to discover anomalies.
Discussion: Organizaon-deﬁned interior points include subnetworks and subsystems. Anomalies
within organizaonal systems include large ﬁle transfers, long-me persistent connecons,
aempts to access informaon from unexpected locaons, the use of unusual protocols and
ports, the use of unmonitored network protocols (e.g., IPv6 usage during IPv4 transion), and
aempted communicaons with suspected malicious external addresses.
(12) SYSTEM MONITORING | AUTOMATED ORGANIZATION-GENERATED ALERTS
Alert [Assignment: organizaon-deﬁned personnel or roles] using [Assignment: organizaon-
deﬁned automated mechanisms] when the following indicaons of inappropriate or unusual
acvies with security or privacy implicaons occur: [Assignment: organizaon-deﬁned
acvies that trigger alerts].
Discussion: Organizaonal personnel on the system alert noﬁcaon list include system
administrators, mission or business owners, system owners, senior agency informaon security
This document is produced from OSCAL source data
FAMILY: SI PAGE 331NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
oﬃcer, senior agency oﬃcial for privacy, system security oﬃcers, or privacy oﬃcers. Automated
organizaon-generated alerts are the security alerts generated by organizaons and transmied
using automated means. The sources for organizaon-generated alerts are focused on other
enes such as suspicious acvity reports and reports on potenal insider threats. In contrast
to alerts generated by the organizaon, alerts generated by the system in SI-4(5) focus on
informaon sources that are internal to the systems, such as audit records.
(13) SYSTEM MONITORING | ANALYZE TRAFFIC AND EVENT PATTERNS
(a) Analyze communicaons traﬃc and event paerns for the system;
(b) Develop proﬁles represenng common traﬃc and event paerns; and
(c) Use the traﬃc and event proﬁles in tuning system-monitoring devices.
Discussion: Idenfying and understanding common communicaons traﬃc and event paerns
help organizaons provide useful informaon to system monitoring devices to more eﬀecvely
idenfy suspicious or anomalous traﬃc and events when they occur. Such informaon can help
reduce the number of false posives and false negaves during system monitoring.
(14) SYSTEM MONITORING | WIRELESS INTRUSION DETECTION
Employ a wireless intrusion detecon system to idenfy rogue wireless devices and to detect
aack aempts and potenal compromises or breaches to the system.
Discussion: Wireless signals may radiate beyond organizaonal facilies. Organizaons proacvely
search for unauthorized wireless connecons, including the conduct of thorough scans for
unauthorized wireless access points. Wireless scans are not limited to those areas within
facilies containing systems but also include areas outside of facilies to verify that unauthorized
wireless access points are not connected to organizaonal systems.
Related controls: AC-18, IA-3.
(15) SYSTEM MONITORING | WIRELESS TO WIRELINE COMMUNICATIONS
Employ an intrusion detecon system to monitor wireless communicaons traﬃc as the traﬃc
passes from wireless to wireline networks.
Discussion: Wireless networks are inherently less secure than wired networks. For example,
wireless networks are more suscepble to eavesdroppers or traﬃc analysis than wireline
networks. When wireless to wireline communicaons exist, the wireless network could become
a port of entry into the wired network. Given the greater facility of unauthorized network
access via wireless access points compared to unauthorized wired network access from within
the physical boundaries of the system, addional monitoring of transioning traﬃc between
wireless and wired networks may be necessary to detect malicious acvies. Employing
intrusion detecon systems to monitor wireless communicaons traﬃc helps to ensure that the
traﬃc does not contain malicious code prior to transioning to the wireline network.
Related control: AC-18.
(16) SYSTEM MONITORING | CORRELATE MONITORING INFORMATION
Correlate informaon from monitoring tools and mechanisms employed throughout the
system.
Discussion: Correlang informaon from diﬀerent system monitoring tools and mechanisms can
provide a more comprehensive view of system acvity. Correlang system monitoring tools and
This document is produced from OSCAL source data
FAMILY: SI PAGE 332NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
mechanisms that typically work in isolaon—including malicious code protecon soware, host
monitoring, and network monitoring—can provide an organizaon-wide monitoring view and
may reveal otherwise unseen aack paerns. Understanding the capabilies and limitaons
of diverse monitoring tools and mechanisms and how to maximize the use of informaon
generated by those tools and mechanisms can help organizaons develop, operate, and
maintain eﬀecve monitoring programs. The correlaon of monitoring informaon is especially
important during the transion from older to newer technologies (e.g., transioning from IPv4
to IPv6 network protocols).
Related control: AU-6.
(17) SYSTEM MONITORING | INTEGRATED SITUATIONAL AWARENESS
Correlate informaon from monitoring physical, cyber, and supply chain acvies to achieve
integrated, organizaon-wide situaonal awareness.
Discussion: Correlang monitoring informaon from a more diverse set of informaon sources
helps to achieve integrated situaonal awareness. Integrated situaonal awareness from a
combinaon of physical, cyber, and supply chain monitoring acvies enhances the capability
of organizaons to more quickly detect sophiscated aacks and invesgate the methods and
techniques employed to carry out such aacks. In contrast to SI-4(16), which correlates the
various cyber monitoring informaon, integrated situaonal awareness is intended to correlate
monitoring beyond the cyber domain. Correlaon of monitoring informaon from mulple
acvies may help reveal aacks on organizaons that are operang across mulple aack
vectors.
Related controls: AU-16, PE-6, SR-2, SR-4, SR-6.
(18) SYSTEM MONITORING | ANALYZE TRAFFIC AND COVERT EXFILTRATION
Analyze outbound communicaons traﬃc at external interfaces to the system and at
the following interior points to detect covert exﬁltraon of informaon: [Assignment:
organizaon-deﬁned interior points within the system].
Discussion: Organizaon-deﬁned interior points include subnetworks and subsystems. Covert
means that can be used to exﬁltrate informaon include steganography.
(19) SYSTEM MONITORING | RISK FOR INDIVIDUALS
Implement [Assignment: organizaon-deﬁned addional monitoring] of individuals who have
been idenﬁed by [Assignment: organizaon-deﬁned sources] as posing an increased level of
risk.
Discussion: Indicaons of increased risk from individuals can be obtained from diﬀerent sources,
including personnel records, intelligence agencies, law enforcement organizaons, and other
sources. The monitoring of individuals is coordinated with the management, legal, security,
privacy, and human resource oﬃcials who conduct such monitoring. Monitoring is conducted in
accordance with applicable laws, execuve orders, direcves, regulaons, policies, standards,
and guidelines.
This document is produced from OSCAL source data
FAMILY: SI PAGE 333NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(20) SYSTEM MONITORING | PRIVILEGED USERS
Implement the following addional monitoring of privileged users: [Assignment: organizaon-
deﬁned addional monitoring].
Discussion: Privileged users have access to more sensive informaon, including security-related
informaon, than the general user populaon. Access to such informaon means that privileged
users can potenally do greater damage to systems and organizaons than non-privileged
users. Therefore, implemenng addional monitoring on privileged users helps to ensure that
organizaons can idenfy malicious acvity at the earliest possible me and take appropriate
acons.
Related control: AC-18.
(21) SYSTEM MONITORING | PROBATIONARY PERIODS
Implement the following addional monitoring of individuals during [Assignment:
organizaon-deﬁned probaonary period]: [Assignment: organizaon-deﬁned addional
monitoring].
Discussion: During probaonary periods, employees do not have permanent employment status
within organizaons. Without such status or access to informaon that is resident on the system,
addional monitoring can help idenfy any potenally malicious acvity or inappropriate
behavior.
Related control: AC-18.
(22) SYSTEM MONITORING | UNAUTHORIZED NETWORK SERVICES
(a) Detect network services that have not been authorized or approved by [Assignment:
organizaon-deﬁned authorizaon or approval processes]; and
(b) [Selecon (one or more): Audit; Alert [Assignment: organizaon-deﬁned personnel or
roles]] when detected.
Discussion: Unauthorized or unapproved network services include services in service-oriented
architectures that lack organizaonal veriﬁcaon or validaon and may therefore be unreliable
or serve as malicious rogues for valid services.
Related control: CM-7.
(23) SYSTEM MONITORING | HOST-BASED DEVICES
Implement the following host-based monitoring mechanisms at [Assignment: organizaon-
deﬁned system components]: [Assignment: organizaon-deﬁned host-based monitoring
mechanisms].
Discussion: Host-based monitoring collects informaon about the host (or system in which it
resides). System components in which host-based monitoring can be implemented include
servers, notebook computers, and mobile devices. Organizaons may consider employing host-
based monitoring mechanisms from mulple product developers or vendors.
Related controls: AC-18, AC-19.
This document is produced from OSCAL source data
FAMILY: SI PAGE 334NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(24) SYSTEM MONITORING | INDICATORS OF COMPROMISE
Discover, collect, and distribute to [Assignment: organizaon-deﬁned personnel or roles],
indicators of compromise provided by [Assignment: organizaon-deﬁned sources].
Discussion: Indicators of compromise (IOC) are forensic arfacts from intrusions that are
idenﬁed on organizaonal systems at the host or network level. IOCs provide valuable
informaon on systems that have been compromised. IOCs can include the creaon of registry
key values. IOCs for network traﬃc include Universal Resource Locator or protocol elements
that indicate malicious code command and control servers. The rapid distribuon and adopon
of IOCs can improve informaon security by reducing the me that systems and organizaons
are vulnerable to the same exploit or aack. Threat indicators, signatures, taccs, techniques,
procedures, and other indicators of compromise may be available via government and non-
government cooperaves, including the Forum of Incident Response and Security Teams, the
United States Computer Emergency Readiness Team, the Defense Industrial Base Cybersecurity
Informaon Sharing Program, and the CERT Coordinaon Center.
Related control: AC-18.
(25) SYSTEM MONITORING | OPTIMIZE NETWORK TRAFFIC ANALYSIS
Provide visibility into network traﬃc at external and key internal system interfaces to opmize
the eﬀecveness of monitoring devices.
Discussion: Encrypted traﬃc, asymmetric roung architectures, capacity and latency limitaons,
and transioning from older to newer technologies (e.g., IPv4 to IPv6 network protocol
transion) may result in blind spots for organizaons when analyzing network traﬃc. Collecng,
decrypng, pre-processing, and distribung only relevant traﬃc to monitoring devices can
streamline the eﬃciency and use of devices and opmize traﬃc analysis.
References: [FIPS 140-3], [OMB A-130], [SP 800-137], [SP 800-61], [SP 800-83], [SP 800-92], [SP 800-94]
SI-5 SECURITY ALERTS, ADVISORIES, AND DIRECTIVES
Control:
a. Receive system security alerts, advisories, and direcves from [Assignment: organizaon-deﬁned
external organizaons] on an ongoing basis;
b. Generate internal security alerts, advisories, and direcves as deemed necessary;
c. Disseminate security alerts, advisories, and direcves to: [Selecon (one or more): [Assignment:
organizaon-deﬁned personnel or roles]; [Assignment: organizaon-deﬁned elements within the
organizaon]; [Assignment: organizaon-deﬁned external organizaons]]; and
d. Implement security direcves in accordance with established me frames, or nofy the issuing
organizaon of the degree of noncompliance.
Discussion: The Cybersecurity and Infrastructure Security Agency (CISA) generates security alerts and
advisories to maintain situaonal awareness throughout the Federal Government. Security direcves
are issued by OMB or other designated organizaons with the responsibility and authority to issue
such direcves. Compliance with security direcves is essenal due to the crical nature of many
of these direcves and the potenal (immediate) adverse eﬀects on organizaonal operaons and
assets, individuals, other organizaons, and the Naon should the direcves not be implemented in
a mely manner. External organizaons include supply chain partners, external mission or business
partners, external service providers, and other peer or supporng organizaons.
This document is produced from OSCAL source data
FAMILY: SI PAGE 335NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
Related controls: PM-15, RA-5, SI-2.
(1) SECURITY ALERTS, ADVISORIES, AND DIRECTIVES | AUTOMATED ALERTS AND
ADVISORIES
Broadcast security alert and advisory informaon throughout the organizaon using
[Assignment: organizaon-deﬁned automated mechanisms].
Discussion: The signiﬁcant number of changes to organizaonal systems and environments
of operaon requires the disseminaon of security-related informaon to a variety of
organizaonal enes that have a direct interest in the success of organizaonal mission and
business funcons. Based on informaon provided by security alerts and advisories, changes
may be required at one or more of the three levels related to the management of risk, including
the governance level, mission and business process level, and the informaon system level.
Reference: [SP 800-40]
SI-6 SECURITY AND PRIVACY FUNCTION VERIFICATION
Control:
a. Verify the correct operaon of [Assignment: organizaon-deﬁned security and privacy funcons];
b. Perform the veriﬁcaon of the funcons speciﬁed in SI-6a [Selecon (one or more): [Assignment:
organizaon-deﬁned system transional states]; upon command by user with appropriate
privilege; [Assignment: organizaon-deﬁned frequency]];
c. Alert [Assignment: organizaon-deﬁned personnel or roles] to failed security and privacy
veriﬁcaon tests; and
d. [Selecon (one or more): Shut the system down; Restart the system; [Assignment: organizaon-
deﬁned alternave acon(s)]] when anomalies are discovered.
Discussion: Transional states for systems include system startup, restart, shutdown, and abort.
System noﬁcaons include hardware indicator lights, electronic alerts to system administrators, and
messages to local computer consoles. In contrast to security funcon veriﬁcaon, privacy funcon
veriﬁcaon ensures that privacy funcons operate as expected and are approved by the senior agency
oﬃcial for privacy or that privacy aributes are applied or used as expected.
Related controls: CA-7, CM-4, CM-6, SI-7.
(1) SECURITY AND PRIVACY FUNCTION VERIFICATION | NOTIFICATION OF FAILED SECURITY
TESTS
[Withdrawn: Incorporated into SI-6.]
(2) SECURITY AND PRIVACY FUNCTION VERIFICATION | AUTOMATION SUPPORT FOR
DISTRIBUTED TESTING
Implement automated mechanisms to support the management of distributed security and
privacy funcon tesng.
Discussion: The use of automated mechanisms to support the management of distributed
funcon tesng helps to ensure the integrity, meliness, completeness, and eﬃcacy of such
tesng.
Related control: SI-2.
This document is produced from OSCAL source data
FAMILY: SI PAGE 336NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(3) SECURITY AND PRIVACY FUNCTION VERIFICATION | REPORT VERIFICATION RESULTS
Report the results of security and privacy funcon veriﬁcaon to [Assignment: organizaon-
deﬁned personnel or roles].
Discussion: Organizaonal personnel with potenal interest in the results of the veriﬁcaon
of security and privacy funcons include systems security oﬃcers, senior agency informaon
security oﬃcers, and senior agency oﬃcials for privacy.
Related controls: SI-4, SR-4, SR-5.
Reference: [OMB A-130]
SI-7 SOFTWARE, FIRMWARE, AND INFORMATION INTEGRITY
Control:
a. Employ integrity veriﬁcaon tools to detect unauthorized changes to the following soware,
ﬁrmware, and informaon: [Assignment: organizaon-deﬁned soware, ﬁrmware, and
informaon]; and
b. Take the following acons when unauthorized changes to the soware, ﬁrmware, and
informaon are detected: [Assignment: organizaon-deﬁned acons].
Discussion: Unauthorized changes to soware, ﬁrmware, and informaon can occur due to errors
or malicious acvity. Soware includes operang systems (with key internal components, such as
kernels or drivers), middleware, and applicaons. Firmware interfaces include Uniﬁed Extensible
Firmware Interface (UEFI) and Basic Input/Output System (BIOS). Informaon includes personally
idenﬁable informaon and metadata that contains security and privacy aributes associated with
informaon. Integrity-checking mechanisms—including parity checks, cyclical redundancy checks,
cryptographic hashes, and associated tools—can automacally monitor the integrity of systems and
hosted applicaons.
Related controls: AC-4, CM-3, CM-7, CM-8, MA-3, MA-4, RA-5, SA-8, SA-9, SA-10, SC-8, SC-12, SC-13,
SC-28, SC-37, SI-3, SR-3, SR-4, SR-5, SR-6, SR-9, SR-10, SR-11.
(1) SOFTWARE, FIRMWARE, AND INFORMATION INTEGRITY | INTEGRITY CHECKS
Perform an integrity check of [Assignment: organizaon-deﬁned soware, ﬁrmware, and
informaon] [Selecon (one or more): at startup; at [Assignment: organizaon-deﬁned
transional states or security-relevant events]; [Assignment: organizaon-deﬁned frequency]].
Discussion: Security-relevant events include the idenﬁcaon of new threats to which
organizaonal systems are suscepble and the installaon of new hardware, soware, or
ﬁrmware. Transional states include system startup, restart, shutdown, and abort.
(2) SOFTWARE, FIRMWARE, AND INFORMATION INTEGRITY | AUTOMATED NOTIFICATIONS
OF INTEGRITY VIOLATIONS
Employ automated tools that provide noﬁcaon to [Assignment: organizaon-deﬁned
personnel or roles] upon discovering discrepancies during integrity veriﬁcaon.
Discussion: The employment of automated tools to report system and informaon integrity
violaons and to nofy organizaonal personnel in a mely maer is essenal to eﬀecve risk
response. Personnel with an interest in system and informaon integrity violaons include
mission and business owners, system owners, senior agency informaon security oﬃcial, senior
This document is produced from OSCAL source data
FAMILY: SI PAGE 337NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
agency oﬃcial for privacy, system administrators, soware developers, systems integrators,
informaon security oﬃcers, and privacy oﬃcers.
(3) SOFTWARE, FIRMWARE, AND INFORMATION INTEGRITY | CENTRALLY MANAGED
INTEGRITY TOOLS
Employ centrally managed integrity veriﬁcaon tools.
Discussion: Centrally managed integrity veriﬁcaon tools provides greater consistency in the
applicaon of such tools and can facilitate more comprehensive coverage of integrity veriﬁcaon
acons.
Related controls: AU-3, SI-2, SI-8.
(4) SOFTWARE, FIRMWARE, AND INFORMATION INTEGRITY | TAMPER-EVIDENT
PACKAGING
[Withdrawn: Incorporated into SR-9.]
(5) SOFTWARE, FIRMWARE, AND INFORMATION INTEGRITY | AUTOMATED RESPONSE TO
INTEGRITY VIOLATIONS
Automacally [Selecon (one or more): shut the system down; restart the system; implement
[Assignment: organizaon-deﬁned controls]] when integrity violaons are discovered.
Discussion: Organizaons may deﬁne diﬀerent integrity-checking responses by type of
informaon, speciﬁc informaon, or a combinaon of both. Types of informaon include
ﬁrmware, soware, and user data. Speciﬁc informaon includes boot ﬁrmware for certain
types of machines. The automac implementaon of controls within organizaonal systems
includes reversing the changes, halng the system, or triggering audit alerts when unauthorized
modiﬁcaons to crical security ﬁles occur.
(6) SOFTWARE, FIRMWARE, AND INFORMATION INTEGRITY | CRYPTOGRAPHIC
PROTECTION
Implement cryptographic mechanisms to detect unauthorized changes to soware, ﬁrmware,
and informaon.
Discussion: Cryptographic mechanisms used to protect integrity include digital signatures and the
computaon and applicaon of signed hashes using asymmetric cryptography, protecng the
conﬁdenality of the key used to generate the hash, and using the public key to verify the hash
informaon. Organizaons that employ cryptographic mechanisms also consider cryptographic
key management soluons.
Related controls: SC-12, SC-13.
(7) SOFTWARE, FIRMWARE, AND INFORMATION INTEGRITY | INTEGRATION OF DETECTION
AND RESPONSE
Incorporate the detecon of the following unauthorized changes into the organizaonal
incident response capability: [Assignment: organizaon-deﬁned security-relevant changes to
the system].
Discussion: Integrang detecon and response helps to ensure that detected events are tracked,
monitored, corrected, and available for historical purposes. Maintaining historical records
is important for being able to idenfy and discern adversary acons over an extended me
This document is produced from OSCAL source data
FAMILY: SI PAGE 338NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
period and for possible legal acons. Security-relevant changes include unauthorized changes to
established conﬁguraon sengs or the unauthorized elevaon of system privileges.
Related controls: AU-2, AU-6, IR-4, IR-5, SI-4.
(8) SOFTWARE, FIRMWARE, AND INFORMATION INTEGRITY | AUDITING CAPABILITY FOR
SIGNIFICANT EVENTS
Upon detecon of a potenal integrity violaon, provide the capability to audit the event and
iniate the following acons: [Selecon (one or more): generate an audit record; alert current
user; alert [Assignment: organizaon-deﬁned personnel or roles]; [Assignment: organizaon-
deﬁned other acons]].
Discussion: Organizaons select response acons based on types of soware, speciﬁc soware,
or informaon for which there are potenal integrity violaons.
Related controls: AU-2, AU-6, AU-12.
(9) SOFTWARE, FIRMWARE, AND INFORMATION INTEGRITY | VERIFY BOOT PROCESS
Verify the integrity of the boot process of the following system components: [Assignment:
organizaon-deﬁned system components].
Discussion: Ensuring the integrity of boot processes is crical to starng system components in
known, trustworthy states. Integrity veriﬁcaon mechanisms provide a level of assurance that
only trusted code is executed during boot processes.
Related control: SI-6.
(10) SOFTWARE, FIRMWARE, AND INFORMATION INTEGRITY | PROTECTION OF BOOT
FIRMWARE
Implement the following mechanisms to protect the integrity of boot ﬁrmware in
[Assignment: organizaon-deﬁned system components]: [Assignment: organizaon-deﬁned
mechanisms].
Discussion: Unauthorized modiﬁcaons to boot ﬁrmware may indicate a sophiscated, targeted
aack. These types of targeted aacks can result in a permanent denial of service or a persistent
malicious code presence. These situaons can occur if the ﬁrmware is corrupted or if the
malicious code is embedded within the ﬁrmware. System components can protect the integrity
of boot ﬁrmware in organizaonal systems by verifying the integrity and authencity of all
updates to the ﬁrmware prior to applying changes to the system component and prevenng
unauthorized processes from modifying the boot ﬁrmware.
Related control: SI-6.
(11) SOFTWARE, FIRMWARE, AND INFORMATION INTEGRITY | CONFINED ENVIRONMENTS
WITH LIMITED PRIVILEGES
[Withdrawn: Incorporated into CM-7(6).]
(12) SOFTWARE, FIRMWARE, AND INFORMATION INTEGRITY | INTEGRITY VERIFICATION
Require that the integrity of the following user-installed soware be veriﬁed prior to
execuon: [Assignment: organizaon-deﬁned user-installed soware].
Discussion: Organizaons verify the integrity of user-installed soware prior to execuon
to reduce the likelihood of execung malicious code or programs that contains errors from
This document is produced from OSCAL source data
FAMILY: SI PAGE 339NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
unauthorized modiﬁcaons. Organizaons consider the praccality of approaches to verifying
soware integrity, including the availability of trustworthy checksums from soware developers
and vendors.
Related control: CM-11.
(13) SOFTWARE, FIRMWARE, AND INFORMATION INTEGRITY | CODE EXECUTION IN
PROTECTED ENVIRONMENTS
[Withdrawn: Incorporated into CM-7(7).]
(14) SOFTWARE, FIRMWARE, AND INFORMATION INTEGRITY | BINARY OR MACHINE
EXECUTABLE CODE
[Withdrawn: Incorporated into CM-7(8).]
(15) SOFTWARE, FIRMWARE, AND INFORMATION INTEGRITY | CODE AUTHENTICATION
Implement cryptographic mechanisms to authencate the following soware or ﬁrmware
components prior to installaon: [Assignment: organizaon-deﬁned soware or ﬁrmware
components].
Discussion: Cryptographic authencaon includes verifying that soware or ﬁrmware
components have been digitally signed using cerﬁcates recognized and approved by
organizaons. Code signing is an eﬀecve method to protect against malicious code.
Organizaons that employ cryptographic mechanisms also consider cryptographic key
management soluons.
Related controls: CM-5, SC-12, SC-13.
(16) SOFTWARE, FIRMWARE, AND INFORMATION INTEGRITY | TIME LIMIT ON PROCESS
EXECUTION WITHOUT SUPERVISION
Prohibit processes from execung without supervision for more than [Assignment:
organizaon-deﬁned me period].
Discussion: Placing a me limit on process execuon without supervision is intended to apply
to processes for which typical or normal execuon periods can be determined and situaons
in which organizaons exceed such periods. Supervision includes mers on operang systems,
automated responses, and manual oversight and response when system process anomalies
occur.
(17) SOFTWARE, FIRMWARE, AND INFORMATION INTEGRITY | RUNTIME APPLICATION SELF-
PROTECTION
Implement [Assignment: organizaon-deﬁned controls] for applicaon self-protecon at
runme.
Discussion: Runme applicaon self-protecon employs runme instrumentaon to detect
and block the exploitaon of soware vulnerabilies by taking advantage of informaon from
the soware in execuon. Runme exploit prevenon diﬀers from tradional perimeter-
based protecons such as guards and ﬁrewalls which can only detect and block aacks by
using network informaon without contextual awareness. Runme applicaon self-protecon
technology can reduce the suscepbility of soware to aacks by monitoring its inputs and
blocking those inputs that could allow aacks. It can also help protect the runme environment
This document is produced from OSCAL source data
FAMILY: SI PAGE 340NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
from unwanted changes and tampering. When a threat is detected, runme applicaon self-
protecon technology can prevent exploitaon and take other acons (e.g., sending a warning
message to the user, terminang the user's session, terminang the applicaon, or sending an
alert to organizaonal personnel). Runme applicaon self-protecon soluons can be deployed
in either a monitor or protecon mode.
Related control: SI-16.
References: [FIPS 140-3], [FIPS 180-4], [FIPS 186-4], [FIPS 202], [OMB A-130], [SP 800-147], [SP 800-70]
SI-8 SPAM PROTECTION
Control:
a. Employ spam protecon mechanisms at system entry and exit points to detect and act on
unsolicited messages; and
b. Update spam protecon mechanisms when new releases are available in accordance with
organizaonal conﬁguraon management policy and procedures.
Discussion: System entry and exit points include ﬁrewalls, remote-access servers, electronic mail
servers, web servers, proxy servers, workstaons, notebook computers, and mobile devices. Spam
can be transported by diﬀerent means, including email, email aachments, and web accesses. Spam
protecon mechanisms include signature deﬁnions.
Related controls: PL-9, SC-5, SC-7, SC-38, SI-3, SI-4.
(1) SPAM PROTECTION | CENTRAL MANAGEMENT
[Withdrawn: Incorporated into PL-9.]
(2) SPAM PROTECTION | AUTOMATIC UPDATES
Automacally update spam protecon mechanisms [Assignment: organizaon-deﬁned
frequency].
Discussion: Using automated mechanisms to update spam protecon mechanisms helps to
ensure that updates occur on a regular basis and provide the latest content and protecon
capabilies.
(3) SPAM PROTECTION | CONTINUOUS LEARNING CAPABILITY
Implement spam protecon mechanisms with a learning capability to more eﬀecvely idenfy
legimate communicaons traﬃc.
Discussion: Learning mechanisms include Bayesian ﬁlters that respond to user inputs that idenfy
speciﬁc traﬃc as spam or legimate by updang algorithm parameters and thereby more
accurately separang types of traﬃc.
References: [SP 800-177], [SP 800-45]
SI-9 Informaon Input Restricons
[Withdrawn: Incorporated into AC-2, AC-3, AC-5, AC-6.]
This document is produced from OSCAL source data
FAMILY: SI PAGE 341NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
SI-10 INFORMATION INPUT VALIDATION
Control: Check the validity of the following informaon inputs: [Assignment: organizaon-deﬁned
informaon inputs to the system].
Discussion: Checking the valid syntax and semancs of system inputs—including character set,
length, numerical range, and acceptable values—veriﬁes that inputs match speciﬁed deﬁnions
for format and content. For example, if the organizaon speciﬁes that numerical values between
1-100 are the only acceptable inputs for a ﬁeld in a given applicaon, inputs of 387, abc, or %K% are
invalid inputs and are not accepted as input to the system. Valid inputs are likely to vary from ﬁeld
to ﬁeld within a soware applicaon. Applicaons typically follow well-deﬁned protocols that use
structured messages (i.e., commands or queries) to communicate between soware modules or
system components. Structured messages can contain raw or unstructured data interspersed with
metadata or control informaon. If soware applicaons use aacker-supplied inputs to construct
structured messages without properly encoding such messages, then the aacker could insert
malicious commands or special characters that can cause the data to be interpreted as control
informaon or metadata. Consequently, the module or component that receives the corrupted output
will perform the wrong operaons or otherwise interpret the data incorrectly. Prescreening inputs
prior to passing them to interpreters prevents the content from being unintenonally interpreted as
commands. Input validaon ensures accurate and correct inputs and prevents aacks such as cross-
site scripng and a variety of injecon aacks.
(1) INFORMATION INPUT VALIDATION | MANUAL OVERRIDE CAPABILITY
(a) Provide a manual override capability for input validaon of the following informaon
inputs: [Assignment: organizaon-deﬁned inputs deﬁned in the base control (SI-10)];
(b) Restrict the use of the manual override capability to only [Assignment: organizaon-
deﬁned authorized individuals]; and
(c) Audit the use of the manual override capability.
Discussion: In certain situaons, such as during events that are deﬁned in conngency plans, a
manual override capability for input validaon may be needed. Manual overrides are used only
in limited circumstances and with the inputs deﬁned by the organizaon.
Related controls: AC-3, AU-2, AU-12.
(2) INFORMATION INPUT VALIDATION | REVIEW AND RESOLVE ERRORS
Review and resolve input validaon errors within [Assignment: organizaon-deﬁned me
period].
Discussion: Resoluon of input validaon errors includes correcng systemic causes of errors and
resubming transacons with corrected input. Input validaon errors are those related to the
informaon inputs deﬁned by the organizaon in the base control (SI-10).
(3) INFORMATION INPUT VALIDATION | PREDICTABLE BEHAVIOR
Verify that the system behaves in a predictable and documented manner when invalid inputs
are received.
Discussion: A common vulnerability in organizaonal systems is unpredictable behavior when
invalid inputs are received. Veriﬁcaon of system predictability helps ensure that the system
behaves as expected when invalid inputs are received. This occurs by specifying system
This document is produced from OSCAL source data
FAMILY: SI PAGE 342NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
responses that allow the system to transion to known states without adverse, unintended side
eﬀects. The invalid inputs are those related to the informaon inputs deﬁned by the organizaon
in the base control (SI-10).
(4) INFORMATION INPUT VALIDATION | TIMING INTERACTIONS
Account for ming interacons among system components in determining appropriate
responses for invalid inputs.
Discussion: In addressing invalid system inputs received across protocol interfaces, ming
interacons become relevant, where one protocol needs to consider the impact of the error
response on other protocols in the protocol stack. For example, 802.11 standard wireless
network protocols do not interact well with Transmission Control Protocols (TCP) when packets
are dropped (which could be due to invalid packet input). TCP assumes packet losses are
due to congeson, while packets lost over 802.11 links are typically dropped due to noise or
collisions on the link. If TCP makes a congeson response, it takes the wrong acon in response
to a collision event. Adversaries may be able to use what appear to be acceptable individual
behaviors of the protocols in concert to achieve adverse eﬀects through suitable construcon
of invalid input. The invalid inputs are those related to the informaon inputs deﬁned by the
organizaon in the base control (SI-10).
(5) INFORMATION INPUT VALIDATION | RESTRICT INPUTS TO TRUSTED SOURCES AND
APPROVED FORMATS
Restrict the use of informaon inputs to [Assignment: organizaon-deﬁned trusted sources]
and/or [Assignment: organizaon-deﬁned formats].
Discussion: Restricng the use of inputs to trusted sources and in trusted formats applies the
concept of authorized or permied soware to informaon inputs. Specifying known trusted
sources for informaon inputs and acceptable formats for such inputs can reduce the probability
of malicious acvity. The informaon inputs are those deﬁned by the organizaon in the base
control (SI-10).
Related controls: AC-3, AC-6.
(6) INFORMATION INPUT VALIDATION | INJECTION PREVENTION
Prevent untrusted data injecons.
Discussion: Untrusted data injecons may be prevented using a parameterized interface or
output escaping (output encoding). Parameterized interfaces separate data from code so that
injecons of malicious or unintended data cannot change the semancs of commands being
sent. Output escaping uses speciﬁed characters to inform the interpreter’s parser whether data
is trusted. Prevenon of untrusted data injecons are with respect to the informaon inputs
deﬁned by the organizaon in the base control (SI-10).
Related controls: AC-3, AC-6.
Reference: [OMB A-130]
SI-11 ERROR HANDLING
Control:
a. Generate error messages that provide informaon necessary for correcve acons without
revealing informaon that could be exploited; and
This document is produced from OSCAL source data
FAMILY: SI PAGE 343NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
b. Reveal error messages only to [Assignment: organizaon-deﬁned personnel or roles].
Discussion: Organizaons consider the structure and content of error messages. The extent to which
systems can handle error condions is guided and informed by organizaonal policy and operaonal
requirements. Exploitable informaon includes stack traces and implementaon details; erroneous
logon aempts with passwords mistakenly entered as the username; mission or business informaon
that can be derived from, if not stated explicitly by, the informaon recorded; and personally
idenﬁable informaon, such as account numbers, social security numbers, and credit card numbers.
Error messages may also provide a covert channel for transming informaon.
Related controls: AU-2, AU-3, SC-31, SI-2, SI-15.
References: None
SI-12 INFORMATION MANAGEMENT AND RETENTION
Control: Manage and retain informaon within the system and informaon output from the system
in accordance with applicable laws, execuve orders, direcves, regulaons, policies, standards,
guidelines and operaonal requirements.
Discussion: Informaon management and retenon requirements cover the full life cycle of
informaon, in some cases extending beyond system disposal. Informaon to be retained may also
include policies, procedures, plans, reports, data output from control implementaon, and other
types of administrave informaon. The Naonal Archives and Records Administraon (NARA)
provides federal policy and guidance on records retenon and schedules. If organizaons have a
records management oﬃce, consider coordinang with records management personnel. Records
produced from the output of implemented controls that may require management and retenon
include, but are not limited to: All XX-1, AC-6(9), AT-4, AU-12, CA-2, CA-3, CA-5, CA-6, CA-7, CA-8,
CA-9, CM-2, CM-3, CM-4, CM-6, CM-8, CM-9, CM-12, CM-13, CP-2, IR-6, IR-8, MA-2, MA-4, PE-2, PE-8,
PE-16, PE-17, PL-2, PL-4, PL-7, PL-8, PM-5, PM-8, PM-9, PM-18, PM-21, PM-27, PM-28, PM-30, PM-31,
PS-2, PS-6, PS-7, PT-2, PT-3, PT-7, RA-2, RA-3, RA-5, RA-8, SA-4, SA-5, SA-8, SA-10, SI-4, SR-2, SR-4, SR-8.
Related controls: AC-16, AU-5, AU-11, CA-2, CA-3, CA-5, CA-6, CA-7, CA-9, CM-5, CM-9, CP-2, IR-8, MP-2,
MP-3, MP-4, MP-6, PL-2, PL-4, PM-4, PM-8, PM-9, PS-2, PS-6, PT-2, PT-3, RA-2, RA-3, SA-5, SA-8, SR-2.
(1) INFORMATION MANAGEMENT AND RETENTION | LIMIT PERSONALLY IDENTIFIABLE
INFORMATION ELEMENTS
Limit personally idenﬁable informaon being processed in the informaon life cycle to the
following elements of personally idenﬁable informaon: [Assignment: organizaon-deﬁned
elements of personally idenﬁable informaon].
Discussion: Liming the use of personally idenﬁable informaon throughout the informaon
life cycle when the informaon is not needed for operaonal purposes helps to reduce the level
of privacy risk created by a system. The informaon life cycle includes informaon creaon,
collecon, use, processing, storage, maintenance, disseminaon, disclosure, and disposion.
Risk assessments as well as applicable laws, regulaons, and policies can provide useful inputs to
determining which elements of personally idenﬁable informaon may create risk.
Related control: PM-25.
This document is produced from OSCAL source data
FAMILY: SI PAGE 344NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(2) INFORMATION MANAGEMENT AND RETENTION | MINIMIZE PERSONALLY IDENTIFIABLE
INFORMATION IN TESTING, TRAINING, AND RESEARCH
Use the following techniques to minimize the use of personally idenﬁable informaon for
research, tesng, or training: [Assignment: organizaon-deﬁned techniques].
Discussion: Organizaons can minimize the risk to an individual’s privacy by employing techniques
such as de-idenﬁcaon or synthec data. Liming the use of personally idenﬁable informaon
throughout the informaon life cycle when the informaon is not needed for research, tesng,
or training helps reduce the level of privacy risk created by a system. Risk assessments as
well as applicable laws, regulaons, and policies can provide useful inputs to determining the
techniques to use and when to use them.
Related controls: PM-22, PM-25, SI-19.
(3) INFORMATION MANAGEMENT AND RETENTION | INFORMATION DISPOSAL
Use the following techniques to dispose of, destroy, or erase informaon following the
retenon period: [Assignment: organizaon-deﬁned techniques].
Discussion: Organizaons can minimize both security and privacy risks by disposing of informaon
when it is no longer needed. The disposal or destrucon of informaon applies to originals
as well as copies and archived records, including system logs that may contain personally
idenﬁable informaon.
References: [OMB A-130], [USC 2901]
SI-13 PREDICTABLE FAILURE PREVENTION
Control:
a. Determine mean me to failure (MTTF) for the following system components in speciﬁc
environments of operaon: [Assignment: organizaon-deﬁned system components]; and
b. Provide substute system components and a means to exchange acve and standby components
in accordance with the following criteria: [Assignment: organizaon-deﬁned MTTF substuon
criteria].
Discussion: While MTTF is primarily a reliability issue, predictable failure prevenon is intended to
address potenal failures of system components that provide security capabilies. Failure rates
reﬂect installaon-speciﬁc consideraon rather than the industry-average. Organizaons deﬁne the
criteria for the substuon of system components based on the MTTF value with consideraon for
the potenal harm from component failures. The transfer of responsibilies between acve and
standby components does not compromise safety, operaonal readiness, or security capabilies.
The preservaon of system state variables is also crical to help ensure a successful transfer process.
Standby components remain available at all mes except for maintenance issues or recovery failures
in progress.
Related controls: CP-2, CP-10, CP-13, MA-2, MA-6, SA-8, SC-6.
This document is produced from OSCAL source data
FAMILY: SI PAGE 345NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(1) PREDICTABLE FAILURE PREVENTION | TRANSFERRING COMPONENT RESPONSIBILITIES
Take system components out of service by transferring component responsibilies to
substute components no later than [Assignment: organizaon-deﬁned fracon or
percentage] of mean me to failure.
Discussion: Transferring primary system component responsibilies to other substute
components prior to primary component failure is important to reduce the risk of degraded
or debilitated mission or business funcons. Making such transfers based on a percentage of
mean me to failure allows organizaons to be proacve based on their risk tolerance. However,
the premature replacement of system components can result in the increased cost of system
operaons.
(2) PREDICTABLE FAILURE PREVENTION | TIME LIMIT ON PROCESS EXECUTION WITHOUT
SUPERVISION
[Withdrawn: Incorporated into SI-7(16).]
(3) PREDICTABLE FAILURE PREVENTION | MANUAL TRANSFER BETWEEN COMPONENTS
Manually iniate transfers between acve and standby system components when the use of
the acve component reaches [Assignment: organizaon-deﬁned percentage] of the mean
me to failure.
Discussion: For example, if the MTTF for a system component is 100 days and the MTTF
percentage deﬁned by the organizaon is 90 percent, the manual transfer would occur aer 90
days.
(4) PREDICTABLE FAILURE PREVENTION | STANDBY COMPONENT INSTALLATION AND
NOTIFICATION
If system component failures are detected:
(a) Ensure that the standby components are successfully and transparently installed within
[Assignment: organizaon-deﬁned me period]; and
(b) [Selecon (one or more): Acvate [Assignment: organizaon-deﬁned alarm];
Automacally shut down the system; [Assignment: organizaon-deﬁned acon]].
Discussion: Automac or manual transfer of components from standby to acve mode can occur
upon the detecon of component failures.
(5) PREDICTABLE FAILURE PREVENTION | FAILOVER CAPABILITY
Provide [Selecon: real-me; near real-me] [Assignment: organizaon-deﬁned failover
capability] for the system.
Discussion: Failover refers to the automac switchover to an alternate system upon the failure
of the primary system. Failover capability includes incorporang mirrored system operaons at
alternate processing sites or periodic data mirroring at regular intervals deﬁned by the recovery
me periods of organizaons.
Related controls: CP-6, CP-7, CP-9.
References: None
This document is produced from OSCAL source data
FAMILY: SI PAGE 346NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
SI-14 NON-PERSISTENCE
Control: Implement non-persistent [Assignment: organizaon-deﬁned system components and
services] that are iniated in a known state and terminated [Selecon (one or more): upon end of
session of use; periodically at [Assignment: organizaon-deﬁned frequency]].
Discussion: Implementaon of non-persistent components and services migates risk from advanced
persistent threats (APTs) by reducing the targeng capability of adversaries (i.e., window of
opportunity and available aack surface) to iniate and complete aacks. By implemenng the
concept of non-persistence for selected system components, organizaons can provide a trusted,
known state compung resource for a speciﬁc me period that does not give adversaries suﬃcient
me to exploit vulnerabilies in organizaonal systems or operang environments. Since the APT is a
high-end, sophiscated threat with regard to capability, intent, and targeng, organizaons assume
that over an extended period, a percentage of aacks will be successful. Non-persistent system
components and services are acvated as required using protected informaon and terminated
periodically or at the end of sessions. Non-persistence increases the work factor of adversaries
aempng to compromise or breach organizaonal systems.
Non-persistence can be achieved by refreshing system components, periodically reimaging
components, or using a variety of common virtualizaon techniques. Non-persistent services can be
implemented by using virtualizaon techniques as part of virtual machines or as new instances of
processes on physical machines (either persistent or non-persistent). The beneﬁt of periodic refreshes
of system components and services is that it does not require organizaons to ﬁrst determine
whether compromises of components or services have occurred (something that may oen be
diﬃcult to determine). The refresh of selected system components and services occurs with suﬃcient
frequency to prevent the spread or intended impact of aacks, but not with such frequency that it
makes the system unstable. Refreshes of crical components and services may be done periodically to
hinder the ability of adversaries to exploit opmum windows of vulnerabilies.
Related controls: SC-30, SC-34, SI-21.
(1) NON-PERSISTENCE | REFRESH FROM TRUSTED SOURCES
Obtain soware and data employed during system component and service refreshes from the
following trusted sources: [Assignment: organizaon-deﬁned trusted sources].
Discussion: Trusted sources include soware and data from write-once, read-only media or from
selected oﬄine secure storage facilies.
(2) NON-PERSISTENCE | NON-PERSISTENT INFORMATION
(a) [Selecon: Refresh [Assignment: organizaon-deﬁned informaon][Assignment:
organizaon-deﬁned frequency]; Generate [Assignment: organizaon-deﬁned
informaon] on demand]; and
(b) Delete informaon when no longer needed.
Discussion: Retaining informaon longer than is needed makes the informaon a potenal
target for advanced adversaries searching for high value assets to compromise through
unauthorized disclosure, unauthorized modiﬁcaon, or exﬁltraon. For system-related
informaon, unnecessary retenon provides advanced adversaries informaon that can assist in
their reconnaissance and lateral movement through the system.
This document is produced from OSCAL source data
FAMILY: SI PAGE 347NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(3) NON-PERSISTENCE | NON-PERSISTENT CONNECTIVITY
Establish connecons to the system on demand and terminate connecons aer [Selecon:
compleon of a request; a period of non-use].
Discussion: Persistent connecons to systems can provide advanced adversaries with paths to
move laterally through systems and potenally posion themselves closer to high value assets.
Liming the availability of such connecons impedes the adversary’s ability to move freely
through organizaonal systems.
Related control: SC-10.
References: None
SI-15 INFORMATION OUTPUT FILTERING
Control: Validate informaon output from the following soware programs and/or applicaons to
ensure that the informaon is consistent with the expected content: [Assignment: organizaon-
deﬁned soware programs and/or applicaons].
Discussion: Certain types of aacks, including SQL injecons, produce output results that are
unexpected or inconsistent with the output results that would be expected from soware programs
or applicaons. Informaon output ﬁltering focuses on detecng extraneous content, prevenng such
extraneous content from being displayed, and then alerng monitoring tools that anomalous behavior
has been discovered.
Related controls: SI-3, SI-4, SI-11.
References: None
SI-16 MEMORY PROTECTION
Control: Implement the following controls to protect the system memory from unauthorized code
execuon: [Assignment: organizaon-deﬁned controls].
Discussion: Some adversaries launch aacks with the intent of execung code in non-executable
regions of memory or in memory locaons that are prohibited. Controls employed to protect
memory include data execuon prevenon and address space layout randomizaon. Data execuon
prevenon controls can either be hardware-enforced or soware-enforced with hardware
enforcement providing the greater strength of mechanism.
Related controls: AC-25, SC-3, SI-7.
References: None
SI-17 FAIL-SAFE PROCEDURES
Control: Implement the indicated fail-safe procedures when the indicated failures occur: [Assignment:
organizaon-deﬁned list of failure condions and associated fail-safe procedures].
Discussion: Failure condions include the loss of communicaons among crical system components or
between system components and operaonal facilies. Fail-safe procedures include alerng operator
personnel and providing speciﬁc instrucons on subsequent steps to take. Subsequent steps may
include doing nothing, reestablishing system sengs, shung down processes, restarng the system,
or contacng designated organizaonal personnel.
Related controls: CP-12, CP-13, SC-24, SI-13.
References: None
This document is produced from OSCAL source data
FAMILY: SI PAGE 348NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
SI-18 PERSONALLY IDENTIFIABLE INFORMATION QUALITY OPERATIONS
Control:
a. Check the accuracy, relevance, meliness, and completeness of personally idenﬁable
informaon across the informaon life cycle [Assignment: organizaon-deﬁned frequency]; and
b. Correct or delete inaccurate or outdated personally idenﬁable informaon.
Discussion: Personally idenﬁable informaon quality operaons include the steps that organizaons
take to conﬁrm the accuracy and relevance of personally idenﬁable informaon throughout the
informaon life cycle. The informaon life cycle includes the creaon, collecon, use, processing,
storage, maintenance, disseminaon, disclosure, and disposal of personally idenﬁable informaon.
Personally idenﬁable informaon quality operaons include eding and validang addresses as
they are collected or entered into systems using automated address veriﬁcaon look-up applicaon
programming interfaces. Checking personally idenﬁable informaon quality includes the tracking of
updates or changes to data over me, which enables organizaons to know how and what personally
idenﬁable informaon was changed should erroneous informaon be idenﬁed. The measures
taken to protect personally idenﬁable informaon quality are based on the nature and context of
the personally idenﬁable informaon, how it is to be used, how it was obtained, and the potenal
de-idenﬁcaon methods employed. The measures taken to validate the accuracy of personally
idenﬁable informaon used to make determinaons about the rights, beneﬁts, or privileges of
individuals covered under federal programs may be more comprehensive than the measures used to
validate personally idenﬁable informaon used for less sensive purposes.
Related controls: PM-22, PM-24, PT-2, SI-4.
(1) PERSONALLY IDENTIFIABLE INFORMATION QUALITY OPERATIONS | AUTOMATION
SUPPORT
Correct or delete personally idenﬁable informaon that is inaccurate or outdated, incorrectly
determined regarding impact, or incorrectly de-idenﬁed using [Assignment: organizaon-
deﬁned automated mechanisms].
Discussion: The use of automated mechanisms to improve data quality may inadvertently create
privacy risks. Automated tools may connect to external or otherwise unrelated systems, and the
matching of records between these systems may create linkages with unintended consequences.
Organizaons assess and document these risks in their privacy impact assessments and make
determinaons that are in alignment with their privacy program plans.
As data is obtained and used across the informaon life cycle, it is important to conﬁrm
the accuracy and relevance of personally idenﬁable informaon. Automated mechanisms
can augment exisng data quality processes and procedures and enable an organizaon to
beer idenfy and manage personally idenﬁable informaon in large-scale systems. For
example, automated tools can greatly improve eﬀorts to consistently normalize data or idenfy
malformed data. Automated tools can also be used to improve the auding of data and detect
errors that may incorrectly alter personally idenﬁable informaon or incorrectly associate
such informaon with the wrong individual. Automated capabilies backstop processes and
procedures at-scale and enable more ﬁne-grained detecon and correcon of data quality
errors.
Related controls: PM-18, RA-8.
This document is produced from OSCAL source data
FAMILY: SI PAGE 349NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(2) PERSONALLY IDENTIFIABLE INFORMATION QUALITY OPERATIONS | DATA TAGS
Employ data tags to automate the correcon or deleon of personally idenﬁable informaon
across the informaon life cycle within organizaonal systems.
Discussion: Data tagging personally idenﬁable informaon includes tags that note processing
permissions, authority to process, de-idenﬁcaon, impact level, informaon life cycle stage,
and retenon or last updated dates. Employing data tags for personally idenﬁable informaon
can support the use of automaon tools to correct or delete relevant personally idenﬁable
informaon.
Related controls: AC-3, AC-16, SC-16.
(3) PERSONALLY IDENTIFIABLE INFORMATION QUALITY OPERATIONS | COLLECTION
Collect personally idenﬁable informaon directly from the individual.
Discussion: Individuals or their designated representaves can be sources of correct personally
idenﬁable informaon. Organizaons consider contextual factors that may incenvize
individuals to provide correct data versus false data. Addional steps may be necessary to
validate collected informaon based on the nature and context of the personally idenﬁable
informaon, how it is to be used, and how it was obtained. The measures taken to validate the
accuracy of personally idenﬁable informaon used to make determinaons about the rights,
beneﬁts, or privileges of individuals under federal programs may be more comprehensive than
the measures taken to validate less sensive personally idenﬁable informaon.
(4) PERSONALLY IDENTIFIABLE INFORMATION QUALITY OPERATIONS | INDIVIDUAL
REQUESTS
Correct or delete personally idenﬁable informaon upon request by individuals or their
designated representaves.
Discussion: Inaccurate personally idenﬁable informaon maintained by organizaons may cause
problems for individuals, especially in those business funcons where inaccurate informaon
may result in inappropriate decisions or the denial of beneﬁts and services to individuals. Even
correct informaon, in certain circumstances, can cause problems for individuals that outweigh
the beneﬁts of an organizaon maintaining the informaon. Organizaons use discreon when
determining if personally idenﬁable informaon is to be corrected or deleted based on the
scope of requests, the changes sought, the impact of the changes, and laws, regulaons, and
policies. Organizaonal personnel consult with the senior agency oﬃcial for privacy and legal
counsel regarding appropriate instances of correcon or deleon.
(5) PERSONALLY IDENTIFIABLE INFORMATION QUALITY OPERATIONS | NOTICE OF
CORRECTION OR DELETION
Nofy [Assignment: organizaon-deﬁned recipients of personally idenﬁable informaon] and
individuals that the personally idenﬁable informaon has been corrected or deleted.
Discussion: When personally idenﬁable informaon is corrected or deleted, organizaons take
steps to ensure that all authorized recipients of such informaon, and the individual with whom
the informaon is associated or their designated representaves, are informed of the corrected
or deleted informaon.
References: [IR 8112], [OMB M-19-15], [SP 800-188]
This document is produced from OSCAL source data
FAMILY: SI PAGE 350NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
SI-19 DE-IDENTIFICATION
Control:
a. Remove the following elements of personally idenﬁable informaon from datasets:
[Assignment: organizaon-deﬁned elements of personally idenﬁable informaon]; and
b. Evaluate [Assignment: organizaon-deﬁned frequency] for eﬀecveness of de-idenﬁcaon.
Discussion: De-idenﬁcaon is the general term for the process of removing the associaon between
a set of idenfying data and the data subject. Many datasets contain informaon about individuals
that can be used to disnguish or trace an individual’s identy, such as name, social security number,
date and place of birth, mother’s maiden name, or biometric records. Datasets may also contain
other informaon that is linked or linkable to an individual, such as medical, educaonal, ﬁnancial,
and employment informaon. Personally idenﬁable informaon is removed from datasets by
trained individuals when such informaon is not (or no longer) necessary to sasfy the requirements
envisioned for the data. For example, if the dataset is only used to produce aggregate stascs, the
idenﬁers that are not needed for producing those stascs are removed. Removing idenﬁers
improves privacy protecon since informaon that is removed cannot be inadvertently disclosed or
improperly used. Organizaons may be subject to speciﬁc de-idenﬁcaon deﬁnions or methods
under applicable laws, regulaons, or policies. Re-idenﬁcaon is a residual risk with de-idenﬁed
data. Re-idenﬁcaon aacks can vary, including combining new datasets or other improvements in
data analycs. Maintaining awareness of potenal aacks and evaluang for the eﬀecveness of the
de-idenﬁcaon over me support the management of this residual risk.
Related controls: MP-6, PM-22, PM-23, PM-24, RA-2, SI-12.
(1) DE-IDENTIFICATION | COLLECTION
De-idenfy the dataset upon collecon by not collecng personally idenﬁable informaon.
Discussion: If a data source contains personally idenﬁable informaon but the informaon
will not be used, the dataset can be de-idenﬁed when it is created by not collecng the data
elements that contain the personally idenﬁable informaon. For example, if an organizaon
does not intend to use the social security number of an applicant, then applicaon forms do not
ask for a social security number.
(2) DE-IDENTIFICATION | ARCHIVING
Prohibit archiving of personally idenﬁable informaon elements if those elements in a
dataset will not be needed aer the dataset is archived.
Discussion: Datasets can be archived for many reasons. The envisioned purposes for the archived
dataset are speciﬁed, and if personally idenﬁable informaon elements are not required, the
elements are not archived. For example, social security numbers may have been collected for
record linkage, but the archived dataset may include the required elements from the linked
records. In this case, it is not necessary to archive the social security numbers.
(3) DE-IDENTIFICATION | RELEASE
Remove personally idenﬁable informaon elements from a dataset prior to its release if
those elements in the dataset do not need to be part of the data release.
Discussion: Prior to releasing a dataset, a data custodian considers the intended uses of the
dataset and determines if it is necessary to release personally idenﬁable informaon. If the
This document is produced from OSCAL source data
FAMILY: SI PAGE 351NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
personally idenﬁable informaon is not necessary, the informaon can be removed using de-
idenﬁcaon techniques.
(4) DE-IDENTIFICATION | REMOVAL, MASKING, ENCRYPTION, HASHING, OR REPLACEMENT
OF DIRECT IDENTIFIERS
Remove, mask, encrypt, hash, or replace direct idenﬁers in a dataset.
Discussion: There are many possible processes for removing direct idenﬁers from a dataset.
Columns in a dataset that contain a direct idenﬁer can be removed. In masking, the direct
idenﬁer is transformed into a repeang character, such as XXXXXX or 999999. Idenﬁers can
be encrypted or hashed so that the linked records remain linked. In the case of encrypon
or hashing, algorithms are employed that require the use of a key, including the Advanced
Encrypon Standard or a Hash-based Message Authencaon Code. Implementaons may use
the same key for all idenﬁers or use a diﬀerent key for each idenﬁer. Using a diﬀerent key for
each idenﬁer provides a higher degree of security and privacy. Idenﬁers can alternavely be
replaced with a keyword, including transforming George Washington to PATIENT or replacing it
with a surrogate value, such as transforming George Washington to Abraham Polk.
Related controls: SC-12, SC-13.
(5) DE-IDENTIFICATION | STATISTICAL DISCLOSURE CONTROL
Manipulate numerical data, conngency tables, and stascal ﬁndings so that no individual or
organizaon is idenﬁable in the results of the analysis.
Discussion: Many types of stascal analyses can result in the disclosure of informaon about
individuals even if only summary informaon is provided. For example, if a school that publishes
a monthly table with the number of minority students enrolled, reports that it has 10-19 such
students in January, and subsequently reports that it has 20-29 such students in March, then it
can be inferred that the student who enrolled in February was a minority.
(6) DE-IDENTIFICATION | DIFFERENTIAL PRIVACY
Prevent disclosure of personally idenﬁable informaon by adding non-determinisc noise to
the results of mathemacal operaons before the results are reported.
Discussion: The mathemacal deﬁnion for diﬀerenal privacy holds that the result of a dataset
analysis should be approximately the same before and aer the addion or removal of a single
data record (which is assumed to be the data from a single individual). In its most basic form,
diﬀerenal privacy applies only to online query systems. However, it can also be used to produce
machine-learning stascal classiﬁers and synthec data. Diﬀerenal privacy comes at the cost
of decreased accuracy of results, forcing organizaons to quanfy the trade-oﬀ between privacy
protecon and the overall accuracy, usefulness, and ulity of the de-idenﬁed dataset. Non-
determinisc noise can include adding small, random values to the results of mathemacal
operaons in dataset analysis.
Related controls: SC-12, SC-13.
(7) DE-IDENTIFICATION | VALIDATED ALGORITHMS AND SOFTWARE
Perform de-idenﬁcaon using validated algorithms and soware that is validated to
implement the algorithms.
Discussion: Algorithms that appear to remove personally idenﬁable informaon from a dataset
may in fact leave informaon that is personally idenﬁable or data that is re-idenﬁable.
This document is produced from OSCAL source data
FAMILY: SI PAGE 352NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
Soware that is claimed to implement a validated algorithm may contain bugs or implement
a diﬀerent algorithm. Soware may de-idenfy one type of data, such as integers, but not
de-idenfy another type of data, such as ﬂoang point numbers. For these reasons, de-
idenﬁcaon is performed using algorithms and soware that are validated.
(8) DE-IDENTIFICATION | MOTIVATED INTRUDER
Perform a movated intruder test on the de-idenﬁed dataset to determine if the idenﬁed
data remains or if the de-idenﬁed data can be re-idenﬁed.
Discussion: A movated intruder test is a test in which an individual or group takes a data release
and speciﬁed resources and aempts to re-idenfy one or more individuals in the de-idenﬁed
dataset. Such tests specify the amount of inside knowledge, computaonal resources, ﬁnancial
resources, data, and skills that intruders possess to conduct the tests. A movated intruder test
can determine if the de-idenﬁcaon is insuﬃcient. It can also be a useful diagnosc tool to
assess if de-idenﬁcaon is likely to be suﬃcient. However, the test alone cannot prove that de-
idenﬁcaon is suﬃcient.
References: [OMB A-130], [SP 800-188]
SI-20 TAINTING
Control: Embed data or capabilies in the following systems or system components to determine if
organizaonal data has been exﬁltrated or improperly removed from the organizaon: [Assignment:
organizaon-deﬁned systems or system components].
Discussion: Many cyber-aacks target organizaonal informaon, or informaon that the organizaon
holds on behalf of other enes (e.g., personally idenﬁable informaon), and exﬁltrate that data. In
addion, insider aacks and erroneous user procedures can remove informaon from the system that
is in violaon of the organizaonal policies. Tainng approaches can range from passive to acve. A
passive tainng approach can be as simple as adding false email names and addresses to an internal
database. If the organizaon receives email at one of the false email addresses, it knows that the
database has been compromised. Moreover, the organizaon knows that the email was sent by
an unauthorized enty, so any packets it includes potenally contain malicious code, and that the
unauthorized enty may have potenally obtained a copy of the database. Another tainng approach
can include embedding false data or steganographic data in ﬁles to enable the data to be found via
open-source analysis. Finally, an acve tainng approach can include embedding soware in the data
that is able to call home, thereby alerng the organizaon to its capture, and possibly its locaon, and
the path by which it was exﬁltrated or removed.
Related control: AU-13.
References: [OMB A-130], [SP 800-160-2]
SI-21 INFORMATION REFRESH
Control: Refresh [Assignment: organizaon-deﬁned informaon] at [Assignment: organizaon-deﬁned
frequencies] or generate the informaon on demand and delete the informaon when no longer
needed.
Discussion: Retaining informaon for longer than it is needed makes it an increasingly valuable and
encing target for adversaries. Keeping informaon available for the minimum period of me needed
to support organizaonal missions or business funcons reduces the opportunity for adversaries to
compromise, capture, and exﬁltrate that informaon.
Related control: SI-14.
This document is produced from OSCAL source data
FAMILY: SI PAGE 353NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
References: [OMB A-130], [SP 800-160-2]
SI-22 INFORMATION DIVERSITY
Control:
a. Idenfy the following alternave sources of informaon for [Assignment: organizaon-deﬁned
essenal funcons and services]: [Assignment: organizaon-deﬁned alternave informaon
sources]; and
b. Use an alternave informaon source for the execuon of essenal funcons or services on
[Assignment: organizaon-deﬁned systems or system components] when the primary source of
informaon is corrupted or unavailable.
Discussion: Acons taken by a system service or a funcon are oen driven by the informaon it
receives. Corrupon, fabricaon, modiﬁcaon, or deleon of that informaon could impact the ability
of the service funcon to properly carry out its intended acons. By having mulple sources of input,
the service or funcon can connue operaon if one source is corrupted or no longer available. It
is possible that the alternave sources of informaon may be less precise or less accurate than the
primary source of informaon. But having such sub-opmal informaon sources may sll provide a
suﬃcient level of quality that the essenal service or funcon can be carried out, even in a degraded
or debilitated manner.
Reference: [SP 800-160-2]
SI-23 INFORMATION FRAGMENTATION
Control: Based on [Assignment: organizaon-deﬁned circumstances]:
a. Fragment the following informaon: [Assignment: organizaon-deﬁned informaon]; and
b. Distribute the fragmented informaon across the following systems or system components:
[Assignment: organizaon-deﬁned systems or system components].
Discussion: One objecve of the advanced persistent threat is to exﬁltrate valuable informaon. Once
exﬁltrated, there is generally no way for the organizaon to recover the lost informaon. Therefore,
organizaons may consider dividing the informaon into disparate elements and distribung those
elements across mulple systems or system components and locaons. Such acons will increase the
adversary’s work factor to capture and exﬁltrate the desired informaon and, in so doing, increase
the probability of detecon. The fragmentaon of informaon impacts the organizaon’s ability to
access the informaon in a mely manner. The extent of the fragmentaon is dictated by the impact
or classiﬁcaon level (and value) of the informaon, threat intelligence informaon received, and
whether data tainng is used (i.e., data tainng-derived informaon about the exﬁltraon of some
informaon could result in the fragmentaon of the remaining informaon).
Reference: [SP 800-160-2]
This document is produced from OSCAL source data
FAMILY: SI PAGE 354NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
FAMILY: SUPPLY CHAIN RISK MANAGEMENT
SR-1 POLICY AND PROCEDURES
Control:
a. Develop, document, and disseminate to [Assignment: organizaon-deﬁned personnel or roles]:
1. [Selecon (one or more): Organizaon-level; Mission/business process-level; System-level]
supply chain risk management policy that:
(a) Addresses purpose, scope, roles, responsibilies, management commitment,
coordinaon among organizaonal enes, and compliance; and
(b) Is consistent with applicable laws, execuve orders, direcves, regulaons, policies,
standards, and guidelines; and
2. Procedures to facilitate the implementaon of the supply chain risk management policy and
the associated supply chain risk management controls;
b. Designate an [Assignment: organizaon-deﬁned oﬃcial] to manage the development,
documentaon, and disseminaon of the supply chain risk management policy and procedures;
and
c. Review and update the current supply chain risk management:
1. Policy [Assignment: organizaon-deﬁned frequency] and following [Assignment:
organizaon-deﬁned events]; and
2. Procedures [Assignment: organizaon-deﬁned frequency] and following [Assignment:
organizaon-deﬁned events].
Discussion: Supply chain risk management policy and procedures address the controls in the SR family
as well as supply chain-related controls in other families that are implemented within systems and
organizaons. The risk management strategy is an important factor in establishing such policies
and procedures. Policies and procedures contribute to security and privacy assurance. Therefore,
it is important that security and privacy programs collaborate on the development of supply chain
risk management policy and procedures. Security and privacy program policies and procedures at
the organizaon level are preferable, in general, and may obviate the need for mission- or system-
speciﬁc policies and procedures. The policy can be included as part of the general security and
privacy policy or be represented by mulple policies that reﬂect the complex nature of organizaons.
Procedures can be established for security and privacy programs, for mission or business processes,
and for systems, if needed. Procedures describe how the policies or controls are implemented and
can be directed at the individual or role that is the object of the procedure. Procedures can be
documented in system security and privacy plans or in one or more separate documents. Events
that may precipitate an update to supply chain risk management policy and procedures include
assessment or audit ﬁndings, security incidents or breaches, or changes in applicable laws, execuve
orders, direcves, regulaons, policies, standards, and guidelines. Simply restang controls does not
constute an organizaonal policy or procedure.
Related controls: PM-9, PM-30, PS-8, SI-12.
References: [41 CFR 201], [CNSSD 505], [EO 13873], [FASC18], [SP 800-100], [SP 800-12], [SP 800-161],
[SP 800-30], [SP 800-39]
This document is produced from OSCAL source data
FAMILY: SR PAGE 355NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
SR-2 SUPPLY CHAIN RISK MANAGEMENT PLAN
Control:
a. Develop a plan for managing supply chain risks associated with the research and development,
design, manufacturing, acquision, delivery, integraon, operaons and maintenance, and
disposal of the following systems, system components or system services: [Assignment:
organizaon-deﬁned systems, system components, or system services];
b. Review and update the supply chain risk management plan [Assignment: organizaon-deﬁned
frequency] or as required, to address threat, organizaonal or environmental changes; and
c. Protect the supply chain risk management plan from unauthorized disclosure and modiﬁcaon.
Discussion: The dependence on products, systems, and services from external providers, as well as the
nature of the relaonships with those providers, present an increasing level of risk to an organizaon.
Threat acons that may increase security or privacy risks include unauthorized producon, the
inseron or use of counterfeits, tampering, the, inseron of malicious soware and hardware, and
poor manufacturing and development pracces in the supply chain. Supply chain risks can be endemic
or systemic within a system element or component, a system, an organizaon, a sector, or the Naon.
Managing supply chain risk is a complex, mulfaceted undertaking that requires a coordinated
eﬀort across an organizaon to build trust relaonships and communicate with internal and external
stakeholders. Supply chain risk management (SCRM) acvies include idenfying and assessing risks,
determining appropriate risk response acons, developing SCRM plans to document response acons,
and monitoring performance against plans. The SCRM plan (at the system-level) is implementaon
speciﬁc, providing policy implementaon, requirements, constraints and implicaons. It can either
be stand-alone, or incorporated into system security and privacy plans. The SCRM plan addresses
managing, implementaon, and monitoring of SCRM controls and the development/sustainment of
systems across the SDLC to support mission and business funcons.
Because supply chains can diﬀer signiﬁcantly across and within organizaons, SCRM plans are tailored
to the individual program, organizaonal, and operaonal contexts. Tailored SCRM plans provide the
basis for determining whether a technology, service, system component, or system is ﬁt for purpose,
and as such, the controls need to be tailored accordingly. Tailored SCRM plans help organizaons
focus their resources on the most crical mission and business funcons based on mission and
business requirements and their risk environment. Supply chain risk management plans include
an expression of the supply chain risk tolerance for the organizaon, acceptable supply chain risk
migaon strategies or controls, a process for consistently evaluang and monitoring supply chain
risk, approaches for implemenng and communicang the plan, a descripon of and jusﬁcaon for
supply chain risk migaon measures taken, and associated roles and responsibilies. Finally, supply
chain risk management plans address requirements for developing trustworthy, secure, privacy-
protecve, and resilient system components and systems, including the applicaon of the security
design principles implemented as part of life cycle-based systems security engineering processes (see
SA-8).
Related controls: CA-2, CP-4, IR-4, MA-2, MA-6, PE-16, PL-2, PM-9, PM-30, RA-3, RA-7, SA-8, SI-4.
(1) SUPPLY CHAIN RISK MANAGEMENT PLAN | ESTABLISH SCRM TEAM
Establish a supply chain risk management team consisng of [Assignment: organizaon-
deﬁned personnel, roles, and responsibilies] to lead and support the following SCRM
acvies: [Assignment: organizaon-deﬁned supply chain risk management acvies].
Discussion: To implement supply chain risk management plans, organizaons establish a
coordinated, team-based approach to idenfy and assess supply chain risks and manage
these risks by using programmac and technical migaon techniques. The team approach
This document is produced from OSCAL source data
FAMILY: SR PAGE 356NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
enables organizaons to conduct an analysis of their supply chain, communicate with internal
and external partners or stakeholders, and gain broad consensus regarding the appropriate
resources for SCRM. The SCRM team consists of organizaonal personnel with diverse roles and
responsibilies for leading and supporng SCRM acvies, including risk execuve, informaon
technology, contracng, informaon security, privacy, mission or business, legal, supply chain
and logiscs, acquision, business connuity, and other relevant funcons. Members of the
SCRM team are involved in various aspects of the SDLC and, collecvely, have an awareness of
and provide experse in acquision processes, legal pracces, vulnerabilies, threats, and aack
vectors, as well as an understanding of the technical aspects and dependencies of systems. The
SCRM team can be an extension of the security and privacy risk management processes or be
included as part of an organizaonal risk management team.
References: [41 CFR 201], [CNSSD 505], [EO 13873], [FASC18], [IR 7622], [IR 8272], [SP 800-160-1], [SP
800-161], [SP 800-181], [SP 800-30], [SP 800-39]
SR-3 SUPPLY CHAIN CONTROLS AND PROCESSES
Control:
a. Establish a process or processes to idenfy and address weaknesses or deﬁciencies in the
supply chain elements and processes of [Assignment: organizaon-deﬁned system or system
component] in coordinaon with [Assignment: organizaon-deﬁned supply chain personnel];
b. Employ the following controls to protect against supply chain risks to the system, system
component, or system service and to limit the harm or consequences from supply chain-related
events: [Assignment: organizaon-deﬁned supply chain controls]; and
c. Document the selected and implemented supply chain processes and controls in [Selecon:
security and privacy plans; supply chain risk management plan; [Assignment: organizaon-
deﬁned document]].
Discussion: Supply chain elements include organizaons, enes, or tools employed for the research
and development, design, manufacturing, acquision, delivery, integraon, operaons and
maintenance, and disposal of systems and system components. Supply chain processes include
hardware, soware, and ﬁrmware development processes; shipping and handling procedures;
personnel security and physical security programs; conﬁguraon management tools, techniques,
and measures to maintain provenance; or other programs, processes, or procedures associated with
the development, acquision, maintenance and disposal of systems and system components. Supply
chain elements and processes may be provided by organizaons, system integrators, or external
providers. Weaknesses or deﬁciencies in supply chain elements or processes represent potenal
vulnerabilies that can be exploited by adversaries to cause harm to the organizaon and aﬀect its
ability to carry out its core missions or business funcons. Supply chain personnel are individuals with
roles and responsibilies in the supply chain.
Related controls: CA-2, MA-2, MA-6, PE-3, PE-16, PL-8, PM-30, SA-2, SA-3, SA-4, SA-5, SA-8, SA-9, SA-10,
SA-15, SC-7, SC-29, SC-30, SC-38, SI-7, SR-6, SR-9, SR-11.
(1) SUPPLY CHAIN CONTROLS AND PROCESSES | DIVERSE SUPPLY BASE
Employ a diverse set of sources for the following system components and services:
[Assignment: organizaon-deﬁned system components and services].
Discussion: Diversifying the supply of systems, system components, and services can reduce
the probability that adversaries will successfully idenfy and target the supply chain and can
reduce the impact of a supply chain event or compromise. Idenfying mulple suppliers for
This document is produced from OSCAL source data
FAMILY: SR PAGE 357NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
replacement components can reduce the probability that the replacement component will
become unavailable. Employing a diverse set of developers or logiscs service providers can
reduce the impact of a natural disaster or other supply chain event. Organizaons consider
designing the system to include diverse materials and components.
(2) SUPPLY CHAIN CONTROLS AND PROCESSES | LIMITATION OF HARM
Employ the following controls to limit harm from potenal adversaries idenfying and
targeng the organizaonal supply chain: [Assignment: organizaon-deﬁned controls].
Discussion: Controls that can be implemented to reduce the probability of adversaries
successfully idenfying and targeng the supply chain include avoiding the purchase of custom
or non-standardized conﬁguraons, employing approved vendor lists with standing reputaons
in industry, following pre-agreed maintenance schedules and update and patch delivery
mechanisms, maintaining a conngency plan in case of a supply chain event, using procurement
carve-outs that provide exclusions to commitments or obligaons, using diverse delivery routes,
and minimizing the me between purchase decisions and delivery.
(3) SUPPLY CHAIN CONTROLS AND PROCESSES | SUB-TIER FLOW DOWN
Ensure that the controls included in the contracts of prime contractors are also included in the
contracts of subcontractors.
Discussion: To manage supply chain risk eﬀecvely and holiscally, it is important that
organizaons ensure that supply chain risk management controls are included at all ers in the
supply chain. This includes ensuring that Tier 1 (prime) contractors have implemented processes
to facilitate the ﬂow down of supply chain risk management controls to sub-er contractors. The
controls subject to ﬂow down are idenﬁed in SR-3b.
Related controls: SR-5, SR-8.
References: [41 CFR 201], [EO 13873], [FASC18], [IR 7622], [ISO 20243], [SP 800-161], [SP 800-30]
SR-4 PROVENANCE
Control: Document, monitor, and maintain valid provenance of the following systems, system
components, and associated data: [Assignment: organizaon-deﬁned systems, system components,
and associated data].
Discussion: Every system and system component has a point of origin and may be changed throughout
its existence. Provenance is the chronology of the origin, development, ownership, locaon, and
changes to a system or system component and associated data. It may also include personnel and
processes used to interact with or make modiﬁcaons to the system, component, or associated
data. Organizaons consider developing procedures (see SR-1) for allocang responsibilies for
the creaon, maintenance, and monitoring of provenance for systems and system components;
transferring provenance documentaon and responsibility between organizaons; and prevenng
and monitoring for unauthorized changes to the provenance records. Organizaons have methods
to document, monitor, and maintain valid provenance baselines for systems, system components,
and related data. These acons help track, assess, and document any changes to the provenance,
including changes in supply chain elements or conﬁguraon, and help ensure non-repudiaon
of provenance informaon and the provenance change records. Provenance consideraons are
addressed throughout the system development life cycle and incorporated into contracts and other
arrangements, as appropriate.
Related controls: CM-8, MA-2, MA-6, RA-9, SA-3, SA-8, SI-4.
This document is produced from OSCAL source data
FAMILY: SR PAGE 358NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
(1) PROVENANCE | IDENTITY
Establish and maintain unique idenﬁcaon of the following supply chain elements,
processes, and personnel associated with the idenﬁed system and crical system
components: [Assignment: organizaon-deﬁned supply chain elements, processes, and
personnel associated with organizaon-deﬁned systems and crical system components].
Discussion: Knowing who and what is in the supply chains of organizaons is crical to gaining
visibility into supply chain acvies. Visibility into supply chain acvies is also important
for monitoring and idenfying high-risk events and acvies. Without reasonable visibility
into supply chains elements, processes, and personnel, it is very diﬃcult for organizaons to
understand and manage risk and reduce their suscepbility to adverse events. Supply chain
elements include organizaons, enes, or tools used for the research and development,
design, manufacturing, acquision, delivery, integraon, operaons, maintenance, and disposal
of systems and system components. Supply chain processes include development processes
for hardware, soware, and ﬁrmware; shipping and handling procedures; conﬁguraon
management tools, techniques, and measures to maintain provenance; personnel and physical
security programs; or other programs, processes, or procedures associated with the producon
and distribuon of supply chain elements. Supply chain personnel are individuals with
speciﬁc roles and responsibilies related to the secure the research and development, design,
manufacturing, acquision, delivery, integraon, operaons and maintenance, and disposal of a
system or system component. Idenﬁcaon methods are suﬃcient to support an invesgaon in
case of a supply chain change (e.g. if a supply company is purchased), compromise, or event.
Related controls: IA-2, IA-8, PE-16.
(2) PROVENANCE | TRACK AND TRACE
Establish and maintain unique idenﬁcaon of the following systems and crical system
components for tracking through the supply chain: [Assignment: organizaon-deﬁned systems
and crical system components].
Discussion: Tracking the unique idenﬁcaon of systems and system components during
development and transport acvies provides a foundaonal identy structure for the
establishment and maintenance of provenance. For example, system components may be
labeled using serial numbers or tagged using radio-frequency idenﬁcaon tags. Labels and
tags can help provide beer visibility into the provenance of a system or system component. A
system or system component may have more than one unique idenﬁer. Idenﬁcaon methods
are suﬃcient to support a forensic invesgaon aer a supply chain compromise or event.
Related controls: IA-2, IA-8, PE-16, PL-2.
(3) PROVENANCE | VALIDATE AS GENUINE AND NOT ALTERED
Employ the following controls to validate that the system or system component received is
genuine and has not been altered: [Assignment: organizaon-deﬁned controls].
Discussion: For many systems and system components, especially hardware, there are technical
means to determine if the items are genuine or have been altered, including opcal and
nanotechnology tagging, physically unclonable funcons, side-channel analysis, cryptographic
hash veriﬁcaons or digital signatures, and visible an-tamper labels or sckers. Controls can
also include monitoring for out of speciﬁcaon performance, which can be an indicator of
tampering or counterfeits. Organizaons may leverage supplier and contractor processes for
validang that a system or component is genuine and has not been altered and for replacing a
This document is produced from OSCAL source data
FAMILY: SR PAGE 359NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
suspect system or component. Some indicaons of tampering may be visible and addressable
before accepng delivery, such as inconsistent packaging, broken seals, and incorrect labels.
When a system or system component is suspected of being altered or counterfeit, the supplier,
contractor, or original equipment manufacturer may be able to replace the item or provide a
forensic capability to determine the origin of the counterfeit or altered item. Organizaons can
provide training to personnel on how to idenfy suspicious system or component deliveries.
Related controls: AT-3, SR-9, SR-10, SR-11.
(4) PROVENANCE | SUPPLY CHAIN INTEGRITY — PEDIGREE
Employ [Assignment: organizaon-deﬁned controls] and conduct [Assignment: organizaon-
deﬁned analysis] to ensure the integrity of the system and system components by validang
the internal composion and provenance of crical or mission-essenal technologies,
products, and services.
Discussion: Authoritave informaon regarding the internal composion of system components
and the provenance of technology, products, and services provides a strong basis for trust.
The validaon of the internal composion and provenance of technologies, products, and
services is referred to as the pedigree. For microelectronics, this includes material composion
of components. For soware this includes the composion of open-source and proprietary
code, including the version of the component at a given point in me. Pedigrees increase the
assurance that the claims suppliers assert about the internal composion and provenance of
the products, services, and technologies they provide are valid. The validaon of the internal
composion and provenance can be achieved by various evidenary arfacts or records
that manufacturers and suppliers produce during the research and development, design,
manufacturing, acquision, delivery, integraon, operaons and maintenance, and disposal of
technology, products, and services. Evidenary arfacts include, but are not limited to, soware
idenﬁcaon (SWID) tags, soware component inventory, the manufacturers’ declaraons of
plaorm aributes (e.g., serial numbers, hardware component inventory), and measurements
(e.g., ﬁrmware hashes) that are ghtly bound to the hardware itself.
Related control: RA-3.
References: [41 CFR 201], [EO 13873], [FASC18], [IR 7622], [IR 8112], [IR 8272], [ISO 20243], [ISO
27036], [SP 800-160-1], [SP 800-161]
SR-5 ACQUISITION STRATEGIES, TOOLS, AND METHODS
Control: Employ the following acquision strategies, contract tools, and procurement methods
to protect against, idenfy, and migate supply chain risks: [Assignment: organizaon-deﬁned
acquision strategies, contract tools, and procurement methods].
Discussion: The use of the acquision process provides an important vehicle to protect the supply
chain. There are many useful tools and techniques available, including obscuring the end use of a
system or system component, using blind or ﬁltered buys, requiring tamper-evident packaging, or
using trusted or controlled distribuon. The results from a supply chain risk assessment can guide
and inform the strategies, tools, and methods that are most applicable to the situaon. Tools and
techniques may provide protecons against unauthorized producon, the, tampering, inseron
of counterfeits, inseron of malicious soware or backdoors, and poor development pracces
throughout the system development life cycle. Organizaons also consider providing incenves
for suppliers who implement controls, promote transparency into their processes and security and
privacy pracces, provide contract language that addresses the prohibion of tainted or counterfeit
components, and restrict purchases from untrustworthy suppliers. Organizaons consider providing
training, educaon, and awareness programs for personnel regarding supply chain risk, available
This document is produced from OSCAL source data
FAMILY: SR PAGE 360NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
migaon strategies, and when the programs should be employed. Methods for reviewing and
protecng development plans, documentaon, and evidence are commensurate with the security
and privacy requirements of the organizaon. Contracts may specify documentaon protecon
requirements.
Related controls: AT-3, SA-2, SA-3, SA-4, SA-5, SA-8, SA-9, SA-10, SA-15, SR-6, SR-9, SR-10, SR-11.
(1) ACQUISITION STRATEGIES, TOOLS, AND METHODS | ADEQUATE SUPPLY
Employ the following controls to ensure an adequate supply of [Assignment: organizaon-
deﬁned crical system components]: [Assignment: organizaon-deﬁned controls].
Discussion: Adversaries can aempt to impede organizaonal operaons by disrupng the
supply of crical system components or corrupng supplier operaons. Organizaons may track
systems and component mean me to failure to migate the loss of temporary or permanent
system funcon. Controls to ensure that adequate supplies of crical system components
include the use of mulple suppliers throughout the supply chain for the idenﬁed crical
components, stockpiling spare components to ensure operaon during mission-crical mes,
and the idenﬁcaon of funconally idencal or similar components that may be used, if
necessary.
Related control: RA-9.
(2) ACQUISITION STRATEGIES, TOOLS, AND METHODS | ASSESSMENTS PRIOR TO
SELECTION, ACCEPTANCE, MODIFICATION, OR UPDATE
Assess the system, system component, or system service prior to selecon, acceptance,
modiﬁcaon, or update.
Discussion: Organizaonal personnel or independent, external enes conduct assessments
of systems, components, products, tools, and services to uncover evidence of tampering,
unintenonal and intenonal vulnerabilies, or evidence of non-compliance with supply chain
controls. These include malicious code, malicious processes, defecve soware, backdoors,
and counterfeits. Assessments can include evaluaons; design proposal reviews; visual or
physical inspecon; stac and dynamic analyses; visual, x-ray, or magnec parcle inspecons;
simulaons; white, gray, or black box tesng; fuzz tesng; stress tesng; and penetraon
tesng (see SR-6(1)). Evidence generated during assessments is documented for follow-on
acons by organizaons. The evidence generated during the organizaonal or independent
assessments of supply chain elements may be used to improve supply chain processes and
inform the supply chain risk management process. The evidence can be leveraged in follow-
on assessments. Evidence and other documentaon may be shared in accordance with
organizaonal agreements.
Related controls: CA-8, RA-5, SA-11, SI-7.
References: [41 CFR 201], [EO 13873], [FASC18], [IR 7622], [IR 8272], [ISO 20243], [ISO 27036], [SP
800-161], [SP 800-30]
SR-6 SUPPLIER ASSESSMENTS AND REVIEWS
Control: Assess and review the supply chain-related risks associated with suppliers or contractors and
the system, system component, or system service they provide [Assignment: organizaon-deﬁned
frequency].
Discussion: An assessment and review of supplier risk includes security and supply chain risk
management processes, foreign ownership, control or inﬂuence (FOCI), and the ability of the supplier
This document is produced from OSCAL source data
FAMILY: SR PAGE 361NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
to eﬀecvely assess subordinate second-er and third-er suppliers and contractors. The reviews may
be conducted by the organizaon or by an independent third party. The reviews consider documented
processes, documented controls, all-source intelligence, and publicly available informaon related to
the supplier or contractor. Organizaons can use open-source informaon to monitor for indicaons
of stolen informaon, poor development and quality control pracces, informaon spillage, or
counterfeits. In some cases, it may be appropriate or required to share assessment and review results
with other organizaons in accordance with any applicable rules, policies, or inter-organizaonal
agreements or contracts.
Related controls: SR-3, SR-5.
(1) SUPPLIER ASSESSMENTS AND REVIEWS | TESTING AND ANALYSIS
Employ [Selecon (one or more): organizaonal analysis; independent third-party analysis;
organizaonal tesng; independent third-party tesng] of the following supply chain
elements, processes, and actors associated with the system, system component, or system
service: [Assignment: organizaon-deﬁned supply chain elements, processes, and actors].
Discussion: Relaonships between enes and procedures within the supply chain, including
development and delivery, are considered. Supply chain elements include organizaons,
enes, or tools that are used for the research and development, design, manufacturing,
acquision, delivery, integraon, operaons, maintenance, and disposal of systems, system
components, or system services. Supply chain processes include supply chain risk management
programs; SCRM strategies and implementaon plans; personnel and physical security programs;
hardware, soware, and ﬁrmware development processes; conﬁguraon management tools,
techniques, and measures to maintain provenance; shipping and handling procedures; and
programs, processes, or procedures associated with the producon and distribuon of supply
chain elements. Supply chain actors are individuals with speciﬁc roles and responsibilies in
the supply chain. The evidence generated and collected during analyses and tesng of supply
chain elements, processes, and actors is documented and used to inform organizaonal risk
management acvies and decisions.
Related controls: CA-8, SI-4.
References: [41 CFR 201], [EO 13873], [FASC18], [FIPS 140-3], [FIPS 180-4], [FIPS 186-4], [FIPS 202], [IR
7622], [IR 8272], [ISO 20243], [ISO 27036], [SP 800-161], [SP 800-30]
SR-7 SUPPLY CHAIN OPERATIONS SECURITY
Control: Employ the following Operaons Security (OPSEC) controls to protect supply chain-related
informaon for the system, system component, or system service: [Assignment: organizaon-deﬁned
Operaons Security (OPSEC) controls].
Discussion: Supply chain OPSEC expands the scope of OPSEC to include suppliers and potenal
suppliers. OPSEC is a process that includes idenfying crical informaon, analyzing friendly
acons related to operaons and other acvies to idenfy acons that can be observed by
potenal adversaries, determining indicators that potenal adversaries might obtain that could be
interpreted or pieced together to derive informaon in suﬃcient me to cause harm to organizaons,
implemenng safeguards or countermeasures to eliminate or reduce exploitable vulnerabilies and
risk to an acceptable level, and considering how aggregated informaon may expose users or speciﬁc
uses of the supply chain. Supply chain informaon includes user idenes; uses for systems, system
components, and system services; supplier idenes; security and privacy requirements; system
and component conﬁguraons; supplier processes; design speciﬁcaons; and tesng and evaluaon
results. Supply chain OPSEC may require organizaons to withhold mission or business informaon
This document is produced from OSCAL source data
FAMILY: SR PAGE 362NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
from suppliers and may include the use of intermediaries to hide the end use or users of systems,
system components, or system services.
Related control: SC-38.
References: [EO 13873], [IR 7622], [ISO 27036], [SP 800-161], [SP 800-30]
SR-8 NOTIFICATION AGREEMENTS
Control: Establish agreements and procedures with enes involved in the supply chain for the system,
system component, or system service for the [Selecon (one or more): noﬁcaon of supply chain
compromises; results of assessments or audits; [Assignment: organizaon-deﬁned informaon]].
Discussion: The establishment of agreements and procedures facilitates communicaons among
supply chain enes. Early noﬁcaon of compromises and potenal compromises in the supply
chain that can potenally adversely aﬀect or have adversely aﬀected organizaonal systems or system
components is essenal for organizaons to eﬀecvely respond to such incidents. The results of
assessments or audits may include open-source informaon that contributed to a decision or result
and could be used to help the supply chain enty resolve a concern or improve its processes.
Related controls: IR-4, IR-6, IR-8.
References: [41 CFR 201], [EO 13873], [FASC18], [IR 7622], [ISO 27036], [SP 800-161], [SP 800-30]
SR-9 TAMPER RESISTANCE AND DETECTION
Control: Implement a tamper protecon program for the system, system component, or system
service.
Discussion: An-tamper technologies, tools, and techniques provide a level of protecon for systems,
system components, and services against many threats, including reverse engineering, modiﬁcaon,
and substuon. Strong idenﬁcaon combined with tamper resistance and/or tamper detecon is
essenal to protecng systems and components during distribuon and when in use.
Related controls: PE-3, PM-30, SA-15, SI-4, SI-7, SR-3, SR-4, SR-5, SR-10, SR-11.
(1) TAMPER RESISTANCE AND DETECTION | MULTIPLE STAGES OF SYSTEM DEVELOPMENT
LIFE CYCLE
Employ an-tamper technologies, tools, and techniques throughout the system development
life cycle.
Discussion: The system development life cycle includes research and development, design,
manufacturing, acquision, delivery, integraon, operaons and maintenance, and disposal.
Organizaons use a combinaon of hardware and soware techniques for tamper resistance
and detecon. Organizaons use obfuscaon and self-checking to make reverse engineering and
modiﬁcaons more diﬃcult, me-consuming, and expensive for adversaries. The customizaon
of systems and system components can make substuons easier to detect and therefore limit
damage.
Related control: SA-3.
Reference: [ISO 20243]
SR-10 INSPECTION OF SYSTEMS OR COMPONENTS
Control: Inspect the following systems or system components [Selecon (one or more): at random; at
[Assignment: organizaon-deﬁned frequency], upon [Assignment: organizaon-deﬁned indicaons
This document is produced from OSCAL source data
FAMILY: SR PAGE 363NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
of need for inspecon]] to detect tampering: [Assignment: organizaon-deﬁned systems or system
components].
Discussion: The inspecon of systems or systems components for tamper resistance and detecon
addresses physical and logical tampering and is applied to systems and system components removed
from organizaon-controlled areas. Indicaons of a need for inspecon include changes in packaging,
speciﬁcaons, factory locaon, or enty in which the part is purchased, and when individuals return
from travel to high-risk locaons.
Related controls: AT-3, PM-30, SI-4, SI-7, SR-3, SR-4, SR-5, SR-9, SR-11.
Reference: [ISO 20243]
SR-11 COMPONENT AUTHENTICITY
Control:
a. Develop and implement an-counterfeit policy and procedures that include the means to detect
and prevent counterfeit components from entering the system; and
b. Report counterfeit system components to [Selecon (one or more): source of counterfeit
component; [Assignment: organizaon-deﬁned external reporng organizaons]; [Assignment:
organizaon-deﬁned personnel or roles]].
Discussion: Sources of counterfeit components include manufacturers, developers, vendors, and
contractors. An-counterfeing policies and procedures support tamper resistance and provide a
level of protecon against the introducon of malicious code. External reporng organizaons include
CISA.
Related controls: PE-3, SA-4, SI-7, SR-9, SR-10.
(1) COMPONENT AUTHENTICITY | ANTI-COUNTERFEIT TRAINING
Train [Assignment: organizaon-deﬁned personnel or roles] to detect counterfeit system
components (including hardware, soware, and ﬁrmware).
Discussion: None.
Related control: AT-3.
(2) COMPONENT AUTHENTICITY | CONFIGURATION CONTROL FOR COMPONENT SERVICE
AND REPAIR
Maintain conﬁguraon control over the following system components awaing service
or repair and serviced or repaired components awaing return to service: [Assignment:
organizaon-deﬁned system components].
Discussion: None.
Related controls: CM-3, MA-2, MA-4, SA-10.
(3) COMPONENT AUTHENTICITY | ANTI-COUNTERFEIT SCANNING
Scan for counterfeit system components [Assignment: organizaon-deﬁned frequency].
Discussion: The type of component determines the type of scanning to be conducted (e.g., web
applicaon scanning if the component is a web applicaon).
Related control: RA-5.
Reference: [ISO 20243]
This document is produced from OSCAL source data
FAMILY: SR PAGE 364NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
SR-12 COMPONENT DISPOSAL
Control: Dispose of [Assignment: organizaon-deﬁned data, documentaon, tools, or system
components] using the following techniques and methods: [Assignment: organizaon-deﬁned
techniques and methods].
Discussion: Data, documentaon, tools, or system components can be disposed of at any me
during the system development life cycle (not only in the disposal or rerement phase of the life
cycle). For example, disposal can occur during research and development, design, prototyping, or
operaons/maintenance and include methods such as disk cleaning, removal of cryptographic keys,
paral reuse of components. Opportunies for compromise during disposal aﬀect physical and
logical data, including system documentaon in paper-based or digital ﬁles; shipping and delivery
documentaon; memory scks with soware code; or complete routers or servers that include
permanent media, which contain sensive or proprietary informaon. Addionally, proper disposal of
system components helps to prevent such components from entering the gray market.
Related control: MP-6.
References: None
This document is produced from OSCAL source data
FAMILY: SR PAGE 365NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
References
[32 CFR 2002] Code of Federal Regulaons, Title 32, Controlled Unclassiﬁed Informaon (32 C.F.R.
2002). hps://www.federalregister.gov/documents/2016/09/14/2016-21665/controlled-
unclassiﬁed-informaon.
[41 CFR 201] Federal Acquision Supply Chain Security Act; Rule, 85 Federal Register 54263 (September
1, 2020), pp 54263-54271. hps://www.federalregister.gov/d/2020-18939.
[5 CFR 731] Code of Federal Regulaons, Title 5, Administrave Personnel, Secon 731.106,
Designaon of Public Trust Posions and Invesgave Requirements (5 C.F.R. 731.106).
hps://www.govinfo.gov/content/pkg/CFR-2012-tle5-vol2/pdf/CFR-2012-tle5-vol2-
sec731-106.pdf.
[CMPPA] Computer Matching and Privacy Protecon Act of 1988 (P.L. 100-503), October 1988.
hps://www.govinfo.gov/content/pkg/STATUTE-102/pdf/STATUTE-102-Pg2507.pdf.
[CNSSD 505] Commiee on Naonal Security Systems Direcve No. 505, Supply Chain Risk Management
(SCRM), August 2017. hps://www.cnss.gov/CNSS/issuances/Direcves.cfm.
[CNSSI 1253] Commiee on Naonal Security Systems Instrucon No. 1253, Security Categorizaon and
Control Selecon for Naonal Security Systems, March 2014. hps://www.cnss.gov/CNSS/
issuances/Instrucons.cfm.
[DHS NIPP] Department of Homeland Security, Naonal Infrastructure Protecon Plan (NIPP), 2009.
hps://www.dhs.gov/xlibrary/assets/NIPP_Plan.pdf.
[DHS TIC] Department of Homeland Security, Trusted Internet Connecons (TIC). hps://
www.dhs.gov/trusted-internet-connecons.
[DOD STIG] Defense Informaon Systems Agency, Security Technical Implementaon Guides (STIG).
hps://public.cyber.mil/sgs.
[EGOV] E-Government Act [includes FISMA] (P.L. 107-347), December 2002. hps://
www.congress.gov/107/plaws/publ347/PLAW-107publ347.pdf.
[EO 13526] Execuve Order 13526, Classiﬁed Naonal Security Informaon, December 2009. hps://
www.archives.gov/isoo/policy-documents/cnsi-eo.html.
[EO 13556] Execuve Order 13556, Controlled Unclassiﬁed Informaon, November 2010. hps://
obamawhitehouse.archives.gov/the-press-oﬃce/2010/11/04/execuve-order-13556-
controlled-unclassiﬁed-informaon.
[EO 13587] Execuve Order 13587, Structural Reforms to Improve the Security of Classiﬁed Networks
and the Responsible Sharing and Safeguarding of Classiﬁed Informaon, October
2011. hps://obamawhitehouse.archives.gov/the-press-oﬃce/2011/10/07/execuve-
order-13587-structural-reforms-improve-security-classiﬁed-net.
[EO 13636] Execuve Order 13636, Improving Crical Infrastructure Cybersecurity, February 2013.
hps://obamawhitehouse.archives.gov/the-press-oﬃce/2013/02/12/execuve-order-
improving-crical-infrastructure-cybersecurity.
[EO 13873] Execuve Order 13873, Execuve Order on Securing the Informaon and Communicaons
Technology and Services Supply Chain, May 2019. hps://www.whitehouse.gov/
presidenal-acons/execuve-order-securing-informaon-communicaons-technology-
services-supply-chain.
[EVIDACT] Foundaons for Evidence-Based Policymaking Act of 2018 (P.L. 115-435), January 2019.
hps://www.congress.gov/115/plaws/publ435/PLAW-115publ435.pdf.
This document is produced from OSCAL source data
REFERENCES PAGE 366NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
[FASC18] Secure Technology Act [includes Federal Acquision Supply Chain Security Act] (P.L.
115-390), December 2018. hps://www.congress.gov/bill/115th-congress/senate-
bill/3085.
[FED PKI] General Services Administraon, Federal Public Key Infrastructure. hps://
www.idmanagement.gov/topics/fpki.
[FIPS 140-3] Naonal Instute of Standards and Technology (2019) Security Requirements for
Cryptographic Modules. (U.S. Department of Commerce, Washington, D.C.), Federal
Informaon Processing Standards Publicaon (FIPS) 140-3. hps://doi.org/10.6028/
NIST.FIPS.140-3.
[FIPS 180-4] Naonal Instute of Standards and Technology (2015) Secure Hash Standard (SHS). (U.S.
Department of Commerce, Washington, D.C.), Federal Informaon Processing Standards
Publicaon (FIPS) 180-4. hps://doi.org/10.6028/NIST.FIPS.180-4.
[FIPS 186-4] Naonal Instute of Standards and Technology (2013) Digital Signature Standard (DSS).
(U.S. Department of Commerce, Washington, D.C.), Federal Informaon Processing
Standards Publicaon (FIPS) 186-4. hps://doi.org/10.6028/NIST.FIPS.186-4.
[FIPS 197] Naonal Instute of Standards and Technology (2001) Advanced Encrypon Standard
(AES). (U.S. Department of Commerce, Washington, D.C.), Federal Informaon Processing
Standards Publicaon (FIPS) 197. hps://doi.org/10.6028/NIST.FIPS.197.
[FIPS 199] Naonal Instute of Standards and Technology (2004) Standards for Security
Categorizaon of Federal Informaon and Informaon Systems. (U.S. Department of
Commerce, Washington, D.C.), Federal Informaon Processing Standards Publicaon (FIPS)
199. hps://doi.org/10.6028/NIST.FIPS.199.
[FIPS 200] Naonal Instute of Standards and Technology (2006) Minimum Security Requirements
for Federal Informaon and Informaon Systems. (U.S. Department of Commerce,
Washington, D.C.), Federal Informaon Processing Standards Publicaon (FIPS) 200.
hps://doi.org/10.6028/NIST.FIPS.200.
[FIPS 201-2] Naonal Instute of Standards and Technology (2013) Personal Identy Veriﬁcaon (PIV)
of Federal Employees and Contractors. (U.S. Department of Commerce, Washington,
D.C.), Federal Informaon Processing Standards Publicaon (FIPS) 201-2. hps://
doi.org/10.6028/NIST.FIPS.201-2.
[FIPS 202] Naonal Instute of Standards and Technology (2015) SHA-3 Standard: Permutaon-
Based Hash and Extendable-Output Funcons. (U.S. Department of Commerce,
Washington, D.C.), Federal Informaon Processing Standards Publicaon (FIPS) 202.
hps://doi.org/10.6028/NIST.FIPS.202.
[FISMA] Federal Informaon Security Modernizaon Act (P.L. 113-283), December 2014. hps://
www.congress.gov/113/plaws/publ283/PLAW-113publ283.pdf.
[HSPD 7] Homeland Security Presidenal Direcve 7, Crical Infrastructure Idenﬁcaon,
Priorizaon, and Protecon, December 2003. hps://www.dhs.gov/homeland-security-
presidenal-direcve-7.
[IETF 5905] Internet Engineering Task Force (IETF), Request for Comments: 5905, Network Time
Protocol Version 4: Protocol and Algorithms Speciﬁcaon, June 2010. hps://tools.ie.org/
pdf/rfc5905.pdf.
[IR 7539] Cooper DA, MacGregor WI (2008) Symmetric Key Injecon onto Smart Cards. (Naonal
Instute of Standards and Technology, Gaithersburg, MD), NIST Interagency or Internal
Report (IR) 7539. hps://doi.org/10.6028/NIST.IR.7539.
This document is produced from OSCAL source data
REFERENCES PAGE 367NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
[IR 7559] Singhal A, Gunestas M, Wijesekera D (2010) Forensics Web Services (FWS). (Naonal
Instute of Standards and Technology, Gaithersburg, MD), NIST Interagency or Internal
Report (IR) 7559. hps://doi.org/10.6028/NIST.IR.7559.
[IR 7622] Boyens JM, Paulsen C, Bartol N, Shankles S, Moorthy R (2012) Noonal Supply Chain Risk
Management Pracces for Federal Informaon Systems. (Naonal Instute of Standards
and Technology, Gaithersburg, MD), NIST Interagency or Internal Report (IR) 7622. hps://
doi.org/10.6028/NIST.IR.7622.
[IR 7676] Cooper DA (2010) Maintaining and Using Key History on Personal Identy Veriﬁcaon
(PIV) Cards. (Naonal Instute of Standards and Technology, Gaithersburg, MD), NIST
Interagency or Internal Report (IR) 7676. hps://doi.org/10.6028/NIST.IR.7676.
[IR 7788] Singhal A, Ou X (2011) Security Risk Analysis of Enterprise Networks Using Probabilisc
Aack Graphs. (Naonal Instute of Standards and Technology, Gaithersburg, MD), NIST
Interagency or Internal Report (IR) 7788. hps://doi.org/10.6028/NIST.IR.7788.
[IR 7817] Ferraiolo H (2012) A Credenal Reliability and Revocaon Model for Federated Idenes.
(Naonal Instute of Standards and Technology, Gaithersburg, MD), NIST Interagency or
Internal Report (IR) 7817. hps://doi.org/10.6028/NIST.IR.7817.
[IR 7849] Chandramouli R (2014) A Methodology for Developing Authencaon Assurance Level
Taxonomy for Smart Card-based Identy Veriﬁcaon. (Naonal Instute of Standards and
Technology, Gaithersburg, MD), NIST Interagency or Internal Report (IR) 7849. hps://
doi.org/10.6028/NIST.IR.7849.
[IR 7870] Cooper DA (2012) NIST Test Personal Identy Veriﬁcaon (PIV) Cards. (Naonal Instute
of Standards and Technology, Gaithersburg, MD), NIST Interagency or Internal Report (IR)
7870. hps://doi.org/10.6028/NIST.IR.7870.
[IR 7874] Hu VC, Scarfone KA (2012) Guidelines for Access Control System Evaluaon Metrics.
(Naonal Instute of Standards and Technology, Gaithersburg, MD), NIST Interagency or
Internal Report (IR) 7874. hps://doi.org/10.6028/NIST.IR.7874.
[IR 7956] Chandramouli R, Iorga M, Chokhani S (2013) Cryptographic Key Management Issues
& Challenges in Cloud Services. (Naonal Instute of Standards and Technology,
Gaithersburg, MD), NIST Interagency or Internal Report (IR) 7956. hps://doi.org/10.6028/
NIST.IR.7956.
[IR 7966] Ylonen T, Turner P, Scarfone KA, Souppaya MP (2015) Security of Interacve and
Automated Access Management Using Secure Shell (SSH). (Naonal Instute of Standards
and Technology, Gaithersburg, MD), NIST Interagency or Internal Report (IR) 7966. hps://
doi.org/10.6028/NIST.IR.7966.
[IR 8011-1] Dempsey KL, Eavy P, Moore G (2017) Automaon Support for Security Control
Assessments: Volume 1: Overview. (Naonal Instute of Standards and Technology,
Gaithersburg, MD), NIST Interagency or Internal Report (IR) 8011, Volume 1. hps://
doi.org/10.6028/NIST.IR.8011-1.
[IR 8011-2] Dempsey KL, Eavy P, Moore G (2017) Automaon Support for Security Control
Assessments: Volume 2: Hardware Asset Management. (Naonal Instute of Standards and
Technology, Gaithersburg, MD), NIST Interagency or Internal Report (IR) 8011, Volume 2.
hps://doi.org/10.6028/NIST.IR.8011-2.
[IR 8011-3] Dempsey KL, Eavy P, Goren N, Moore G (2018) Automaon Support for Security Control
Assessments: Volume 3: Soware Asset Management. (Naonal Instute of Standards and
Technology, Gaithersburg, MD), NIST Interagency or Internal Report (IR) 8011, Volume 3.
hps://doi.org/10.6028/NIST.IR.8011-3.
This document is produced from OSCAL source data
REFERENCES PAGE 368NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
[IR 8011-4] Dempsey KL, Takamura E, Eavy P, Moore G (2020) Automaon Support for Security Control
Assessments: Volume 4: Soware Vulnerability Management. (Naonal Instute of
Standards and Technology, Gaithersburg, MD), NIST Interagency or Internal Report (IR)
8011, Volume 4. hps://doi.org/10.6028/NIST.IR.8011-4.
[IR 8023] Dempsey KL, Paulsen C (2015) Risk Management for Replicaon Devices. (Naonal Instute
of Standards and Technology, Gaithersburg, MD), NIST Interagency or Internal Report (IR)
8023. hps://doi.org/10.6028/NIST.IR.8023.
[IR 8040] Greene KK, Kelsey JM, Franklin JM (2016) Measuring the Usability and Security of
Permuted Passwords on Mobile Plaorms. (Naonal Instute of Standards and Technology,
Gaithersburg, MD), NIST Interagency or Internal Report (IR) 8040. hps://doi.org/10.6028/
NIST.IR.8040.
[IR 8062] Brooks S, Garcia M, Leovitz N, Lightman S, Nadeau E (2017) An Introducon to Privacy
Engineering and Risk Management in Federal Systems. (Naonal Instute of Standards
and Technology, Gaithersburg, MD), NIST Interagency or Internal Report (IR) 8062. hps://
doi.org/10.6028/NIST.IR.8062.
[IR 8112] Grassi P, Leovitz N, Nadeau E, Galluzzo R, Dinh, A (2018) Aribute Metadata: A Proposed
Schema for Evaluang Federated Aributes. (Naonal Instute of Standards and
Technology, Gaithersburg, MD), NIST Interagency or Internal Report (IR) 8112. hps://
doi.org/10.6028/NIST.IR.8112.
[IR 8179] Paulsen C, Boyens JM, Bartol N, Winkler K (2018) Cricality Analysis Process Model:
Priorizing Systems and Components. (Naonal Instute of Standards and Technology,
Gaithersburg, MD), NIST Interagency or Internal Report (IR) 8179. hps://doi.org/10.6028/
NIST.IR.8179.
[IR 8272] Paulsen C, Winkler K, Boyens JM, Ng J, Gimbi J (2020) Impact Analysis Tool for
Interdependent Cyber Supply Chain Risks. (Naonal Instute of Standards and Technology,
Gaithersburg, MD), NIST Interagency or Internal Report (IR) 8272. hps://doi.org/10.6028/
NIST.IR.8272.
[ISO 15408-1] Internaonal Organizaon for Standardizaon/Internaonal Electrotechnical
Commission 15408-1:2009, Informaon technology —Security techniques — Evaluaon
criteria for IT security — Part 1: Introducon and general model, April 2017. hps://
www.commoncriteriaportal.org/ﬁles/ccﬁles/CCPART1V3.1R5.pdf.
[ISO 15408-2] Internaonal Organizaon for Standardizaon/Internaonal Electrotechnical Commission
15408-2:2008, Informaon technology —Security techniques — Evaluaon criteria
for IT security — Part 2: Security funconal requirements, April 2017. hps://
www.commoncriteriaportal.org/ﬁles/ccﬁles/CCPART2V3.1R5.pdf.
[ISO 15408-3] Internaonal Organizaon for Standardizaon/Internaonal Electrotechnical Commission
15408-3:2008, Informaon technology—Security techniques — Evaluaon criteria
for IT security — Part 3: Security assurance requirements, April 2017. hps://
www.commoncriteriaportal.org/ﬁles/ccﬁles/CCPART3V3.1R5.pdf.
[ISO 20243] Internaonal Organizaon for Standardizaon/Internaonal Electrotechnical Commission
20243-1:2018, Informaon technology — Open Trusted Technology ProviderTM Standard
(O-TTPS) — Migang maliciously tainted and counterfeit products — Part 1: Requirements
and recommendaons, February 2018. hps://www.iso.org/standard/74399.html.
This document is produced from OSCAL source data
REFERENCES PAGE 369NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
[ISO 27036] Internaonal Organizaon for Standardizaon/Internaonal Electrotechnical Commission
27036-1:2014, Informaon technology—Security techniques—Informaon security for
supplier relaonships, Part 1: Overview and concepts, April 2014. hps://www.iso.org/
standard/59648.html.
[ISO 29147] Internaonal Organizaon for Standardizaon/Internaonal Electrotechnical Commission
29147:2018, Informaon technology—Security techniques—Vulnerability disclosure,
October 2018. hps://www.iso.org/standard/72311.html.
[ISO 29148] Internaonal Organizaon for Standardizaon/Internaonal Electrotechnical Commission/
Instute of Electrical and Electronics Engineers (ISO/IEC/IEEE) 29148:2018, Systems and
soware engineering—Life cycle processes—Requirements engineering, November 2018.
hps://www.iso.org/standard/72089.html.
[NARA CUI] Naonal Archives and Records Administraon, Controlled Unclassiﬁed Informaon (CUI)
Registry. hps://www.archives.gov/cui.
[NCPR] Naonal Instute of Standards and Technology (2020) Naonal Checklist Program
Repository. Available at. hps://nvd.nist.gov/ncp/repository.
[NIAP CCEVS] Naonal Informaon Assurance Partnership, Common Criteria Evaluaon and Validaon
Scheme. hps://www.niap-ccevs.org.
[NITP12] Presidenal Memorandum for the Heads of Execuve Departments and Agencies,
Naonal Insider Threat Policy and Minimum Standards for Execuve Branch Insider
Threat Programs, November 2012. hps://obamawhitehouse.archives.gov/the-press-
oﬃce/2012/11/21/presidenal-memorandum-naonal-insider-threat-policy-and-
minimum-stand.
[NSA CSFC] Naonal Security Agency, Commercial Soluons for Classiﬁed Program (CSfC). hps://
www.nsa.gov/resources/everyone/csfc.
[NSA MEDIA] Naonal Security Agency, Media Destrucon Guidance. hps://www.nsa.gov/resources/
everyone/media-destrucon.
[ODNI CTF] Oﬃce of the Director of Naonal Intelligence (ODNI) Cyber Threat Framework. hps://
www.dni.gov/index.php/cyber-threat-framework.
[ODNI NITP] Oﬃce of the Director Naonal Intelligence, Naonal Insider Threat Policy . hps://
www.dni.gov/ﬁles/NCSC/documents/ni/Naonal_Insider_Threat_Policy.pdf.
[OMB A-108] Oﬃce of Management and Budget Memorandum Circular A-108, Federal Agency
Responsibilies for Review, Reporng, and Publicaon under the Privacy Act, December
2016. hps://www.whitehouse.gov/sites/whitehouse.gov/ﬁles/omb/circulars/A108/
omb_circular_a-108.pdf.
[OMB A-130] Oﬃce of Management and Budget Memorandum Circular A-130, Managing Informaon as
a Strategic Resource, July 2016. hps://www.whitehouse.gov/sites/whitehouse.gov/ﬁles/
omb/circulars/A130/a130revised.pdf.
[OMB M-03-22] Oﬃce of Management and Budget Memorandum M-03-22, OMB Guidance for
Implemenng the Privacy Provisions of the E-Government Act of 2002, September
2003.hps://www.whitehouse.gov/sites/whitehouse.gov/ﬁles/omb/memoranda/2003/
m03_22.pdf . hps://www.whitehouse.gov/sites/whitehouse.gov/ﬁles/omb/
memoranda/2003/m03_22.pdf.
[OMB M-08-05] Oﬃce of Management and Budget Memorandum M-08-05, Implementaon of Trusted
Internet Connecons (TIC), November 2007. hps://obamawhitehouse.archives.gov/sites/
default/ﬁles/omb/assets/omb/memoranda/fy2008/m08-05.pdf.
This document is produced from OSCAL source data
REFERENCES PAGE 370NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
[OMB M-17-06] Oﬃce of Management and Budget Memorandum M-17-06, Policies for Federal Agency
Public Websites and Digital Services, November 2016. hps://www.whitehouse.gov/sites/
whitehouse.gov/ﬁles/omb/memoranda/2017/m-17-06.pdf.
[OMB M-17-12] Oﬃce of Management and Budget Memorandum M-17-12, Preparing for and
Responding to a Breach of Personally Idenﬁable Informaon, January 2017.
hps://obamawhitehouse.archives.gov/sites/default/ﬁles/omb/memoranda/2017/
m-17-12_0.pdf.
[OMB M-17-25] Oﬃce of Management and Budget Memorandum M-17-25, Reporng Guidance for
Execuve Order on Strengthening the Cybersecurity of Federal Networks and Crical
Infrastructure, May 2017. hps://www.whitehouse.gov/sites/whitehouse.gov/ﬁles/omb/
memoranda/2017/M-17-25.pdf.
[OMB M-19-15] Oﬃce of Management and Budget Memorandum M-19-15, Improving Implementaon
of the Informaon Quality Act, April 2019. hps://www.whitehouse.gov/wp-content/
uploads/2019/04/M-19-15.pdf.
[OMB M-19-23] Oﬃce of Management and Budget Memorandum M-19-23, Phase 1 Implementaon
of the Foundaons for Evidence-Based Policymaking Act of 2018: Learning Agendas,
Personnel, and Planning Guidance, July 2019. hps://www.whitehouse.gov/wp-content/
uploads/2019/07/M-19-23.pdf.
[PRIVACT] Privacy Act (P.L. 93-579), December 1974. hps://www.govinfo.gov/content/pkg/
STATUTE-88/pdf/STATUTE-88-Pg1896.pdf.
[SP 800-100] Bowen P, Hash J, Wilson M (2006) Informaon Security Handbook: A Guide for Managers.
(Naonal Instute of Standards and Technology, Gaithersburg, MD), NIST Special
Publicaon (SP) 800-100, Includes updates as of March 7, 2007. hps://doi.org/10.6028/
NIST.SP.800-100.
[SP 800-101] Ayers RP, Brothers S, Jansen W (2014) Guidelines on Mobile Device Forensics. (Naonal
Instute of Standards and Technology, Gaithersburg, MD), NIST Special Publicaon (SP)
800-101, Rev. 1. hps://doi.org/10.6028/NIST.SP.800-101r1.
[SP 800-111] Scarfone KA, Souppaya MP, Sexton M (2007) Guide to Storage Encrypon Technologies for
End User Devices. (Naonal Instute of Standards and Technology, Gaithersburg, MD), NIST
Special Publicaon (SP) 800-111. hps://doi.org/10.6028/NIST.SP.800-111.
[SP 800-113] Frankel SE, Hoﬀman P, Orebaugh AD, Park R (2008) Guide to SSL VPNs. (Naonal Instute
of Standards and Technology, Gaithersburg, MD), NIST Special Publicaon (SP) 800-113.
hps://doi.org/10.6028/NIST.SP.800-113.
[SP 800-114] Souppaya MP, Scarfone KA (2016) User's Guide to Telework and Bring Your Own Device
(BYOD) Security. (Naonal Instute of Standards and Technology, Gaithersburg, MD), NIST
Special Publicaon (SP) 800-114, Rev. 1. hps://doi.org/10.6028/NIST.SP.800-114r1.
[SP 800-115] Scarfone KA, Souppaya MP, Cody A, Orebaugh AD (2008) Technical Guide to Informaon
Security Tesng and Assessment. (Naonal Instute of Standards and Technology,
Gaithersburg, MD), NIST Special Publicaon (SP) 800-115. hps://doi.org/10.6028/
NIST.SP.800-115.
[SP 800-116] Ferraiolo H, Mehta KL, Ghadiali N, Mohler J, Johnson V, Brady S (2018) A Recommendaon
for the Use of PIV Credenals in Physical Access Control Systems (PACS). (Naonal Instute
of Standards and Technology, Gaithersburg, MD), NIST Special Publicaon (SP) 800-116,
Rev. 1. hps://doi.org/10.6028/NIST.SP.800-116r1.
This document is produced from OSCAL source data
REFERENCES PAGE 371NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
[SP 800-12] Nieles M, Pillieri VY, Dempsey KL (2017) An Introducon to Informaon Security. (Naonal
Instute of Standards and Technology, Gaithersburg, MD), NIST Special Publicaon (SP)
800-12, Rev. 1. hps://doi.org/10.6028/NIST.SP.800-12r1.
[SP 800-121] Padgee J, Bahr J, Holtmann M, Batra M, Chen L, Smithbey R, Scarfone KA (2017) Guide
to Bluetooth Security. (Naonal Instute of Standards and Technology, Gaithersburg, MD),
NIST Special Publicaon (SP) 800-121, Rev. 2. hps://doi.org/10.6028/NIST.SP.800-121r2.
[SP 800-124] Souppaya MP, Scarfone KA (2013) Guidelines for Managing the Security of Mobile Devices
in the Enterprise. (Naonal Instute of Standards and Technology, Gaithersburg, MD), NIST
Special Publicaon (SP) 800-124, Rev. 1. hps://doi.org/10.6028/NIST.SP.800-124r1.
[SP 800-125B] Chandramouli R (2016) Secure Virtual Network Conﬁguraon for Virtual Machine (VM)
Protecon. (Naonal Instute of Standards and Technology, Gaithersburg, MD), NIST
Special Publicaon (SP) 800-125B. hps://doi.org/10.6028/NIST.SP.800-125B.
[SP 800-126] Waltermire DA, Quinn SD, Booth H, III, Scarfone KA, Prisaca D (2018) The Technical
Speciﬁcaon for the Security Content Automaon Protocol (SCAP): SCAP Version 1.3.
(Naonal Instute of Standards and Technology, Gaithersburg, MD), NIST Special
Publicaon (SP) 800-126, Rev. 3. hps://doi.org/10.6028/NIST.SP.800-126r3.
[SP 800-128] Johnson LA, Dempsey KL, Ross RS, Gupta S, Bailey D (2011) Guide for Security-Focused
Conﬁguraon Management of Informaon Systems. (Naonal Instute of Standards and
Technology, Gaithersburg, MD), NIST Special Publicaon (SP) 800-128, Includes updates as
of October 10, 2019. hps://doi.org/10.6028/NIST.SP.800-128.
[SP 800-130] Barker EB, Smid ME, Branstad DK, Chokhani S (2013) A Framework for Designing
Cryptographic Key Management Systems. (Naonal Instute of Standards and Technology,
Gaithersburg, MD), NIST Special Publicaon (SP) 800-130. hps://doi.org/10.6028/
NIST.SP.800-130.
[SP 800-137] Dempsey KL, Chawla NS, Johnson LA, Johnston R, Jones AC, Orebaugh AD, Scholl MA, Sne
KM (2011) Informaon Security Connuous Monitoring (ISCM) for Federal Informaon
Systems and Organizaons. (Naonal Instute of Standards and Technology, Gaithersburg,
MD), NIST Special Publicaon (SP) 800-137. hps://doi.org/10.6028/NIST.SP.800-137.
[SP 800-137A] Dempsey KL, Pillieri VY, Baer C, Niemeyer R, Rudman R, Urban S (2020) Assessing
Informaon Security Connuous Monitoring (ISCM) Programs: Developing an ISCM
Program Assessment. (Naonal Instute of Standards and Technology, Gaithersburg, MD),
NIST Special Publicaon (SP) 800-137A. hps://doi.org/10.6028/NIST.SP.800-137A.
[SP 800-147] Cooper DA, Polk T, Regenscheid AR, Souppaya MP (2011) BIOS Protecon Guidelines.
(Naonal Instute of Standards and Technology, Gaithersburg, MD), NIST Special
Publicaon (SP) 800-147. hps://doi.org/10.6028/NIST.SP.800-147.
[SP 800-150] Johnson CS, Waltermire DA, Badger ML, Skorupka C, Snyder J (2016) Guide to Cyber Threat
Informaon Sharing. (Naonal Instute of Standards and Technology, Gaithersburg, MD),
NIST Special Publicaon (SP) 800-150. hps://doi.org/10.6028/NIST.SP.800-150.
[SP 800-152] Barker EB, Branstad DK, Smid ME (2015) A Proﬁle for U.S. Federal Cryptographic
Key Management Systems (CKMS). (Naonal Instute of Standards and Technology,
Gaithersburg, MD), NIST Special Publicaon (SP) 800-152. hps://doi.org/10.6028/
NIST.SP.800-152.
[SP 800-154] Souppaya MP, Scarfone KA (2016) Guide to Data-Centric System Threat Modeling. (Naonal
Instute of Standards and Technology, Gaithersburg, MD), Dra NIST Special Publicaon
(SP) 800-154. hps://csrc.nist.gov/publicaons/detail/sp/800-154/dra.
This document is produced from OSCAL source data
REFERENCES PAGE 372NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
[SP 800-156] Ferraiolo H, Chandramouli R, Mehta KL, Mohler J, Skordinski S, Brady S (2016)
Representaon of PIV Chain-of-Trust for Import and Export. (Naonal Instute of Standards
and Technology, Gaithersburg, MD), NIST Special Publicaon (SP) 800-156. hps://
doi.org/10.6028/NIST.SP.800-156.
[SP 800-160-1] Ross RS, Oren JC, McEvilley M (2016) Systems Security Engineering: Consideraons for a
Muldisciplinary Approach in the Engineering of Trustworthy Secure Systems. (Naonal
Instute of Standards and Technology, Gaithersburg, MD), NIST Special Publicaon
(SP) 800-160, Vol. 1, Includes updates as of March 21, 2018. hps://doi.org/10.6028/
NIST.SP.800-160v1.
[SP 800-160-2] Ross RS, Pillieri VY, Graubart R, Bodeau D, McQuaid R (2019) Developing Cyber Resilient
Systems: A Systems Security Engineering Approach. (Naonal Instute of Standards and
Technology, Gaithersburg, MD), NIST Special Publicaon (SP) 800-160, Vol. 2. hps://
doi.org/10.6028/NIST.SP.800-160v2.
[SP 800-161] Boyens JM, Paulsen C, Moorthy R, Bartol N (2015) Supply Chain Risk Management Pracces
for Federal Informaon Systems and Organizaons. (Naonal Instute of Standards
and Technology, Gaithersburg, MD), NIST Special Publicaon (SP) 800-161. hps://
doi.org/10.6028/NIST.SP.800-161.
[SP 800-162] Hu VC, Ferraiolo DF, Kuhn R, Schnitzer A, Sandlin K, Miller R, Scarfone KA (2014) Guide to
Aribute Based Access Control (ABAC) Deﬁnion and Consideraons. (Naonal Instute
of Standards and Technology, Gaithersburg, MD), NIST Special Publicaon (SP) 800-162,
Includes updates as of August 2, 2019. hps://doi.org/10.6028/NIST.SP.800-162.
[SP 800-166] Cooper DA, Ferraiolo H, Chandramouli R, Ghadiali N, Mohler J, Brady S (2016) Derived
PIV Applicaon and Data Model Test Guidelines. (Naonal Instute of Standards
and Technology, Gaithersburg, MD), NIST Special Publicaon (SP) 800-166. hps://
doi.org/10.6028/NIST.SP.800-166.
[SP 800-167] Sedgewick A, Souppaya MP, Scarfone KA (2015) Guide to Applicaon Whitelisng. (Naonal
Instute of Standards and Technology, Gaithersburg, MD), NIST Special Publicaon (SP)
800-167. hps://doi.org/10.6028/NIST.SP.800-167.
[SP 800-171] Ross RS, Pillieri VY, Dempsey KL, Riddle M, Guissanie G (2020) Protecng Controlled
Unclassiﬁed Informaon in Nonfederal Systems and Organizaons. (Naonal Instute of
Standards and Technology, Gaithersburg, MD), NIST Special Publicaon (SP) 800-171, Rev.
2. hps://doi.org/10.6028/NIST.SP.800-171r2.
[SP 800-172] Ross RS, Pillieri VY, Graubart RD, Guissanie G, Wagner R, Bodeau D (2020) Enhanced
Security Requirements for Protecng Controlled Unclassiﬁed Informaon: A Supplement
to NIST Special Publicaon 800-171 (Final Public Dra). (Naonal Instute of Standards
and Technology, Gaithersburg, MD), NIST Special Publicaon (SP) 800-172. hps://
doi.org/10.6028/NIST.SP.800-172-dra.
[SP 800-177] Rose SW, Nighngale S, Garﬁnkel SL, Chandramouli R (2019) Trustworthy Email. (Naonal
Instute of Standards and Technology, Gaithersburg, MD), NIST Special Publicaon (SP)
800-177, Rev. 1. hps://doi.org/10.6028/NIST.SP.800-177r1.
[SP 800-178] Ferraiolo DF, Hu VC, Kuhn R, Chandramouli R (2016) A Comparison of Aribute Based
Access Control (ABAC) Standards for Data Service Applicaons: Extensible Access Control
Markup Language (XACML) and Next Generaon Access Control (NGAC). (Naonal Instute
of Standards and Technology, Gaithersburg, MD), NIST Special Publicaon (SP) 800-178.
hps://doi.org/10.6028/NIST.SP.800-178.
This document is produced from OSCAL source data
REFERENCES PAGE 373NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
[SP 800-18] Swanson MA, Hash J, Bowen P (2006) Guide for Developing Security Plans for Federal
Informaon Systems. (Naonal Instute of Standards and Technology, Gaithersburg, MD),
NIST Special Publicaon (SP) 800-18, Rev. 1. hps://doi.org/10.6028/NIST.SP.800-18r1.
[SP 800-181] Petersen R, Santos D, Smith MC, Wetzel KA, Wie G (2020) Workforce Framework
for Cybersecurity (NICE Framework). (Naonal Instute of Standards and Technology,
Gaithersburg, MD), NIST Special Publicaon (SP) 800-181, Rev. 1. hps://doi.org/10.6028/
NIST.SP.800-181r1.
[SP 800-184] Bartock M, Scarfone KA, Smith MC, Wie GA, Cichonski JA, Souppaya MP (2016) Guide
for Cybersecurity Event Recovery. (Naonal Instute of Standards and Technology,
Gaithersburg, MD), NIST Special Publicaon (SP) 800-184. hps://doi.org/10.6028/
NIST.SP.800-184.
[SP 800-188] Garﬁnkel S (2016) De-Idenfying Government Datasets. (Naonal Instute of Standards
and Technology, Gaithersburg, MD), Second Dra NIST Special Publicaon (SP) 800-188.
hps://csrc.nist.gov/publicaons/detail/sp/800-188/dra.
[SP 800-189] Sriram K, Montgomery D (2019) Resilient Interdomain Traﬃc Exchange: BGP Security and
DDoS Migaon. (Naonal Instute of Standards and Technology, Gaithersburg, MD), NIST
Special Publicaon (SP) 800-189. hps://doi.org/10.6028/NIST.SP.800-189.
[SP 800-192] Yaga DJ, Kuhn R, Hu VC (2017) Veriﬁcaon and Test Methods for Access Control Policies/
Models. (Naonal Instute of Standards and Technology, Gaithersburg, MD), NIST Special
Publicaon (SP) 800-192. hps://doi.org/10.6028/NIST.SP.800-192.
[SP 800-28] Jansen W, Winograd T, Scarfone KA (2008) Guidelines on Acve Content and Mobile
Code. (Naonal Instute of Standards and Technology, Gaithersburg, MD), NIST Special
Publicaon (SP) 800-28, Version 2. hps://doi.org/10.6028/NIST.SP.800-28ver2.
[SP 800-30] Joint Task Force Transformaon Iniave (2012) Guide for Conducng Risk Assessments.
(Naonal Instute of Standards and Technology, Gaithersburg, MD), NIST Special
Publicaon (SP) 800-30, Rev. 1. hps://doi.org/10.6028/NIST.SP.800-30r1.
[SP 800-32] Kuhn R, Hu VC, Polk T, Chang S-J (2001) Introducon to Public Key Technology and the
Federal PKI Infrastructure. (Naonal Instute of Standards and Technology, Gaithersburg,
MD), NIST Special Publicaon (SP) 800-32. hps://doi.org/10.6028/NIST.SP.800-32.
[SP 800-34] Swanson MA, Bowen P, Phillips AW, Gallup D, Lynes D (2010) Conngency Planning
Guide for Federal Informaon Systems. (Naonal Instute of Standards and Technology,
Gaithersburg, MD), NIST Special Publicaon (SP) 800-34, Rev. 1, Includes updates as of
November 11, 2010. hps://doi.org/10.6028/NIST.SP.800-34r1.
[SP 800-35] Grance T, Hash J, Stevens M, O'Neal K, Bartol N (2003) Guide to Informaon Technology
Security Services. (Naonal Instute of Standards and Technology, Gaithersburg, MD), NIST
Special Publicaon (SP) 800-35. hps://doi.org/10.6028/NIST.SP.800-35.
[SP 800-37] Joint Task Force (2018) Risk Management Framework for Informaon Systems and
Organizaons: A System Life Cycle Approach for Security and Privacy. (Naonal Instute of
Standards and Technology, Gaithersburg, MD), NIST Special Publicaon (SP) 800-37, Rev. 2.
hps://doi.org/10.6028/NIST.SP.800-37r2.
[SP 800-39] Joint Task Force Transformaon Iniave (2011) Managing Informaon Security Risk:
Organizaon, Mission, and Informaon System View. (Naonal Instute of Standards
and Technology, Gaithersburg, MD), NIST Special Publicaon (SP) 800-39. hps://
doi.org/10.6028/NIST.SP.800-39.
This document is produced from OSCAL source data
REFERENCES PAGE 374NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
[SP 800-40] Souppaya MP, Scarfone KA (2013) Guide to Enterprise Patch Management Technologies.
(Naonal Instute of Standards and Technology, Gaithersburg, MD), NIST Special
Publicaon (SP) 800-40, Rev. 3. hps://doi.org/10.6028/NIST.SP.800-40r3.
[SP 800-41] Scarfone KA, Hoﬀman P (2009) Guidelines on Firewalls and Firewall Policy. (Naonal
Instute of Standards and Technology, Gaithersburg, MD), NIST Special Publicaon (SP)
800-41, Rev. 1. hps://doi.org/10.6028/NIST.SP.800-41r1.
[SP 800-45] Tracy MC, Jansen W, Scarfone KA, Buerﬁeld J (2007) Guidelines on Electronic Mail
Security. (Naonal Instute of Standards and Technology, Gaithersburg, MD), NIST Special
Publicaon (SP) 800-45, Version 2. hps://doi.org/10.6028/NIST.SP.800-45ver2.
[SP 800-46] Souppaya MP, Scarfone KA (2016) Guide to Enterprise Telework, Remote Access, and
Bring Your Own Device (BYOD) Security. (Naonal Instute of Standards and Technology,
Gaithersburg, MD), NIST Special Publicaon (SP) 800-46, Rev. 2. hps://doi.org/10.6028/
NIST.SP.800-46r2.
[SP 800-47] Grance T, Hash J, Peck S, Smith J, Korow-Diks K (2002) Security Guide for Interconnecng
Informaon Technology Systems. (Naonal Instute of Standards and Technology,
Gaithersburg, MD), NIST Special Publicaon (SP) 800-47. hps://doi.org/10.6028/
NIST.SP.800-47.
[SP 800-50] Wilson M, Hash J (2003) Building an Informaon Technology Security Awareness and
Training Program. (Naonal Instute of Standards and Technology, Gaithersburg, MD), NIST
Special Publicaon (SP) 800-50. hps://doi.org/10.6028/NIST.SP.800-50.
[SP 800-52] McKay KA, Cooper DA (2019) Guidelines for the Selecon, Conﬁguraon, and Use of
Transport Layer Security (TLS) Implementaons. (Naonal Instute of Standards and
Technology, Gaithersburg, MD), NIST Special Publicaon (SP) 800-52, Rev. 2. hps://
doi.org/10.6028/NIST.SP.800-52r2.
[SP 800-53A] Joint Task Force Transformaon Iniave (2014) Assessing Security and Privacy Controls
in Federal Informaon Systems and Organizaons: Building Eﬀecve Assessment Plans.
(Naonal Instute of Standards and Technology, Gaithersburg, MD), NIST Special
Publicaon (SP) 800-53A, Rev. 4, Includes updates as of December 18, 2014. hps://
doi.org/10.6028/NIST.SP.800-53Ar4.
[SP 800-53B] Joint Task Force (2020) Control Baselines and Tailoring Guidance for Federal Informaon
Systems and Organizaons. (Naonal Instute of Standards and Technology, Gaithersburg,
MD), NIST Special Publicaon (SP) 800-53B. hps://doi.org/10.6028/NIST.SP.800-53B.
[SP 800-55] Chew E, Swanson MA, Sne KM, Bartol N, Brown A, Robinson W (2008) Performance
Measurement Guide for Informaon Security. (Naonal Instute of Standards and
Technology, Gaithersburg, MD), NIST Special Publicaon (SP) 800-55, Rev. 1. hps://
doi.org/10.6028/NIST.SP.800-55r1.
[SP 800-56A] Barker EB, Chen L, Roginsky A, Vassilev A, Davis R (2018) Recommendaon for Pair-Wise
Key-Establishment Schemes Using Discrete Logarithm Cryptography. (Naonal Instute of
Standards and Technology, Gaithersburg, MD), NIST Special Publicaon (SP) 800-56A, Rev.
3. hps://doi.org/10.6028/NIST.SP.800-56Ar3.
[SP 800-56B] Barker EB, Chen L, Roginsky A, Vassilev A, Davis R, Simon S (2019) Recommendaon for
Pair-Wise Key-Establishment Using Integer Factorizaon Cryptography. (Naonal Instute
of Standards and Technology, Gaithersburg, MD), NIST Special Publicaon (SP) 800-56B,
Rev. 2. hps://doi.org/10.6028/NIST.SP.800-56Br2.
This document is produced from OSCAL source data
REFERENCES PAGE 375NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
[SP 800-56C] Barker EB, Chen L, Davis R (2020) Recommendaon for Key-Derivaon Methods
in Key-Establishment Schemes. (Naonal Instute of Standards and Technology,
Gaithersburg, MD), NIST Special Publicaon (SP) 800-56C, Rev. 2. hps://doi.org/10.6028/
NIST.SP.800-56Cr2.
[SP 800-57-1] Barker EB (2020) Recommendaon for Key Management: Part 1 – General. (Naonal
Instute of Standards and Technology, Gaithersburg, MD), NIST Special Publicaon (SP)
800-57 Part 1, Rev. 5. hps://doi.org/10.6028/NIST.SP.800-57pt1r5.
[SP 800-57-2] Barker EB, Barker WC (2019) Recommendaon for Key Management: Part 2 – Best
Pracces for Key Management Organizaons. (Naonal Instute of Standards and
Technology, Gaithersburg, MD), NIST Special Publicaon (SP) 800-57 Part 2, Rev. 1. hps://
doi.org/10.6028/NIST.SP.800-57pt2r1.
[SP 800-57-3] Barker EB, Dang QH (2015) Recommendaon for Key Management, Part 3: Applicaon-
Speciﬁc Key Management Guidance. (Naonal Instute of Standards and Technology,
Gaithersburg, MD), NIST Special Publicaon (SP) 800-57 Part 3, Rev. 1. hps://
doi.org/10.6028/NIST.SP.800-57pt3r1.
[SP 800-60-1] Sne KM, Kissel RL, Barker WC, Fahlsing J, Gulick J (2008) Guide for Mapping Types
of Informaon and Informaon Systems to Security Categories. (Naonal Instute of
Standards and Technology, Gaithersburg, MD), NIST Special Publicaon (SP) 800-60, Vol. 1,
Rev. 1. hps://doi.org/10.6028/NIST.SP.800-60v1r1.
[SP 800-60-2] Sne KM, Kissel RL, Barker WC, Lee A, Fahlsing J (2008) Guide for Mapping Types of
Informaon and Informaon Systems to Security Categories: Appendices. (Naonal
Instute of Standards and Technology, Gaithersburg, MD), NIST Special Publicaon (SP)
800-60, Vol. 2, Rev. 1. hps://doi.org/10.6028/NIST.SP.800-60v2r1.
[SP 800-61] Cichonski PR, Millar T, Grance T, Scarfone KA (2012) Computer Security Incident Handling
Guide. (Naonal Instute of Standards and Technology, Gaithersburg, MD), NIST Special
Publicaon (SP) 800-61, Rev. 2. hps://doi.org/10.6028/NIST.SP.800-61r2.
[SP 800-63-3] Grassi PA, Garcia ME, Fenton JL (2017) Digital Identy Guidelines. (Naonal Instute of
Standards and Technology, Gaithersburg, MD), NIST Special Publicaon (SP) 800-63-3,
Includes updates as of March 2, 2020. hps://doi.org/10.6028/NIST.SP.800-63-3.
[SP 800-63A] Grassi PA, Fenton JL, Leovitz NB, Danker JM, Choong Y-Y, Greene KK, Theofanos MF
(2017) Digital Identy Guidelines: Enrollment and Identy Prooﬁng. (Naonal Instute
of Standards and Technology, Gaithersburg, MD), NIST Special Publicaon (SP) 800-63A,
Includes updates as of March 2, 2020. hps://doi.org/10.6028/NIST.SP.800-63a.
[SP 800-70] Quinn SD, Souppaya MP, Cook MR, Scarfone KA (2018) Naonal Checklist Program for IT
Products: Guidelines for Checklist Users and Developers. (Naonal Instute of Standards
and Technology, Gaithersburg, MD), NIST Special Publicaon (SP) 800-70, Rev. 4. hps://
doi.org/10.6028/NIST.SP.800-70r4.
[SP 800-73-4] Cooper DA, Ferraiolo H, Mehta KL, Francomacaro S, Chandramouli R, Mohler J (2015)
Interfaces for Personal Identy Veriﬁcaon. (Naonal Instute of Standards and
Technology, Gaithersburg, MD), NIST Special Publicaon (SP) 800-73-4, Includes updates as
of February 8, 2016. hps://doi.org/10.6028/NIST.SP.800-73-4.
[SP 800-76-2] Grother PJ, Salamon WJ, Chandramouli R (2013) Biometric Speciﬁcaons for Personal
Identy Veriﬁcaon. (Naonal Instute of Standards and Technology, Gaithersburg, MD),
NIST Special Publicaon (SP) 800-76-2. hps://doi.org/10.6028/NIST.SP.800-76-2.
This document is produced from OSCAL source data
REFERENCES PAGE 376NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
[SP 800-77] Barker EB, Dang QH, Frankel SE, Scarfone KA, Wouters P (2020) Guide to IPsec VPNs.
(Naonal Instute of Standards and Technology, Gaithersburg, MD), NIST Special
Publicaon (SP) 800-77, Rev. 1. hps://doi.org/10.6028/NIST.SP.800-77r1.
[SP 800-78-4] Polk T, Dodson DF, Burr WE, Ferraiolo H, Cooper DA (2015) Cryptographic Algorithms and
Key Sizes for Personal Identy Veriﬁcaon. (Naonal Instute of Standards and Technology,
Gaithersburg, MD), NIST Special Publicaon (SP) 800-78-4. hps://doi.org/10.6028/
NIST.SP.800-78-4.
[SP 800-79-2] Ferraiolo H, Chandramouli R, Ghadiali N, Mohler J, Shorter S (2015) Guidelines for the
Authorizaon of Personal Identy Veriﬁcaon Card Issuers (PCI) and Derived PIV Credenal
Issuers (DPCI). (Naonal Instute of Standards and Technology, Gaithersburg, MD), NIST
Special Publicaon (SP) 800-79-2. hps://doi.org/10.6028/NIST.SP.800-79-2.
[SP 800-81-2] Chandramouli R, Rose SW (2013) Secure Domain Name System (DNS) Deployment
Guide. (Naonal Instute of Standards and Technology, Gaithersburg, MD), NIST Special
Publicaon (SP) 800-81-2. hps://doi.org/10.6028/NIST.SP.800-81-2.
[SP 800-83] Souppaya MP, Scarfone KA (2013) Guide to Malware Incident Prevenon and Handling for
Desktops and Laptops. (Naonal Instute of Standards and Technology, Gaithersburg, MD),
NIST Special Publicaon (SP) 800-83, Rev. 1. hps://doi.org/10.6028/NIST.SP.800-83r1.
[SP 800-84] Grance T, Nolan T, Burke K, Dudley R, White G, Good T (2006) Guide to Test, Training,
and Exercise Programs for IT Plans and Capabilies. (Naonal Instute of Standards
and Technology, Gaithersburg, MD), NIST Special Publicaon (SP) 800-84. hps://
doi.org/10.6028/NIST.SP.800-84.
[SP 800-86] Kent K, Chevalier S, Grance T, Dang H (2006) Guide to Integrang Forensic Techniques into
Incident Response. (Naonal Instute of Standards and Technology, Gaithersburg, MD),
NIST Special Publicaon (SP) 800-86. hps://doi.org/10.6028/NIST.SP.800-86.
[SP 800-88] Kissel RL, Regenscheid AR, Scholl MA, Sne KM (2014) Guidelines for Media Sanizaon.
(Naonal Instute of Standards and Technology, Gaithersburg, MD), NIST Special
Publicaon (SP) 800-88, Rev. 1. hps://doi.org/10.6028/NIST.SP.800-88r1.
[SP 800-92] Kent K, Souppaya MP (2006) Guide to Computer Security Log Management. (Naonal
Instute of Standards and Technology, Gaithersburg, MD), NIST Special Publicaon (SP)
800-92. hps://doi.org/10.6028/NIST.SP.800-92.
[SP 800-94] Scarfone KA, Mell PM (2007) Guide to Intrusion Detecon and Prevenon Systems
(IDPS). (Naonal Instute of Standards and Technology, Gaithersburg, MD), NIST Special
Publicaon (SP) 800-94. hps://doi.org/10.6028/NIST.SP.800-94.
[SP 800-95] Singhal A, Winograd T, Scarfone KA (2007) Guide to Secure Web Services. (Naonal
Instute of Standards and Technology, Gaithersburg, MD), NIST Special Publicaon (SP)
800-95. hps://doi.org/10.6028/NIST.SP.800-95.
[SP 800-97] Frankel SE, Eydt B, Owens L, Scarfone KA (2007) Establishing Wireless Robust Security
Networks: A Guide to IEEE 802.11i. (Naonal Instute of Standards and Technology,
Gaithersburg, MD), NIST Special Publicaon (SP) 800-97. hps://doi.org/10.6028/
NIST.SP.800-97.
[USC 2901] United States Code, 2008 Edion, Title 44 - Public Prinng and Documents, Chapters 29, 31,
and 33, January 2012. hps://www.govinfo.gov/content/pkg/USCODE-2011-tle44/pdf/
USCODE-2011-tle44-chap29-sec2901.pdf.
[USCERT IR] Department of Homeland Security, US-CERT Federal Incident Noﬁcaon Guidelines, April
2017. hps://us-cert.cisa.gov/incident-noﬁcaon-guidelines.
This document is produced from OSCAL source data
REFERENCES PAGE 377NIST SP 800-53 Revision 5.1 Security and Privacy Controls for Informaon Systems and Organizaons
This publicaon is available free of charge from: hps://doi.org/10.6028/NIST.SP.800-53r5
[USGCB] Naonal Instute of Standards and Technology (2020) United States Government
Conﬁguraon Baseline. Available at. hps://csrc.nist.gov/projects/united-states-
government-conﬁguraon-baseline.
This document is produced from OSCAL source data
REFERENCES PAGE 378